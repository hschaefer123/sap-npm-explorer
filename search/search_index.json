{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Packages Overview \u00b6 Welcome to the Collection of API documentation from currently available npm packages from SAP . This documentation is automatically generated to easily allow a central access for the ease of reference. SAP Announcement \u00b6 As of June 10th, 2020 all public SAP Node.js modules from the SAP NPM registry will become part of the official NPM registry , as well as future public SAP Node.js modules will be published there. The SAP NPM registry will continue to exist for the time being with the published content but the recommendation for developers is to switch to using the official NPM regirstry also for all public SAP Node.js modules. Cloud Application Programming Model (CAP) for SCP \u00b6 The SAP Cloud Application Programming Model is an open and opinionated, framework of languages, libraries, and tools for building enterprise-grade services and applications. It guides developers through proven best practices and a great wealth of out-of-the-box solutions for recurring tasks. A good starting point is DJ Adams start here blog. Package Description audit-logging Provides audit logging functionalities for Node.js applications. cds The API package for the SAP Cloud Application Programming Model (CAP). xsenv Utility for easily reading application configurations for bound services and certificates in the SAP Cloud Platform Cloud Foundry environment, SAP XS advanced model and Kubernetes (K8S). xssec XS Advanced Authentication Primer. Fiori Application Programming Model for Cloud Foundry \u00b6 A good starting point ist Sergio Rozenszajn blog . Package Description approuter Node.js based application router. html5-app-deployer Handles the upload of the HTML5 applications content to the HTML5 application repository. node-jwt JWT validation library for Node.js site-content-deployer SAP site deployer for independent mta SAP Cloud SDK for JavaScript \u00b6 The SAP Cloud SDK is a one-stop shop for developing and extending SAP applications in a Cloud and is als available as SAP Cloud SDK for JavaScript . Package Description cloud-sdk-core This package contains the core functionality for the Virtual Data Model (VDM) as well as the Cloud Platform abstractions. cloud-sdk-generator Generate your own service module using a service specification (.edmx file). cloud-sdk-vdm-xxx Prebuild OData Virtual Data Models (VDM) for SAP S/4HANA Cloud.","title":"Packages Overview"},{"location":"#packages-overview","text":"Welcome to the Collection of API documentation from currently available npm packages from SAP . This documentation is automatically generated to easily allow a central access for the ease of reference.","title":"Packages Overview"},{"location":"#sap-announcement","text":"As of June 10th, 2020 all public SAP Node.js modules from the SAP NPM registry will become part of the official NPM registry , as well as future public SAP Node.js modules will be published there. The SAP NPM registry will continue to exist for the time being with the published content but the recommendation for developers is to switch to using the official NPM regirstry also for all public SAP Node.js modules.","title":"SAP Announcement"},{"location":"#cloud-application-programming-model-cap-for-scp","text":"The SAP Cloud Application Programming Model is an open and opinionated, framework of languages, libraries, and tools for building enterprise-grade services and applications. It guides developers through proven best practices and a great wealth of out-of-the-box solutions for recurring tasks. A good starting point is DJ Adams start here blog. Package Description audit-logging Provides audit logging functionalities for Node.js applications. cds The API package for the SAP Cloud Application Programming Model (CAP). xsenv Utility for easily reading application configurations for bound services and certificates in the SAP Cloud Platform Cloud Foundry environment, SAP XS advanced model and Kubernetes (K8S). xssec XS Advanced Authentication Primer.","title":"Cloud Application Programming Model (CAP) for SCP"},{"location":"#fiori-application-programming-model-for-cloud-foundry","text":"A good starting point ist Sergio Rozenszajn blog . Package Description approuter Node.js based application router. html5-app-deployer Handles the upload of the HTML5 applications content to the HTML5 application repository. node-jwt JWT validation library for Node.js site-content-deployer SAP site deployer for independent mta","title":"Fiori Application Programming Model for Cloud Foundry"},{"location":"#sap-cloud-sdk-for-javascript","text":"The SAP Cloud SDK is a one-stop shop for developing and extending SAP applications in a Cloud and is als available as SAP Cloud SDK for JavaScript . Package Description cloud-sdk-core This package contains the core functionality for the Virtual Data Model (VDM) as well as the Cloud Platform abstractions. cloud-sdk-generator Generate your own service module using a service specification (.edmx file). cloud-sdk-vdm-xxx Prebuild OData Virtual Data Models (VDM) for SAP S/4HANA Cloud.","title":"SAP Cloud SDK for JavaScript"},{"location":"apis/approuter/","text":"@sap/approuter \u00b6 Overview Deploying a business application with microservices Working directory Configurations Destinations Environment-destinations Destination-service UAA configuration Additional headers configuration Additional cookies configuration Plugins configuration Session timeout X-Frame-Options configuration Cross-Origin Routes Example routes Replacements xs-app.json configuration file welcomeFile property authenticationMethod property routes property login property logout property destinations property services property compression property pluginMetadataEndpoint property whitelistService property websockets property errorPage property Complete example of an xs-app.json configuration file Headers Forwarding Headers Hop-by-hop Headers Custom Headers Authorization Header (Beta version) CSRF Protection Connectivity SaaS Application Registration in CF How To Expose Approuter for SaaS Subscription Integration with HTML5 Application Repository Integration with Business Services Web Sockets Session Handling Session Contents Service to Application Router (Beta version) Central Logout Whitelist Service Enable the service Configuring allowed hostnames / domains Return value Scaling Sizing Guide for Application Router Configure server-side HTTPS Audit-Log Service Troubleshooting Getting Support Extending Application Router Best practices Security best practices Content-Security-Policy Overview \u00b6 When a business application consists of several different apps (microservices), the application router is used to provide a single entry point to that business application. It has the responsibility to: Dispatch requests to backend microservices (reverse proxy) Authenticate users Serve static content Let's think of the different apps (microservices) as destinations to which the incoming request will be forwarded. The rules that determine which request should be forwarded to which destination are called routes . For every destination there can be more than one route. You may read more on the concept of routes later in this document. If the backend microservices require authentication, the application router can be configured to authenticate the users and propagate the user information. Again by using routes, the application router can serve static content. The application router is designed to work in XS Advanced - Cloud Foundry and XS OnPremise Runtime. A calling component accesses a target service by means of the application router only if there is no JWT token available, for example, if a user invokes the application from a Web browser. If a JWT token is already available, for example, because the user has already been authenticated, or the calling component uses a JWT token for its own OAuth client, the calling component calls the target service directly; it does not need to use the application router. Note that the application router does not hide the backend microservices in any way. They are still directly accessible bypassing the application router. So the backend microservices must protect all their endpoints by validating the JWT token and implementing proper scope checks. Network isolation is not provided currently by the platform. Deploying a business application with microservices \u00b6 For example we can have a business application that has the following structure: +-- manifest.yml +-- manifest-op.yml | +-- microservice-1 | | +-- ... | | +-- ... | +-- microservice-2 | | +-- ... | | +-- ... | +-- web | | +-- ... | | +-- ... The manifest.yml file is used to deploy the business application on Cloud Foundry and the manifest-op.yml - on the XS OnPremise Runtime. These files should describe all the microservices for that business application. Folders are used to isolate the different microservices. Let's assume that the application router is the microservice in the web folder (every business application has its own application router). Here is how we can include the application router: Manually create the node_modules folder in the web folder. Copy and paste the folder that contains the self-contained application router into node_modules . In this example the name of that folder is @sap/approuter , see the start script in the package.json below. Check the version of the application router you just copied. Create a package.json file in web with content similar to the following and replace the version's value with the version of your application router: { \"name\" : \"hello-world-approuter\" , \"dependencies\" : { \"@sap/approuter\" : \"2.6.1\" }, \"scripts\" : { \"start\" : \"node node_modules/@sap/approuter/approuter.js\" } } In order to use the application router you don't have to write any JavaScript code. Only some configurations have to be provided in the web folder. Here is a complete example: +-- web | +-- package.json | +-- xs-app.json | +-- resources | | +-- hello-world.html | | +-- my-page.html | +-- node_modules | | +-- ... | +-- default-env.json | +-- default-services.json The web folder contains the package.json , node_modules , some configuration files used by the application router, and static resources to be served. You can read more about the configurations later in this document. By default, the application router runs on port 5000 (if started locally) or it takes the port from the PORT environment variable. Working directory \u00b6 The working directory contains configuration files that the application router needs and static resources that can be served at runtime. In the previous example , the web folder is the working directory. By default the current directory is the working directory. It is possible to configure it during start up of the application router with the following command line argument: node approuter.js -w <working-dir> Application router will abort if the working directory does not contain xs-app.json file. Configurations \u00b6 The application router makes use of the following configurations: Main configuration - this is the xs-app.json file. This file is mandatory and contains the main configurations of the application router. UAA configuration - the application router reads this configuration either from the VCAP_SERVICES environment variable (when deployed on Cloud Foundry or XS Advanced OnPremise Runtime) or from the default-services.json file (when running locally). Refer to the documentation of the @sap/xsenv package for more details. Configurations from the environment - these configurations are either read from the application router's environment (when deployed on Cloud Foundry or XS Advanced OnPremise Runtime) or from the default-env.json file (when running locally). Refer to the documentation of the @sap/xsenv package for more details. The environment variables that the application router takes into account are: Configuration Environment variable Description UAA service name UAA_SERVICE_NAME Contains the name of the UAA service to be used. Destinations destinations Provides information about the available destinations. Additional headers httpHeaders Provides headers that the application router will return to the client in its responses. Additional cookies COOKIES Provides cookies that the application router will return to the client in its responses. Currently only SameSite cookie is supported. Plugins plugins A plugin is just like a route except that you can't configure some inner properties. Session timeout SESSION_TIMEOUT Positive integer representing the session timeout in minutes. The default timeout is 15 minutes. X-Frame-Options SEND_XFRAMEOPTIONS , httpHeaders Configuration for the X-Frame-Options header value. Clickjack whitelist service CJ_PROTECT_WHITELIST Configuration for the whitelist service preventing clickjack attacks. Web Sockets origins whitelist WS_ALLOWED_ORIGINS Whitelist configuration used for verifying the Origin header of the initial upgrade request when establishing a web socket connection. JWT Token refresh JWT_REFRESH The time in minutes before a JWT token expires and the application router should trigger a token refresh routine. Incoming connection timeout INCOMING_CONNECTION_TIMEOUT Maximum time in milliseconds for a client connection. After that time the connection is closed. If set to 0, the timeout is disabled. Default: 120000 (2 min) Tenant host pattern TENANT_HOST_PATTERN String containing a regular expression with a capturing group. The request host is matched against this regular expression. The value of the first capturing group is used as tenant id. Destination host pattern DESTINATION_HOST_PATTERN String containing a regular expression with a capturing group. The request host is matched against this regular expression. The value of the capturing group is used as destination name. Compression COMPRESSION Configuration regarding compressing resources before responding to the client. Secure flag of session cookie SECURE_SESSION_COOKIE Can be set to true or false . By default, the Secure flag of the session cookie is set depending on the environment the application router runs in. For example, when application router is behind a router (Cloud Foundry's router or SAP Web Dispatcher) that is configured to serve HTTPS traffic, then this flag will be present. During local development the flag is not set. This environment variable can be used to enforce setting or omitting the Secure flag. Note : If the Secure flag is enforced, the application router will reject requests sent over unencrypted connection (http). Trusted CA certificates XS_CACERT_PATH List of files paths with trusted CA certificates used for outbound https connections (UAA, destinations, etc.). File paths are separated by path.delimiter . If this is omitted, several well known \"root\" CAs (like VeriSign) will be used. This variable is set automatically by XSA On-premise runtime. Reject untrusted certificates NODE_TLS_REJECT_UNAUTHORIZED By default an outbound https connection is terminated if the remote end does not provide a trusted certificate. This check can be disabled by setting NODE_TLS_REJECT_UNAUTHORIZED to 0 . This is a built-in feature of Node.js. Note: Do not use this in production as it compromises security! External reverse proxy flag EXTERNAL_REVERSE_PROXY Boolean value that indicates the use of application router behind an external reverse proxy (outside of Cloud Foundry domain) Cross-Origin Resource Sharing CORS Configuration regarding CORS enablement. Preserve URL fragment PRESERVE_FRAGMENT Note: The Preserve URL fragment (PRESERVE_FRAGMENT) is being deprecated and will be removed in the near future. When set to true or not set, fragment part of the URL provided during first request of not logged-in user to protected route will be preserved, and after login flow user is redirected to original URL including fragment part. However, this may break programmatic access to Approuter (e.g. e2e tests), since it introduces change in login flow, which is incompatible with Approuter version 4.0.1 and earlier. Setting value to false makes login flow backward compatible, however will not take fragment part of the URL into account. Backend Cookies Secret BACKEND_COOKIES_SECRET Secret that is used to encrypt backend session cookies in service to Application Router flow. Should be set in case multiple instances of Application Router are used. By default a random sequence of characters is used. Note: all those environment variables are optional. Destinations \u00b6 The destinations configuration can be provided by the destinations environment variable or by destination service. There has to be a destination for every single app (microservice) that is a part of the business application. Environment destinations \u00b6 The destinations configuration is an array of objects. Here are the properties that a destination can have: Property Type Optional Description name String A unique alphanumeric identifier of the destination. url String URL of the app (microservice). proxyHost String x The host of the proxy server used in case the request should go through a proxy to reach the destination. proxyPort String x The port of the proxy server used in case the request should go through a proxy to reach the destination. forwardAuthToken Boolean x If true the OAuth token will be sent to the destination. The default value is false . This token contains user identity, scopes and other attributes. It is signed by the UAA so it can be used for user authentication and authorization with backend services. strictSSL Boolean x Configures whether the application router should reject untrusted certificates. The default value is true . Note: Do not use this in production as it compromises security! timeout Number x Positive integer representing the maximum wait time for a response (in milliseconds) from the destination. Default is 30000ms. setXForwardedHeaders Boolean x If true , the application router adds X-Forwarded-(Host, Path, Proto) headers to the backend request.Default value is true. proxyType String x Configures whether the destination is used to access applications in on-premise networks or on public Internet. Possible value: OnPremise . if the property is not provided, it is assumed that it is a public Internet access. Note: if OnPremise value is set, binding to SAP Cloud Platform connectivity service is required, and forwardAuthToken property should not be set. Note: The timeout specified will also apply to the destination's logout path or service's logout path (if you have set one). Note: proxyHost and proxyPort are optional, but if one of them is defined, then the other one becomes mandatory. Sample content of the destinations environment variable: [ { \"name\" : \"ui5\" , \"url\" : \"https://sapui5.netweaver.ondemand.com\" , \"proxyHost\" : \"proxy\" , \"proxyPort\" : \"8080\" , \"forwardAuthToken\" : false , \"timeout\" : 1200 } ] It is also possible to include the destinations in the manifest.yml and manifest-op.yml files: - name: node-hello-world memory: 100M path: web env: destinations: > [ {\"name\":\"ui5\", \"url\":\"https://sapui5.netweaver.ondemand.com\"} ] Destination service \u00b6 Destination configuration can also be read from destination service . Here are the Approuter limitations to destination properties configuration from destination service : Property Additional Property Description Type only HTTP supported. Authentication All authentication types are supported. Note: User and Password are mandatory if the authentication type is basic authentication . Note: if the authentication type set to principal propagation the ProxyType have to be on-premise . Note: if the authentication type set to OAuth2SAMLBearerAssertion , uaa.user scope in xs-security.json is required. ProxyType Supported proxy type : on-premise , internet . Note: if ProxyType set to on-premise , binding to SAP Cloud Platform connectivity service is required. Optional additional properties: \u00b6 Property Additional Property Description HTML5.ForwardAuthToken x If true the OAuth token will be sent to the destination. The default value is false . This token contains user identity, scopes and other attributes. It is signed by the UAA so it can be used for user authentication and authorization with backend services. Note: if ProxyType set to on-premise , ForwardAuthToken property should not be set. Note: if Authentication type is other than NoAuthentication, ForwardAuthToken property should not be set. HTML5.Timeout x Positive integer representing the maximum wait time for a response (in milliseconds) from the destination. Default is 30000ms. Note: The timeout specified will also apply to the destination's logout path or service's logout path (if you have set one). HTML5.PreserveHostHeader x If true , the application router preserves the host header in the backend request. This is expected by some back-end systems like AS ABAP, which do not process x-forwarded-* headers. HTML5.DynamicDestination x If true , the application router allows to use this destination dynamically on host or path level. HTML5.SetXForwardedHeaders x If true , the application router adds X-Forwarded-(Host, Path, Proto) headers to the backend request.Default value is true. sap-client x If provided, the application router propagates the sap-client and its value as a header in the backend request. This is expected by ABAP back-end systems. Note: * In case destination with the same name is defined both in environment destination and destination service, the destination configuration will load from the environment. * Destination service available only in Cloud Foundry. * Destinations on destination service instance level are supported. UAA configuration \u00b6 The User Account and Authentication (UAA) server is responsible for user authentication. In Cloud Foundry and XS OnPremise Runtime a service is created for this configuration and by using the standard service binding mechanism the content of this configuration is available in the VCAP_SERVICES environment variable. Note: The service should have xsuaa in its tags or the environment variable UAA_SERVICE_NAME should be specified (stating the exact name of the UAA service). During local development the UAA configuration is provided in the default-services.json file. When the UAA is used for authentication the user is redirected to the UAA's login page to enter their credentials. Sample content for a default-services.json file: { \"uaa\" : { \"url\" : \"http://my.uaa.server/\" , \"clientid\" : \"client-id\" , \"clientsecret\" : \"client-secret\" , \"xsappname\" : \"my-business-application\" } } The application router supports the $XSAPPNAME placeholder (upper case letters). You may use it in your route configurations in the scope property. The value of $XSAPPNAME is taken from the UAA configuration (the xsappname property). Additional headers configuration \u00b6 If configured, the application router can send additional http headers in its responses to the client. Additional headers can be set in the httpHeaders environment variable. Sample configuration for additional headers: [ { \"X-Frame-Options\" : \"ALLOW-FROM http://localhost\" }, { \"Test-Additional-Header\" : \"1\" } ] In this case the application router will send two additional headers in the responses to the client. Caution: For security reasons, the following headers must not be configured: authorization', 'cookie', and 'set-cookie'. Additional cookies configuration \u00b6 If configured, the application router will send additional cookies in its responses to the client. Additional cookies can be set in the COOKIES environment variable. Example of configuration for cookies in the manifest.yml : env: COOKIES: > { \"SameSite\" : \"None\" } In this example, the application router sets the SameSite cookie attribute to None for the JSESSIONID cookie in the responses to the client. Note: Currently, only the SameSite cookie is supported Plugins configuration \u00b6 A plugin serves almost the same purpose as routes . The difference is that plugins can be configured through the environment and that way you can add new routes to the application router without changing the design-time artefact xs-app.json . The plugin configuration properties are the same as those of a route except that you can't configure localDir , replace and cacheControl . Property Type Optional Description name String The name of this plugin source String/Object Describes a regular expression that matches the incoming request URL . Note: A request matches a particular route if its path contains the given pattern. To ensure the RegExp matches the complete path, use the following form: ^ $`. Note: Be aware that the RegExp is applied to on the full URL including query parameters. target String x Defines how the incoming request path will be rewritten for the corresponding destination. destination String An alphanumeric name of the destination to which the incoming request should be forwarded. authenticationType String x The value can be xsuaa , basic or none . The default one is xsuaa . When xsuaa is used the specified UAA server will handle the authentication (the user is redirected to the UAA's login form). The basic mechanism works with SAP HANA users. If none is used then no authentication is needed for this route. csrfProtection Boolean x Enable CSRF protection for this route. The default value is true . scope Array/String/Object x Scopes are related to the permissions a user needs to access a resource. This property holds the required scopes to access the target path. Access is granted if the user has at least one of the listed scopes. Sample content of the plugins environment variable: [ { \"name\" : \"insecurePlugin\" , \"source\" : \"/plugin\" , \"destination\" : \"plugin\" , \"target\" : \"/\" , \"csrfProtection\" : false , \"scope\" : [ \"viewer\" , \"reader\" ] }, { \"name\" : \"publicPlugin\" , \"source\" : \"/public-plugin\" , \"destination\" : \"publicPlugin\" , \"authenticationType\" : \"none\" } ] Session timeout \u00b6 For example, if you have the following line in your manifest.yml or manifest-op.yml file: - name: node-hello-world memory: 100M path: web env: SESSION_TIMEOUT: 40 After 40 minutes of user inactivity (no requests have been sent to the application router), a Central Logout will be triggered due to session timeout. Note: The application router depends on the UAA server for user authentication, if the authenticationType for a route is xsuaa . The UAA server may have a different session timeout configured. It is recommended that the configurations of the application router and the UAA are identical. X-Frame-Options configuration \u00b6 Application router sends X-Frame-Options header by default with value SAMEORIGIN . This behaviour can be changed in 2 ways: Disable sending the default header value by setting SEND_XFRAMEOPTIONS environment variable to false Override the value to be sent via additional headers configuration Cross-Origin \u00b6 The CORS keyword enables you to provide support for cross-origin requests, for example, by allowing the modification of the request header. Cross-origin resource sharing (CORS) permits Web pages from other domains to make HTTP requests to your application domain, where normally such requests would automatically be refused by the Web browser's security policy. Cross-origin resource sharing(CORS) is a mechanism that allows restricted resources on a webpage to be requested from another domain (/protocol/port) outside the domain (/protocol/port) from which the first resource was served. CORS configuration enables you to define details to control access to your application resource from other Web browsers. For example, you can specify where requests can originate from or what is allowed in the request and response headers. The Cross-Origin configuration is provided in the CORS environment variable. The CORS configuration is an array of objects. Here are the properties that a CORS object can have: Property Type Optional Description uriPattern String A regular expression representing for which source routes CORS configuration is applicable. To ensure the RegExp matches the complete path, surround it with ^ and $. Defaults: none. allowedOrigin Array A comma-separated list of objects that each one of them containing host name, port and protocol that are allowed by the server.for example: [{?host?: \"www.sap.com\"}] or [{?host?: ? .sap.com?}]. Note: matching is case-sensitive. In addition, if port or protocol are not specified the default is ?_ _?. Defaults: none. allowedMethods Array of upper-case HTTP methods x Comma-separated list of HTTP methods that are allowed by the server. Defaults: [?GET?, ?POST?, ?HEAD?, ?OPTIONS?] (all) applies. Note: matching is case-sensitive. maxAge Number x A single value specifying how long, in seconds, a preflight response should be cached. A negative value will prevent CORS Filter from adding this response header to pre-flight response. Defaults: 1800. allowedHeaders Array of headers x Comma-separated list of request headers that are allowed by the serve. Defaults: [?Origin?, ?Accept?, ?X-Requested-With?, ?Content-Type?, ?Access-Control-Request-Method?, ?Access-Control-Request-Headers?]. exposeHeaders Array of headers x Comma-separated list of response headers (other than simple headers) that can be exposed. Defaults: none. allowedCredentials Boolean x A flag that indicates whether the resource supports user credentials. Defaults: true. Sample content of the CORS environment variable: [ { \"uriPattern\" : \"^\\route1$\" , \"allowedMethods\" : [ \"GET\" ], \"allowedOrigin\" : [ { \"host\" : \"my_example.my_domain\" , \"protocol\" : \"https\" , \"port\" : 345 } ], \"maxAge\" : 3600 , \"allowedHeaders\" : [ \"Authorization\" , \"Content-Type\" ], \"exposeHeaders\" : [ \"customHeader1\" , \"customHeader2\" ], \"allowedCredentials\" : true } ] It is also possible to include the CORS in the manifest.yml and manifest-op.yml files: - name: node-hello-world memory: 100M path: web env: CORS: > [ { \"allowedOrigin\":[ { \"host\":\"my_host\", \"protocol\":\"https\" } ], \"uriPattern\":\"^/route1$\" } ] For route with source that match the REGEX ?^\\route1$?, the CORS configuration is enabled. Routes \u00b6 A route is a configuration that instructs the application router how to process an incoming request with a specific path. Property Type Optional Description source String/Object Describes a regular expression that matches the incoming request URL . Note: A request matches a particular route if its path contains the given pattern. To ensure the RegExp matches the complete path, use the following form: ^ $`. Note: Be aware that the RegExp is applied to on the full URL including query parameters. httpMethods Array of upper-case HTTP methods x Which HTTP methods will be served by this route; the methods supported are: DELETE , GET , HEAD , OPTIONS , POST , PUT , TRACE , PATCH (no extension methods are supported). If this option is not specified, the route will serve any HTTP method. target String x Defines how the incoming request path will be rewritten for the corresponding destination or static resource. destination String x The name of the destination to which the incoming request should be forwarded. The destination name can be a static string or a regular expression that defines how to dynamically fetch the destination name from the source property or from the host. service String x The name of the service to which the incoming request should be forwarded. endpoint String x The name of the endpoint within the service to which the incoming request should be forwarded. Can only be used in a route containing a service attribute. localDir String x Folder in the working directory from which the application router will serve static content Note: localDir routes support only HEAD and GET requests; requests with any other method receive a 405 Method Not Allowed. replace Object x An object that contains the configuration for replacing placeholders with values from the environment. It is only relevant for static resources . Its structure is described in Replacements . authenticationType String x The value can be xsuaa , basic or none . The default one is xsuaa . When xsuaa is used the specified UAA server will handle the authentication (the user is redirected to the UAA's login form). The basic mechanism works with SAP HANA users. If none is used then no authentication is needed for this route. csrfProtection Boolean x Enable CSRF protection for this route. The default value is true . scope Array/String/Object x Scopes are related to the permissions a user needs to access a resource. This property holds the required scopes to access the target path. cacheControl String x String representing the value of the Cache-Control header, which is set on the response when serving static resources. By default the Cache-Control header is not set. It is only relevant for static resources. identityProvider String x The name of the identity provider to use if provided in route\u2019s definition. If not provided, the route will be authenticated with the default identity provider. Note: If the authenticationType is set to Basic Authentication or None, do not define the identityProvider property. Note: The properties destination , localDir and service are optional, but exactly one of them must be defined. Note: When using the property replace it is mandatory to define the localDir property. Note: The cacheControl property is effective only when one of the following settings is performed: * The localDir property was set * A service pointing to HTML5 Application Repository (\"service\": \"html5-apps-repo-rt\") was set Example routes \u00b6 For example, if you have a configuration with the following destination: [ { \"name\" : \"app-1\" , \"url\" : \"http://localhost:3001\" } ] Here are some sample route configurations: Route with a destination and no target { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"app-1\" } Since there is no target property for that route, no path rewriting will take place. If we receive /app1/a/b as a path, then a request to http://localhost:3001/app1/a/b is sent. The source path is appended to the destination URL. Route with case-insensitive matching { \"source\" : { \"path\" : \"^/app1/(.*)$\" , \"matchCase\" : false }, \"destination\" : \"app-1\" } This example is much like the previous one, but instead of accepting only paths starting with /app1/ , we accept any variation of app1 's case. That means if we receive /ApP1/a/B , then a request to http://localhost:3001/ApP1/a/B is sent. Note: The property matchCase has to be of type boolean. It is optional and has a default value true . Route with a destination and a target { \"source\" : \"^/app1/(.*)$\" , \"target\" : \"/before/$1/after\" , \"destination\" : \"app-1\" } Route with a service , a target and an endpoint { \"source\" : \"^/odata/v2/(.*)$\" , \"target\" : \"$1\" , \"service\" : \"com.sap.appbasic.country\" , \"endpoint\" : \"countryservice\" } When a request with path /app1/a/b is received, the path rewriting is done according to the rules in the target property. The request will be forwarded to http://localhost:3001/before/a/b/after. Note: In regular expressions there is the term capturing group . If a part of a regular expression is surrounded with parenthesis, then what has been matched can be accessed using $ + the number of the group (starting from 1). In the last example $1 is mapped to the (.*) part of the regular expression in the source property. Route with dynamic destination and target { \"source\" : \"^/destination/([^/]+)/(.*)$\" , \"target\" : \"$2\" , \"destination\" : \"$1\" , \"authenticationType\" : \"xsuaa\" } If you have a another destination configured: [ { \"name\" : \"myDestination\" , \"url\" : \"http://localhost:3002\" } ] when a request with the path /destination/myDestination/myTarget is received, the destination will be replaced with the url from \"myDestination\", the target will get \"myTarget\" and the request will be redirected to http://localhost:3002/myTarget Note: You can use a dynamic value (regex) or a static string for both destination and target values Note: The approuter first looks for the destination name in the mainfest.yaml file, and if not found, looks for it in the destination service. Destination In Host For legacy applications that do not support relative URL paths, you need to define your URL in the following way to enable the destination to be extracted from the host the url should be defined in the following way: https://<tenant>-<destination>.<customdomain>/<pathtofile> To enable the application router to determine the destination of the URL host, a DESTINATION_HOST_PATTERN attribute must be provided as an environment variable. Example: When a request with the path https://myDestination.some-approuter.someDomain.com/app1/myTarget is received, the following route is used: { \"source\" : \"^/app1/([^/]+)/\" , \"target\" : \"$1\" , \"destination\" : \"*\" , \"authenticationType\" : \"xsuaa\" } In this example, the target will be extracted from the source and the \u2018$1\u2019 value is replaced with \u2018myTarget\u2019. The destination value is extracted from the host and the \u2018*\u2019 value is replaced with \u2018myDestination\u2019. Route with a localDir and no target { \"source\" : \"^/web-pages/(.*)$\" , \"localDir\" : \"my-static-resources\" } Since there is no target property for that route, no path rewriting will take place. If we receive a request with a path /web-pages/welcome-page.html , the local file at my-static-resources/web-pages/welcome-page.html under the working directory will be served. Route with a localDir and a target { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"localDir\" : \"my-static-resources\" } If we receive a request with a path '/web-pages/welcome-page.html', the local file at 'my-static-resources/welcome-page.html' under the working directory will be served. Note: The capturing group used in the target property. Route with localDir and cacheControl { \"source\" : \"^/web-pages/\" , \"localDir\" : \"my-static-resources\" , \"cacheControl\" : \"public, max-age=1000,must-revalidate\" } Route with service \"html5-apps-repo-rt\" and cacheControl { \"source\" : \"^/index.html$\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"cacheControl\" : \"public,max-age=1000,must-revalidate\" } Route with httpMethods restrictions The httpMethods option allows you to split the same path across different targets depending on the HTTP method. For example: { \"source\" : \"^/app1/(.*)$\" , \"target\" : \"/before/$1/after\" , \"httpMethods\" : [ \"GET\" , \"POST\" ] } This route will be able to serve only GET and POST requests. Any other method (including extension ones) will get a 405 Method Not Allowed response. The same endpoint can be split across multiple destinations depending on the HTTP method of the requests: { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-1\" , \"httpMethods\" : [ \"GET\" ] } , { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-2\" , \"httpMethods\" : [ \"DELETE\" , \"POST\" , \"PUT\" ] } The setup above will route GET requests to the target dest-1 , DELETE, POST and PUT to dest-2 , and any other method receives a 405. It is also possible to specify \"catchAll\" routes, namely those that do not specify httpMethods restrictions: { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-1\" , \"httpMethods\" : [ \"GET\" ] } , { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-2\" } In the setup above, GET requests will be routed to dest-1 , and all the rest to dest-2 . Why using httpMethods ? It is often useful to split the implementation of microservices across multiple, highly specialized applications. For example, a Java application written to serve high amounts of GET requests that return large payloads is implemented, sized, scaled and load-tested differently than applications that offer APIs to upload limited amounts of data. httpMethods allows you to split your REST APIs, e.g., /Things to different applications depending on the HTTP methods of the requests, without having to make the difference visible in the URL of the endpoints. Another usecase for httpMethods is to \"disable\" parts of the REST API. For example, it may be necessary to disable some endpoints that accept DELETE for external usage. By whitelisting in the relative route only the allow methods, you can hide functionalities of your microservice that should not be consumable without having to modify the code or configurations of your service. Note: localDir and httpMethods are incompatible. The following route is invalid: { \"source\" : \"^/app1/(.*)$\" , \"target\" : \"/before/$1/after\" , \"localDir\" : \"resources\" , \"httpMethods\" : [ \"GET\" , \"POST\" ] } However, since localDir supports only GET and HEAD requests, returning 405 to requests with any other method, any localDir route is \"implicitly\" restricted in terms of supported HTTP methods. Route with a scope An application specific scope has the following format: <application-name>.<scope-name> It is possible to configure what scope the user needs to possess in order to access a specific resource. Those configurations are per route . In this example, the user should have at least one of the scopes in order to access the corresponding resource. { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"scope\" : [ \"$XSAPPNAME.viewer\" , \"$XSAPPNAME.reader\" , \"$XSAPPNAME.writer\" ] } For convenience if our route requires only one scope the scope property can be a string instead of an array. The following configuration is valid as well: { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"scope\" : \"$XSAPPNAME.viewer\" } You can configure scopes for the different HTTP methods (GET, POST, PUT, HEAD, DELETE, CONNECT, TRACE, PATCH and OPTIONS). If some of the HTTP methods are not explicitly set, the behaviour for them is defined by the default property. In case there is no default property specified and the HTTP method is also not specified, the request is rejected by default. { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"scope\" : { \"GET\" : \"$XSAPPNAME.viewer\" , \"POST\" : [ \"$XSAPPNAME.reader\" , \"$XSAPPNAME.writer\" ], \"default\" : \"$XSAPPNAME.guest\" } } The application router supports the $XSAPPNAME placeholder. Its value is taken (and then substituted in the routes) from the UAA configuration. You may read more about it here . Note: The substitution is case sensitive. You can use the name of the business application directly instead of using the $XSAPPNAME placeholder: { \"source\" : \"^/backend/(.*)$\" , \"scope\" : \"my-business-application.viewer\" } Examples for Routes With identityProvider For example, we can define several identity providers for different types of users. In this example, there are 2 categories: hospital patients and hospital personnel: 1. patientsIDP \u2013 use for authenticating patients. 2. hospitalIDP \u2013 use for authenticating all hospital personnel (doctors, nurses etc..). We can configure 2 routes with the following identityProvider properties: [ { \"source\" : \"^/patients/sap/opu/odata/(.*)\" , \"target\" : \"/sap/opu/odata$1\" , \"destination\" : \"backend\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"patientsIDP\" }, { \"source\" : \"^/hospital/sap/opu/odata/(.*)\" , \"target\" : \"/sap/opu/odata$1\" , \"destination\" : \"backend\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"hospitalIDP\" } ] So, a patient who tries to log into the system will be authenticated by patientIDP, and a doctor who tries to log in will be authenticated by hospitalIDP. Note: After logging in using one of the identity providers, to switch to the other one it is necessary to logout and perform a new log in. Note: Currently, dynamic provisioning of the subscriber account identity provider is not supported. Note: Identity provider configuration is only supported in the client side login redirect flow. Replacements \u00b6 This object configures the placeholder replacement in static text resources. Property Type Description pathSuffixes Array An array containing the path suffixes that are relative to localDir . Only files with a path ending with any of these suffixes will be processed. vars Array A whitelist with the environment variables that will be replaced in the files matching the suffix. services Object An object describing bound services that will provide replacement values. Each property of this object is used to lookup a separate service. The property names are arbitrary. Service lookup format is described in Service Query section in @sap/xsenv documentation. The supported tags for replacing environment variables are: {{ENV_VAR}} and {{{ENV_VAR}}} . If there is such an environment variable it will be replaced, otherwise it will be just an empty string. For services you can specify a property from the credentials section of the service binding which will be replaced. For example {{{my_service.property}}} and {{my_service.property}} Every variable that is replaced using two-brackets syntax will be HTML-escaped. For example if the value of the environment variable is ab\"cd the result will be ab&amp;quot;cd . The triple brackets syntax is used when the replaced values don't need to be escaped and all values will be unchanged. For example, if somewhere in your xs-app.json you have a route: { \"source\" : \"^/get/home(.*)\" , \"target\" : \"$1\" , \"localDir\" : \"resources\" , \"replace\" : { \"pathSuffixes\" : [ \"index.html\" ], \"vars\" : [ \"escaped_text\" , \"NOT_ESCAPED\" ], \"services\" : { \"my-sapui5-service\" : { \"tag\" : \"ui5\" } } } } and you have the following index.html : < html > < head > < title > {{escaped_text}} </ title > < script src = \"{{{NOT_ESCAPED}}}/index.js\" /> < script src = \"{{{my-sapui5-service.url}}}\" /> </ head > </ html > then in index.html , {{escaped_text}} and {{{NOT_ESCAPED}}} will be replaced with the values of the environment variables escaped_text and NOT_ESCAPED . If you have a service in VCAP_SERVICES like: { \"sapui5_service\" : [{ \"name\" : \"sapui5\" , \"tags\" : [ \"ui5\" ], \"credentials\" : { \"url\" : \"http://sapui5url\" } }] } then {{{my-sapui5-service.url}}} will be replaced with the url property from sapui5 service - in this case http://sapui5url . Note: All index.html files will be processed. If you want to replace only specific files, you have to set the path of the file relative to localDir . Note: All files should be UTF-8 encoded. Note: If a service is not found an error is thrown on startup. Note: If a service and an environment variable from vars have the same name, an error is thrown on startup. The returned content type is based on the file extension. Currently the supported file extensions are: * .json - application/json * .txt - text/plain * .html - text/html * .js - application/javascript * .css - test/css If the file extension is different, the default content type is text/html . Example for pathSuffixes : { \"pathSuffixes\" : [ \".html\" ] } The suffix .html means that all files with the extension .html under localDir and it's subfolders will be processed. { \"pathSuffixes\" : [ \"/abc/main.html\" , \"some.html\" ] } The suffix /abc/main.html means that all files named main.html which are inside a folder named abc will be processed. The suffix some.html means that all files which have a name that ends with some.html will be processed. For example: some.html , awesome.html . { \"pathSuffixes\" : [ \"/some.html\" ] } The suffix /some.html means that all files which have the exact name some.html will be processed. For example: some.html , /abc/some.html . Note: URL path parameters are not supported for replacements. For example, replacements will not work if the path looks like '/test;color=red/index.html'. For more information regarding path parameters refer to http://tools.ietf.org/html/rfc3986#section-3.3 . xs-app.json configuration file \u00b6 This is the main configuration file of the application router. It contains a JSON object with the following properties: Property Type Optional Description welcomeFile String x The client is redirected to this page by default, if the request does not have a path. For more information, see welcomeFile . authenticationMethod String x If set to none the UAA login roundtrip is disabled. If the property is not set and authentication is defined per route , the value is set to route by default. sessionTimeout Number x Used to set session timeout. The default is 15 minutes. If the SESSION_TIMEOUT environment variable is set this property will be overwritten. routes Array x Contains all route configurations. The position of a configuration in this array is of significance for the application router in case a path matches more than one source . The first route whose source matches the path of the incoming request gets activated. login Object x Contains the configuration for the endpoint of the application router which will be used by the UAA during the OAuth2 authentication routine. By default this endpoint is /login/callback . logout Object x Provides options for a Central Logout endpoint and a page to which the client to be redirected by the UAA after logout. destinations Object x Additional options for your destinations (besides the ones in the destinations environment variable). services Object x Additional options for your business services. compression Object x Configuration regarding compressing resources before responding to the client. If the COMPRESSION environment variable is set it will overwrite existing values. pluginMetadataEndpoint String x Adds an endpoint that will serve a JSON representing all configured plugins. whitelistService Object x Options for the whitelist service preventing clickjack attacks. websockets Object x Options for the web socket communication . errorPage Array x Optional configuration to set-up a custom error pages whenever the approuter encouters an error. welcomeFile property \u00b6 Approuter will redirect to this URL when / (root path) is requested. This could be a file located inside the static resources folder or a resource hosted at a different location. Note: Approuter will serve the content of the resource instead of returning a redirect if the request contains a x-csrf-token: fetch header. See CSRF Protection . Example: \"welcomeFile\" : \"/web-pages/hello-world.html\" web-pages has to be a part of a local resource or an external destination { \"source\" : \"^/web-pages/(.*)$\" , \"localDir\" : \"my-static-resources\" } or { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"destination\" : \"mydest\" } Note: If there isn't a route with a localDir property, the folloing default is added to the list of routes: { \"source\" : \"^/(.*)$\" , \"localDir\" : \"resources\" } authenticationMethod property \u00b6 It may have the following values: none - disables authentication for all routes route - authentication type is defined in the route configurations The default value is route . routes property \u00b6 It holds an array of route configuration objects. The order of the configurations is important for the application router. The first route whose source pattern gets matched with the path of the incoming request will be activated. See Routes for more info. login property \u00b6 A redirect to the application router at a specific endpoint takes place during OAuth2 authentication with UAA. This endpoint can be configured in order to avoid possible collisions. For example: \"login\" : { \"callbackEndpoint\" : \"/custom/login/callback\" } The default endpoint is /login/callback . logout property \u00b6 In this object you can define your business application's central logout endpoint through the logoutEndpoint property. For example, if somewhere in your xs-app.json you have: \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" } This will open an endpoint on application router which, when requested, will trigger the central logout routine. Changing the browser location from the client-side JavaScript code: window . location . replace ( '/my/logout' ); will trigger client initiated central Logout. In addition, a page to which the user will be redirected by the UAA after logout can be configured using the logoutPage property. It may hold: URL path - the UAA will redirect the user back to the application router and the path will be interpreted according the configured routes . The logoutEndpoint can be called with query parameters. For example: window . location . replace ( '/my/logout?siteId=3' ); These parameters will be appended as is to the redirect url set by the logoutPage property. For example, if the logout section is the following: \"logout\": { \"logoutEndpoint\": \"/logout\", \"logoutPage\": \"/logoff.html\" }, The redirect url will end with: /logoff.html?siteId=3 Note : The resource that matches the path should not require authentication. The property authenticationType should be set to none for that particular route. Example: { \"authenticationMethod\" : \"route\" , \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"/logout-page.html\" }, \"routes\" : [ { \"source\" : \"^/logout-page.html$\" , \"localDir\" : \"my-static-resources\" , \"authenticationType\" : \"none\" } ] } In this case my-static-resources (contains logout-page.html ) is a folder with static resources in the working directory of the application router. Note : Be sure that your main route in your xs-app.json resource that matches the path is not cached by browser. Therefore, the best practice here would be to model cacheControl accordingly: { \"routes\" : [ { \"source\" : \"^/ui/index.html\" , \"target\" : \"index.html\" , \"localDir\" : \"web\" , \"cacheControl\" : \"no-cache, no-store, must-revalidate\" } ] } Absolute http(s) URL - the UAA will redirect the user to a page (or application) different from the application router. For example: \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"http://employees.portal\" } Note : UAA will execute redirect only in case redirect URL is a valid redirect-uri in xs-security.json - redirect-uris are maintained as part of the oauth2-configuration section in the UAA application security descriptor JSON file given at the creation of the service instance. For example: UAA application security descriptor: \"oauth2-configuration\": { \"redirect-uris\": [ \"http://employees.portal\" ] } destinations property \u00b6 Let's say you have a destination called node-backend . You can specify options for it by adding the destinations property in your xs-app.json: \"destinations\" : { \"node-backend\" : {} } The value of node-backend should be an object with the following properties: Property Type Optional Description logoutPath String x The logout endpoint for your destination. logoutMethod String x Could be POST, PUT, GET. The default value is POST. The logoutPath will be called when Central Logout is triggered or a session is deleted due to timeout. The request to the logoutPath will contain additional headers, including the JWT token. The logoutMethod property specifies the HTTP method with which the logoutPath will be requested. For example: { \"destinations\" : { \"node-backend\" : { \"logoutPath\" : \"/ui5logout\" , \"logoutMethod\" : \"GET\" } } } services property \u00b6 Let's say you have a service called com.sap.appbasic.country . You can specify options for it by adding the services property in your xs-app.json: \"services\" : { \"com.sap.appbasic.country\" : {} } The value of com.sap.appbasic.country should be an object with the following properties: Property Type Optional Description endpoint String x The name of the attribute in the VCAP_SERVICES that contains the URL of the service. logoutPath String x The path to be used when logging out from the service. logoutMethod String x Could be POST, PUT, GET. The default value is POST. The logoutPath will be called when Central Logout is triggered or a session is deleted due to timeout. The request to the logoutPath will contain additional headers, including the JWT token in header authorization and approuter host in header x-approuter-host . The logoutMethod property specifies the HTTP method with which the logoutPath will be requested. For example: { \"services\" : { \"com.sap.appbasic.country\" : { \"endpoint\" : \"countryservice\" , \"logoutPath\" : \"/countrieslogout\" , \"logoutMethod\" : \"GET\" } } } compression property \u00b6 By default text resources are compressed before being sent to the client. The default threshold for using compression is 1K. Text resources under this size will not be compressed. If you need to change the compression size threshold, you can add the optional property minSize . Here is an example of a compression section (2048 bytes): { \"compression\" : { \"minSize\" : 2048 } } Property Type Optional Description minSize Number x Text resources larger than this size will be compressed. enabled Boolean x Globally disables or enables compression. Default value is true. Note: There are 3 ways to disable compression: * Global - within the compression section add \"enabled\": false * Front-End - the client sends a header Accept-Encoding which omits gzip * Backend - the application sends a header Cache-Control with the 'no-transform' directive Example of globally disabling compression using the environment variable COMPRESSION : { \"enabled\" : false } Note: The header field Content-Length is used to determine the resource size. If Content-Length is missing, the chunk size is used to determine whether to compress the resource. For more information, see the npm module compression. pluginMetadataEndpoint property \u00b6 Example: { \"pluginMetadataEndpoint\" : \"/metadata\" } Note : If you request relative path /metadata of your application, you will receive a JSON with configured plugins. whitelistService property \u00b6 Enabling the whitelist service is used for prevention of clickjack attacks. An endpoint accepting GET requests will be opened at the relative path configured in the endpoint property. For more details see Whitelist service section. Example: { \"whitelistService\" : { \"endpoint\" : \"/whitelist/service\" } } websockets property \u00b6 For more details about the web socket communication see Web sockets section. Example: { \"websockets\" : { \"enabled\" : true } } To use Websockets when approuter is integrated with HTML5 Application Repository, this property should be added to the xs-app.json of the deployed HTML5 application. When an incoming request for an application in the repository goes through approuter, approuter retrieves the application's configuration from the repository. If this flag is set, approuter creates a websockets connection with the backend (the target url of the request) and acts as a proxy which delivers messages on top of ws protocol from the backend to the user and vice versa. errorPage property \u00b6 By default, errors originating in the application router are shown the status code of the error. It is also possible to display a custom error page using the errorPage property. The property is an array of objects, each object having the following properties: Property Type Optional Description status Number/Array HTTP status code file String File path relative to the working directory of the application router Example: { \"errorPage\" : [ { \"status\" : [ 400 , 401 , 402 ], \"file\" : \"./custom-err-40x.html\" }, { \"status\" : 501 , \"file\" : \"./http_resources/custom-err-501.html\" } ] } In the example above 400, 401 and 402 errors would be shown the content of ./custom-err-4xx.html and for 501 errors the user would see ./http_resources/custom-err-501.html . Note: The errorPage conifiguration section has no effect on errors generated outside of the application router. Complete example of an xs-app.json configuration file \u00b6 Without HTML5 Application Repository integration: \u00b6 { \"welcomeFile\" : \"index.html\" , \"authenticationMethod\" : \"route\" , \"sessionTimeout\" : 10 , \"pluginMetadataEndpoint\" : \"/metadata\" , \"routes\" : [ { \"source\" : \"^/sap/ui5/1(.*)$\" , \"target\" : \"$1\" , \"destination\" : \"ui5\" , \"csrfProtection\" : false }, { \"source\" : \"/employeeData/(.*)\" , \"target\" : \"/services/employeeService/$1\" , \"destination\" : \"employeeServices\" , \"authenticationType\" : \"xsuaa\" , \"scope\" : [ \"$XSAPPNAME.viewer\" , \"$XSAPPNAME.writer\" ], \"csrfProtection\" : true }, { \"source\" : \"^/(.*)$\" , \"target\" : \"/web/$1\" , \"localDir\" : \"static-content\" , \"replace\" : { \"pathSuffixes\" : [ \"/abc/index.html\" ], \"vars\" : [ \"NAME\" ] } } ], \"login\" : { \"callbackEndpoint\" : \"/custom/login/callback\" }, \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"/logout-page.html\" }, \"destinations\" : { \"employeeServices\" : { \"logoutPath\" : \"/services/employeeService/logout\" , \"logoutMethod\" : \"GET\" } }, \"compression\" : { \"minSize\" : 2048 }, \"whitelistService\" : { \"endpoint\" : \"/whitelist/service\" }, \"websockets\" : { \"enabled\" : true }, \"errorPage\" : [ { \"status\" : [ 400 , 401 , 402 ], \"file\" : \"/custom-err-4xx.html\" }, { \"status\" : 501 , \"file\" : \"/custom-err-501.html\" } ] } With HTML5 Application Repository integration (xs-app.json file stored in HTML5 Application Repository): \u00b6 { \"welcomeFile\" : \"index.html\" , \"authenticationMethod\" : \"route\" , \"routes\" : [ { \"source\" : \"/employeeData/(.*)\" , \"target\" : \"/services/employeeService/$1\" , \"destination\" : \"employeeServices\" , \"authenticationType\" : \"xsuaa\" , \"scope\" : [ \"$XSAPPNAME.viewer\" , \"$XSAPPNAME.writer\" ], \"csrfProtection\" : true }, { \"source\" : \"^/odata/v2/(.*)$\" , \"target\" : \"$1\" , \"service\" : \"com.sap.appbasic.country\" , \"endpoint\" : \"countryservice\" }, { \"source\" : \"^(/.*)$\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" } ], \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"/logout-page.html\" }, \"destinations\" : { \"employeeServices\" : { \"logoutPath\" : \"/services/employeeService/logout\" , \"logoutMethod\" : \"GET\" } }, \"services\" : { \"com.sap.appbasic.country\" : { \"logoutPath\" : \"/countryService/logout\" , \"endpoint\" : \"countryservice\" , \"logoutMethod\" : \"GET\" } } } Note: The route in bold is the route that provides access to the HTML5 Application Repository service. Headers \u00b6 Forwarding Headers \u00b6 The application router passes the following x-forwarding-* headers to the route targets: Header Name Description x-forwarded-host Contains the Host header which was sent by the client to the application router. x-forwarded-proto Contains the protocol which was used by the client to connect to the application router. x-forwarded-for Contains the address of the client which connects to the application router. x-forwarded-path Contains the original path which was requested by the client. If a client performs a path rewriting, it sends the x-forwarded-proto, x-forwarded-host, and the x-forwarded-path headers to the application router. The values of these headers are forwarded to the route targets without modifications instead of being generated from the application router request URL. The x-forwarded-path header of a request does not impact the source pattern of routes in the xs-app.json. Hop-by-hop Headers \u00b6 Hop-by-hop headers are meaningful only for a single transport-level connection and therefore are not forwarded by the application router. These headers are: * Connection * Keep-Alive * Public * Proxy-Authenticate * Transfer-Encoding * Upgrade Custom Headers \u00b6 x-custom-host: Contains the internal reverse proxy host. Relevant only if the application router is used behind an internal reverse proxy as well as an external reverse proxy (EXTERNAL_REVERSE_PROXY environment variable is set to true). Add this header to the request to internal reverse proxy. In a multi-tenancy landscape, the application router will calculate the tenant id based on the value of a certain request header as follows: - x-custom-host header or host if EXTERNAL_REVERSE_PROXY is true - x-forwarded-host header or host if EXTERNAL_REVERSE_PROXY is false or not specified Authorization Header (Beta version) \u00b6 x-approuter-authorization: Contains the JWT token to support the Service to Application Router scenario. Caution : You should not use SAP Cloud Platform beta features in subaccounts that belong to productive enterprise accounts. Any use of beta functionality is at the customer's own risk, and SAP shall not be liable for errors or damages caused by the use of beta features. For more information, see Using Beta Features in Subaccounts . CSRF Protection \u00b6 By default the application router enables CSRF protection for any HTTP method that is not HEAD or GET and the route is not public. A path is considered public , if it does not require authentication. This is the case for routes with authenticationType: none or if authentication is disabled completely via the top level property authenticationMethod: none . To obtain a CSRF token one must send a GET or HEAD request with a x-csrf-token: fetch header to the application router. The application router will return the created token in a x-csrf-token: <token> header, where <token> will be the value of the CSRF token. If a CSRF protected route is requested with any of the above mentioned methods, x-csrf-token: <token> header should be present in the request with the previously obtained token. This request must use the same session as the fetch token request. If the x-csrf-token header is not present or invalid, the application router will return status code 403 Forbidden and a response header x-csrf-token: Required . Connectivity \u00b6 The application router supports integration with SAP Cloud Platform connectivity service. The connectivity service handles proxy access to SAP Cloud Platform cloud connector, which tunnels connections to private network systems. In order to use connectivity, a connectivity service instance should be created and bound to the Approuter application. In addition, the relevant destination configurations should have proxyType=OnPremise . Also, a valid XSUAA login token should be obtained via the login flow. SaaS Application Registration in Cloud Foundry \u00b6 The application router supports SaaS registration. A SaaS business application based on application router may be registered in the SaaS registry by creating and binding a SaaS Registry service instance. After fulfilling the CIS process to enable application subscription, the SaaS business application will be visible in the SAP Cloud Platform cockpit in the Cloud Foundry environment for all entitled customers. Once a customer is entitled to the SaaS business application, the subaccounts (tenants) created under the global account will be able to view, subscribe to, and unsubscribe from the application. When a tenant is subscribed/unsubscribed to/from an application, the tenant will be subscribed/unsubscribed: * In the XSUAA instance of the application itself * In the reuse services (e.g.: destination ), if the application is dependent on the reuse service. Also, onboarding and offboarding callbacks will be triggered for the subscribed/unsubscribed application and for the reuse services. How To Expose Approuter for SaaS Subscription \u00b6 Multi-tenancy \u00b6 The application router should be configured to handle multi-tenant access by maintaining the TENANT_HOST_PATTERN environment configuration. Entitle org for SaaS Registry consumption \u00b6 The SaaS Registry service should be available in your space marketplace. Authorize LPS for invoking callbacks \u00b6 SaaS business applications should grant LPS the authorization to invoke the application's callbacks. Callback scope should be granted to LPS in the application router\u2019s xs-security.json file: xs-security.json: ... { \"name\":\"$XSAPPNAME.Callback\", \"description\":\"With this scope set, the callbacks for tenant onboarding, offboarding and getDependencies can be called.\", \"grant-as-authority-to-apps\":[ \"$XSAPPNAME(application,sap-provisioning,tenant-onboarding)\" ] } ... Register an application (SaaS Registry Configuration) \u00b6 For a customer to be able to subscribe to an application through the SAP Cloud Platform cockpit, each SaaS business application should register itself on all CF landscapes where it is deployed. To register a SaaS application in LPS, a service instance of saas-registry should be created and the SaaS business application should be bound to it. The instance of saas-registry is created with a configuration json - saas-config.json: . In the configuration.json file a url for the getDependencies and onSubscription callbacks must be provided. Note that the path segment of these urls are configurable however the tenantId url variable in onSubscription callback must be provided anyway. { \"appId\" : \"<appId>\", # xsappname generated by XSUAA - can be obtained by checking the xsuaa-> xsappname by executing: cf env <application name> \"appName\" : \"<appName>\", # Business application name to be shown to subscribers \"appUrls\": { \"getDependencies\" : \"<approuter-host>/callback/v1.0/dependencies\", \"onSubscription\" : \"<approuter-host>/callback/v1.0/tenants/{tenantId}\" }, \"providerTenantId\" : \"<tenant>\" # Approuter provider account tenant ID. } Integration with HTML5 Application Repository \u00b6 The application router supports seamless integration with the HTML5 Application Repository service. When the application router interacts with HTML5 Application Repository to serve HTML5 Applications, all static content and routes (xs-app.json) are retrieved from HTML5 Application Repository. In case application router needs to route to non HTML5 Applications, it is possible to model that in the xs-app.json of the application router. To integrate HTML5 Application Repository to an application router based it is required to create an instance of html5-apps-repo service of plan app-runtime and bind it to the application. xs-app.json routes that are used to retrieve static content from HTML5 Application Repository may be modeled in the following format: { \"source\": \"^(/.*)\", \"target\": \"$1\", \"service\": \"html5-apps-repo-rt\", \"authenticationType\": \"xsuaa\" } Known Gaps in Integration with HTML5 Application Repository \u00b6 The following limitations apply when application router is bound to HTML5 Application Repository service: It is not possible to implement the \"first\" middleware slot to provide routes dynamically. No option apart from workingDir can be provided in application router start. External session management via extensibility is not supported Note: Mixed scenario of modeling part of the static content in local resources folder and also retrieving static content from HTML5 Application Repository is not supported. Note: This feature is only supported in Cloud Foundry. There is no HTML5 Application Repository service in XSA. Runtime Processing \u00b6 During runtime, based on request url path (see URL Format), application router will try to fetch the xs-app.json file from the corresponding HTML5 Application in HTML5 Application Repository and use it for routing the request. The following algorithm is applied for request processing: * If no HTML5 Application is found in HTML5 Application Repository for current request, central application router xs-app.json will be used for routing * If HTML5 Application exists in HTML5 Application Repository but no xs-app.json file is returned, an error message will be issued and request processing will be stopped. URL Format \u00b6 A valid request to application router that uses HTML5 Application Repository must have the following format: https://<tenantId>.<appRouterHost>.<domain>/<bsPrefix>.<appName-appVersion>/<resourcePath> bsPrefix (business service prefix) - Optional * It should be used in case the application is provided by a business service bound to this approuter appName (application name) - Mandatory * Used to uniquely identify the application in HTML5 Application Repository persistence * Must not contain dots or special characters appVersion (application version) - Optional * Used to uniquely identify a specific application version in HTML5 Application Repository persistence * If no version provided, default application version will be used resourcePath (path to file) * The path to the file as it was stored in HTML5 Application Repository persistence Cache Buster Handling \u00b6 A cache buster allows the application router to notify the browser to refresh the resources only when the application resources have been changed. Otherwise the resources are always fetched from the browser's cache. This flow applies to requests that should be forwarded to HTML5 Application Repository. If requests are forwarded to backend applications that return data, cache buster handling is not applied. When the second path segment of the request url contains the pattern \u201c~timestamp~\u201d, this segment is removed from the subsequent request to HTML5 Application Repository In case the request had a cache buster segment, application router adds to corresponding response the header: Cache-Control: public, max-age=31536000 Note: Cache buster flow is only supported in HTML5 Application Repository integration flow. Integration with Business Services \u00b6 Application router supports integration with Business Services. Business Services are a flavour of reuse-services that expose specific information in VCAP_SERVICES credentials block that enable application router to serve Business Service UI and/or data. * Business Service UI must be stored in HTML5 Application Repository to be accessible from application router * Business Service UI must be defined as \"public\" to be accessible from an application router in a different space than the one from where the UI was uploaded * Business Service data can be served using two grant types: 1. User Token Grant: Application router performs a token exchange between login JWT token and Business Service token and uses it to trigger a request to the Business Service endpoint 2. Client Credentials Grant: Application router generates a client_credentials token and uses it to trigger a request to the Business Service endpoint Business Service Credentials \u00b6 While binding a Business Service instance to application router the following information should be provided in VCAP_SERVICES credentials: sap.cloud.service: Service name as referenced from xs-app.json route and business service prefix (if Business Service UI provided) - Mandatory sap.cloud.service.alias: Short service name alias for user friendly URL business service prefix- Optional endpoints: One or more endpoints that can be used to access Business Service data. html5-apps-repo: html5-apps-repo.app_host_id contains one or more html5-apps-repo service instance GUIDs that can be used to retrieve Business Service UIs - Optional saasregistryenabled: flag that indicates that this Business Service supports SaaS Registry subscription. If provided, application router will return this Business Service xsappname in SaaS Registry getDependencies callback - Optional grant_type: the grant type that should be used to trigger requests to the Business Service. Allowed values: user_token or client_credentials. Default value, in case this attribute is not provided, user_token - Optional The value of endpoints should be an object with the following properties: Property Type Optional Default Description url String URL to access the Business Service data. timeout Number x 30000ms Positive integer representing the maximum wait time for a response (in milliseconds) from the Business Service. For example: \"country\": [ { ... \"credentials\": { \"sap.cloud.service\": \"com.sap.appbasic.country\", \"sap.cloud.service.alias\": \"country\", \"endpoints\": { \"countryservice\": { \"url\": https://icf-countriesapp-test-service.cfapps.sap.hana.ondemand.com/odata/v2/countryservice\"}, \"countryconfig\": { \"url\": https://icf-countriesapp-test-service.cfapps.sap.hana.ondemand.com/rest/v1/countryconfig\", \"timeout\": 120000 } }, \"html5-apps-repo\": { \"app_host_id\": \"1bd7c044-6cf4-4c5a-b904-2d3f44cd5569, 1cd7c044-6cf4-4c5a-b904-2d3f44cd54445\" }, \"saasregistryenabled\": true, \"grant_type\": \"user_token\" .... Accessing Business Service Data \u00b6 To access Business Service data xs-app.json configuration file should have a route referencing a specific sap.cloud.service or sap.cloud.service.alias via the service attribute. If an endpoint attribute is also modeled, it will be used to get the service url otherwise the fallback url or uri attribute will be used. For example: \"routes\": [ { \"source\": \"^/odata/v2/(.*)$\", \"target\": \"$1\", \"service\": \"com.sap.appbasic.country\", \"endpoint\": \"countryservice\" }, In order to support JWT token exchange, the login JWT token should contain the uaa.user scope. For that the xs-security configuration must contain a role template that references the uaa.user scope. For example: { \"xsappname\" : \"simple-approuter\", \"tenant-mode\" : \"shared\", \"scopes\": [ { \"name\": \"uaa.user\", \"description\": \"UAA\" }, { \"name\": \"$XSAPPNAME.simple-approuter.admin\", \"description\": \"Simple approuter administrator\" } ], \"role-templates\": [ { \"name\": \"Token_Exchange\", \"description\": \"UAA\", \"scope-references\": [ \"uaa.user\" ] }, { \"name\": \"simple-approuter-admin\", \"description\": \"Simple approuter administrator\", \"scope-references\": [ \"$XSAPPNAME.simple-approuter.admin\" ] } ] } Accessing Business Service UI \u00b6 Business Service UI's must be stored in HTML5 Application Repository and defined in their manifest.json files as \"public: true\" in order to be accessible from an application router application that is typically running in a different space than the Business Service space. In addition dataSources uris must be relative to base url (no slash as first character). Business Service manifest.json example: { \u201csap.app\u201d: { \u201cid\u201d:\u201ccom.sap.appbasic.country.list\u201d, \u201capplicationVersion: { \u201cversion\u201d: \u201c1.0.0\u201d }, \"dataSources\": { \"mainService\":{ \"uri\": \"odata/v2/countryservice\", \"type\": \"OData\" } }, \u201csap.cloud\u201d: { \"public\": true, \u201cservice\u201d: \u201ccom.sap.appbasic.country\u201c } } A Business Service that exposes UI must provide one or more app-host GUIDs in an html5-apps-repo block in VCAP_SERVICES credentials (see Business Service credentials). To access Business Service UI the request url that hits application router must contain a business service prefix as described above. Request URL example: https://approuter-repo-examples.cfapps.sap.hana.ondemand.com/comsapappbasiccountry.comsapappbasicscountrylist/test/flpSandbox.html In this example \"comsapappbasiccountry\" is the business service prefix which matches the sap.cloud.service attribute in country service VCAP_SERVICES credentials (without dots). The \"comsapappbasicscountrylist\" is the name of the HTML5 Application as defined in the app.id attribute in the manifest.json (without dots). Web Sockets \u00b6 The application router is capable of forwarding web socket communication. In order to use the web socket communication, it should be enabled through the websockets property . If the backend service requires authentication then the upgrade request should contain a valid session cookie. The destination schemas \"ws\" and \"wss\" are supported in addition to \"http\" and \"https\". When the application router receives an upgrade request, it verifies that the Origin header holds the URL of the application router. If this is not the case, then an HTTP response with status 403 is returned to the client. This origin verification can be further configured via the environment variable WS_ALLOWED_ORIGINS . It contains the allowed origins the application router verifies against. It's structure is the same as CJ_PROTECT_WHITELIST . Note: A current limitation is that a web socket ping is not forwarded to the backend service. Session Handling \u00b6 The application router establishes a session with the client (browser) using a session cookie. The application router intercepts all session cookies, sent by backend services and stores them in its own session. Backend session cookies are not sent to the client in order to prevent cookie collisions. Upon subsequent requests the application router sends back the cookies to the respective backend services so they can establish their own sessions. Note: Non-session cookies from backend services are forwarded to the client. Cookie collisions may occur and the application should be able to handle them. If a pending request is canceled, the request cancellation will be propagated to the backend service. Session Contents \u00b6 CSRF token - the generated CSRF token so it can be verified against the token in the request, see CSRF Protection above. OAuth token - JSON Web Token (JWT) fetched from UAA and forwarded to backend services in the Authorization header. The client never gets this token. The application router refreshes the JWT automatically before it expires (if the session is valid). By default this routine is triggered 5 minutes before the expiration of the JWT. This can also be configured via the JWT_REFRESH environment variable (the value is in minutes). If JWT_REFRESH is set to 0 then the refresh is disabled. OAuth scopes - scopes owned by the current user, used to check if the user has the scope required for each request. See scope in Routes . Backend session cookies - all session cookies sent by backend services. Business Services OAuth tokens - JSON Web Token (JWT) exchanged and used to access re-use services bound to the application router Note: If the JWT is close to expiration and the session is still active a JWT refresh will be triggered in JWT_REFRESH minutes before expiration. JWT_REFRESH is an environment variable stating the number of minutes before the JWT expiration the refresh will be triggered. The default value is 5 minutes. Service to Application Router (Beta version) \u00b6 The application router can receive a consumer service xsuaa JWT token and use it to access the UI and the data. The JWT token is passed to the application router in the \"x-approuter-authorization\" header of the request. For more information, see Authorization Header . Note : The xsuaa JWT token is generated with the same xsuaa service instance that is bound to the application router. Caution : You should not use SAP Cloud Platform beta features in subaccounts that belong to productive enterprise accounts. Any use of beta functionality is at the customer's own risk, and SAP shall not be liable for errors or damages caused by the use of beta features. For more information, see Using Beta Features in Subaccounts . Central Logout \u00b6 Central Logout can be client initiated or can be triggered due to session timeout. * Client initiated * Deletes the user session. * Requests all backend services logout paths (if configured in the destinations property ). * Request all business services logout paths (if configured in the services property ). * Redirects the client to logout from UAA. * If configured, redirects back to a custom page (for XS OnPremise Runtime only). For more information, see logout-property . * Session timeout * Deletes the user session. * Requests all backend services logout paths (if configured in the destinations property ). * Requests all business services logout paths (if configured in the services property ). The session timeout can be configured with the SESSION_TIMEOUT variable through the environment. Whitelist Service \u00b6 What is it for? A protection concept is designed in SAP that uses UI libraries and whitelist service for proper clickjack protection of applications. The general idea is that when an html page needs to be rendered in a frame, a check is done by calling the whitelist service to validate if the parent frame is allowed to render the content in a frame. The actual check is provided by the whitelist service. Enable the service \u00b6 To enable the service and open the service endpoint you need to configure the whitelistService property in xs-app.json . Configuring allowed hostnames / domains \u00b6 The whitelist service reads allowed hostnames and domains from the environment variable CJ_PROTECT_WHITELIST . The content is a JSON array of object with the following properties: Property Type Optional Description protocol String x URI scheme, for example http . host String Hostname / domain - valid hostname, or domain defined with a star (*), for example some.concrete.hostname , or *.example.domain . port String / Number x Port string or number containing a valid port. Example: [ { \"protocol\" : \"http\" , \"host\" : \"*.example.domain\" , \"port\" : 12345 }, { \"host\" : \"some.concrete.hostname\" , } ] Matching is done against provided properties. For example if only host is provided then the service will return framing: true for all and matching will be for all schemas and protocols. Return value \u00b6 The service accepts only GET requests and the response is a JSON object. The whitelist service call uses the parent origin as URI parameter (URL encoded) as follows: GET url/to/whitelist/service?parentOrigin=https://parent.domain.com The response is a JSON object with following properties: { \"version\" : \"1.0\", \"active\" : true | false, // indicates whether framing control is switched on \"origin\" : \"<same as passed to service>\", \"framing\" : true | false // if active, describes if framing should be allowed } The property active will have value false only in case CJ_PROTECT_WHITELIST is not provided. Note : Keep in mind that the application router sends by default the X-Frame-Options header with value SAMEORIGIN , in the case whitelist service is enabled, this header value probably needs to be changed, see the X-Frame-Options header section for details how to change it. Scaling \u00b6 The application router keeps all established sessions in local memory and does not sync them across multiple instances. In order to scale the application router to multiple instances, session stickiness should be enabled. This means that each HTTP session is handled by the same application router instance. In Cloud Foundry's router, session stickiness is enabled from version 0.1.0. In SAP HANA XS Advanced OnPremise Runtime session stickiness is enabled, if SAP Web Dispatcher is used as a router. This is set by default from version 0.1535 of SAP HANA XS Advanced runtime. If your on-premise runtime uses nginx as router, you can switch to SAP Web Dispatcher by passing the command line option --router=webdispatcher to xs-controller . Sizing Guide for Application Router \u00b6 The memory consumption of the application router is described in the sizing guide . Configure server-side HTTPS \u00b6 You can configure application router to accept only HTTPS connections. See httpsOptions option of start function. Audit-Log Service \u00b6 The application router logs information regarding unauthorized requests. To avoid exposure of private information such as user id and IP address, you must bind the consuming application to an instance of the audit-log service. If you do not bind the consuming application to the audit-log service, the application router will log this information to the console output, using asterisks to mask the user id and IP address. (This is the default behavior.) Troubleshooting \u00b6 The application router uses @sap/logging package so all of its features are available to control logging. For example to set all logging and tracing to finest level set XS_APP_LOG_LEVEL environment variable to debug . If the application is deployed on Cloud Foundry, you can change the log level by running command: cf set-env <application-name> XS_APP_LOG_LEVEL DEBUG If the application is deployed on XS Advanced On-premise Runtime, you can change the log level without restarting the application. For example this command will set all logging and tracing to finest level. xs set-logging-level <application-name> \"*\" debug See @sap/logging documentation for details. You can enable additional traces of the incoming and outgoing requests by setting the environment variable REQUEST_TRACE to true . When enabled they will log basic information for every incoming and outgoing request of the application router. This could have a performance impact. Some of the libraries used by this package employ other tracing mechanisms. For example many use the popular debug package. This means that by setting DEBUG environment variable, you can enable additional traces. Set it to * to enable all of them, but be careful as the output may be overwhelming. In addition internal Node.js traces can be enabled via NODE_DEBUG environment variable. This post describes it in more detail. Warning: Enabling some of these options may trace security sensitive data, so use with caution. The @sap/logging package sets the header 'x-request-id' in the application router's responses. This is useful if you would like to search entries belonging to a particular request execution in the application router's logs and traces. Note that the application router does not change the headers received from the backend and being forwarded to the client. If the backend is a Node.js application which uses the @sap/logging package (and also sets the 'x-request-id' header), then the value of the header that the client will receive will be the one coming from the backend and not the one of the application router itself. Getting Support \u00b6 Create a BCP ticket on component BC-XS-APR Extending Application Router \u00b6 See extending for information how to extend the application router with custom logic. Best practices \u00b6 Security best practices \u00b6 Content-Security-Policy \u00b6 Setting the Content-Security-Policy header - this is a response header which informs browsers (capable of interpreting it) about the trusted sources from which an application expects to load resources. This mechanism allows the client to detect and block malicious scripts injected into an application. A value can be set via the httpHeaders environment variable in the additional headers configuration . The value represents a security policy which contains directive-value pairs. The value of a directive is a whitelist of trusted sources. Refer to the Content-Security-Policy specification for more information on the header's value. Note: Usage of the Content-Security-Policy header is considered second line of defense. An application should always provide proper input validation and output encoding. Identity Provider Configuration Best Practices \u00b6 Modelling options: \u00b6 If you to enable login in same browser window as doctor and patient you can create 2 cf routes to same approuter: https://approuter-doctors.cfapps.hana.com/myapp/doctors/index.html { \"source\" : \"^/doctors(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"doctorsIDP\" } https://approuter-patients.cfapps.hana.com/myapp/patients/index.html { \"source\" : \"^/patients(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"patrientsIDP\" } If you to enable single access at a time (force logout from doctors idp and re-login to patients idp), create a single cf route https://approuter-hospital.cfapps.hana.com/myapp/doctors/index.html { \"source\" : \"^/doctors(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"doctorsIDP\" } https://approuter-hospital.cfapps.hana.com/myapp/patients/index.html { \"source\" : \"^/patients(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"patrientsIDP\" }","title":"Index"},{"location":"apis/approuter/#sapapprouter","text":"Overview Deploying a business application with microservices Working directory Configurations Destinations Environment-destinations Destination-service UAA configuration Additional headers configuration Additional cookies configuration Plugins configuration Session timeout X-Frame-Options configuration Cross-Origin Routes Example routes Replacements xs-app.json configuration file welcomeFile property authenticationMethod property routes property login property logout property destinations property services property compression property pluginMetadataEndpoint property whitelistService property websockets property errorPage property Complete example of an xs-app.json configuration file Headers Forwarding Headers Hop-by-hop Headers Custom Headers Authorization Header (Beta version) CSRF Protection Connectivity SaaS Application Registration in CF How To Expose Approuter for SaaS Subscription Integration with HTML5 Application Repository Integration with Business Services Web Sockets Session Handling Session Contents Service to Application Router (Beta version) Central Logout Whitelist Service Enable the service Configuring allowed hostnames / domains Return value Scaling Sizing Guide for Application Router Configure server-side HTTPS Audit-Log Service Troubleshooting Getting Support Extending Application Router Best practices Security best practices Content-Security-Policy","title":"@sap/approuter"},{"location":"apis/approuter/#overview","text":"When a business application consists of several different apps (microservices), the application router is used to provide a single entry point to that business application. It has the responsibility to: Dispatch requests to backend microservices (reverse proxy) Authenticate users Serve static content Let's think of the different apps (microservices) as destinations to which the incoming request will be forwarded. The rules that determine which request should be forwarded to which destination are called routes . For every destination there can be more than one route. You may read more on the concept of routes later in this document. If the backend microservices require authentication, the application router can be configured to authenticate the users and propagate the user information. Again by using routes, the application router can serve static content. The application router is designed to work in XS Advanced - Cloud Foundry and XS OnPremise Runtime. A calling component accesses a target service by means of the application router only if there is no JWT token available, for example, if a user invokes the application from a Web browser. If a JWT token is already available, for example, because the user has already been authenticated, or the calling component uses a JWT token for its own OAuth client, the calling component calls the target service directly; it does not need to use the application router. Note that the application router does not hide the backend microservices in any way. They are still directly accessible bypassing the application router. So the backend microservices must protect all their endpoints by validating the JWT token and implementing proper scope checks. Network isolation is not provided currently by the platform.","title":"Overview"},{"location":"apis/approuter/#deploying-a-business-application-with-microservices","text":"For example we can have a business application that has the following structure: +-- manifest.yml +-- manifest-op.yml | +-- microservice-1 | | +-- ... | | +-- ... | +-- microservice-2 | | +-- ... | | +-- ... | +-- web | | +-- ... | | +-- ... The manifest.yml file is used to deploy the business application on Cloud Foundry and the manifest-op.yml - on the XS OnPremise Runtime. These files should describe all the microservices for that business application. Folders are used to isolate the different microservices. Let's assume that the application router is the microservice in the web folder (every business application has its own application router). Here is how we can include the application router: Manually create the node_modules folder in the web folder. Copy and paste the folder that contains the self-contained application router into node_modules . In this example the name of that folder is @sap/approuter , see the start script in the package.json below. Check the version of the application router you just copied. Create a package.json file in web with content similar to the following and replace the version's value with the version of your application router: { \"name\" : \"hello-world-approuter\" , \"dependencies\" : { \"@sap/approuter\" : \"2.6.1\" }, \"scripts\" : { \"start\" : \"node node_modules/@sap/approuter/approuter.js\" } } In order to use the application router you don't have to write any JavaScript code. Only some configurations have to be provided in the web folder. Here is a complete example: +-- web | +-- package.json | +-- xs-app.json | +-- resources | | +-- hello-world.html | | +-- my-page.html | +-- node_modules | | +-- ... | +-- default-env.json | +-- default-services.json The web folder contains the package.json , node_modules , some configuration files used by the application router, and static resources to be served. You can read more about the configurations later in this document. By default, the application router runs on port 5000 (if started locally) or it takes the port from the PORT environment variable.","title":"Deploying a business application with microservices"},{"location":"apis/approuter/#working-directory","text":"The working directory contains configuration files that the application router needs and static resources that can be served at runtime. In the previous example , the web folder is the working directory. By default the current directory is the working directory. It is possible to configure it during start up of the application router with the following command line argument: node approuter.js -w <working-dir> Application router will abort if the working directory does not contain xs-app.json file.","title":"Working directory"},{"location":"apis/approuter/#configurations","text":"The application router makes use of the following configurations: Main configuration - this is the xs-app.json file. This file is mandatory and contains the main configurations of the application router. UAA configuration - the application router reads this configuration either from the VCAP_SERVICES environment variable (when deployed on Cloud Foundry or XS Advanced OnPremise Runtime) or from the default-services.json file (when running locally). Refer to the documentation of the @sap/xsenv package for more details. Configurations from the environment - these configurations are either read from the application router's environment (when deployed on Cloud Foundry or XS Advanced OnPremise Runtime) or from the default-env.json file (when running locally). Refer to the documentation of the @sap/xsenv package for more details. The environment variables that the application router takes into account are: Configuration Environment variable Description UAA service name UAA_SERVICE_NAME Contains the name of the UAA service to be used. Destinations destinations Provides information about the available destinations. Additional headers httpHeaders Provides headers that the application router will return to the client in its responses. Additional cookies COOKIES Provides cookies that the application router will return to the client in its responses. Currently only SameSite cookie is supported. Plugins plugins A plugin is just like a route except that you can't configure some inner properties. Session timeout SESSION_TIMEOUT Positive integer representing the session timeout in minutes. The default timeout is 15 minutes. X-Frame-Options SEND_XFRAMEOPTIONS , httpHeaders Configuration for the X-Frame-Options header value. Clickjack whitelist service CJ_PROTECT_WHITELIST Configuration for the whitelist service preventing clickjack attacks. Web Sockets origins whitelist WS_ALLOWED_ORIGINS Whitelist configuration used for verifying the Origin header of the initial upgrade request when establishing a web socket connection. JWT Token refresh JWT_REFRESH The time in minutes before a JWT token expires and the application router should trigger a token refresh routine. Incoming connection timeout INCOMING_CONNECTION_TIMEOUT Maximum time in milliseconds for a client connection. After that time the connection is closed. If set to 0, the timeout is disabled. Default: 120000 (2 min) Tenant host pattern TENANT_HOST_PATTERN String containing a regular expression with a capturing group. The request host is matched against this regular expression. The value of the first capturing group is used as tenant id. Destination host pattern DESTINATION_HOST_PATTERN String containing a regular expression with a capturing group. The request host is matched against this regular expression. The value of the capturing group is used as destination name. Compression COMPRESSION Configuration regarding compressing resources before responding to the client. Secure flag of session cookie SECURE_SESSION_COOKIE Can be set to true or false . By default, the Secure flag of the session cookie is set depending on the environment the application router runs in. For example, when application router is behind a router (Cloud Foundry's router or SAP Web Dispatcher) that is configured to serve HTTPS traffic, then this flag will be present. During local development the flag is not set. This environment variable can be used to enforce setting or omitting the Secure flag. Note : If the Secure flag is enforced, the application router will reject requests sent over unencrypted connection (http). Trusted CA certificates XS_CACERT_PATH List of files paths with trusted CA certificates used for outbound https connections (UAA, destinations, etc.). File paths are separated by path.delimiter . If this is omitted, several well known \"root\" CAs (like VeriSign) will be used. This variable is set automatically by XSA On-premise runtime. Reject untrusted certificates NODE_TLS_REJECT_UNAUTHORIZED By default an outbound https connection is terminated if the remote end does not provide a trusted certificate. This check can be disabled by setting NODE_TLS_REJECT_UNAUTHORIZED to 0 . This is a built-in feature of Node.js. Note: Do not use this in production as it compromises security! External reverse proxy flag EXTERNAL_REVERSE_PROXY Boolean value that indicates the use of application router behind an external reverse proxy (outside of Cloud Foundry domain) Cross-Origin Resource Sharing CORS Configuration regarding CORS enablement. Preserve URL fragment PRESERVE_FRAGMENT Note: The Preserve URL fragment (PRESERVE_FRAGMENT) is being deprecated and will be removed in the near future. When set to true or not set, fragment part of the URL provided during first request of not logged-in user to protected route will be preserved, and after login flow user is redirected to original URL including fragment part. However, this may break programmatic access to Approuter (e.g. e2e tests), since it introduces change in login flow, which is incompatible with Approuter version 4.0.1 and earlier. Setting value to false makes login flow backward compatible, however will not take fragment part of the URL into account. Backend Cookies Secret BACKEND_COOKIES_SECRET Secret that is used to encrypt backend session cookies in service to Application Router flow. Should be set in case multiple instances of Application Router are used. By default a random sequence of characters is used. Note: all those environment variables are optional.","title":"Configurations"},{"location":"apis/approuter/#destinations","text":"The destinations configuration can be provided by the destinations environment variable or by destination service. There has to be a destination for every single app (microservice) that is a part of the business application.","title":"Destinations"},{"location":"apis/approuter/#environment-destinations","text":"The destinations configuration is an array of objects. Here are the properties that a destination can have: Property Type Optional Description name String A unique alphanumeric identifier of the destination. url String URL of the app (microservice). proxyHost String x The host of the proxy server used in case the request should go through a proxy to reach the destination. proxyPort String x The port of the proxy server used in case the request should go through a proxy to reach the destination. forwardAuthToken Boolean x If true the OAuth token will be sent to the destination. The default value is false . This token contains user identity, scopes and other attributes. It is signed by the UAA so it can be used for user authentication and authorization with backend services. strictSSL Boolean x Configures whether the application router should reject untrusted certificates. The default value is true . Note: Do not use this in production as it compromises security! timeout Number x Positive integer representing the maximum wait time for a response (in milliseconds) from the destination. Default is 30000ms. setXForwardedHeaders Boolean x If true , the application router adds X-Forwarded-(Host, Path, Proto) headers to the backend request.Default value is true. proxyType String x Configures whether the destination is used to access applications in on-premise networks or on public Internet. Possible value: OnPremise . if the property is not provided, it is assumed that it is a public Internet access. Note: if OnPremise value is set, binding to SAP Cloud Platform connectivity service is required, and forwardAuthToken property should not be set. Note: The timeout specified will also apply to the destination's logout path or service's logout path (if you have set one). Note: proxyHost and proxyPort are optional, but if one of them is defined, then the other one becomes mandatory. Sample content of the destinations environment variable: [ { \"name\" : \"ui5\" , \"url\" : \"https://sapui5.netweaver.ondemand.com\" , \"proxyHost\" : \"proxy\" , \"proxyPort\" : \"8080\" , \"forwardAuthToken\" : false , \"timeout\" : 1200 } ] It is also possible to include the destinations in the manifest.yml and manifest-op.yml files: - name: node-hello-world memory: 100M path: web env: destinations: > [ {\"name\":\"ui5\", \"url\":\"https://sapui5.netweaver.ondemand.com\"} ]","title":"Environment destinations"},{"location":"apis/approuter/#destination-service","text":"Destination configuration can also be read from destination service . Here are the Approuter limitations to destination properties configuration from destination service : Property Additional Property Description Type only HTTP supported. Authentication All authentication types are supported. Note: User and Password are mandatory if the authentication type is basic authentication . Note: if the authentication type set to principal propagation the ProxyType have to be on-premise . Note: if the authentication type set to OAuth2SAMLBearerAssertion , uaa.user scope in xs-security.json is required. ProxyType Supported proxy type : on-premise , internet . Note: if ProxyType set to on-premise , binding to SAP Cloud Platform connectivity service is required.","title":"Destination service"},{"location":"apis/approuter/#optional-additional-properties","text":"Property Additional Property Description HTML5.ForwardAuthToken x If true the OAuth token will be sent to the destination. The default value is false . This token contains user identity, scopes and other attributes. It is signed by the UAA so it can be used for user authentication and authorization with backend services. Note: if ProxyType set to on-premise , ForwardAuthToken property should not be set. Note: if Authentication type is other than NoAuthentication, ForwardAuthToken property should not be set. HTML5.Timeout x Positive integer representing the maximum wait time for a response (in milliseconds) from the destination. Default is 30000ms. Note: The timeout specified will also apply to the destination's logout path or service's logout path (if you have set one). HTML5.PreserveHostHeader x If true , the application router preserves the host header in the backend request. This is expected by some back-end systems like AS ABAP, which do not process x-forwarded-* headers. HTML5.DynamicDestination x If true , the application router allows to use this destination dynamically on host or path level. HTML5.SetXForwardedHeaders x If true , the application router adds X-Forwarded-(Host, Path, Proto) headers to the backend request.Default value is true. sap-client x If provided, the application router propagates the sap-client and its value as a header in the backend request. This is expected by ABAP back-end systems. Note: * In case destination with the same name is defined both in environment destination and destination service, the destination configuration will load from the environment. * Destination service available only in Cloud Foundry. * Destinations on destination service instance level are supported.","title":"Optional additional properties:"},{"location":"apis/approuter/#uaa-configuration","text":"The User Account and Authentication (UAA) server is responsible for user authentication. In Cloud Foundry and XS OnPremise Runtime a service is created for this configuration and by using the standard service binding mechanism the content of this configuration is available in the VCAP_SERVICES environment variable. Note: The service should have xsuaa in its tags or the environment variable UAA_SERVICE_NAME should be specified (stating the exact name of the UAA service). During local development the UAA configuration is provided in the default-services.json file. When the UAA is used for authentication the user is redirected to the UAA's login page to enter their credentials. Sample content for a default-services.json file: { \"uaa\" : { \"url\" : \"http://my.uaa.server/\" , \"clientid\" : \"client-id\" , \"clientsecret\" : \"client-secret\" , \"xsappname\" : \"my-business-application\" } } The application router supports the $XSAPPNAME placeholder (upper case letters). You may use it in your route configurations in the scope property. The value of $XSAPPNAME is taken from the UAA configuration (the xsappname property).","title":"UAA configuration"},{"location":"apis/approuter/#additional-headers-configuration","text":"If configured, the application router can send additional http headers in its responses to the client. Additional headers can be set in the httpHeaders environment variable. Sample configuration for additional headers: [ { \"X-Frame-Options\" : \"ALLOW-FROM http://localhost\" }, { \"Test-Additional-Header\" : \"1\" } ] In this case the application router will send two additional headers in the responses to the client. Caution: For security reasons, the following headers must not be configured: authorization', 'cookie', and 'set-cookie'.","title":"Additional headers configuration"},{"location":"apis/approuter/#additional-cookies-configuration","text":"If configured, the application router will send additional cookies in its responses to the client. Additional cookies can be set in the COOKIES environment variable. Example of configuration for cookies in the manifest.yml : env: COOKIES: > { \"SameSite\" : \"None\" } In this example, the application router sets the SameSite cookie attribute to None for the JSESSIONID cookie in the responses to the client. Note: Currently, only the SameSite cookie is supported","title":"Additional cookies configuration"},{"location":"apis/approuter/#plugins-configuration","text":"A plugin serves almost the same purpose as routes . The difference is that plugins can be configured through the environment and that way you can add new routes to the application router without changing the design-time artefact xs-app.json . The plugin configuration properties are the same as those of a route except that you can't configure localDir , replace and cacheControl . Property Type Optional Description name String The name of this plugin source String/Object Describes a regular expression that matches the incoming request URL . Note: A request matches a particular route if its path contains the given pattern. To ensure the RegExp matches the complete path, use the following form: ^ $`. Note: Be aware that the RegExp is applied to on the full URL including query parameters. target String x Defines how the incoming request path will be rewritten for the corresponding destination. destination String An alphanumeric name of the destination to which the incoming request should be forwarded. authenticationType String x The value can be xsuaa , basic or none . The default one is xsuaa . When xsuaa is used the specified UAA server will handle the authentication (the user is redirected to the UAA's login form). The basic mechanism works with SAP HANA users. If none is used then no authentication is needed for this route. csrfProtection Boolean x Enable CSRF protection for this route. The default value is true . scope Array/String/Object x Scopes are related to the permissions a user needs to access a resource. This property holds the required scopes to access the target path. Access is granted if the user has at least one of the listed scopes. Sample content of the plugins environment variable: [ { \"name\" : \"insecurePlugin\" , \"source\" : \"/plugin\" , \"destination\" : \"plugin\" , \"target\" : \"/\" , \"csrfProtection\" : false , \"scope\" : [ \"viewer\" , \"reader\" ] }, { \"name\" : \"publicPlugin\" , \"source\" : \"/public-plugin\" , \"destination\" : \"publicPlugin\" , \"authenticationType\" : \"none\" } ]","title":"Plugins configuration"},{"location":"apis/approuter/#session-timeout","text":"For example, if you have the following line in your manifest.yml or manifest-op.yml file: - name: node-hello-world memory: 100M path: web env: SESSION_TIMEOUT: 40 After 40 minutes of user inactivity (no requests have been sent to the application router), a Central Logout will be triggered due to session timeout. Note: The application router depends on the UAA server for user authentication, if the authenticationType for a route is xsuaa . The UAA server may have a different session timeout configured. It is recommended that the configurations of the application router and the UAA are identical.","title":"Session timeout"},{"location":"apis/approuter/#x-frame-options-configuration","text":"Application router sends X-Frame-Options header by default with value SAMEORIGIN . This behaviour can be changed in 2 ways: Disable sending the default header value by setting SEND_XFRAMEOPTIONS environment variable to false Override the value to be sent via additional headers configuration","title":"X-Frame-Options configuration"},{"location":"apis/approuter/#cross-origin","text":"The CORS keyword enables you to provide support for cross-origin requests, for example, by allowing the modification of the request header. Cross-origin resource sharing (CORS) permits Web pages from other domains to make HTTP requests to your application domain, where normally such requests would automatically be refused by the Web browser's security policy. Cross-origin resource sharing(CORS) is a mechanism that allows restricted resources on a webpage to be requested from another domain (/protocol/port) outside the domain (/protocol/port) from which the first resource was served. CORS configuration enables you to define details to control access to your application resource from other Web browsers. For example, you can specify where requests can originate from or what is allowed in the request and response headers. The Cross-Origin configuration is provided in the CORS environment variable. The CORS configuration is an array of objects. Here are the properties that a CORS object can have: Property Type Optional Description uriPattern String A regular expression representing for which source routes CORS configuration is applicable. To ensure the RegExp matches the complete path, surround it with ^ and $. Defaults: none. allowedOrigin Array A comma-separated list of objects that each one of them containing host name, port and protocol that are allowed by the server.for example: [{?host?: \"www.sap.com\"}] or [{?host?: ? .sap.com?}]. Note: matching is case-sensitive. In addition, if port or protocol are not specified the default is ?_ _?. Defaults: none. allowedMethods Array of upper-case HTTP methods x Comma-separated list of HTTP methods that are allowed by the server. Defaults: [?GET?, ?POST?, ?HEAD?, ?OPTIONS?] (all) applies. Note: matching is case-sensitive. maxAge Number x A single value specifying how long, in seconds, a preflight response should be cached. A negative value will prevent CORS Filter from adding this response header to pre-flight response. Defaults: 1800. allowedHeaders Array of headers x Comma-separated list of request headers that are allowed by the serve. Defaults: [?Origin?, ?Accept?, ?X-Requested-With?, ?Content-Type?, ?Access-Control-Request-Method?, ?Access-Control-Request-Headers?]. exposeHeaders Array of headers x Comma-separated list of response headers (other than simple headers) that can be exposed. Defaults: none. allowedCredentials Boolean x A flag that indicates whether the resource supports user credentials. Defaults: true. Sample content of the CORS environment variable: [ { \"uriPattern\" : \"^\\route1$\" , \"allowedMethods\" : [ \"GET\" ], \"allowedOrigin\" : [ { \"host\" : \"my_example.my_domain\" , \"protocol\" : \"https\" , \"port\" : 345 } ], \"maxAge\" : 3600 , \"allowedHeaders\" : [ \"Authorization\" , \"Content-Type\" ], \"exposeHeaders\" : [ \"customHeader1\" , \"customHeader2\" ], \"allowedCredentials\" : true } ] It is also possible to include the CORS in the manifest.yml and manifest-op.yml files: - name: node-hello-world memory: 100M path: web env: CORS: > [ { \"allowedOrigin\":[ { \"host\":\"my_host\", \"protocol\":\"https\" } ], \"uriPattern\":\"^/route1$\" } ] For route with source that match the REGEX ?^\\route1$?, the CORS configuration is enabled.","title":"Cross-Origin"},{"location":"apis/approuter/#routes","text":"A route is a configuration that instructs the application router how to process an incoming request with a specific path. Property Type Optional Description source String/Object Describes a regular expression that matches the incoming request URL . Note: A request matches a particular route if its path contains the given pattern. To ensure the RegExp matches the complete path, use the following form: ^ $`. Note: Be aware that the RegExp is applied to on the full URL including query parameters. httpMethods Array of upper-case HTTP methods x Which HTTP methods will be served by this route; the methods supported are: DELETE , GET , HEAD , OPTIONS , POST , PUT , TRACE , PATCH (no extension methods are supported). If this option is not specified, the route will serve any HTTP method. target String x Defines how the incoming request path will be rewritten for the corresponding destination or static resource. destination String x The name of the destination to which the incoming request should be forwarded. The destination name can be a static string or a regular expression that defines how to dynamically fetch the destination name from the source property or from the host. service String x The name of the service to which the incoming request should be forwarded. endpoint String x The name of the endpoint within the service to which the incoming request should be forwarded. Can only be used in a route containing a service attribute. localDir String x Folder in the working directory from which the application router will serve static content Note: localDir routes support only HEAD and GET requests; requests with any other method receive a 405 Method Not Allowed. replace Object x An object that contains the configuration for replacing placeholders with values from the environment. It is only relevant for static resources . Its structure is described in Replacements . authenticationType String x The value can be xsuaa , basic or none . The default one is xsuaa . When xsuaa is used the specified UAA server will handle the authentication (the user is redirected to the UAA's login form). The basic mechanism works with SAP HANA users. If none is used then no authentication is needed for this route. csrfProtection Boolean x Enable CSRF protection for this route. The default value is true . scope Array/String/Object x Scopes are related to the permissions a user needs to access a resource. This property holds the required scopes to access the target path. cacheControl String x String representing the value of the Cache-Control header, which is set on the response when serving static resources. By default the Cache-Control header is not set. It is only relevant for static resources. identityProvider String x The name of the identity provider to use if provided in route\u2019s definition. If not provided, the route will be authenticated with the default identity provider. Note: If the authenticationType is set to Basic Authentication or None, do not define the identityProvider property. Note: The properties destination , localDir and service are optional, but exactly one of them must be defined. Note: When using the property replace it is mandatory to define the localDir property. Note: The cacheControl property is effective only when one of the following settings is performed: * The localDir property was set * A service pointing to HTML5 Application Repository (\"service\": \"html5-apps-repo-rt\") was set","title":"Routes"},{"location":"apis/approuter/#example-routes","text":"For example, if you have a configuration with the following destination: [ { \"name\" : \"app-1\" , \"url\" : \"http://localhost:3001\" } ] Here are some sample route configurations: Route with a destination and no target { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"app-1\" } Since there is no target property for that route, no path rewriting will take place. If we receive /app1/a/b as a path, then a request to http://localhost:3001/app1/a/b is sent. The source path is appended to the destination URL. Route with case-insensitive matching { \"source\" : { \"path\" : \"^/app1/(.*)$\" , \"matchCase\" : false }, \"destination\" : \"app-1\" } This example is much like the previous one, but instead of accepting only paths starting with /app1/ , we accept any variation of app1 's case. That means if we receive /ApP1/a/B , then a request to http://localhost:3001/ApP1/a/B is sent. Note: The property matchCase has to be of type boolean. It is optional and has a default value true . Route with a destination and a target { \"source\" : \"^/app1/(.*)$\" , \"target\" : \"/before/$1/after\" , \"destination\" : \"app-1\" } Route with a service , a target and an endpoint { \"source\" : \"^/odata/v2/(.*)$\" , \"target\" : \"$1\" , \"service\" : \"com.sap.appbasic.country\" , \"endpoint\" : \"countryservice\" } When a request with path /app1/a/b is received, the path rewriting is done according to the rules in the target property. The request will be forwarded to http://localhost:3001/before/a/b/after. Note: In regular expressions there is the term capturing group . If a part of a regular expression is surrounded with parenthesis, then what has been matched can be accessed using $ + the number of the group (starting from 1). In the last example $1 is mapped to the (.*) part of the regular expression in the source property. Route with dynamic destination and target { \"source\" : \"^/destination/([^/]+)/(.*)$\" , \"target\" : \"$2\" , \"destination\" : \"$1\" , \"authenticationType\" : \"xsuaa\" } If you have a another destination configured: [ { \"name\" : \"myDestination\" , \"url\" : \"http://localhost:3002\" } ] when a request with the path /destination/myDestination/myTarget is received, the destination will be replaced with the url from \"myDestination\", the target will get \"myTarget\" and the request will be redirected to http://localhost:3002/myTarget Note: You can use a dynamic value (regex) or a static string for both destination and target values Note: The approuter first looks for the destination name in the mainfest.yaml file, and if not found, looks for it in the destination service. Destination In Host For legacy applications that do not support relative URL paths, you need to define your URL in the following way to enable the destination to be extracted from the host the url should be defined in the following way: https://<tenant>-<destination>.<customdomain>/<pathtofile> To enable the application router to determine the destination of the URL host, a DESTINATION_HOST_PATTERN attribute must be provided as an environment variable. Example: When a request with the path https://myDestination.some-approuter.someDomain.com/app1/myTarget is received, the following route is used: { \"source\" : \"^/app1/([^/]+)/\" , \"target\" : \"$1\" , \"destination\" : \"*\" , \"authenticationType\" : \"xsuaa\" } In this example, the target will be extracted from the source and the \u2018$1\u2019 value is replaced with \u2018myTarget\u2019. The destination value is extracted from the host and the \u2018*\u2019 value is replaced with \u2018myDestination\u2019. Route with a localDir and no target { \"source\" : \"^/web-pages/(.*)$\" , \"localDir\" : \"my-static-resources\" } Since there is no target property for that route, no path rewriting will take place. If we receive a request with a path /web-pages/welcome-page.html , the local file at my-static-resources/web-pages/welcome-page.html under the working directory will be served. Route with a localDir and a target { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"localDir\" : \"my-static-resources\" } If we receive a request with a path '/web-pages/welcome-page.html', the local file at 'my-static-resources/welcome-page.html' under the working directory will be served. Note: The capturing group used in the target property. Route with localDir and cacheControl { \"source\" : \"^/web-pages/\" , \"localDir\" : \"my-static-resources\" , \"cacheControl\" : \"public, max-age=1000,must-revalidate\" } Route with service \"html5-apps-repo-rt\" and cacheControl { \"source\" : \"^/index.html$\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"cacheControl\" : \"public,max-age=1000,must-revalidate\" } Route with httpMethods restrictions The httpMethods option allows you to split the same path across different targets depending on the HTTP method. For example: { \"source\" : \"^/app1/(.*)$\" , \"target\" : \"/before/$1/after\" , \"httpMethods\" : [ \"GET\" , \"POST\" ] } This route will be able to serve only GET and POST requests. Any other method (including extension ones) will get a 405 Method Not Allowed response. The same endpoint can be split across multiple destinations depending on the HTTP method of the requests: { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-1\" , \"httpMethods\" : [ \"GET\" ] } , { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-2\" , \"httpMethods\" : [ \"DELETE\" , \"POST\" , \"PUT\" ] } The setup above will route GET requests to the target dest-1 , DELETE, POST and PUT to dest-2 , and any other method receives a 405. It is also possible to specify \"catchAll\" routes, namely those that do not specify httpMethods restrictions: { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-1\" , \"httpMethods\" : [ \"GET\" ] } , { \"source\" : \"^/app1/(.*)$\" , \"destination\" : \"dest-2\" } In the setup above, GET requests will be routed to dest-1 , and all the rest to dest-2 . Why using httpMethods ? It is often useful to split the implementation of microservices across multiple, highly specialized applications. For example, a Java application written to serve high amounts of GET requests that return large payloads is implemented, sized, scaled and load-tested differently than applications that offer APIs to upload limited amounts of data. httpMethods allows you to split your REST APIs, e.g., /Things to different applications depending on the HTTP methods of the requests, without having to make the difference visible in the URL of the endpoints. Another usecase for httpMethods is to \"disable\" parts of the REST API. For example, it may be necessary to disable some endpoints that accept DELETE for external usage. By whitelisting in the relative route only the allow methods, you can hide functionalities of your microservice that should not be consumable without having to modify the code or configurations of your service. Note: localDir and httpMethods are incompatible. The following route is invalid: { \"source\" : \"^/app1/(.*)$\" , \"target\" : \"/before/$1/after\" , \"localDir\" : \"resources\" , \"httpMethods\" : [ \"GET\" , \"POST\" ] } However, since localDir supports only GET and HEAD requests, returning 405 to requests with any other method, any localDir route is \"implicitly\" restricted in terms of supported HTTP methods. Route with a scope An application specific scope has the following format: <application-name>.<scope-name> It is possible to configure what scope the user needs to possess in order to access a specific resource. Those configurations are per route . In this example, the user should have at least one of the scopes in order to access the corresponding resource. { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"scope\" : [ \"$XSAPPNAME.viewer\" , \"$XSAPPNAME.reader\" , \"$XSAPPNAME.writer\" ] } For convenience if our route requires only one scope the scope property can be a string instead of an array. The following configuration is valid as well: { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"scope\" : \"$XSAPPNAME.viewer\" } You can configure scopes for the different HTTP methods (GET, POST, PUT, HEAD, DELETE, CONNECT, TRACE, PATCH and OPTIONS). If some of the HTTP methods are not explicitly set, the behaviour for them is defined by the default property. In case there is no default property specified and the HTTP method is also not specified, the request is rejected by default. { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"scope\" : { \"GET\" : \"$XSAPPNAME.viewer\" , \"POST\" : [ \"$XSAPPNAME.reader\" , \"$XSAPPNAME.writer\" ], \"default\" : \"$XSAPPNAME.guest\" } } The application router supports the $XSAPPNAME placeholder. Its value is taken (and then substituted in the routes) from the UAA configuration. You may read more about it here . Note: The substitution is case sensitive. You can use the name of the business application directly instead of using the $XSAPPNAME placeholder: { \"source\" : \"^/backend/(.*)$\" , \"scope\" : \"my-business-application.viewer\" } Examples for Routes With identityProvider For example, we can define several identity providers for different types of users. In this example, there are 2 categories: hospital patients and hospital personnel: 1. patientsIDP \u2013 use for authenticating patients. 2. hospitalIDP \u2013 use for authenticating all hospital personnel (doctors, nurses etc..). We can configure 2 routes with the following identityProvider properties: [ { \"source\" : \"^/patients/sap/opu/odata/(.*)\" , \"target\" : \"/sap/opu/odata$1\" , \"destination\" : \"backend\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"patientsIDP\" }, { \"source\" : \"^/hospital/sap/opu/odata/(.*)\" , \"target\" : \"/sap/opu/odata$1\" , \"destination\" : \"backend\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"hospitalIDP\" } ] So, a patient who tries to log into the system will be authenticated by patientIDP, and a doctor who tries to log in will be authenticated by hospitalIDP. Note: After logging in using one of the identity providers, to switch to the other one it is necessary to logout and perform a new log in. Note: Currently, dynamic provisioning of the subscriber account identity provider is not supported. Note: Identity provider configuration is only supported in the client side login redirect flow.","title":"Example routes"},{"location":"apis/approuter/#replacements","text":"This object configures the placeholder replacement in static text resources. Property Type Description pathSuffixes Array An array containing the path suffixes that are relative to localDir . Only files with a path ending with any of these suffixes will be processed. vars Array A whitelist with the environment variables that will be replaced in the files matching the suffix. services Object An object describing bound services that will provide replacement values. Each property of this object is used to lookup a separate service. The property names are arbitrary. Service lookup format is described in Service Query section in @sap/xsenv documentation. The supported tags for replacing environment variables are: {{ENV_VAR}} and {{{ENV_VAR}}} . If there is such an environment variable it will be replaced, otherwise it will be just an empty string. For services you can specify a property from the credentials section of the service binding which will be replaced. For example {{{my_service.property}}} and {{my_service.property}} Every variable that is replaced using two-brackets syntax will be HTML-escaped. For example if the value of the environment variable is ab\"cd the result will be ab&amp;quot;cd . The triple brackets syntax is used when the replaced values don't need to be escaped and all values will be unchanged. For example, if somewhere in your xs-app.json you have a route: { \"source\" : \"^/get/home(.*)\" , \"target\" : \"$1\" , \"localDir\" : \"resources\" , \"replace\" : { \"pathSuffixes\" : [ \"index.html\" ], \"vars\" : [ \"escaped_text\" , \"NOT_ESCAPED\" ], \"services\" : { \"my-sapui5-service\" : { \"tag\" : \"ui5\" } } } } and you have the following index.html : < html > < head > < title > {{escaped_text}} </ title > < script src = \"{{{NOT_ESCAPED}}}/index.js\" /> < script src = \"{{{my-sapui5-service.url}}}\" /> </ head > </ html > then in index.html , {{escaped_text}} and {{{NOT_ESCAPED}}} will be replaced with the values of the environment variables escaped_text and NOT_ESCAPED . If you have a service in VCAP_SERVICES like: { \"sapui5_service\" : [{ \"name\" : \"sapui5\" , \"tags\" : [ \"ui5\" ], \"credentials\" : { \"url\" : \"http://sapui5url\" } }] } then {{{my-sapui5-service.url}}} will be replaced with the url property from sapui5 service - in this case http://sapui5url . Note: All index.html files will be processed. If you want to replace only specific files, you have to set the path of the file relative to localDir . Note: All files should be UTF-8 encoded. Note: If a service is not found an error is thrown on startup. Note: If a service and an environment variable from vars have the same name, an error is thrown on startup. The returned content type is based on the file extension. Currently the supported file extensions are: * .json - application/json * .txt - text/plain * .html - text/html * .js - application/javascript * .css - test/css If the file extension is different, the default content type is text/html . Example for pathSuffixes : { \"pathSuffixes\" : [ \".html\" ] } The suffix .html means that all files with the extension .html under localDir and it's subfolders will be processed. { \"pathSuffixes\" : [ \"/abc/main.html\" , \"some.html\" ] } The suffix /abc/main.html means that all files named main.html which are inside a folder named abc will be processed. The suffix some.html means that all files which have a name that ends with some.html will be processed. For example: some.html , awesome.html . { \"pathSuffixes\" : [ \"/some.html\" ] } The suffix /some.html means that all files which have the exact name some.html will be processed. For example: some.html , /abc/some.html . Note: URL path parameters are not supported for replacements. For example, replacements will not work if the path looks like '/test;color=red/index.html'. For more information regarding path parameters refer to http://tools.ietf.org/html/rfc3986#section-3.3 .","title":"Replacements"},{"location":"apis/approuter/#xs-appjson-configuration-file","text":"This is the main configuration file of the application router. It contains a JSON object with the following properties: Property Type Optional Description welcomeFile String x The client is redirected to this page by default, if the request does not have a path. For more information, see welcomeFile . authenticationMethod String x If set to none the UAA login roundtrip is disabled. If the property is not set and authentication is defined per route , the value is set to route by default. sessionTimeout Number x Used to set session timeout. The default is 15 minutes. If the SESSION_TIMEOUT environment variable is set this property will be overwritten. routes Array x Contains all route configurations. The position of a configuration in this array is of significance for the application router in case a path matches more than one source . The first route whose source matches the path of the incoming request gets activated. login Object x Contains the configuration for the endpoint of the application router which will be used by the UAA during the OAuth2 authentication routine. By default this endpoint is /login/callback . logout Object x Provides options for a Central Logout endpoint and a page to which the client to be redirected by the UAA after logout. destinations Object x Additional options for your destinations (besides the ones in the destinations environment variable). services Object x Additional options for your business services. compression Object x Configuration regarding compressing resources before responding to the client. If the COMPRESSION environment variable is set it will overwrite existing values. pluginMetadataEndpoint String x Adds an endpoint that will serve a JSON representing all configured plugins. whitelistService Object x Options for the whitelist service preventing clickjack attacks. websockets Object x Options for the web socket communication . errorPage Array x Optional configuration to set-up a custom error pages whenever the approuter encouters an error.","title":"xs-app.json configuration file"},{"location":"apis/approuter/#welcomefile-property","text":"Approuter will redirect to this URL when / (root path) is requested. This could be a file located inside the static resources folder or a resource hosted at a different location. Note: Approuter will serve the content of the resource instead of returning a redirect if the request contains a x-csrf-token: fetch header. See CSRF Protection . Example: \"welcomeFile\" : \"/web-pages/hello-world.html\" web-pages has to be a part of a local resource or an external destination { \"source\" : \"^/web-pages/(.*)$\" , \"localDir\" : \"my-static-resources\" } or { \"source\" : \"^/web-pages/(.*)$\" , \"target\" : \"$1\" , \"destination\" : \"mydest\" } Note: If there isn't a route with a localDir property, the folloing default is added to the list of routes: { \"source\" : \"^/(.*)$\" , \"localDir\" : \"resources\" }","title":"welcomeFile property"},{"location":"apis/approuter/#authenticationmethod-property","text":"It may have the following values: none - disables authentication for all routes route - authentication type is defined in the route configurations The default value is route .","title":"authenticationMethod property"},{"location":"apis/approuter/#routes-property","text":"It holds an array of route configuration objects. The order of the configurations is important for the application router. The first route whose source pattern gets matched with the path of the incoming request will be activated. See Routes for more info.","title":"routes property"},{"location":"apis/approuter/#login-property","text":"A redirect to the application router at a specific endpoint takes place during OAuth2 authentication with UAA. This endpoint can be configured in order to avoid possible collisions. For example: \"login\" : { \"callbackEndpoint\" : \"/custom/login/callback\" } The default endpoint is /login/callback .","title":"login property"},{"location":"apis/approuter/#logout-property","text":"In this object you can define your business application's central logout endpoint through the logoutEndpoint property. For example, if somewhere in your xs-app.json you have: \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" } This will open an endpoint on application router which, when requested, will trigger the central logout routine. Changing the browser location from the client-side JavaScript code: window . location . replace ( '/my/logout' ); will trigger client initiated central Logout. In addition, a page to which the user will be redirected by the UAA after logout can be configured using the logoutPage property. It may hold: URL path - the UAA will redirect the user back to the application router and the path will be interpreted according the configured routes . The logoutEndpoint can be called with query parameters. For example: window . location . replace ( '/my/logout?siteId=3' ); These parameters will be appended as is to the redirect url set by the logoutPage property. For example, if the logout section is the following: \"logout\": { \"logoutEndpoint\": \"/logout\", \"logoutPage\": \"/logoff.html\" }, The redirect url will end with: /logoff.html?siteId=3 Note : The resource that matches the path should not require authentication. The property authenticationType should be set to none for that particular route. Example: { \"authenticationMethod\" : \"route\" , \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"/logout-page.html\" }, \"routes\" : [ { \"source\" : \"^/logout-page.html$\" , \"localDir\" : \"my-static-resources\" , \"authenticationType\" : \"none\" } ] } In this case my-static-resources (contains logout-page.html ) is a folder with static resources in the working directory of the application router. Note : Be sure that your main route in your xs-app.json resource that matches the path is not cached by browser. Therefore, the best practice here would be to model cacheControl accordingly: { \"routes\" : [ { \"source\" : \"^/ui/index.html\" , \"target\" : \"index.html\" , \"localDir\" : \"web\" , \"cacheControl\" : \"no-cache, no-store, must-revalidate\" } ] } Absolute http(s) URL - the UAA will redirect the user to a page (or application) different from the application router. For example: \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"http://employees.portal\" } Note : UAA will execute redirect only in case redirect URL is a valid redirect-uri in xs-security.json - redirect-uris are maintained as part of the oauth2-configuration section in the UAA application security descriptor JSON file given at the creation of the service instance. For example: UAA application security descriptor: \"oauth2-configuration\": { \"redirect-uris\": [ \"http://employees.portal\" ] }","title":"logout property"},{"location":"apis/approuter/#destinations-property","text":"Let's say you have a destination called node-backend . You can specify options for it by adding the destinations property in your xs-app.json: \"destinations\" : { \"node-backend\" : {} } The value of node-backend should be an object with the following properties: Property Type Optional Description logoutPath String x The logout endpoint for your destination. logoutMethod String x Could be POST, PUT, GET. The default value is POST. The logoutPath will be called when Central Logout is triggered or a session is deleted due to timeout. The request to the logoutPath will contain additional headers, including the JWT token. The logoutMethod property specifies the HTTP method with which the logoutPath will be requested. For example: { \"destinations\" : { \"node-backend\" : { \"logoutPath\" : \"/ui5logout\" , \"logoutMethod\" : \"GET\" } } }","title":"destinations property"},{"location":"apis/approuter/#services-property","text":"Let's say you have a service called com.sap.appbasic.country . You can specify options for it by adding the services property in your xs-app.json: \"services\" : { \"com.sap.appbasic.country\" : {} } The value of com.sap.appbasic.country should be an object with the following properties: Property Type Optional Description endpoint String x The name of the attribute in the VCAP_SERVICES that contains the URL of the service. logoutPath String x The path to be used when logging out from the service. logoutMethod String x Could be POST, PUT, GET. The default value is POST. The logoutPath will be called when Central Logout is triggered or a session is deleted due to timeout. The request to the logoutPath will contain additional headers, including the JWT token in header authorization and approuter host in header x-approuter-host . The logoutMethod property specifies the HTTP method with which the logoutPath will be requested. For example: { \"services\" : { \"com.sap.appbasic.country\" : { \"endpoint\" : \"countryservice\" , \"logoutPath\" : \"/countrieslogout\" , \"logoutMethod\" : \"GET\" } } }","title":"services property"},{"location":"apis/approuter/#compression-property","text":"By default text resources are compressed before being sent to the client. The default threshold for using compression is 1K. Text resources under this size will not be compressed. If you need to change the compression size threshold, you can add the optional property minSize . Here is an example of a compression section (2048 bytes): { \"compression\" : { \"minSize\" : 2048 } } Property Type Optional Description minSize Number x Text resources larger than this size will be compressed. enabled Boolean x Globally disables or enables compression. Default value is true. Note: There are 3 ways to disable compression: * Global - within the compression section add \"enabled\": false * Front-End - the client sends a header Accept-Encoding which omits gzip * Backend - the application sends a header Cache-Control with the 'no-transform' directive Example of globally disabling compression using the environment variable COMPRESSION : { \"enabled\" : false } Note: The header field Content-Length is used to determine the resource size. If Content-Length is missing, the chunk size is used to determine whether to compress the resource. For more information, see the npm module compression.","title":"compression property"},{"location":"apis/approuter/#pluginmetadataendpoint-property","text":"Example: { \"pluginMetadataEndpoint\" : \"/metadata\" } Note : If you request relative path /metadata of your application, you will receive a JSON with configured plugins.","title":"pluginMetadataEndpoint property"},{"location":"apis/approuter/#whitelistservice-property","text":"Enabling the whitelist service is used for prevention of clickjack attacks. An endpoint accepting GET requests will be opened at the relative path configured in the endpoint property. For more details see Whitelist service section. Example: { \"whitelistService\" : { \"endpoint\" : \"/whitelist/service\" } }","title":"whitelistService property"},{"location":"apis/approuter/#websockets-property","text":"For more details about the web socket communication see Web sockets section. Example: { \"websockets\" : { \"enabled\" : true } } To use Websockets when approuter is integrated with HTML5 Application Repository, this property should be added to the xs-app.json of the deployed HTML5 application. When an incoming request for an application in the repository goes through approuter, approuter retrieves the application's configuration from the repository. If this flag is set, approuter creates a websockets connection with the backend (the target url of the request) and acts as a proxy which delivers messages on top of ws protocol from the backend to the user and vice versa.","title":"websockets property"},{"location":"apis/approuter/#errorpage-property","text":"By default, errors originating in the application router are shown the status code of the error. It is also possible to display a custom error page using the errorPage property. The property is an array of objects, each object having the following properties: Property Type Optional Description status Number/Array HTTP status code file String File path relative to the working directory of the application router Example: { \"errorPage\" : [ { \"status\" : [ 400 , 401 , 402 ], \"file\" : \"./custom-err-40x.html\" }, { \"status\" : 501 , \"file\" : \"./http_resources/custom-err-501.html\" } ] } In the example above 400, 401 and 402 errors would be shown the content of ./custom-err-4xx.html and for 501 errors the user would see ./http_resources/custom-err-501.html . Note: The errorPage conifiguration section has no effect on errors generated outside of the application router.","title":"errorPage property"},{"location":"apis/approuter/#complete-example-of-an-xs-appjson-configuration-file","text":"","title":"Complete example of an xs-app.json configuration file"},{"location":"apis/approuter/#without-html5-application-repository-integration","text":"{ \"welcomeFile\" : \"index.html\" , \"authenticationMethod\" : \"route\" , \"sessionTimeout\" : 10 , \"pluginMetadataEndpoint\" : \"/metadata\" , \"routes\" : [ { \"source\" : \"^/sap/ui5/1(.*)$\" , \"target\" : \"$1\" , \"destination\" : \"ui5\" , \"csrfProtection\" : false }, { \"source\" : \"/employeeData/(.*)\" , \"target\" : \"/services/employeeService/$1\" , \"destination\" : \"employeeServices\" , \"authenticationType\" : \"xsuaa\" , \"scope\" : [ \"$XSAPPNAME.viewer\" , \"$XSAPPNAME.writer\" ], \"csrfProtection\" : true }, { \"source\" : \"^/(.*)$\" , \"target\" : \"/web/$1\" , \"localDir\" : \"static-content\" , \"replace\" : { \"pathSuffixes\" : [ \"/abc/index.html\" ], \"vars\" : [ \"NAME\" ] } } ], \"login\" : { \"callbackEndpoint\" : \"/custom/login/callback\" }, \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"/logout-page.html\" }, \"destinations\" : { \"employeeServices\" : { \"logoutPath\" : \"/services/employeeService/logout\" , \"logoutMethod\" : \"GET\" } }, \"compression\" : { \"minSize\" : 2048 }, \"whitelistService\" : { \"endpoint\" : \"/whitelist/service\" }, \"websockets\" : { \"enabled\" : true }, \"errorPage\" : [ { \"status\" : [ 400 , 401 , 402 ], \"file\" : \"/custom-err-4xx.html\" }, { \"status\" : 501 , \"file\" : \"/custom-err-501.html\" } ] }","title":"Without HTML5 Application Repository integration:"},{"location":"apis/approuter/#with-html5-application-repository-integration-xs-appjson-file-stored-in-html5-application-repository","text":"{ \"welcomeFile\" : \"index.html\" , \"authenticationMethod\" : \"route\" , \"routes\" : [ { \"source\" : \"/employeeData/(.*)\" , \"target\" : \"/services/employeeService/$1\" , \"destination\" : \"employeeServices\" , \"authenticationType\" : \"xsuaa\" , \"scope\" : [ \"$XSAPPNAME.viewer\" , \"$XSAPPNAME.writer\" ], \"csrfProtection\" : true }, { \"source\" : \"^/odata/v2/(.*)$\" , \"target\" : \"$1\" , \"service\" : \"com.sap.appbasic.country\" , \"endpoint\" : \"countryservice\" }, { \"source\" : \"^(/.*)$\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" } ], \"logout\" : { \"logoutEndpoint\" : \"/my/logout\" , \"logoutPage\" : \"/logout-page.html\" }, \"destinations\" : { \"employeeServices\" : { \"logoutPath\" : \"/services/employeeService/logout\" , \"logoutMethod\" : \"GET\" } }, \"services\" : { \"com.sap.appbasic.country\" : { \"logoutPath\" : \"/countryService/logout\" , \"endpoint\" : \"countryservice\" , \"logoutMethod\" : \"GET\" } } } Note: The route in bold is the route that provides access to the HTML5 Application Repository service.","title":"With HTML5 Application Repository integration (xs-app.json file stored in HTML5 Application Repository):"},{"location":"apis/approuter/#headers","text":"","title":"Headers"},{"location":"apis/approuter/#forwarding-headers","text":"The application router passes the following x-forwarding-* headers to the route targets: Header Name Description x-forwarded-host Contains the Host header which was sent by the client to the application router. x-forwarded-proto Contains the protocol which was used by the client to connect to the application router. x-forwarded-for Contains the address of the client which connects to the application router. x-forwarded-path Contains the original path which was requested by the client. If a client performs a path rewriting, it sends the x-forwarded-proto, x-forwarded-host, and the x-forwarded-path headers to the application router. The values of these headers are forwarded to the route targets without modifications instead of being generated from the application router request URL. The x-forwarded-path header of a request does not impact the source pattern of routes in the xs-app.json.","title":"Forwarding Headers"},{"location":"apis/approuter/#hop-by-hop-headers","text":"Hop-by-hop headers are meaningful only for a single transport-level connection and therefore are not forwarded by the application router. These headers are: * Connection * Keep-Alive * Public * Proxy-Authenticate * Transfer-Encoding * Upgrade","title":"Hop-by-hop Headers"},{"location":"apis/approuter/#custom-headers","text":"x-custom-host: Contains the internal reverse proxy host. Relevant only if the application router is used behind an internal reverse proxy as well as an external reverse proxy (EXTERNAL_REVERSE_PROXY environment variable is set to true). Add this header to the request to internal reverse proxy. In a multi-tenancy landscape, the application router will calculate the tenant id based on the value of a certain request header as follows: - x-custom-host header or host if EXTERNAL_REVERSE_PROXY is true - x-forwarded-host header or host if EXTERNAL_REVERSE_PROXY is false or not specified","title":"Custom Headers"},{"location":"apis/approuter/#authorization-header-beta-version","text":"x-approuter-authorization: Contains the JWT token to support the Service to Application Router scenario. Caution : You should not use SAP Cloud Platform beta features in subaccounts that belong to productive enterprise accounts. Any use of beta functionality is at the customer's own risk, and SAP shall not be liable for errors or damages caused by the use of beta features. For more information, see Using Beta Features in Subaccounts .","title":"Authorization Header (Beta version)"},{"location":"apis/approuter/#csrf-protection","text":"By default the application router enables CSRF protection for any HTTP method that is not HEAD or GET and the route is not public. A path is considered public , if it does not require authentication. This is the case for routes with authenticationType: none or if authentication is disabled completely via the top level property authenticationMethod: none . To obtain a CSRF token one must send a GET or HEAD request with a x-csrf-token: fetch header to the application router. The application router will return the created token in a x-csrf-token: <token> header, where <token> will be the value of the CSRF token. If a CSRF protected route is requested with any of the above mentioned methods, x-csrf-token: <token> header should be present in the request with the previously obtained token. This request must use the same session as the fetch token request. If the x-csrf-token header is not present or invalid, the application router will return status code 403 Forbidden and a response header x-csrf-token: Required .","title":"CSRF Protection"},{"location":"apis/approuter/#connectivity","text":"The application router supports integration with SAP Cloud Platform connectivity service. The connectivity service handles proxy access to SAP Cloud Platform cloud connector, which tunnels connections to private network systems. In order to use connectivity, a connectivity service instance should be created and bound to the Approuter application. In addition, the relevant destination configurations should have proxyType=OnPremise . Also, a valid XSUAA login token should be obtained via the login flow.","title":"Connectivity"},{"location":"apis/approuter/#saas-application-registration-in-cloud-foundry","text":"The application router supports SaaS registration. A SaaS business application based on application router may be registered in the SaaS registry by creating and binding a SaaS Registry service instance. After fulfilling the CIS process to enable application subscription, the SaaS business application will be visible in the SAP Cloud Platform cockpit in the Cloud Foundry environment for all entitled customers. Once a customer is entitled to the SaaS business application, the subaccounts (tenants) created under the global account will be able to view, subscribe to, and unsubscribe from the application. When a tenant is subscribed/unsubscribed to/from an application, the tenant will be subscribed/unsubscribed: * In the XSUAA instance of the application itself * In the reuse services (e.g.: destination ), if the application is dependent on the reuse service. Also, onboarding and offboarding callbacks will be triggered for the subscribed/unsubscribed application and for the reuse services.","title":"SaaS Application Registration in Cloud Foundry"},{"location":"apis/approuter/#how-to-expose-approuter-for-saas-subscription","text":"","title":"How To Expose Approuter for SaaS Subscription"},{"location":"apis/approuter/#multi-tenancy","text":"The application router should be configured to handle multi-tenant access by maintaining the TENANT_HOST_PATTERN environment configuration.","title":"Multi-tenancy"},{"location":"apis/approuter/#entitle-org-for-saas-registry-consumption","text":"The SaaS Registry service should be available in your space marketplace.","title":"Entitle org for SaaS Registry consumption"},{"location":"apis/approuter/#authorize-lps-for-invoking-callbacks","text":"SaaS business applications should grant LPS the authorization to invoke the application's callbacks. Callback scope should be granted to LPS in the application router\u2019s xs-security.json file: xs-security.json: ... { \"name\":\"$XSAPPNAME.Callback\", \"description\":\"With this scope set, the callbacks for tenant onboarding, offboarding and getDependencies can be called.\", \"grant-as-authority-to-apps\":[ \"$XSAPPNAME(application,sap-provisioning,tenant-onboarding)\" ] } ...","title":"Authorize LPS for invoking callbacks"},{"location":"apis/approuter/#register-an-application-saas-registry-configuration","text":"For a customer to be able to subscribe to an application through the SAP Cloud Platform cockpit, each SaaS business application should register itself on all CF landscapes where it is deployed. To register a SaaS application in LPS, a service instance of saas-registry should be created and the SaaS business application should be bound to it. The instance of saas-registry is created with a configuration json - saas-config.json: . In the configuration.json file a url for the getDependencies and onSubscription callbacks must be provided. Note that the path segment of these urls are configurable however the tenantId url variable in onSubscription callback must be provided anyway. { \"appId\" : \"<appId>\", # xsappname generated by XSUAA - can be obtained by checking the xsuaa-> xsappname by executing: cf env <application name> \"appName\" : \"<appName>\", # Business application name to be shown to subscribers \"appUrls\": { \"getDependencies\" : \"<approuter-host>/callback/v1.0/dependencies\", \"onSubscription\" : \"<approuter-host>/callback/v1.0/tenants/{tenantId}\" }, \"providerTenantId\" : \"<tenant>\" # Approuter provider account tenant ID. }","title":"Register an application (SaaS Registry Configuration)"},{"location":"apis/approuter/#integration-with-html5-application-repository","text":"The application router supports seamless integration with the HTML5 Application Repository service. When the application router interacts with HTML5 Application Repository to serve HTML5 Applications, all static content and routes (xs-app.json) are retrieved from HTML5 Application Repository. In case application router needs to route to non HTML5 Applications, it is possible to model that in the xs-app.json of the application router. To integrate HTML5 Application Repository to an application router based it is required to create an instance of html5-apps-repo service of plan app-runtime and bind it to the application. xs-app.json routes that are used to retrieve static content from HTML5 Application Repository may be modeled in the following format: { \"source\": \"^(/.*)\", \"target\": \"$1\", \"service\": \"html5-apps-repo-rt\", \"authenticationType\": \"xsuaa\" }","title":"Integration with HTML5 Application Repository"},{"location":"apis/approuter/#known-gaps-in-integration-with-html5-application-repository","text":"The following limitations apply when application router is bound to HTML5 Application Repository service: It is not possible to implement the \"first\" middleware slot to provide routes dynamically. No option apart from workingDir can be provided in application router start. External session management via extensibility is not supported Note: Mixed scenario of modeling part of the static content in local resources folder and also retrieving static content from HTML5 Application Repository is not supported. Note: This feature is only supported in Cloud Foundry. There is no HTML5 Application Repository service in XSA.","title":"Known Gaps in Integration with HTML5 Application Repository"},{"location":"apis/approuter/#runtime-processing","text":"During runtime, based on request url path (see URL Format), application router will try to fetch the xs-app.json file from the corresponding HTML5 Application in HTML5 Application Repository and use it for routing the request. The following algorithm is applied for request processing: * If no HTML5 Application is found in HTML5 Application Repository for current request, central application router xs-app.json will be used for routing * If HTML5 Application exists in HTML5 Application Repository but no xs-app.json file is returned, an error message will be issued and request processing will be stopped.","title":"Runtime Processing"},{"location":"apis/approuter/#url-format","text":"A valid request to application router that uses HTML5 Application Repository must have the following format: https://<tenantId>.<appRouterHost>.<domain>/<bsPrefix>.<appName-appVersion>/<resourcePath> bsPrefix (business service prefix) - Optional * It should be used in case the application is provided by a business service bound to this approuter appName (application name) - Mandatory * Used to uniquely identify the application in HTML5 Application Repository persistence * Must not contain dots or special characters appVersion (application version) - Optional * Used to uniquely identify a specific application version in HTML5 Application Repository persistence * If no version provided, default application version will be used resourcePath (path to file) * The path to the file as it was stored in HTML5 Application Repository persistence","title":"URL Format"},{"location":"apis/approuter/#cache-buster-handling","text":"A cache buster allows the application router to notify the browser to refresh the resources only when the application resources have been changed. Otherwise the resources are always fetched from the browser's cache. This flow applies to requests that should be forwarded to HTML5 Application Repository. If requests are forwarded to backend applications that return data, cache buster handling is not applied. When the second path segment of the request url contains the pattern \u201c~timestamp~\u201d, this segment is removed from the subsequent request to HTML5 Application Repository In case the request had a cache buster segment, application router adds to corresponding response the header: Cache-Control: public, max-age=31536000 Note: Cache buster flow is only supported in HTML5 Application Repository integration flow.","title":"Cache Buster Handling"},{"location":"apis/approuter/#integration-with-business-services","text":"Application router supports integration with Business Services. Business Services are a flavour of reuse-services that expose specific information in VCAP_SERVICES credentials block that enable application router to serve Business Service UI and/or data. * Business Service UI must be stored in HTML5 Application Repository to be accessible from application router * Business Service UI must be defined as \"public\" to be accessible from an application router in a different space than the one from where the UI was uploaded * Business Service data can be served using two grant types: 1. User Token Grant: Application router performs a token exchange between login JWT token and Business Service token and uses it to trigger a request to the Business Service endpoint 2. Client Credentials Grant: Application router generates a client_credentials token and uses it to trigger a request to the Business Service endpoint","title":"Integration with Business Services"},{"location":"apis/approuter/#business-service-credentials","text":"While binding a Business Service instance to application router the following information should be provided in VCAP_SERVICES credentials: sap.cloud.service: Service name as referenced from xs-app.json route and business service prefix (if Business Service UI provided) - Mandatory sap.cloud.service.alias: Short service name alias for user friendly URL business service prefix- Optional endpoints: One or more endpoints that can be used to access Business Service data. html5-apps-repo: html5-apps-repo.app_host_id contains one or more html5-apps-repo service instance GUIDs that can be used to retrieve Business Service UIs - Optional saasregistryenabled: flag that indicates that this Business Service supports SaaS Registry subscription. If provided, application router will return this Business Service xsappname in SaaS Registry getDependencies callback - Optional grant_type: the grant type that should be used to trigger requests to the Business Service. Allowed values: user_token or client_credentials. Default value, in case this attribute is not provided, user_token - Optional The value of endpoints should be an object with the following properties: Property Type Optional Default Description url String URL to access the Business Service data. timeout Number x 30000ms Positive integer representing the maximum wait time for a response (in milliseconds) from the Business Service. For example: \"country\": [ { ... \"credentials\": { \"sap.cloud.service\": \"com.sap.appbasic.country\", \"sap.cloud.service.alias\": \"country\", \"endpoints\": { \"countryservice\": { \"url\": https://icf-countriesapp-test-service.cfapps.sap.hana.ondemand.com/odata/v2/countryservice\"}, \"countryconfig\": { \"url\": https://icf-countriesapp-test-service.cfapps.sap.hana.ondemand.com/rest/v1/countryconfig\", \"timeout\": 120000 } }, \"html5-apps-repo\": { \"app_host_id\": \"1bd7c044-6cf4-4c5a-b904-2d3f44cd5569, 1cd7c044-6cf4-4c5a-b904-2d3f44cd54445\" }, \"saasregistryenabled\": true, \"grant_type\": \"user_token\" ....","title":"Business Service Credentials"},{"location":"apis/approuter/#accessing-business-service-data","text":"To access Business Service data xs-app.json configuration file should have a route referencing a specific sap.cloud.service or sap.cloud.service.alias via the service attribute. If an endpoint attribute is also modeled, it will be used to get the service url otherwise the fallback url or uri attribute will be used. For example: \"routes\": [ { \"source\": \"^/odata/v2/(.*)$\", \"target\": \"$1\", \"service\": \"com.sap.appbasic.country\", \"endpoint\": \"countryservice\" }, In order to support JWT token exchange, the login JWT token should contain the uaa.user scope. For that the xs-security configuration must contain a role template that references the uaa.user scope. For example: { \"xsappname\" : \"simple-approuter\", \"tenant-mode\" : \"shared\", \"scopes\": [ { \"name\": \"uaa.user\", \"description\": \"UAA\" }, { \"name\": \"$XSAPPNAME.simple-approuter.admin\", \"description\": \"Simple approuter administrator\" } ], \"role-templates\": [ { \"name\": \"Token_Exchange\", \"description\": \"UAA\", \"scope-references\": [ \"uaa.user\" ] }, { \"name\": \"simple-approuter-admin\", \"description\": \"Simple approuter administrator\", \"scope-references\": [ \"$XSAPPNAME.simple-approuter.admin\" ] } ] }","title":"Accessing Business Service Data"},{"location":"apis/approuter/#accessing-business-service-ui","text":"Business Service UI's must be stored in HTML5 Application Repository and defined in their manifest.json files as \"public: true\" in order to be accessible from an application router application that is typically running in a different space than the Business Service space. In addition dataSources uris must be relative to base url (no slash as first character). Business Service manifest.json example: { \u201csap.app\u201d: { \u201cid\u201d:\u201ccom.sap.appbasic.country.list\u201d, \u201capplicationVersion: { \u201cversion\u201d: \u201c1.0.0\u201d }, \"dataSources\": { \"mainService\":{ \"uri\": \"odata/v2/countryservice\", \"type\": \"OData\" } }, \u201csap.cloud\u201d: { \"public\": true, \u201cservice\u201d: \u201ccom.sap.appbasic.country\u201c } } A Business Service that exposes UI must provide one or more app-host GUIDs in an html5-apps-repo block in VCAP_SERVICES credentials (see Business Service credentials). To access Business Service UI the request url that hits application router must contain a business service prefix as described above. Request URL example: https://approuter-repo-examples.cfapps.sap.hana.ondemand.com/comsapappbasiccountry.comsapappbasicscountrylist/test/flpSandbox.html In this example \"comsapappbasiccountry\" is the business service prefix which matches the sap.cloud.service attribute in country service VCAP_SERVICES credentials (without dots). The \"comsapappbasicscountrylist\" is the name of the HTML5 Application as defined in the app.id attribute in the manifest.json (without dots).","title":"Accessing Business Service UI"},{"location":"apis/approuter/#web-sockets","text":"The application router is capable of forwarding web socket communication. In order to use the web socket communication, it should be enabled through the websockets property . If the backend service requires authentication then the upgrade request should contain a valid session cookie. The destination schemas \"ws\" and \"wss\" are supported in addition to \"http\" and \"https\". When the application router receives an upgrade request, it verifies that the Origin header holds the URL of the application router. If this is not the case, then an HTTP response with status 403 is returned to the client. This origin verification can be further configured via the environment variable WS_ALLOWED_ORIGINS . It contains the allowed origins the application router verifies against. It's structure is the same as CJ_PROTECT_WHITELIST . Note: A current limitation is that a web socket ping is not forwarded to the backend service.","title":"Web Sockets"},{"location":"apis/approuter/#session-handling","text":"The application router establishes a session with the client (browser) using a session cookie. The application router intercepts all session cookies, sent by backend services and stores them in its own session. Backend session cookies are not sent to the client in order to prevent cookie collisions. Upon subsequent requests the application router sends back the cookies to the respective backend services so they can establish their own sessions. Note: Non-session cookies from backend services are forwarded to the client. Cookie collisions may occur and the application should be able to handle them. If a pending request is canceled, the request cancellation will be propagated to the backend service.","title":"Session Handling"},{"location":"apis/approuter/#session-contents","text":"CSRF token - the generated CSRF token so it can be verified against the token in the request, see CSRF Protection above. OAuth token - JSON Web Token (JWT) fetched from UAA and forwarded to backend services in the Authorization header. The client never gets this token. The application router refreshes the JWT automatically before it expires (if the session is valid). By default this routine is triggered 5 minutes before the expiration of the JWT. This can also be configured via the JWT_REFRESH environment variable (the value is in minutes). If JWT_REFRESH is set to 0 then the refresh is disabled. OAuth scopes - scopes owned by the current user, used to check if the user has the scope required for each request. See scope in Routes . Backend session cookies - all session cookies sent by backend services. Business Services OAuth tokens - JSON Web Token (JWT) exchanged and used to access re-use services bound to the application router Note: If the JWT is close to expiration and the session is still active a JWT refresh will be triggered in JWT_REFRESH minutes before expiration. JWT_REFRESH is an environment variable stating the number of minutes before the JWT expiration the refresh will be triggered. The default value is 5 minutes.","title":"Session Contents"},{"location":"apis/approuter/#service-to-application-router-beta-version","text":"The application router can receive a consumer service xsuaa JWT token and use it to access the UI and the data. The JWT token is passed to the application router in the \"x-approuter-authorization\" header of the request. For more information, see Authorization Header . Note : The xsuaa JWT token is generated with the same xsuaa service instance that is bound to the application router. Caution : You should not use SAP Cloud Platform beta features in subaccounts that belong to productive enterprise accounts. Any use of beta functionality is at the customer's own risk, and SAP shall not be liable for errors or damages caused by the use of beta features. For more information, see Using Beta Features in Subaccounts .","title":"Service to Application Router (Beta version)"},{"location":"apis/approuter/#central-logout","text":"Central Logout can be client initiated or can be triggered due to session timeout. * Client initiated * Deletes the user session. * Requests all backend services logout paths (if configured in the destinations property ). * Request all business services logout paths (if configured in the services property ). * Redirects the client to logout from UAA. * If configured, redirects back to a custom page (for XS OnPremise Runtime only). For more information, see logout-property . * Session timeout * Deletes the user session. * Requests all backend services logout paths (if configured in the destinations property ). * Requests all business services logout paths (if configured in the services property ). The session timeout can be configured with the SESSION_TIMEOUT variable through the environment.","title":"Central Logout"},{"location":"apis/approuter/#whitelist-service","text":"What is it for? A protection concept is designed in SAP that uses UI libraries and whitelist service for proper clickjack protection of applications. The general idea is that when an html page needs to be rendered in a frame, a check is done by calling the whitelist service to validate if the parent frame is allowed to render the content in a frame. The actual check is provided by the whitelist service.","title":"Whitelist Service"},{"location":"apis/approuter/#enable-the-service","text":"To enable the service and open the service endpoint you need to configure the whitelistService property in xs-app.json .","title":"Enable the service"},{"location":"apis/approuter/#configuring-allowed-hostnames-domains","text":"The whitelist service reads allowed hostnames and domains from the environment variable CJ_PROTECT_WHITELIST . The content is a JSON array of object with the following properties: Property Type Optional Description protocol String x URI scheme, for example http . host String Hostname / domain - valid hostname, or domain defined with a star (*), for example some.concrete.hostname , or *.example.domain . port String / Number x Port string or number containing a valid port. Example: [ { \"protocol\" : \"http\" , \"host\" : \"*.example.domain\" , \"port\" : 12345 }, { \"host\" : \"some.concrete.hostname\" , } ] Matching is done against provided properties. For example if only host is provided then the service will return framing: true for all and matching will be for all schemas and protocols.","title":"Configuring allowed hostnames / domains"},{"location":"apis/approuter/#return-value","text":"The service accepts only GET requests and the response is a JSON object. The whitelist service call uses the parent origin as URI parameter (URL encoded) as follows: GET url/to/whitelist/service?parentOrigin=https://parent.domain.com The response is a JSON object with following properties: { \"version\" : \"1.0\", \"active\" : true | false, // indicates whether framing control is switched on \"origin\" : \"<same as passed to service>\", \"framing\" : true | false // if active, describes if framing should be allowed } The property active will have value false only in case CJ_PROTECT_WHITELIST is not provided. Note : Keep in mind that the application router sends by default the X-Frame-Options header with value SAMEORIGIN , in the case whitelist service is enabled, this header value probably needs to be changed, see the X-Frame-Options header section for details how to change it.","title":"Return value"},{"location":"apis/approuter/#scaling","text":"The application router keeps all established sessions in local memory and does not sync them across multiple instances. In order to scale the application router to multiple instances, session stickiness should be enabled. This means that each HTTP session is handled by the same application router instance. In Cloud Foundry's router, session stickiness is enabled from version 0.1.0. In SAP HANA XS Advanced OnPremise Runtime session stickiness is enabled, if SAP Web Dispatcher is used as a router. This is set by default from version 0.1535 of SAP HANA XS Advanced runtime. If your on-premise runtime uses nginx as router, you can switch to SAP Web Dispatcher by passing the command line option --router=webdispatcher to xs-controller .","title":"Scaling"},{"location":"apis/approuter/#sizing-guide-for-application-router","text":"The memory consumption of the application router is described in the sizing guide .","title":"Sizing Guide for Application Router"},{"location":"apis/approuter/#configure-server-side-https","text":"You can configure application router to accept only HTTPS connections. See httpsOptions option of start function.","title":"Configure server-side HTTPS"},{"location":"apis/approuter/#audit-log-service","text":"The application router logs information regarding unauthorized requests. To avoid exposure of private information such as user id and IP address, you must bind the consuming application to an instance of the audit-log service. If you do not bind the consuming application to the audit-log service, the application router will log this information to the console output, using asterisks to mask the user id and IP address. (This is the default behavior.)","title":"Audit-Log Service"},{"location":"apis/approuter/#troubleshooting","text":"The application router uses @sap/logging package so all of its features are available to control logging. For example to set all logging and tracing to finest level set XS_APP_LOG_LEVEL environment variable to debug . If the application is deployed on Cloud Foundry, you can change the log level by running command: cf set-env <application-name> XS_APP_LOG_LEVEL DEBUG If the application is deployed on XS Advanced On-premise Runtime, you can change the log level without restarting the application. For example this command will set all logging and tracing to finest level. xs set-logging-level <application-name> \"*\" debug See @sap/logging documentation for details. You can enable additional traces of the incoming and outgoing requests by setting the environment variable REQUEST_TRACE to true . When enabled they will log basic information for every incoming and outgoing request of the application router. This could have a performance impact. Some of the libraries used by this package employ other tracing mechanisms. For example many use the popular debug package. This means that by setting DEBUG environment variable, you can enable additional traces. Set it to * to enable all of them, but be careful as the output may be overwhelming. In addition internal Node.js traces can be enabled via NODE_DEBUG environment variable. This post describes it in more detail. Warning: Enabling some of these options may trace security sensitive data, so use with caution. The @sap/logging package sets the header 'x-request-id' in the application router's responses. This is useful if you would like to search entries belonging to a particular request execution in the application router's logs and traces. Note that the application router does not change the headers received from the backend and being forwarded to the client. If the backend is a Node.js application which uses the @sap/logging package (and also sets the 'x-request-id' header), then the value of the header that the client will receive will be the one coming from the backend and not the one of the application router itself.","title":"Troubleshooting"},{"location":"apis/approuter/#getting-support","text":"Create a BCP ticket on component BC-XS-APR","title":"Getting Support"},{"location":"apis/approuter/#extending-application-router","text":"See extending for information how to extend the application router with custom logic.","title":"Extending Application Router"},{"location":"apis/approuter/#best-practices","text":"","title":"Best practices"},{"location":"apis/approuter/#security-best-practices","text":"","title":"Security best practices"},{"location":"apis/approuter/#content-security-policy","text":"Setting the Content-Security-Policy header - this is a response header which informs browsers (capable of interpreting it) about the trusted sources from which an application expects to load resources. This mechanism allows the client to detect and block malicious scripts injected into an application. A value can be set via the httpHeaders environment variable in the additional headers configuration . The value represents a security policy which contains directive-value pairs. The value of a directive is a whitelist of trusted sources. Refer to the Content-Security-Policy specification for more information on the header's value. Note: Usage of the Content-Security-Policy header is considered second line of defense. An application should always provide proper input validation and output encoding.","title":"Content-Security-Policy"},{"location":"apis/approuter/#identity-provider-configuration-best-practices","text":"","title":"Identity Provider Configuration Best Practices"},{"location":"apis/approuter/#modelling-options","text":"If you to enable login in same browser window as doctor and patient you can create 2 cf routes to same approuter: https://approuter-doctors.cfapps.hana.com/myapp/doctors/index.html { \"source\" : \"^/doctors(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"doctorsIDP\" } https://approuter-patients.cfapps.hana.com/myapp/patients/index.html { \"source\" : \"^/patients(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"patrientsIDP\" } If you to enable single access at a time (force logout from doctors idp and re-login to patients idp), create a single cf route https://approuter-hospital.cfapps.hana.com/myapp/doctors/index.html { \"source\" : \"^/doctors(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"doctorsIDP\" } https://approuter-hospital.cfapps.hana.com/myapp/patients/index.html { \"source\" : \"^/patients(/.*)\" , \"target\" : \"$1\" , \"service\" : \"html5-apps-repo-rt\" , \"authenticationType\" : \"xsuaa\" , \"identityProvider\" : \"patrientsIDP\" }","title":"Modelling options:"},{"location":"apis/approuter/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 8.1.0 - 2020-06-14 \u00b6 Added \u00b6 Added fallback mechanism for html5 repo client_credentials token refresh Security improvement for signature verifying during login Fixed \u00b6 Bug fix when calling connectivity in a non-authenticated flow (no login in approuter) 8.0.0 - 2020-05-26 \u00b6 Updated dependencies \u00b6 deps: @sap/xssec@3.0.3 Removed \u00b6 Remove of SAP_JWT_TRUST_ACL environment variable support (functionality now comes with audience validation) 7.1.3 - 2020-05-17 \u00b6 Added \u00b6 Enhances of the x-approuter-authorization token security check in the service2Approuter flow. 7.1.2 - 2020-05-08 \u00b6 Fixed \u00b6 Fix appurl usage of x-subscriber-tenant 7.1.1 - 2020-05-05 \u00b6 Added \u00b6 Cache improvements Usage of x-subscriber-tenant header when provided. handle html5 repo and xsuaa destinations separately Fixed \u00b6 Fix connectivity token handling for Kubernetes 7.1.0 - 2020-04-16 \u00b6 Added \u00b6 Enable service logout configuration in central xs-app.json. Fixed \u00b6 Destination token cached in session is never refreshed. 7.0.0 - 2020-04-06 \u00b6 Added \u00b6 Support node version 10 and node version 12 instead of node version 8 and node version 10 6.8.2 - 2020-03-04 \u00b6 Fixed \u00b6 Fix extension of resolveUaaConfig 6.8.1 - 2020-02-20 \u00b6 Fixed \u00b6 Fix default route 6.8.0 - 2020-02-10 \u00b6 Added \u00b6 Enable external session manager extensibility when using HTML5 Repository 6.7.2 - 2020-01-30 \u00b6 Added \u00b6 Support SameSite cookie attribute Updated dependencies \u00b6 deps: express-session@1.17.0 deps: @sap/logging@5.2.0 6.7.1 - 2019-12-24 \u00b6 Added \u00b6 Backend cookies secret variable (BACKEND_COOKIES_SECRET) Secret that is used to encrypt backend session cookies in service to Application Router flow. Should be set in case multiple instances of Application Router are used. By default a random sequence of characters is used. 6.7.0 - 2019-11-24 \u00b6 Added \u00b6 Enhance the use of the xsenv@2.1.0 library to access bound destination service credentials, which support reading destination service credentials in Kubernetes. Fixed \u00b6 Anonymous login on destination flow 6.6.0 - 2019-11-12 \u00b6 Announcement \u00b6 The Preserve URL fragment (PRESERVE_FRAGMENT) is being deprecated and will be removed in the near future Updated dependencies \u00b6 deps: sap/xsenv@2.1.0 Application Router uses xsenv library to access bound services credentials. We have upgraded the library to xsenv version 2.1.0 which supports reading credentials in Kubernetes. deps: https-proxy-agent@2.2.4 6.5.1 - 2019-10-10 \u00b6 Fixed \u00b6 Adding sec-websocket-protocol header as the protocol of websockets 6.5.0 - 2019-10-03 \u00b6 Added \u00b6 Timeout for Business Service Fixed \u00b6 Adding destination token middleware for websockets 6.4.1 - 2019-09-23 \u00b6 Fixed \u00b6 CSP header fix return frame-ancestors in login 6.4.0 - 2019-09-16 \u00b6 Added \u00b6 Allowed dynamic destinations Return CSP header with no cache Added setXForwardedHeaders option 6.3.0 - 2019-09-10 \u00b6 Added \u00b6 Support Cache-Control for static content from html5-repo 6.2.0 - 2019-09-03 \u00b6 Added \u00b6 Support Subscription url from vcap. Adding validation - Session created for one tenant must not be used by other tenants Updated dependencies \u00b6 deps: @sap/xssec@2.2.2 6.1.2 - 2019-08-28 \u00b6 Support Xsuaa credentials in request body 6.1.1 - 2019-08-27 \u00b6 Fix in destination middleware - session.update 6.1.0 - 2019-07-31 \u00b6 Added \u00b6 Support for redirection to logout page with query parameters after central logout Connectivity is now returned in subscription getDependencies callback Fixed \u00b6 Error when processing unknown authentication types 6.0.2 - 2019-07-14 \u00b6 Fixed \u00b6 Validation of destination with OnPremise proxyType CSRF protection in Service to Approuter flow Updated dependencies \u00b6 deps: lodash@4.17.13 6.0.1 - 2019-05-30 \u00b6 Fixed \u00b6 Fixed TypeError bug when Approuter saves a cookie from backend and should logout when session timeout exceeded. Fixed calculation of location after login. 6.0.0 - 2019-05-06 \u00b6 Added \u00b6 Support node version 8 and node version 10 instead of node version 4.5 and node version 6 5.15.0 - 2019-04-29 \u00b6 Added \u00b6 Support for Service to Application Router functionality (Beta version). Added destination in host support. 5.14.1 - 2019-04-17 \u00b6 Added \u00b6 Enhanced Approuter application logs when serving of static content (from HTML5 App Repo) was failed. Fixed \u00b6 Fixed subscription callbacks url. 5.14.0 - 2019-04-04 \u00b6 Added \u00b6 Websockets support for HTML5 Application Repository. Fixed \u00b6 onSubscription callback. 5.13.1 - 2019-03-27 \u00b6 Added \u00b6 Added automatic recovery of Approuter after recovery of UAA. Fixed \u00b6 Fixed subscription callbacks url. Fixed avoid central appConfig routes overrides. Updated dependencies \u00b6 deps: @sap/xssec@2.1.16 5.13.0 - 2019-02-14 \u00b6 Added \u00b6 Ability to define identity provider for authentication in the route. 5.12.0 - 2019-02-05 \u00b6 Added \u00b6 Dynamic destination support. 5.11.0 - 2019-01-22 \u00b6 Added \u00b6 Client credentials token support. 5.10.2 - 2019-01-08 \u00b6 Fixed \u00b6 Fix proxy issue in Connectivity flow. 5.10.1 - 2019-01-03 \u00b6 Fixed \u00b6 Fixed flow of access destination via desination service. 5.10.0 - 2018-12-30 \u00b6 Added \u00b6 Propagation of approuter host during logout. 5.9.0 - 2018-12-18 \u00b6 Added \u00b6 Ability to change destination without restarting application on CF Access destination that is exposed on destination service instance level. Enabled all authentication types defined in the destination service. 5.8.0 - 2018-10-27 \u00b6 Fixed \u00b6 Fix login flow for URLs with empty query (URL that ends with '?'). Added \u00b6 Documentation of integration with HTML5 Apps Repo. Updated dependencies \u00b6 deps: ws@1.1.5 deps: lodash@4.17.11 deps: @sap/logging@4.0.2 deps: lodash@4.17.11 5.7.0 - 2018-10-08 \u00b6 Added \u00b6 Propagate client id to UAA during Logout 5.6.4 - 2018-08-27 \u00b6 Updated dependencies \u00b6 deps: @sap/audit-logging@2.2.4 deps: sync-request@5.0.0 Fixed \u00b6 Duplicate destination names in xs-app.json bug 5.6.3 - 2018-08-15 \u00b6 Updated dependencies \u00b6 deps: e2e-trace@1.3.0 deps: xssec@2.1.15 deps: request@2.88.0 Fixed \u00b6 Fix bug of post/put requests with content/type=application/json 5.6.2 - 2018-08-09 \u00b6 Updated dependencies \u00b6 deps: serve-static@1.13.2 deps: send@0.16.1 deps: mime@1.4.1 deps: debug@2.6.9 Fixed \u00b6 Fix error in case of local destination and UAA with tenant mode shared 5.6.1 - 2018-08-07 \u00b6 Updated dependencies \u00b6 deps: body-parser@1.18.3 deps: uid-safe@2.1.5 deps: @sap/xssec@2.1.9 deps: send@0.16.2 deps: compression@1.7.3 deps: express-session@1.15.6 deps: connect@3.6.5 5.6.0 - 2018-08-05 \u00b6 Added \u00b6 Added SaaS application registration support (subscription) Enhanced usage of PreserveHostHeader additional property Fixed \u00b6 Fix error handling in case of bad signature 5.5.0 - 2018-07-19 \u00b6 Added \u00b6 Added optional additional properties 'PreserveHostHeader' to Destination service Added optional additional properties 'sap-client' to Destination service 5.4.2 - 2018-07-04 \u00b6 Fixed \u00b6 Fix refresh page location after timeout bug Fix fragment cookie name bug Fix vulnerabilities issues 5.4.1 - 2018-06-25 \u00b6 Fixed \u00b6 Fix logout bug 5.4.0 - 2018-06-10 \u00b6 Added \u00b6 Support extensibility of logout end-point Fixed \u00b6 Fix vulnerabilities issues 5.3.0 - 2018-05-13 \u00b6 Added \u00b6 Enable extended session management Enable Correlation ID propagation 5.2.1 - 2018-05-02 \u00b6 Added \u00b6 Support audit log service 5.2.0 - 2018-04-16 \u00b6 Added \u00b6 Support routing to destination with authentication type OAuth2SAMLBearerAssertion Fixed \u00b6 Fix bug in forward undefine token 5.1.0 - 2018-03-14 \u00b6 Added \u00b6 Support destination configuration from destination service Fixed \u00b6 Fix bug in trace functionality Fix bug in fragment functionality 5.0.0 - 2018-01-29 \u00b6 Fixed \u00b6 Minor fix in destinations handling in Extension flow. Fix fragment handling in URL during Login flow. 4.0.1 - 2018-01-01 \u00b6 Fixed \u00b6 Minor fixes in CORs. 4.0.0 - 2017-12-18 \u00b6 Added \u00b6 Application router can consume content from the HTML5 application repository. Fixed \u00b6 Fix in headers handling when using CF destination and onPremise destination in same xs-app.json. Minor fix in CORs. 3.0.1 - 2017-10-08 \u00b6 Removed \u00b6 Node 0.12 support. 2.10.0 - 2017-07-30 \u00b6 Added \u00b6 Enabled connectivity to on premise backend. Added external reverse proxy support. Fixed \u00b6 Fix CSRF token generation to use a Secure Random number generator. 2.9.1 - 2017-06-29 \u00b6 Fixed \u00b6 Minor fixes in CORs. Introduce CORs feature in README.md. 2.9.0 - 2017-06-27 \u00b6 Added \u00b6 Support for CORs functionality. 2.8.2 - 2017-06-13 \u00b6 Fixed \u00b6 Fix cancel request. Fix logout in dynamic routing. 2.8.1 - 2017-06-01 \u00b6 Fixed \u00b6 Fixes in documentation of dynamic routing and troubleshooting section. Fix logout when using websocket. 2.8.0 - 2017-04-26 \u00b6 Added \u00b6 Introduce table of contents in README.md. Added JWT refresh in websocket connections. Significant performance improvements via adopting @sap/logging version 3 2.7.1 - 2017-03-20 \u00b6 Fixed \u00b6 Add username to logs. Minor fixes in websockets and session handling. 2.7.0 - 2017-02-13 \u00b6 Added \u00b6 Replacements from services. Start approuter on https Show warning when a route is explicitly both public and csrf protected. Fixed \u00b6 Should not escape client cookies. Redirect to welcome page if not CSRF token fetch request. Wrong basic authentication status codes. 2.6.1 - 2017-01-25 \u00b6 Changed \u00b6 Rename package to use @sap scope 2.6.0 - 2017-01-25 \u00b6 Added \u00b6 REQUEST_TRACE environment variable for enhanced request tracing. Support for PATCH in router configuration. New extensions - see extending.md. Removed \u00b6 Customizable UAA config resolution. Fixed \u00b6 Fixes in documentation. Handling of request protocol. Removed npm 2 restriction. 2.5.0 - 2016-12-13 \u00b6 Added \u00b6 Enable customizable UAA config resolution Support for custom error pages (errorPage in xs-app.json) Extend sizing guide Fixed \u00b6 Crash in error handler due to missing logger. Does not cache login responses. Does not log UAA missing when not needed. In case of parallel logins Approuter may use wrong user. Does not send basic credentials to backend, unless route is public. 2.4.0 - 2016-11-16 \u00b6 Added \u00b6 Introduce SECURE_SESSION_COOKIE environment variable - enforces the secure flag of application router's session cookie. Additional checks for regular expressions during startup. Changed \u00b6 Previous component name in sap passport has been changed to 'XSA Approuter'. Fixed \u00b6 Missing logging context in error handler when using extensions. 2.3.4 - 2016-11-04 \u00b6 Fixed \u00b6 The x-csrf-token header is no longer forwarded to backend in case a path requires authentication and CSRF token protection. Set the Secure flag of the session cookie depending on the environment application router runs in. Some of the links in README.md were broken. 2.3.3 - 2016-11-02 \u00b6 Added \u00b6 Add COMPRESSION env var to be able to configure compression. Fixed \u00b6 Do not cache wsAllowedOrigins across requests. Favor UAA config from default-env.json over default-services.json. Extend error message for proxy settings problem. Enable compression by default when custom setting is provided. Propagate errors to handler. Avoid session resave at the end of request. Fix session overwrite. 2.3.2 - 2016-09-30 \u00b6 Fixed \u00b6 Cookie locationAfterLogin clash in port based routing. 2.3.1 - 2016-09-28 \u00b6 Fixed \u00b6 Unverified redirect via locationAfterLogin cookie. Fallback to default UAA if no tenant captured. Fix X-Frame-Options header overwriting. Session cookie name - use application_id instead of instance_id. Fix port validation for approuter.start(). 2.3.0 - 2016-09-02 \u00b6 Added \u00b6 Multitenancy support. Matching route by both URL path and HTTP method. Fixed \u00b6 Fixed race condition while CSRF token generation. 2.2.0 - 2016-08-17 \u00b6 Added \u00b6 Start approuter with xs-app.json passed as an object. Follow symlinks in localDir config. Document the Content-Security-Policy header as a best practice. 2.1.3 - 2016-08-13 \u00b6 Added \u00b6 Genarate CSRF token once per session. 2.1.2 - 2016-08-06 \u00b6 Fixed \u00b6 Remove instance cookies from client request. Fix locatioinAfterLogin cookie path. 2.1.1 - 2016-07-24 \u00b6 Fixed \u00b6 Support to host welcome page externally. Fix logout path matching. Fix 500 sent in case locationAfterLogin cookie is missing. 2.1.0 - 2016-07-17 \u00b6 Added \u00b6 Allow source of route to be matched in case-insensitive way. New configuration for maximum client connection timeout. Add support for approuter extensions (custom middleware). Allow fetching CSRF token with HEAD request. 2.0.0 - 2016-05-12 \u00b6 Added \u00b6 Configuration for the Cache-Control header in xs-app.json. The header is used when serving static resources. Removed \u00b6 local-* files (e.g. local-destinations, local-plugins) can no longer be used in the approuter during local development. Instead of these the approuter reads a single file located in the working directory (default-env.json), which contains the corresponding environment variables (e.g. destinations, plugins) and their values.","title":"Change Log"},{"location":"apis/approuter/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/approuter/CHANGELOG/#810-2020-06-14","text":"","title":"8.1.0 - 2020-06-14"},{"location":"apis/approuter/CHANGELOG/#added","text":"Added fallback mechanism for html5 repo client_credentials token refresh Security improvement for signature verifying during login","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed","text":"Bug fix when calling connectivity in a non-authenticated flow (no login in approuter)","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#800-2020-05-26","text":"","title":"8.0.0 - 2020-05-26"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies","text":"deps: @sap/xssec@3.0.3","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#removed","text":"Remove of SAP_JWT_TRUST_ACL environment variable support (functionality now comes with audience validation)","title":"Removed"},{"location":"apis/approuter/CHANGELOG/#713-2020-05-17","text":"","title":"7.1.3 - 2020-05-17"},{"location":"apis/approuter/CHANGELOG/#added_1","text":"Enhances of the x-approuter-authorization token security check in the service2Approuter flow.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#712-2020-05-08","text":"","title":"7.1.2 - 2020-05-08"},{"location":"apis/approuter/CHANGELOG/#fixed_1","text":"Fix appurl usage of x-subscriber-tenant","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#711-2020-05-05","text":"","title":"7.1.1 - 2020-05-05"},{"location":"apis/approuter/CHANGELOG/#added_2","text":"Cache improvements Usage of x-subscriber-tenant header when provided. handle html5 repo and xsuaa destinations separately","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_2","text":"Fix connectivity token handling for Kubernetes","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#710-2020-04-16","text":"","title":"7.1.0 - 2020-04-16"},{"location":"apis/approuter/CHANGELOG/#added_3","text":"Enable service logout configuration in central xs-app.json.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_3","text":"Destination token cached in session is never refreshed.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#700-2020-04-06","text":"","title":"7.0.0 - 2020-04-06"},{"location":"apis/approuter/CHANGELOG/#added_4","text":"Support node version 10 and node version 12 instead of node version 8 and node version 10","title":"Added"},{"location":"apis/approuter/CHANGELOG/#682-2020-03-04","text":"","title":"6.8.2 - 2020-03-04"},{"location":"apis/approuter/CHANGELOG/#fixed_4","text":"Fix extension of resolveUaaConfig","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#681-2020-02-20","text":"","title":"6.8.1 - 2020-02-20"},{"location":"apis/approuter/CHANGELOG/#fixed_5","text":"Fix default route","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#680-2020-02-10","text":"","title":"6.8.0 - 2020-02-10"},{"location":"apis/approuter/CHANGELOG/#added_5","text":"Enable external session manager extensibility when using HTML5 Repository","title":"Added"},{"location":"apis/approuter/CHANGELOG/#672-2020-01-30","text":"","title":"6.7.2 - 2020-01-30"},{"location":"apis/approuter/CHANGELOG/#added_6","text":"Support SameSite cookie attribute","title":"Added"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_1","text":"deps: express-session@1.17.0 deps: @sap/logging@5.2.0","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#671-2019-12-24","text":"","title":"6.7.1 - 2019-12-24"},{"location":"apis/approuter/CHANGELOG/#added_7","text":"Backend cookies secret variable (BACKEND_COOKIES_SECRET) Secret that is used to encrypt backend session cookies in service to Application Router flow. Should be set in case multiple instances of Application Router are used. By default a random sequence of characters is used.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#670-2019-11-24","text":"","title":"6.7.0 - 2019-11-24"},{"location":"apis/approuter/CHANGELOG/#added_8","text":"Enhance the use of the xsenv@2.1.0 library to access bound destination service credentials, which support reading destination service credentials in Kubernetes.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_6","text":"Anonymous login on destination flow","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#660-2019-11-12","text":"","title":"6.6.0 - 2019-11-12"},{"location":"apis/approuter/CHANGELOG/#announcement","text":"The Preserve URL fragment (PRESERVE_FRAGMENT) is being deprecated and will be removed in the near future","title":"Announcement"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_2","text":"deps: sap/xsenv@2.1.0 Application Router uses xsenv library to access bound services credentials. We have upgraded the library to xsenv version 2.1.0 which supports reading credentials in Kubernetes. deps: https-proxy-agent@2.2.4","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#651-2019-10-10","text":"","title":"6.5.1 - 2019-10-10"},{"location":"apis/approuter/CHANGELOG/#fixed_7","text":"Adding sec-websocket-protocol header as the protocol of websockets","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#650-2019-10-03","text":"","title":"6.5.0 - 2019-10-03"},{"location":"apis/approuter/CHANGELOG/#added_9","text":"Timeout for Business Service","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_8","text":"Adding destination token middleware for websockets","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#641-2019-09-23","text":"","title":"6.4.1 - 2019-09-23"},{"location":"apis/approuter/CHANGELOG/#fixed_9","text":"CSP header fix return frame-ancestors in login","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#640-2019-09-16","text":"","title":"6.4.0 - 2019-09-16"},{"location":"apis/approuter/CHANGELOG/#added_10","text":"Allowed dynamic destinations Return CSP header with no cache Added setXForwardedHeaders option","title":"Added"},{"location":"apis/approuter/CHANGELOG/#630-2019-09-10","text":"","title":"6.3.0 - 2019-09-10"},{"location":"apis/approuter/CHANGELOG/#added_11","text":"Support Cache-Control for static content from html5-repo","title":"Added"},{"location":"apis/approuter/CHANGELOG/#620-2019-09-03","text":"","title":"6.2.0 - 2019-09-03"},{"location":"apis/approuter/CHANGELOG/#added_12","text":"Support Subscription url from vcap. Adding validation - Session created for one tenant must not be used by other tenants","title":"Added"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_3","text":"deps: @sap/xssec@2.2.2","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#612-2019-08-28","text":"Support Xsuaa credentials in request body","title":"6.1.2 - 2019-08-28"},{"location":"apis/approuter/CHANGELOG/#611-2019-08-27","text":"Fix in destination middleware - session.update","title":"6.1.1 - 2019-08-27"},{"location":"apis/approuter/CHANGELOG/#610-2019-07-31","text":"","title":"6.1.0 - 2019-07-31"},{"location":"apis/approuter/CHANGELOG/#added_13","text":"Support for redirection to logout page with query parameters after central logout Connectivity is now returned in subscription getDependencies callback","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_10","text":"Error when processing unknown authentication types","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#602-2019-07-14","text":"","title":"6.0.2 - 2019-07-14"},{"location":"apis/approuter/CHANGELOG/#fixed_11","text":"Validation of destination with OnPremise proxyType CSRF protection in Service to Approuter flow","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_4","text":"deps: lodash@4.17.13","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#601-2019-05-30","text":"","title":"6.0.1 - 2019-05-30"},{"location":"apis/approuter/CHANGELOG/#fixed_12","text":"Fixed TypeError bug when Approuter saves a cookie from backend and should logout when session timeout exceeded. Fixed calculation of location after login.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#600-2019-05-06","text":"","title":"6.0.0 - 2019-05-06"},{"location":"apis/approuter/CHANGELOG/#added_14","text":"Support node version 8 and node version 10 instead of node version 4.5 and node version 6","title":"Added"},{"location":"apis/approuter/CHANGELOG/#5150-2019-04-29","text":"","title":"5.15.0 - 2019-04-29"},{"location":"apis/approuter/CHANGELOG/#added_15","text":"Support for Service to Application Router functionality (Beta version). Added destination in host support.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#5141-2019-04-17","text":"","title":"5.14.1 - 2019-04-17"},{"location":"apis/approuter/CHANGELOG/#added_16","text":"Enhanced Approuter application logs when serving of static content (from HTML5 App Repo) was failed.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_13","text":"Fixed subscription callbacks url.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#5140-2019-04-04","text":"","title":"5.14.0 - 2019-04-04"},{"location":"apis/approuter/CHANGELOG/#added_17","text":"Websockets support for HTML5 Application Repository.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_14","text":"onSubscription callback.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#5131-2019-03-27","text":"","title":"5.13.1 - 2019-03-27"},{"location":"apis/approuter/CHANGELOG/#added_18","text":"Added automatic recovery of Approuter after recovery of UAA.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_15","text":"Fixed subscription callbacks url. Fixed avoid central appConfig routes overrides.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_5","text":"deps: @sap/xssec@2.1.16","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#5130-2019-02-14","text":"","title":"5.13.0 - 2019-02-14"},{"location":"apis/approuter/CHANGELOG/#added_19","text":"Ability to define identity provider for authentication in the route.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#5120-2019-02-05","text":"","title":"5.12.0 - 2019-02-05"},{"location":"apis/approuter/CHANGELOG/#added_20","text":"Dynamic destination support.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#5110-2019-01-22","text":"","title":"5.11.0 - 2019-01-22"},{"location":"apis/approuter/CHANGELOG/#added_21","text":"Client credentials token support.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#5102-2019-01-08","text":"","title":"5.10.2 - 2019-01-08"},{"location":"apis/approuter/CHANGELOG/#fixed_16","text":"Fix proxy issue in Connectivity flow.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#5101-2019-01-03","text":"","title":"5.10.1 - 2019-01-03"},{"location":"apis/approuter/CHANGELOG/#fixed_17","text":"Fixed flow of access destination via desination service.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#5100-2018-12-30","text":"","title":"5.10.0 - 2018-12-30"},{"location":"apis/approuter/CHANGELOG/#added_22","text":"Propagation of approuter host during logout.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#590-2018-12-18","text":"","title":"5.9.0 - 2018-12-18"},{"location":"apis/approuter/CHANGELOG/#added_23","text":"Ability to change destination without restarting application on CF Access destination that is exposed on destination service instance level. Enabled all authentication types defined in the destination service.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#580-2018-10-27","text":"","title":"5.8.0 - 2018-10-27"},{"location":"apis/approuter/CHANGELOG/#fixed_18","text":"Fix login flow for URLs with empty query (URL that ends with '?').","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#added_24","text":"Documentation of integration with HTML5 Apps Repo.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_6","text":"deps: ws@1.1.5 deps: lodash@4.17.11 deps: @sap/logging@4.0.2 deps: lodash@4.17.11","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#570-2018-10-08","text":"","title":"5.7.0 - 2018-10-08"},{"location":"apis/approuter/CHANGELOG/#added_25","text":"Propagate client id to UAA during Logout","title":"Added"},{"location":"apis/approuter/CHANGELOG/#564-2018-08-27","text":"","title":"5.6.4 - 2018-08-27"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_7","text":"deps: @sap/audit-logging@2.2.4 deps: sync-request@5.0.0","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#fixed_19","text":"Duplicate destination names in xs-app.json bug","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#563-2018-08-15","text":"","title":"5.6.3 - 2018-08-15"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_8","text":"deps: e2e-trace@1.3.0 deps: xssec@2.1.15 deps: request@2.88.0","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#fixed_20","text":"Fix bug of post/put requests with content/type=application/json","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#562-2018-08-09","text":"","title":"5.6.2 - 2018-08-09"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_9","text":"deps: serve-static@1.13.2 deps: send@0.16.1 deps: mime@1.4.1 deps: debug@2.6.9","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#fixed_21","text":"Fix error in case of local destination and UAA with tenant mode shared","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#561-2018-08-07","text":"","title":"5.6.1 - 2018-08-07"},{"location":"apis/approuter/CHANGELOG/#updated-dependencies_10","text":"deps: body-parser@1.18.3 deps: uid-safe@2.1.5 deps: @sap/xssec@2.1.9 deps: send@0.16.2 deps: compression@1.7.3 deps: express-session@1.15.6 deps: connect@3.6.5","title":"Updated dependencies"},{"location":"apis/approuter/CHANGELOG/#560-2018-08-05","text":"","title":"5.6.0 - 2018-08-05"},{"location":"apis/approuter/CHANGELOG/#added_26","text":"Added SaaS application registration support (subscription) Enhanced usage of PreserveHostHeader additional property","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_22","text":"Fix error handling in case of bad signature","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#550-2018-07-19","text":"","title":"5.5.0 - 2018-07-19"},{"location":"apis/approuter/CHANGELOG/#added_27","text":"Added optional additional properties 'PreserveHostHeader' to Destination service Added optional additional properties 'sap-client' to Destination service","title":"Added"},{"location":"apis/approuter/CHANGELOG/#542-2018-07-04","text":"","title":"5.4.2 - 2018-07-04"},{"location":"apis/approuter/CHANGELOG/#fixed_23","text":"Fix refresh page location after timeout bug Fix fragment cookie name bug Fix vulnerabilities issues","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#541-2018-06-25","text":"","title":"5.4.1 - 2018-06-25"},{"location":"apis/approuter/CHANGELOG/#fixed_24","text":"Fix logout bug","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#540-2018-06-10","text":"","title":"5.4.0 - 2018-06-10"},{"location":"apis/approuter/CHANGELOG/#added_28","text":"Support extensibility of logout end-point","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_25","text":"Fix vulnerabilities issues","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#530-2018-05-13","text":"","title":"5.3.0 - 2018-05-13"},{"location":"apis/approuter/CHANGELOG/#added_29","text":"Enable extended session management Enable Correlation ID propagation","title":"Added"},{"location":"apis/approuter/CHANGELOG/#521-2018-05-02","text":"","title":"5.2.1 - 2018-05-02"},{"location":"apis/approuter/CHANGELOG/#added_30","text":"Support audit log service","title":"Added"},{"location":"apis/approuter/CHANGELOG/#520-2018-04-16","text":"","title":"5.2.0 - 2018-04-16"},{"location":"apis/approuter/CHANGELOG/#added_31","text":"Support routing to destination with authentication type OAuth2SAMLBearerAssertion","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_26","text":"Fix bug in forward undefine token","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#510-2018-03-14","text":"","title":"5.1.0 - 2018-03-14"},{"location":"apis/approuter/CHANGELOG/#added_32","text":"Support destination configuration from destination service","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_27","text":"Fix bug in trace functionality Fix bug in fragment functionality","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#500-2018-01-29","text":"","title":"5.0.0 - 2018-01-29"},{"location":"apis/approuter/CHANGELOG/#fixed_28","text":"Minor fix in destinations handling in Extension flow. Fix fragment handling in URL during Login flow.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#401-2018-01-01","text":"","title":"4.0.1 - 2018-01-01"},{"location":"apis/approuter/CHANGELOG/#fixed_29","text":"Minor fixes in CORs.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#400-2017-12-18","text":"","title":"4.0.0 - 2017-12-18"},{"location":"apis/approuter/CHANGELOG/#added_33","text":"Application router can consume content from the HTML5 application repository.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_30","text":"Fix in headers handling when using CF destination and onPremise destination in same xs-app.json. Minor fix in CORs.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#301-2017-10-08","text":"","title":"3.0.1 - 2017-10-08"},{"location":"apis/approuter/CHANGELOG/#removed_1","text":"Node 0.12 support.","title":"Removed"},{"location":"apis/approuter/CHANGELOG/#2100-2017-07-30","text":"","title":"2.10.0 - 2017-07-30"},{"location":"apis/approuter/CHANGELOG/#added_34","text":"Enabled connectivity to on premise backend. Added external reverse proxy support.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_31","text":"Fix CSRF token generation to use a Secure Random number generator.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#291-2017-06-29","text":"","title":"2.9.1 - 2017-06-29"},{"location":"apis/approuter/CHANGELOG/#fixed_32","text":"Minor fixes in CORs. Introduce CORs feature in README.md.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#290-2017-06-27","text":"","title":"2.9.0 - 2017-06-27"},{"location":"apis/approuter/CHANGELOG/#added_35","text":"Support for CORs functionality.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#282-2017-06-13","text":"","title":"2.8.2 - 2017-06-13"},{"location":"apis/approuter/CHANGELOG/#fixed_33","text":"Fix cancel request. Fix logout in dynamic routing.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#281-2017-06-01","text":"","title":"2.8.1 - 2017-06-01"},{"location":"apis/approuter/CHANGELOG/#fixed_34","text":"Fixes in documentation of dynamic routing and troubleshooting section. Fix logout when using websocket.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#280-2017-04-26","text":"","title":"2.8.0 - 2017-04-26"},{"location":"apis/approuter/CHANGELOG/#added_36","text":"Introduce table of contents in README.md. Added JWT refresh in websocket connections. Significant performance improvements via adopting @sap/logging version 3","title":"Added"},{"location":"apis/approuter/CHANGELOG/#271-2017-03-20","text":"","title":"2.7.1 - 2017-03-20"},{"location":"apis/approuter/CHANGELOG/#fixed_35","text":"Add username to logs. Minor fixes in websockets and session handling.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#270-2017-02-13","text":"","title":"2.7.0 - 2017-02-13"},{"location":"apis/approuter/CHANGELOG/#added_37","text":"Replacements from services. Start approuter on https Show warning when a route is explicitly both public and csrf protected.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_36","text":"Should not escape client cookies. Redirect to welcome page if not CSRF token fetch request. Wrong basic authentication status codes.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#261-2017-01-25","text":"","title":"2.6.1 - 2017-01-25"},{"location":"apis/approuter/CHANGELOG/#changed","text":"Rename package to use @sap scope","title":"Changed"},{"location":"apis/approuter/CHANGELOG/#260-2017-01-25","text":"","title":"2.6.0 - 2017-01-25"},{"location":"apis/approuter/CHANGELOG/#added_38","text":"REQUEST_TRACE environment variable for enhanced request tracing. Support for PATCH in router configuration. New extensions - see extending.md.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#removed_2","text":"Customizable UAA config resolution.","title":"Removed"},{"location":"apis/approuter/CHANGELOG/#fixed_37","text":"Fixes in documentation. Handling of request protocol. Removed npm 2 restriction.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#250-2016-12-13","text":"","title":"2.5.0 - 2016-12-13"},{"location":"apis/approuter/CHANGELOG/#added_39","text":"Enable customizable UAA config resolution Support for custom error pages (errorPage in xs-app.json) Extend sizing guide","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_38","text":"Crash in error handler due to missing logger. Does not cache login responses. Does not log UAA missing when not needed. In case of parallel logins Approuter may use wrong user. Does not send basic credentials to backend, unless route is public.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#240-2016-11-16","text":"","title":"2.4.0 - 2016-11-16"},{"location":"apis/approuter/CHANGELOG/#added_40","text":"Introduce SECURE_SESSION_COOKIE environment variable - enforces the secure flag of application router's session cookie. Additional checks for regular expressions during startup.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#changed_1","text":"Previous component name in sap passport has been changed to 'XSA Approuter'.","title":"Changed"},{"location":"apis/approuter/CHANGELOG/#fixed_39","text":"Missing logging context in error handler when using extensions.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#234-2016-11-04","text":"","title":"2.3.4 - 2016-11-04"},{"location":"apis/approuter/CHANGELOG/#fixed_40","text":"The x-csrf-token header is no longer forwarded to backend in case a path requires authentication and CSRF token protection. Set the Secure flag of the session cookie depending on the environment application router runs in. Some of the links in README.md were broken.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#233-2016-11-02","text":"","title":"2.3.3 - 2016-11-02"},{"location":"apis/approuter/CHANGELOG/#added_41","text":"Add COMPRESSION env var to be able to configure compression.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_41","text":"Do not cache wsAllowedOrigins across requests. Favor UAA config from default-env.json over default-services.json. Extend error message for proxy settings problem. Enable compression by default when custom setting is provided. Propagate errors to handler. Avoid session resave at the end of request. Fix session overwrite.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#232-2016-09-30","text":"","title":"2.3.2 - 2016-09-30"},{"location":"apis/approuter/CHANGELOG/#fixed_42","text":"Cookie locationAfterLogin clash in port based routing.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#231-2016-09-28","text":"","title":"2.3.1 - 2016-09-28"},{"location":"apis/approuter/CHANGELOG/#fixed_43","text":"Unverified redirect via locationAfterLogin cookie. Fallback to default UAA if no tenant captured. Fix X-Frame-Options header overwriting. Session cookie name - use application_id instead of instance_id. Fix port validation for approuter.start().","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#230-2016-09-02","text":"","title":"2.3.0 - 2016-09-02"},{"location":"apis/approuter/CHANGELOG/#added_42","text":"Multitenancy support. Matching route by both URL path and HTTP method.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#fixed_44","text":"Fixed race condition while CSRF token generation.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#220-2016-08-17","text":"","title":"2.2.0 - 2016-08-17"},{"location":"apis/approuter/CHANGELOG/#added_43","text":"Start approuter with xs-app.json passed as an object. Follow symlinks in localDir config. Document the Content-Security-Policy header as a best practice.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#213-2016-08-13","text":"","title":"2.1.3 - 2016-08-13"},{"location":"apis/approuter/CHANGELOG/#added_44","text":"Genarate CSRF token once per session.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#212-2016-08-06","text":"","title":"2.1.2 - 2016-08-06"},{"location":"apis/approuter/CHANGELOG/#fixed_45","text":"Remove instance cookies from client request. Fix locatioinAfterLogin cookie path.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#211-2016-07-24","text":"","title":"2.1.1 - 2016-07-24"},{"location":"apis/approuter/CHANGELOG/#fixed_46","text":"Support to host welcome page externally. Fix logout path matching. Fix 500 sent in case locationAfterLogin cookie is missing.","title":"Fixed"},{"location":"apis/approuter/CHANGELOG/#210-2016-07-17","text":"","title":"2.1.0 - 2016-07-17"},{"location":"apis/approuter/CHANGELOG/#added_45","text":"Allow source of route to be matched in case-insensitive way. New configuration for maximum client connection timeout. Add support for approuter extensions (custom middleware). Allow fetching CSRF token with HEAD request.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#200-2016-05-12","text":"","title":"2.0.0 - 2016-05-12"},{"location":"apis/approuter/CHANGELOG/#added_46","text":"Configuration for the Cache-Control header in xs-app.json. The header is used when serving static resources.","title":"Added"},{"location":"apis/approuter/CHANGELOG/#removed_3","text":"local-* files (e.g. local-destinations, local-plugins) can no longer be used in the approuter during local development. Instead of these the approuter reads a single file located in the working directory (default-env.json), which contains the corresponding environment variables (e.g. destinations, plugins) and their values.","title":"Removed"},{"location":"apis/approuter/doc/extending/","text":"Extending Application Router \u00b6 Basics Inject Custom Middleware Application Router Extensions Customize Command Line Dynamic Routing State synchronization API Reference approuter approuter() Event: 'login' Event: 'logout' first beforeRequestHandler beforeErrorHandler start(options, callback) close(callback) createRouterConfig(options, callback) resolveUaaConfig(request, uaaOptions, callback) Middleware Slot use(path, handler) Basics \u00b6 Insead of starting the application router directly, your application can have its own start script. You can use the application router as a regular Node.js package. var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start (); Inject Custom Middleware \u00b6 The application router uses the connect framework. You can reuse all connect middlewares within the application router directly. You can do this directly in your start script: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); Tip: Name your middleware to improve troubleshooting. The path argument is optional. You can also chain use calls. var approuter = require ( '@sap/approuter' ); var morgan = require ( 'morgan' ); var ar = approuter (); ar . beforeRequestHandler . use ( morgan ( 'combined' )) . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); The application router defines the following slots where you can insert custom middleware: * first - right after the connect application is created, and before any application router middleware. At this point security checks are not performed yet. Tip: This is a good place for infrastructure logic like logging and monitoring. * beforeRequestHandler - before standard application router request handling, that is static resource serving or forwarding to destinations. Tip: This is a good place for custom REST API handling. * beforeErrorHandler - before standard application router error handling. Tip: This is a good place to capture or customize error handling. If your middleware does not complete the request processing, call next to return control to the application router middleware: ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . setHeader ( 'x-my-ext' , 'passed' ); next (); }); Application Router Extensions \u00b6 You can use application router extensions. An extension is defined by an object with the following properties: * insertMiddleware - describes the middleware provided by this extension * first , beforeRequestHandler , beforeErrorHandler - an array of middleware, where each one is either * a middleware function (invoked on all requests), or * an object with properties: * path - handle requests only for this path * handler - middleware function to invoke Here is an example (my-ext.js): module . exports = { insertMiddleware : { first : [ function logRequest ( req , res , next ) { console . log ( 'Got request %s %s' , req . method , req . url ); } ], beforeRequestHandler : [ { path : '/my-ext' , handler : function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); } } ] } }; You can use it in your start script like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ extensions : [ require ( './my-ext.js' ) ] }); Customize Command Line \u00b6 By default the application router handles its command line parameters, but you can customize that too. An approuter instance provides the property cmdParser that is a commander instance. It is configured with the standard application router command line options. There you can add custom options like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); var params = ar . cmdParser // add here custom command line options if needed . option ( '-d, --dummy' , 'A dummy option' ) . parse ( process . argv ); console . log ( 'Dummy option:' , params . dummy ); To completely disable the command line option handling in the application router, reset the following property: ar . cmdParser = false ; Dynamic Routing \u00b6 The application router can use a custom routing configuration for each request. Here is an example: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ getRouterConfig : getRouterConfig }); var customRouterConfig ; var options = { xsappConfig : { routes : [ { source : '/service' , destination : 'backend' , scope : '$XSAPPNAME.viewer' , } ] }, destinations : [ { name : 'backend' , url : 'https://my.app.com' , forwardAuthToken : true } ], xsappname : 'MYAPP' }; ar . createRouterConfig ( options , function ( err , routerConfig ) { if ( err ) { console . error ( err ); } else { customRouterConfig = routerConfig ; } }); function getRouterConfig ( request , callback ) { if ( /\\?custom-query/ . test ( request . url )) { callback ( null , customRouterConfig ); } else { callback ( null , null ); // use default router config } } State synchronization \u00b6 The application router can be scaled to run with multiple instances like any other application on Cloud Foundry. Still application router instances are not aware of each other and there is no communication among them. So if extensions introduce some state, they should take care to synchronize it across application router instances. API Reference \u00b6 approuter \u00b6 approuter() \u00b6 Creates a new instance of the application router. Event: 'login' \u00b6 Parameters: * session * id - session id as a string Emitted when a new user session is created. Event: 'logout' \u00b6 Parameters: * session * id - session id as a string Emitted when a user session has expired or a user has requested to log out. first \u00b6 A Middleware Slot before the first application router middleware beforeRequestHandler \u00b6 A Middleware Slot before the standard application router request handling beforeErrorHandler \u00b6 A Middleware Slot before the standard application router error handling start(options, callback) \u00b6 Starts the application router with the given options. options this argument is optional. If provided, it should be an object which can have any of the following properties: port - a TCP port the application router will listen to (string, optional) workingDir - the working directory for the application router, should contain the xs-app.json file (string, optional) extensions - an array of extensions, each one is an object as defined in Application Router Extensions (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. If this property is present it will take precedence over the content of xs-app.json. (optional) httpsOptions - Options similar to https.createServer . If this property is present, application router will be started as an https server. (optional) getToken - function(request, callback) Provide custom access token (optional) request - Node request object callback - function(error, token) error - Error object in case of error token - Access token to use in request to backend getRouterConfig - function(request, callback) Provide custom routing configuration (optional) request - Node request object callback - function(error, routerConfig) error - Error object in case of error routerConfig - Custom routing configuration to use for given request. This object should be created via createRouterConfig . If null or undefined , default configuration will be used. callback - optional function with signature callback(err) . It is invoked when the application router has started or an error has occurred. If not provided and an error occurs (e.g. the port is busy), the application will abort. close(callback) \u00b6 Stops the application router. callback - optional function with signature callback(err) . It is invoked when the application router has stopped or an error has occurred. createRouterConfig(options, callback) \u00b6 Prepares the routing configuration to be used by the application router. As part of this, the application router validates the given options. This function can be used at any point in runtime to create additional routing configurations. Note: This function can be called only after start function. options xsappname - Value to replace $XSAPPNAME placeholder in scope names. If not provided, it will be taken from UAA service binding. (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. Note: Only the following configurations are taken into account from this property (the rest are taken from the xs-app.json file): welcomeFile , logout.logoutEndpoint , logout.logoutPage , routes , websockets , errorPage . destinations - An array containing the configuration of the backend destinations. If not provided, it will be taken from destinations environment variable. (optional) callback - function(error, routerConfig) error - Error object in case of error routerConfig - Routing configuration to be passed to the callback of getRouterConfig . Approuter extensions should not access the content of this object. resolveUaaConfig(request, uaaOptions, callback) \u00b6 Calculates tenant-specific UAA configuration. request - node request object used to identify the tenant uaaOptions - UAA options as provided in service binding callback - function(error, tenantUaaOptions) error - Error object in case of error tenantUaaOptions - new UAA configuration with tenant-specific properties Middleware Slot \u00b6 use(path, handler) \u00b6 Inserts a request handling middleware in the current slot. path - handle only requests starting with this path (string, optional) handler - a middleware function to invoke (function, mandatory) Returns this for chaining.","title":"Extending"},{"location":"apis/approuter/doc/extending/#extending-application-router","text":"Basics Inject Custom Middleware Application Router Extensions Customize Command Line Dynamic Routing State synchronization API Reference approuter approuter() Event: 'login' Event: 'logout' first beforeRequestHandler beforeErrorHandler start(options, callback) close(callback) createRouterConfig(options, callback) resolveUaaConfig(request, uaaOptions, callback) Middleware Slot use(path, handler)","title":"Extending Application Router"},{"location":"apis/approuter/doc/extending/#basics","text":"Insead of starting the application router directly, your application can have its own start script. You can use the application router as a regular Node.js package. var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ();","title":"Basics"},{"location":"apis/approuter/doc/extending/#inject-custom-middleware","text":"The application router uses the connect framework. You can reuse all connect middlewares within the application router directly. You can do this directly in your start script: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); Tip: Name your middleware to improve troubleshooting. The path argument is optional. You can also chain use calls. var approuter = require ( '@sap/approuter' ); var morgan = require ( 'morgan' ); var ar = approuter (); ar . beforeRequestHandler . use ( morgan ( 'combined' )) . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); The application router defines the following slots where you can insert custom middleware: * first - right after the connect application is created, and before any application router middleware. At this point security checks are not performed yet. Tip: This is a good place for infrastructure logic like logging and monitoring. * beforeRequestHandler - before standard application router request handling, that is static resource serving or forwarding to destinations. Tip: This is a good place for custom REST API handling. * beforeErrorHandler - before standard application router error handling. Tip: This is a good place to capture or customize error handling. If your middleware does not complete the request processing, call next to return control to the application router middleware: ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . setHeader ( 'x-my-ext' , 'passed' ); next (); });","title":"Inject Custom Middleware"},{"location":"apis/approuter/doc/extending/#application-router-extensions","text":"You can use application router extensions. An extension is defined by an object with the following properties: * insertMiddleware - describes the middleware provided by this extension * first , beforeRequestHandler , beforeErrorHandler - an array of middleware, where each one is either * a middleware function (invoked on all requests), or * an object with properties: * path - handle requests only for this path * handler - middleware function to invoke Here is an example (my-ext.js): module . exports = { insertMiddleware : { first : [ function logRequest ( req , res , next ) { console . log ( 'Got request %s %s' , req . method , req . url ); } ], beforeRequestHandler : [ { path : '/my-ext' , handler : function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); } } ] } }; You can use it in your start script like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ extensions : [ require ( './my-ext.js' ) ] });","title":"Application Router Extensions"},{"location":"apis/approuter/doc/extending/#customize-command-line","text":"By default the application router handles its command line parameters, but you can customize that too. An approuter instance provides the property cmdParser that is a commander instance. It is configured with the standard application router command line options. There you can add custom options like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); var params = ar . cmdParser // add here custom command line options if needed . option ( '-d, --dummy' , 'A dummy option' ) . parse ( process . argv ); console . log ( 'Dummy option:' , params . dummy ); To completely disable the command line option handling in the application router, reset the following property: ar . cmdParser = false ;","title":"Customize Command Line"},{"location":"apis/approuter/doc/extending/#dynamic-routing","text":"The application router can use a custom routing configuration for each request. Here is an example: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ getRouterConfig : getRouterConfig }); var customRouterConfig ; var options = { xsappConfig : { routes : [ { source : '/service' , destination : 'backend' , scope : '$XSAPPNAME.viewer' , } ] }, destinations : [ { name : 'backend' , url : 'https://my.app.com' , forwardAuthToken : true } ], xsappname : 'MYAPP' }; ar . createRouterConfig ( options , function ( err , routerConfig ) { if ( err ) { console . error ( err ); } else { customRouterConfig = routerConfig ; } }); function getRouterConfig ( request , callback ) { if ( /\\?custom-query/ . test ( request . url )) { callback ( null , customRouterConfig ); } else { callback ( null , null ); // use default router config } }","title":"Dynamic Routing"},{"location":"apis/approuter/doc/extending/#state-synchronization","text":"The application router can be scaled to run with multiple instances like any other application on Cloud Foundry. Still application router instances are not aware of each other and there is no communication among them. So if extensions introduce some state, they should take care to synchronize it across application router instances.","title":"State synchronization"},{"location":"apis/approuter/doc/extending/#api-reference","text":"","title":"API Reference"},{"location":"apis/approuter/doc/extending/#approuter","text":"","title":"approuter"},{"location":"apis/approuter/doc/extending/#approuter_1","text":"Creates a new instance of the application router.","title":"approuter()"},{"location":"apis/approuter/doc/extending/#event-login","text":"Parameters: * session * id - session id as a string Emitted when a new user session is created.","title":"Event: 'login'"},{"location":"apis/approuter/doc/extending/#event-logout","text":"Parameters: * session * id - session id as a string Emitted when a user session has expired or a user has requested to log out.","title":"Event: 'logout'"},{"location":"apis/approuter/doc/extending/#first","text":"A Middleware Slot before the first application router middleware","title":"first"},{"location":"apis/approuter/doc/extending/#beforerequesthandler","text":"A Middleware Slot before the standard application router request handling","title":"beforeRequestHandler"},{"location":"apis/approuter/doc/extending/#beforeerrorhandler","text":"A Middleware Slot before the standard application router error handling","title":"beforeErrorHandler"},{"location":"apis/approuter/doc/extending/#startoptions-callback","text":"Starts the application router with the given options. options this argument is optional. If provided, it should be an object which can have any of the following properties: port - a TCP port the application router will listen to (string, optional) workingDir - the working directory for the application router, should contain the xs-app.json file (string, optional) extensions - an array of extensions, each one is an object as defined in Application Router Extensions (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. If this property is present it will take precedence over the content of xs-app.json. (optional) httpsOptions - Options similar to https.createServer . If this property is present, application router will be started as an https server. (optional) getToken - function(request, callback) Provide custom access token (optional) request - Node request object callback - function(error, token) error - Error object in case of error token - Access token to use in request to backend getRouterConfig - function(request, callback) Provide custom routing configuration (optional) request - Node request object callback - function(error, routerConfig) error - Error object in case of error routerConfig - Custom routing configuration to use for given request. This object should be created via createRouterConfig . If null or undefined , default configuration will be used. callback - optional function with signature callback(err) . It is invoked when the application router has started or an error has occurred. If not provided and an error occurs (e.g. the port is busy), the application will abort.","title":"start(options, callback)"},{"location":"apis/approuter/doc/extending/#closecallback","text":"Stops the application router. callback - optional function with signature callback(err) . It is invoked when the application router has stopped or an error has occurred.","title":"close(callback)"},{"location":"apis/approuter/doc/extending/#createrouterconfigoptions-callback","text":"Prepares the routing configuration to be used by the application router. As part of this, the application router validates the given options. This function can be used at any point in runtime to create additional routing configurations. Note: This function can be called only after start function. options xsappname - Value to replace $XSAPPNAME placeholder in scope names. If not provided, it will be taken from UAA service binding. (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. Note: Only the following configurations are taken into account from this property (the rest are taken from the xs-app.json file): welcomeFile , logout.logoutEndpoint , logout.logoutPage , routes , websockets , errorPage . destinations - An array containing the configuration of the backend destinations. If not provided, it will be taken from destinations environment variable. (optional) callback - function(error, routerConfig) error - Error object in case of error routerConfig - Routing configuration to be passed to the callback of getRouterConfig . Approuter extensions should not access the content of this object.","title":"createRouterConfig(options, callback)"},{"location":"apis/approuter/doc/extending/#resolveuaaconfigrequest-uaaoptions-callback","text":"Calculates tenant-specific UAA configuration. request - node request object used to identify the tenant uaaOptions - UAA options as provided in service binding callback - function(error, tenantUaaOptions) error - Error object in case of error tenantUaaOptions - new UAA configuration with tenant-specific properties","title":"resolveUaaConfig(request, uaaOptions, callback)"},{"location":"apis/approuter/doc/extending/#middleware-slot","text":"","title":"Middleware Slot"},{"location":"apis/approuter/doc/extending/#usepath-handler","text":"Inserts a request handling middleware in the current slot. path - handle only requests starting with this path (string, optional) handler - a middleware function to invoke (function, mandatory) Returns this for chaining.","title":"use(path, handler)"},{"location":"apis/approuter/doc/sessionManagement/","text":"Extended Session Management \u00b6 Abstract Session Lifecycle Security Data Privacy API Reference Example Performance Abstract \u00b6 The application router uses a memory store as a session repository to provide the best runtime performance. However, it is not persisted and it is not shared across multiple instances of the application router. Note: The Limitations above do not prevent the application router from being scaled out, since session stickiness is in place by default. While it is good enough for most of the cases, it may be required to provide a highly-available solution, which may be achieved by storing the state (session) of the application router outside - in durable shared storage. To allow implementing these qualities, the application router exposes the extended session management API described below. Session Lifecycle \u00b6 The application router stores user agent sessions as JavaScript objects serialized to strings. It also stores the session timeout associated with each session, which indicates the amount of time left until session invalidation. Initial Data \u00b6 During the start of the application router, the internal session store is initiated. It contains an empty list of sessions and their timeouts. The internal session store is not available right after the application router instance is created, but is available in the callback of approuter.start and all the time afterwards until the application router is stopped. In case an external session storage is used, the application router extension should perform the following actions to synchronize the internal session store with the external one: Load existing sessions from external storage Start the application router Populate the application router's internal session store Read \u00b6 A session identifier may be obtained from the request object req.sessionID . On each request, the application router executes registered middlewares in a certain order and the session is not available to all of them. First it passes the request to approuter.first middleware. At this point, there is no session associated with the incoming request. Afterwards, the application router checks if the user is authenticated, reads the relevant session from the internal session store and puts it into the request context. Next, the application router passes a request to approuter.broforeRequestHandler . At this point, the session object is available and associated with the incoming request. approuter.beforeErrorHandler also has access to session. Login \u00b6 When a user agent requests a resource, served via a route that requires authentication, the application router will request the user agent to pass authentication first (usually via redirect to XSUAA). At this point, the application router does not create any session. Only after the authentication process is finished, the application router creates a session, stores it in the internal session storage and emits a login event. Update Session \u00b6 Any changes made to the session are not stored in the internal session store immediately, but are accumulated to make a bulk update after the end of the response. While the request is passed through the chain of middlewares, the session object may be modified. Also, when the backend access token is close to expire, the application router may trigger the refresh backend token flow. In both cases, the actual update of the internal session store is done later on, outside of the request context. Timeout \u00b6 There is a time-based job in the application router that basis outside the request context and destroys sessions with an elapsed timeout. Each time the application router reads a session from the session store, the timeout of this session is reset to the initial value that may be retrieved using the getDefaultSessionTimeout() API. Logout \u00b6 When a user agent requests a URL defined as the logoutEndpoint in the xs-app.json file, a central logout process takes place. As part of this process, the application router emits a logout event. More detailed information about the central logout may be found in README.md Security \u00b6 The application router uses session secret to sign session cookies and prevent tampering. The session secret, by default, is generated using a random sequence of bytes at the startup of the application router. It is different for each instance and changed on each restart of the same instance. Using the default session secret generation mechanism for highly available application routers may cause issues in the following scenarios: The user agent is authenticated and the session is stored in a session store. The application router is restarted (due to internal error or triggered by platform) and a new session secret is generated. The authenticated user agent makes a request, which contains the session cookies. However, the cookies are signed using another secret and the application router ignores them. The user agent is authenticated and the session is stored in the session store. The application router instance is unavailable. The authenticated user agent makes a request to the application router and the request contains the session cookies. The load balancer forwards the request to another instance of the application router. However, cookies are signed using another secret and the application router ignores them. In both scenarios, the session in the store is no longer accessible, the cookies sent by the user agent are redundant, and the user agent will be requested to pass authentication once again. To avoid the issues described above, the extension that implements the extended session management mechanism, should make sure to implement the getSessionSecret hook. var ar = AppRouter (); ar . start ({ getSessionSecret : function () { return 'CUSTOM_PERSISTED_SESSION_SECRET' ; }, ... }); It is recommended to have at least 128 characters in the string that replaces CUSTOM_PERSISTED_SESSION_SECRET . Data Privacy \u00b6 The user agent session potentially contains personal data. By implementing the custom session management behaviour, you take the responsibility to be compliant with all personal data protection laws and regulations (e.g. GDPR ) that may be applied in the regions, where the application will be used. API Reference \u00b6 Methods \u00b6 approuter.start(options) \u00b6 options getSessionSecret - returns the session secret to be used by the application router for the signing of the session cookies. approuter.getSessionStore() \u00b6 returns SessionStore instance. sessionStore.getDefaultSessionTimeout() \u00b6 returns the default session timeout in minutes. sessionStore.getSessionTimeout(sessionId, callback) \u00b6 sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null timeout - time, in minutes, until the session times out sessionStore.get(sessionId, callback) \u00b6 sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null session - the session object id - session identifier, immutable sessionStore.set(sessionId, sessionString, timeout, callback) \u00b6 sessionId - an unsigned session identifier sessionString - a session object serialized to string timeout - a timestamp in milliseconds, after which the session should be automatically invalidated callback - a function that is called after the session is saved in the internal session storage of the application router sessionStore.update(sessionId, callback, resetTimeout) \u00b6 sessionId - an unsigned session identifier callback - function(currentSession) function, which returns session object. Callback function may modify and return current session object or create and return brand new session object currentSession - current session object resetTimeout - a boolean that indicates whether to reset the session timeout sessionStore.destroy(sessionId, callback) \u00b6 sessionId - an unsigned session identifier callback - a function that is called after the session is destroyed in the internal session storage of the application router Events \u00b6 Extension may subscribe to application router events using the standard EventEmitter API. var ar = AppRouter (); ar . on ( 'someEvent' , function handler () { // Handle event }); login \u00b6 Emitted when user agent is authenticated. Parameters: * session - session object * id - session identifier, immutable logout \u00b6 Emitted when a user agent session is going to be terminated in the internal session store of the application router. Emitted either when the user agent session is timed-out or when logoutEndpoint was requested. Note: Central logout is an asynchronous process. The order in which the backend and the application router sessions are invalidated, is not guaranteed. Parameters: * session - session object * id - session identifier, immutable Example \u00b6 There may be many various options, how the application router extension decides to store sessions exposed via the session management API. The example below assumes a SessionDataAccessObject to be implemented by the extension developer and to have the following API: Methods: \u00b6 sessionDataAccessObject.create - function(session, timeout) sessionDataAccessObject.update - function(sessionId, timeout) sessionDataAccessObject.delete - function(sessionId) sessionDataAccessObject.load - function() Events: \u00b6 create \u00b6 Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should expire callback - function to be called after session is stored in internal session storage update \u00b6 Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should be expired callback - function to be called after session is stored in internal session storage delete \u00b6 Parameters: sessionId - session identifier load \u00b6 Parameters: sessions[] - array of objects id - session identifier session - session object serialized to string timeout - timestamp, when session should expire var ar = new require ( '@sap/approuter' )(); var dao = new SessionDataAccessObject (); dao . on ( 'load' , function ( data ) { ar . start ({ getSessionSecret : function getSessionSecret () { return process . env . SESSION_SECRET ; } }, function () { var store = ar . getSessionStore (); var defaultTimeout = store . getDefaultSessionTimeout (); // AppRouter -> Persistence ar . on ( 'login' , function ( session ) { dao . create ( session , defaultTimeout ); }); ar . on ( 'update' , function ( sessionId , timeout ) { dao . update ( sessionId , timeout ); }); ar . on ( 'logout' , function ( sessionId ) { dao . delete ( sessionId ); }); // Load Initial Data data . forEach ( function ( item ) { store . set ( item . id , item . session , item . timeout ); }); // Persistence -> AppRouter dao . on ( 'create' , store . set ); dao . on ( 'update' , store . set ); dao . on ( 'delete' , store . destroy ); }); }); dao . load (); Performance \u00b6 Note: The update event of the application router may be potentially triggered thousands of times a second. It is recommended to throttle or debounce calls to the external storage to reduce network and CPU consumption. Here is an example of a throttled dao.update() , where the latest change will be persisted in the external storage no more than once in 500ms for the same session. // Throttled update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( ! this . updateTimers [ sessionId ]) { this . updateTimers [ sessionId ] = setTimeout ( function () { dao . updateTimers [ sessionId ] = null ; }, 500 ); sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); } } else { if ( ! this . timeoutTimers [ sessionId ]) { this . timeoutTimers [ sessionId ] = setTimeout ( function () { dao . timeoutTimers [ sessionId ] = null ; }, 500 ); sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); } } } And here is an example of a debounced dao.update() , where the latest change will be persisted in the external storage only if there were no other changes during the last 500ms for the same session. // Debounced update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( this . updateTimers [ sessionId ]) { clearTimeout ( this . updateTimers [ sessionId ]); } this . updateTimers [ sessionId ] = setTimeout ( function () { sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); }, 500 ); } else { if ( this . timeoutTimers [ sessionId ]) { clearTimeout ( this . timeoutTimers [ sessionId ]); } this . timeoutTimers [ sessionId ] = setTimeout ( function () { sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); }, 500 ); } } To understand the difference between throttling and debouncing, let's consider an example, where requests for the same session come every 100ms for 1sec . In case of 500ms debouncing, changes will be persisted one time. In case of 500ms throttling, changes will be persisted two times. Without any optimisation, changes will be persisted ten times.","title":"sessionManagement"},{"location":"apis/approuter/doc/sessionManagement/#extended-session-management","text":"Abstract Session Lifecycle Security Data Privacy API Reference Example Performance","title":"Extended Session Management"},{"location":"apis/approuter/doc/sessionManagement/#abstract","text":"The application router uses a memory store as a session repository to provide the best runtime performance. However, it is not persisted and it is not shared across multiple instances of the application router. Note: The Limitations above do not prevent the application router from being scaled out, since session stickiness is in place by default. While it is good enough for most of the cases, it may be required to provide a highly-available solution, which may be achieved by storing the state (session) of the application router outside - in durable shared storage. To allow implementing these qualities, the application router exposes the extended session management API described below.","title":"Abstract"},{"location":"apis/approuter/doc/sessionManagement/#session-lifecycle","text":"The application router stores user agent sessions as JavaScript objects serialized to strings. It also stores the session timeout associated with each session, which indicates the amount of time left until session invalidation.","title":"Session Lifecycle"},{"location":"apis/approuter/doc/sessionManagement/#initial-data","text":"During the start of the application router, the internal session store is initiated. It contains an empty list of sessions and their timeouts. The internal session store is not available right after the application router instance is created, but is available in the callback of approuter.start and all the time afterwards until the application router is stopped. In case an external session storage is used, the application router extension should perform the following actions to synchronize the internal session store with the external one: Load existing sessions from external storage Start the application router Populate the application router's internal session store","title":"Initial Data"},{"location":"apis/approuter/doc/sessionManagement/#read","text":"A session identifier may be obtained from the request object req.sessionID . On each request, the application router executes registered middlewares in a certain order and the session is not available to all of them. First it passes the request to approuter.first middleware. At this point, there is no session associated with the incoming request. Afterwards, the application router checks if the user is authenticated, reads the relevant session from the internal session store and puts it into the request context. Next, the application router passes a request to approuter.broforeRequestHandler . At this point, the session object is available and associated with the incoming request. approuter.beforeErrorHandler also has access to session.","title":"Read"},{"location":"apis/approuter/doc/sessionManagement/#login","text":"When a user agent requests a resource, served via a route that requires authentication, the application router will request the user agent to pass authentication first (usually via redirect to XSUAA). At this point, the application router does not create any session. Only after the authentication process is finished, the application router creates a session, stores it in the internal session storage and emits a login event.","title":"Login"},{"location":"apis/approuter/doc/sessionManagement/#update-session","text":"Any changes made to the session are not stored in the internal session store immediately, but are accumulated to make a bulk update after the end of the response. While the request is passed through the chain of middlewares, the session object may be modified. Also, when the backend access token is close to expire, the application router may trigger the refresh backend token flow. In both cases, the actual update of the internal session store is done later on, outside of the request context.","title":"Update Session"},{"location":"apis/approuter/doc/sessionManagement/#timeout","text":"There is a time-based job in the application router that basis outside the request context and destroys sessions with an elapsed timeout. Each time the application router reads a session from the session store, the timeout of this session is reset to the initial value that may be retrieved using the getDefaultSessionTimeout() API.","title":"Timeout"},{"location":"apis/approuter/doc/sessionManagement/#logout","text":"When a user agent requests a URL defined as the logoutEndpoint in the xs-app.json file, a central logout process takes place. As part of this process, the application router emits a logout event. More detailed information about the central logout may be found in README.md","title":"Logout"},{"location":"apis/approuter/doc/sessionManagement/#security","text":"The application router uses session secret to sign session cookies and prevent tampering. The session secret, by default, is generated using a random sequence of bytes at the startup of the application router. It is different for each instance and changed on each restart of the same instance. Using the default session secret generation mechanism for highly available application routers may cause issues in the following scenarios: The user agent is authenticated and the session is stored in a session store. The application router is restarted (due to internal error or triggered by platform) and a new session secret is generated. The authenticated user agent makes a request, which contains the session cookies. However, the cookies are signed using another secret and the application router ignores them. The user agent is authenticated and the session is stored in the session store. The application router instance is unavailable. The authenticated user agent makes a request to the application router and the request contains the session cookies. The load balancer forwards the request to another instance of the application router. However, cookies are signed using another secret and the application router ignores them. In both scenarios, the session in the store is no longer accessible, the cookies sent by the user agent are redundant, and the user agent will be requested to pass authentication once again. To avoid the issues described above, the extension that implements the extended session management mechanism, should make sure to implement the getSessionSecret hook. var ar = AppRouter (); ar . start ({ getSessionSecret : function () { return 'CUSTOM_PERSISTED_SESSION_SECRET' ; }, ... }); It is recommended to have at least 128 characters in the string that replaces CUSTOM_PERSISTED_SESSION_SECRET .","title":"Security"},{"location":"apis/approuter/doc/sessionManagement/#data-privacy","text":"The user agent session potentially contains personal data. By implementing the custom session management behaviour, you take the responsibility to be compliant with all personal data protection laws and regulations (e.g. GDPR ) that may be applied in the regions, where the application will be used.","title":"Data Privacy"},{"location":"apis/approuter/doc/sessionManagement/#api-reference","text":"","title":"API Reference"},{"location":"apis/approuter/doc/sessionManagement/#methods","text":"","title":"Methods"},{"location":"apis/approuter/doc/sessionManagement/#approuterstartoptions","text":"options getSessionSecret - returns the session secret to be used by the application router for the signing of the session cookies.","title":"approuter.start(options)"},{"location":"apis/approuter/doc/sessionManagement/#approutergetsessionstore","text":"returns SessionStore instance.","title":"approuter.getSessionStore()"},{"location":"apis/approuter/doc/sessionManagement/#sessionstoregetdefaultsessiontimeout","text":"returns the default session timeout in minutes.","title":"sessionStore.getDefaultSessionTimeout()"},{"location":"apis/approuter/doc/sessionManagement/#sessionstoregetsessiontimeoutsessionid-callback","text":"sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null timeout - time, in minutes, until the session times out","title":"sessionStore.getSessionTimeout(sessionId, callback)"},{"location":"apis/approuter/doc/sessionManagement/#sessionstoregetsessionid-callback","text":"sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null session - the session object id - session identifier, immutable","title":"sessionStore.get(sessionId, callback)"},{"location":"apis/approuter/doc/sessionManagement/#sessionstoresetsessionid-sessionstring-timeout-callback","text":"sessionId - an unsigned session identifier sessionString - a session object serialized to string timeout - a timestamp in milliseconds, after which the session should be automatically invalidated callback - a function that is called after the session is saved in the internal session storage of the application router","title":"sessionStore.set(sessionId, sessionString, timeout, callback)"},{"location":"apis/approuter/doc/sessionManagement/#sessionstoreupdatesessionid-callback-resettimeout","text":"sessionId - an unsigned session identifier callback - function(currentSession) function, which returns session object. Callback function may modify and return current session object or create and return brand new session object currentSession - current session object resetTimeout - a boolean that indicates whether to reset the session timeout","title":"sessionStore.update(sessionId, callback, resetTimeout)"},{"location":"apis/approuter/doc/sessionManagement/#sessionstoredestroysessionid-callback","text":"sessionId - an unsigned session identifier callback - a function that is called after the session is destroyed in the internal session storage of the application router","title":"sessionStore.destroy(sessionId, callback)"},{"location":"apis/approuter/doc/sessionManagement/#events","text":"Extension may subscribe to application router events using the standard EventEmitter API. var ar = AppRouter (); ar . on ( 'someEvent' , function handler () { // Handle event });","title":"Events"},{"location":"apis/approuter/doc/sessionManagement/#login_1","text":"Emitted when user agent is authenticated. Parameters: * session - session object * id - session identifier, immutable","title":"login"},{"location":"apis/approuter/doc/sessionManagement/#logout_1","text":"Emitted when a user agent session is going to be terminated in the internal session store of the application router. Emitted either when the user agent session is timed-out or when logoutEndpoint was requested. Note: Central logout is an asynchronous process. The order in which the backend and the application router sessions are invalidated, is not guaranteed. Parameters: * session - session object * id - session identifier, immutable","title":"logout"},{"location":"apis/approuter/doc/sessionManagement/#example","text":"There may be many various options, how the application router extension decides to store sessions exposed via the session management API. The example below assumes a SessionDataAccessObject to be implemented by the extension developer and to have the following API:","title":"Example"},{"location":"apis/approuter/doc/sessionManagement/#methods_1","text":"sessionDataAccessObject.create - function(session, timeout) sessionDataAccessObject.update - function(sessionId, timeout) sessionDataAccessObject.delete - function(sessionId) sessionDataAccessObject.load - function()","title":"Methods:"},{"location":"apis/approuter/doc/sessionManagement/#events_1","text":"","title":"Events:"},{"location":"apis/approuter/doc/sessionManagement/#create","text":"Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should expire callback - function to be called after session is stored in internal session storage","title":"create"},{"location":"apis/approuter/doc/sessionManagement/#update","text":"Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should be expired callback - function to be called after session is stored in internal session storage","title":"update"},{"location":"apis/approuter/doc/sessionManagement/#delete","text":"Parameters: sessionId - session identifier","title":"delete"},{"location":"apis/approuter/doc/sessionManagement/#load","text":"Parameters: sessions[] - array of objects id - session identifier session - session object serialized to string timeout - timestamp, when session should expire var ar = new require ( '@sap/approuter' )(); var dao = new SessionDataAccessObject (); dao . on ( 'load' , function ( data ) { ar . start ({ getSessionSecret : function getSessionSecret () { return process . env . SESSION_SECRET ; } }, function () { var store = ar . getSessionStore (); var defaultTimeout = store . getDefaultSessionTimeout (); // AppRouter -> Persistence ar . on ( 'login' , function ( session ) { dao . create ( session , defaultTimeout ); }); ar . on ( 'update' , function ( sessionId , timeout ) { dao . update ( sessionId , timeout ); }); ar . on ( 'logout' , function ( sessionId ) { dao . delete ( sessionId ); }); // Load Initial Data data . forEach ( function ( item ) { store . set ( item . id , item . session , item . timeout ); }); // Persistence -> AppRouter dao . on ( 'create' , store . set ); dao . on ( 'update' , store . set ); dao . on ( 'delete' , store . destroy ); }); }); dao . load ();","title":"load"},{"location":"apis/approuter/doc/sessionManagement/#performance","text":"Note: The update event of the application router may be potentially triggered thousands of times a second. It is recommended to throttle or debounce calls to the external storage to reduce network and CPU consumption. Here is an example of a throttled dao.update() , where the latest change will be persisted in the external storage no more than once in 500ms for the same session. // Throttled update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( ! this . updateTimers [ sessionId ]) { this . updateTimers [ sessionId ] = setTimeout ( function () { dao . updateTimers [ sessionId ] = null ; }, 500 ); sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); } } else { if ( ! this . timeoutTimers [ sessionId ]) { this . timeoutTimers [ sessionId ] = setTimeout ( function () { dao . timeoutTimers [ sessionId ] = null ; }, 500 ); sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); } } } And here is an example of a debounced dao.update() , where the latest change will be persisted in the external storage only if there were no other changes during the last 500ms for the same session. // Debounced update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( this . updateTimers [ sessionId ]) { clearTimeout ( this . updateTimers [ sessionId ]); } this . updateTimers [ sessionId ] = setTimeout ( function () { sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); }, 500 ); } else { if ( this . timeoutTimers [ sessionId ]) { clearTimeout ( this . timeoutTimers [ sessionId ]); } this . timeoutTimers [ sessionId ] = setTimeout ( function () { sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); }, 500 ); } } To understand the difference between throttling and debouncing, let's consider an example, where requests for the same session come every 100ms for 1sec . In case of 500ms debouncing, changes will be persisted one time. In case of 500ms throttling, changes will be persisted two times. Without any optimisation, changes will be persisted ten times.","title":"Performance"},{"location":"apis/approuter/doc/sizingGuide/","text":"Sizing Guide for Application Router \u00b6 Idle Test Setup HTTP Traffic Web Socket Traffic Memory Configuration In this guide we provide measurements done in different application router scenarios. You can use them to approximately calculate the amount of memory that would be required by the application router. The tables contain the exact results from the measurements with Node.js v6.9.1. It is a good idea to provide higher numbers for productive usage. All measurements are with authentication. If you have additional session content and want to count the session memory consumption please take a look at what is stored in the session - described in README's Session Contents section. You will need to add the calculated session size taking into account the number of different users and the session timeout. In our tests only the JWT token took ~4KB. Idle \u00b6 The memory consumption for an idle application router is around 50 MB. Test Setup \u00b6 The application router runs in a container with limited amount of memory. Swap is turned off. The test client creates new sessions on the server with a step of 100. No more than 100 users request the application router at a given time (e.g. 100 sessions are initialized and become idle, then 100 more session are created and become idle ...). The test ends when an Out of Memory event occurs, causing the container to be stopped. The number of created sessions before the process ends is taken. HTTP Traffic \u00b6 There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - Scenario (2) - A 'Hello World' static resource is being served. - A static resource of 84.78kb (compressed by application router to 28.36kb) is being served. - A backend which returns a payload of 80kb (compressed by application router to 58kb) is being called. - Another backend which returns a payload of 160kb (compressed by application router to 116kb) is being called. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 5 300 800 512MB 13 300 2 300 1GB 30 100 8 400 2GB 65 500 19 500 4GB 134 900 46 400 8GB 275 500 102 300 Web Socket Traffic \u00b6 There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - A single 'Hello' message is sent and then received through a web socket connection. - Scenario (2) - A 'Hello World' static resource is being served. - A backend which returns a payload of 80kb over a web socket is being called. - Another backend which returns a payload of 160kb over a web socket is being called. Note : Web sockets require a certain amount of file handles to be available to the process - it is approximately two times the number of the sessions. In Cloud Foundry the default value is 16384. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 600 300 512MB 1 100 500 1GB 3 100 800 2GB 6 500 1 400 4GB 13 300 2 900 8GB 20 700 6 100 Note : --max-old-space-size restricts the amount of memory used in the JavaScript heap. Its default value is below 2GB. So in order to use the full resources that has been provided to the application, the value of this restriction should be set to a number equal to the memory limit of the whole application. For example, if the application memory is limited to 2GB, set the V8 heap limit like this in the package.json : \"scripts\": { \"start\": \"node --max-old-space-size=2048 node_modules/@sap/approuter/approuter.js\" } Memory Configuration \u00b6 Application router process should run with at least 256MB memory. It may require more memory depending on the application. These aspects influence memory usage: - concurrent connections - active sessions - JWT token size - backend session cookies","title":"sizingGuide"},{"location":"apis/approuter/doc/sizingGuide/#sizing-guide-for-application-router","text":"Idle Test Setup HTTP Traffic Web Socket Traffic Memory Configuration In this guide we provide measurements done in different application router scenarios. You can use them to approximately calculate the amount of memory that would be required by the application router. The tables contain the exact results from the measurements with Node.js v6.9.1. It is a good idea to provide higher numbers for productive usage. All measurements are with authentication. If you have additional session content and want to count the session memory consumption please take a look at what is stored in the session - described in README's Session Contents section. You will need to add the calculated session size taking into account the number of different users and the session timeout. In our tests only the JWT token took ~4KB.","title":"Sizing Guide for Application Router"},{"location":"apis/approuter/doc/sizingGuide/#idle","text":"The memory consumption for an idle application router is around 50 MB.","title":"Idle"},{"location":"apis/approuter/doc/sizingGuide/#test-setup","text":"The application router runs in a container with limited amount of memory. Swap is turned off. The test client creates new sessions on the server with a step of 100. No more than 100 users request the application router at a given time (e.g. 100 sessions are initialized and become idle, then 100 more session are created and become idle ...). The test ends when an Out of Memory event occurs, causing the container to be stopped. The number of created sessions before the process ends is taken.","title":"Test Setup"},{"location":"apis/approuter/doc/sizingGuide/#http-traffic","text":"There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - Scenario (2) - A 'Hello World' static resource is being served. - A static resource of 84.78kb (compressed by application router to 28.36kb) is being served. - A backend which returns a payload of 80kb (compressed by application router to 58kb) is being called. - Another backend which returns a payload of 160kb (compressed by application router to 116kb) is being called. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 5 300 800 512MB 13 300 2 300 1GB 30 100 8 400 2GB 65 500 19 500 4GB 134 900 46 400 8GB 275 500 102 300","title":"HTTP Traffic"},{"location":"apis/approuter/doc/sizingGuide/#web-socket-traffic","text":"There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - A single 'Hello' message is sent and then received through a web socket connection. - Scenario (2) - A 'Hello World' static resource is being served. - A backend which returns a payload of 80kb over a web socket is being called. - Another backend which returns a payload of 160kb over a web socket is being called. Note : Web sockets require a certain amount of file handles to be available to the process - it is approximately two times the number of the sessions. In Cloud Foundry the default value is 16384. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 600 300 512MB 1 100 500 1GB 3 100 800 2GB 6 500 1 400 4GB 13 300 2 900 8GB 20 700 6 100 Note : --max-old-space-size restricts the amount of memory used in the JavaScript heap. Its default value is below 2GB. So in order to use the full resources that has been provided to the application, the value of this restriction should be set to a number equal to the memory limit of the whole application. For example, if the application memory is limited to 2GB, set the V8 heap limit like this in the package.json : \"scripts\": { \"start\": \"node --max-old-space-size=2048 node_modules/@sap/approuter/approuter.js\" }","title":"Web Socket Traffic"},{"location":"apis/approuter/doc/sizingGuide/#memory-configuration","text":"Application router process should run with at least 256MB memory. It may require more memory depending on the application. These aspects influence memory usage: - concurrent connections - active sessions - JWT token size - backend session cookies","title":"Memory Configuration"},{"location":"apis/approuter/doc/doc/extending/","text":"Extending Application Router \u00b6 Basics Inject Custom Middleware Application Router Extensions Customize Command Line Dynamic Routing State synchronization API Reference approuter approuter() Event: 'login' Event: 'logout' first beforeRequestHandler beforeErrorHandler start(options, callback) close(callback) createRouterConfig(options, callback) resolveUaaConfig(request, uaaOptions, callback) Middleware Slot use(path, handler) Basics \u00b6 Insead of starting the application router directly, your application can have its own start script. You can use the application router as a regular Node.js package. var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start (); Inject Custom Middleware \u00b6 The application router uses the connect framework. You can reuse all connect middlewares within the application router directly. You can do this directly in your start script: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); Tip: Name your middleware to improve troubleshooting. The path argument is optional. You can also chain use calls. var approuter = require ( '@sap/approuter' ); var morgan = require ( 'morgan' ); var ar = approuter (); ar . beforeRequestHandler . use ( morgan ( 'combined' )) . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); The application router defines the following slots where you can insert custom middleware: * first - right after the connect application is created, and before any application router middleware. At this point security checks are not performed yet. Tip: This is a good place for infrastructure logic like logging and monitoring. * beforeRequestHandler - before standard application router request handling, that is static resource serving or forwarding to destinations. Tip: This is a good place for custom REST API handling. * beforeErrorHandler - before standard application router error handling. Tip: This is a good place to capture or customize error handling. If your middleware does not complete the request processing, call next to return control to the application router middleware: ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . setHeader ( 'x-my-ext' , 'passed' ); next (); }); Application Router Extensions \u00b6 You can use application router extensions. An extension is defined by an object with the following properties: * insertMiddleware - describes the middleware provided by this extension * first , beforeRequestHandler , beforeErrorHandler - an array of middleware, where each one is either * a middleware function (invoked on all requests), or * an object with properties: * path - handle requests only for this path * handler - middleware function to invoke Here is an example (my-ext.js): module . exports = { insertMiddleware : { first : [ function logRequest ( req , res , next ) { console . log ( 'Got request %s %s' , req . method , req . url ); } ], beforeRequestHandler : [ { path : '/my-ext' , handler : function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); } } ] } }; You can use it in your start script like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ extensions : [ require ( './my-ext.js' ) ] }); Customize Command Line \u00b6 By default the application router handles its command line parameters, but you can customize that too. An approuter instance provides the property cmdParser that is a commander instance. It is configured with the standard application router command line options. There you can add custom options like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); var params = ar . cmdParser // add here custom command line options if needed . option ( '-d, --dummy' , 'A dummy option' ) . parse ( process . argv ); console . log ( 'Dummy option:' , params . dummy ); To completely disable the command line option handling in the application router, reset the following property: ar . cmdParser = false ; Dynamic Routing \u00b6 The application router can use a custom routing configuration for each request. Here is an example: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ getRouterConfig : getRouterConfig }); var customRouterConfig ; var options = { xsappConfig : { routes : [ { source : '/service' , destination : 'backend' , scope : '$XSAPPNAME.viewer' , } ] }, destinations : [ { name : 'backend' , url : 'https://my.app.com' , forwardAuthToken : true } ], xsappname : 'MYAPP' }; ar . createRouterConfig ( options , function ( err , routerConfig ) { if ( err ) { console . error ( err ); } else { customRouterConfig = routerConfig ; } }); function getRouterConfig ( request , callback ) { if ( /\\?custom-query/ . test ( request . url )) { callback ( null , customRouterConfig ); } else { callback ( null , null ); // use default router config } } State synchronization \u00b6 The application router can be scaled to run with multiple instances like any other application on Cloud Foundry. Still application router instances are not aware of each other and there is no communication among them. So if extensions introduce some state, they should take care to synchronize it across application router instances. API Reference \u00b6 approuter \u00b6 approuter() \u00b6 Creates a new instance of the application router. Event: 'login' \u00b6 Parameters: * session * id - session id as a string Emitted when a new user session is created. Event: 'logout' \u00b6 Parameters: * session * id - session id as a string Emitted when a user session has expired or a user has requested to log out. first \u00b6 A Middleware Slot before the first application router middleware beforeRequestHandler \u00b6 A Middleware Slot before the standard application router request handling beforeErrorHandler \u00b6 A Middleware Slot before the standard application router error handling start(options, callback) \u00b6 Starts the application router with the given options. options this argument is optional. If provided, it should be an object which can have any of the following properties: port - a TCP port the application router will listen to (string, optional) workingDir - the working directory for the application router, should contain the xs-app.json file (string, optional) extensions - an array of extensions, each one is an object as defined in Application Router Extensions (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. If this property is present it will take precedence over the content of xs-app.json. (optional) httpsOptions - Options similar to https.createServer . If this property is present, application router will be started as an https server. (optional) getToken - function(request, callback) Provide custom access token (optional) request - Node request object callback - function(error, token) error - Error object in case of error token - Access token to use in request to backend getRouterConfig - function(request, callback) Provide custom routing configuration (optional) request - Node request object callback - function(error, routerConfig) error - Error object in case of error routerConfig - Custom routing configuration to use for given request. This object should be created via createRouterConfig . If null or undefined , default configuration will be used. callback - optional function with signature callback(err) . It is invoked when the application router has started or an error has occurred. If not provided and an error occurs (e.g. the port is busy), the application will abort. close(callback) \u00b6 Stops the application router. callback - optional function with signature callback(err) . It is invoked when the application router has stopped or an error has occurred. createRouterConfig(options, callback) \u00b6 Prepares the routing configuration to be used by the application router. As part of this, the application router validates the given options. This function can be used at any point in runtime to create additional routing configurations. Note: This function can be called only after start function. options xsappname - Value to replace $XSAPPNAME placeholder in scope names. If not provided, it will be taken from UAA service binding. (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. Note: Only the following configurations are taken into account from this property (the rest are taken from the xs-app.json file): welcomeFile , logout.logoutEndpoint , logout.logoutPage , routes , websockets , errorPage . destinations - An array containing the configuration of the backend destinations. If not provided, it will be taken from destinations environment variable. (optional) callback - function(error, routerConfig) error - Error object in case of error routerConfig - Routing configuration to be passed to the callback of getRouterConfig . Approuter extensions should not access the content of this object. resolveUaaConfig(request, uaaOptions, callback) \u00b6 Calculates tenant-specific UAA configuration. request - node request object used to identify the tenant uaaOptions - UAA options as provided in service binding callback - function(error, tenantUaaOptions) error - Error object in case of error tenantUaaOptions - new UAA configuration with tenant-specific properties Middleware Slot \u00b6 use(path, handler) \u00b6 Inserts a request handling middleware in the current slot. path - handle only requests starting with this path (string, optional) handler - a middleware function to invoke (function, mandatory) Returns this for chaining.","title":"Extending"},{"location":"apis/approuter/doc/doc/extending/#extending-application-router","text":"Basics Inject Custom Middleware Application Router Extensions Customize Command Line Dynamic Routing State synchronization API Reference approuter approuter() Event: 'login' Event: 'logout' first beforeRequestHandler beforeErrorHandler start(options, callback) close(callback) createRouterConfig(options, callback) resolveUaaConfig(request, uaaOptions, callback) Middleware Slot use(path, handler)","title":"Extending Application Router"},{"location":"apis/approuter/doc/doc/extending/#basics","text":"Insead of starting the application router directly, your application can have its own start script. You can use the application router as a regular Node.js package. var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ();","title":"Basics"},{"location":"apis/approuter/doc/doc/extending/#inject-custom-middleware","text":"The application router uses the connect framework. You can reuse all connect middlewares within the application router directly. You can do this directly in your start script: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); Tip: Name your middleware to improve troubleshooting. The path argument is optional. You can also chain use calls. var approuter = require ( '@sap/approuter' ); var morgan = require ( 'morgan' ); var ar = approuter (); ar . beforeRequestHandler . use ( morgan ( 'combined' )) . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); }); ar . start (); The application router defines the following slots where you can insert custom middleware: * first - right after the connect application is created, and before any application router middleware. At this point security checks are not performed yet. Tip: This is a good place for infrastructure logic like logging and monitoring. * beforeRequestHandler - before standard application router request handling, that is static resource serving or forwarding to destinations. Tip: This is a good place for custom REST API handling. * beforeErrorHandler - before standard application router error handling. Tip: This is a good place to capture or customize error handling. If your middleware does not complete the request processing, call next to return control to the application router middleware: ar . beforeRequestHandler . use ( '/my-ext' , function myMiddleware ( req , res , next ) { res . setHeader ( 'x-my-ext' , 'passed' ); next (); });","title":"Inject Custom Middleware"},{"location":"apis/approuter/doc/doc/extending/#application-router-extensions","text":"You can use application router extensions. An extension is defined by an object with the following properties: * insertMiddleware - describes the middleware provided by this extension * first , beforeRequestHandler , beforeErrorHandler - an array of middleware, where each one is either * a middleware function (invoked on all requests), or * an object with properties: * path - handle requests only for this path * handler - middleware function to invoke Here is an example (my-ext.js): module . exports = { insertMiddleware : { first : [ function logRequest ( req , res , next ) { console . log ( 'Got request %s %s' , req . method , req . url ); } ], beforeRequestHandler : [ { path : '/my-ext' , handler : function myMiddleware ( req , res , next ) { res . end ( 'Request handled by my extension!' ); } } ] } }; You can use it in your start script like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ extensions : [ require ( './my-ext.js' ) ] });","title":"Application Router Extensions"},{"location":"apis/approuter/doc/doc/extending/#customize-command-line","text":"By default the application router handles its command line parameters, but you can customize that too. An approuter instance provides the property cmdParser that is a commander instance. It is configured with the standard application router command line options. There you can add custom options like this: var approuter = require ( '@sap/approuter' ); var ar = approuter (); var params = ar . cmdParser // add here custom command line options if needed . option ( '-d, --dummy' , 'A dummy option' ) . parse ( process . argv ); console . log ( 'Dummy option:' , params . dummy ); To completely disable the command line option handling in the application router, reset the following property: ar . cmdParser = false ;","title":"Customize Command Line"},{"location":"apis/approuter/doc/doc/extending/#dynamic-routing","text":"The application router can use a custom routing configuration for each request. Here is an example: var approuter = require ( '@sap/approuter' ); var ar = approuter (); ar . start ({ getRouterConfig : getRouterConfig }); var customRouterConfig ; var options = { xsappConfig : { routes : [ { source : '/service' , destination : 'backend' , scope : '$XSAPPNAME.viewer' , } ] }, destinations : [ { name : 'backend' , url : 'https://my.app.com' , forwardAuthToken : true } ], xsappname : 'MYAPP' }; ar . createRouterConfig ( options , function ( err , routerConfig ) { if ( err ) { console . error ( err ); } else { customRouterConfig = routerConfig ; } }); function getRouterConfig ( request , callback ) { if ( /\\?custom-query/ . test ( request . url )) { callback ( null , customRouterConfig ); } else { callback ( null , null ); // use default router config } }","title":"Dynamic Routing"},{"location":"apis/approuter/doc/doc/extending/#state-synchronization","text":"The application router can be scaled to run with multiple instances like any other application on Cloud Foundry. Still application router instances are not aware of each other and there is no communication among them. So if extensions introduce some state, they should take care to synchronize it across application router instances.","title":"State synchronization"},{"location":"apis/approuter/doc/doc/extending/#api-reference","text":"","title":"API Reference"},{"location":"apis/approuter/doc/doc/extending/#approuter","text":"","title":"approuter"},{"location":"apis/approuter/doc/doc/extending/#approuter_1","text":"Creates a new instance of the application router.","title":"approuter()"},{"location":"apis/approuter/doc/doc/extending/#event-login","text":"Parameters: * session * id - session id as a string Emitted when a new user session is created.","title":"Event: 'login'"},{"location":"apis/approuter/doc/doc/extending/#event-logout","text":"Parameters: * session * id - session id as a string Emitted when a user session has expired or a user has requested to log out.","title":"Event: 'logout'"},{"location":"apis/approuter/doc/doc/extending/#first","text":"A Middleware Slot before the first application router middleware","title":"first"},{"location":"apis/approuter/doc/doc/extending/#beforerequesthandler","text":"A Middleware Slot before the standard application router request handling","title":"beforeRequestHandler"},{"location":"apis/approuter/doc/doc/extending/#beforeerrorhandler","text":"A Middleware Slot before the standard application router error handling","title":"beforeErrorHandler"},{"location":"apis/approuter/doc/doc/extending/#startoptions-callback","text":"Starts the application router with the given options. options this argument is optional. If provided, it should be an object which can have any of the following properties: port - a TCP port the application router will listen to (string, optional) workingDir - the working directory for the application router, should contain the xs-app.json file (string, optional) extensions - an array of extensions, each one is an object as defined in Application Router Extensions (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. If this property is present it will take precedence over the content of xs-app.json. (optional) httpsOptions - Options similar to https.createServer . If this property is present, application router will be started as an https server. (optional) getToken - function(request, callback) Provide custom access token (optional) request - Node request object callback - function(error, token) error - Error object in case of error token - Access token to use in request to backend getRouterConfig - function(request, callback) Provide custom routing configuration (optional) request - Node request object callback - function(error, routerConfig) error - Error object in case of error routerConfig - Custom routing configuration to use for given request. This object should be created via createRouterConfig . If null or undefined , default configuration will be used. callback - optional function with signature callback(err) . It is invoked when the application router has started or an error has occurred. If not provided and an error occurs (e.g. the port is busy), the application will abort.","title":"start(options, callback)"},{"location":"apis/approuter/doc/doc/extending/#closecallback","text":"Stops the application router. callback - optional function with signature callback(err) . It is invoked when the application router has stopped or an error has occurred.","title":"close(callback)"},{"location":"apis/approuter/doc/doc/extending/#createrouterconfigoptions-callback","text":"Prepares the routing configuration to be used by the application router. As part of this, the application router validates the given options. This function can be used at any point in runtime to create additional routing configurations. Note: This function can be called only after start function. options xsappname - Value to replace $XSAPPNAME placeholder in scope names. If not provided, it will be taken from UAA service binding. (optional) xsappConfig - An object representing the content which is usually put in xs-app.json file. Note: Only the following configurations are taken into account from this property (the rest are taken from the xs-app.json file): welcomeFile , logout.logoutEndpoint , logout.logoutPage , routes , websockets , errorPage . destinations - An array containing the configuration of the backend destinations. If not provided, it will be taken from destinations environment variable. (optional) callback - function(error, routerConfig) error - Error object in case of error routerConfig - Routing configuration to be passed to the callback of getRouterConfig . Approuter extensions should not access the content of this object.","title":"createRouterConfig(options, callback)"},{"location":"apis/approuter/doc/doc/extending/#resolveuaaconfigrequest-uaaoptions-callback","text":"Calculates tenant-specific UAA configuration. request - node request object used to identify the tenant uaaOptions - UAA options as provided in service binding callback - function(error, tenantUaaOptions) error - Error object in case of error tenantUaaOptions - new UAA configuration with tenant-specific properties","title":"resolveUaaConfig(request, uaaOptions, callback)"},{"location":"apis/approuter/doc/doc/extending/#middleware-slot","text":"","title":"Middleware Slot"},{"location":"apis/approuter/doc/doc/extending/#usepath-handler","text":"Inserts a request handling middleware in the current slot. path - handle only requests starting with this path (string, optional) handler - a middleware function to invoke (function, mandatory) Returns this for chaining.","title":"use(path, handler)"},{"location":"apis/approuter/doc/doc/sessionManagement/","text":"Extended Session Management \u00b6 Abstract Session Lifecycle Security Data Privacy API Reference Example Performance Abstract \u00b6 The application router uses a memory store as a session repository to provide the best runtime performance. However, it is not persisted and it is not shared across multiple instances of the application router. Note: The Limitations above do not prevent the application router from being scaled out, since session stickiness is in place by default. While it is good enough for most of the cases, it may be required to provide a highly-available solution, which may be achieved by storing the state (session) of the application router outside - in durable shared storage. To allow implementing these qualities, the application router exposes the extended session management API described below. Session Lifecycle \u00b6 The application router stores user agent sessions as JavaScript objects serialized to strings. It also stores the session timeout associated with each session, which indicates the amount of time left until session invalidation. Initial Data \u00b6 During the start of the application router, the internal session store is initiated. It contains an empty list of sessions and their timeouts. The internal session store is not available right after the application router instance is created, but is available in the callback of approuter.start and all the time afterwards until the application router is stopped. In case an external session storage is used, the application router extension should perform the following actions to synchronize the internal session store with the external one: Load existing sessions from external storage Start the application router Populate the application router's internal session store Read \u00b6 A session identifier may be obtained from the request object req.sessionID . On each request, the application router executes registered middlewares in a certain order and the session is not available to all of them. First it passes the request to approuter.first middleware. At this point, there is no session associated with the incoming request. Afterwards, the application router checks if the user is authenticated, reads the relevant session from the internal session store and puts it into the request context. Next, the application router passes a request to approuter.broforeRequestHandler . At this point, the session object is available and associated with the incoming request. approuter.beforeErrorHandler also has access to session. Login \u00b6 When a user agent requests a resource, served via a route that requires authentication, the application router will request the user agent to pass authentication first (usually via redirect to XSUAA). At this point, the application router does not create any session. Only after the authentication process is finished, the application router creates a session, stores it in the internal session storage and emits a login event. Update Session \u00b6 Any changes made to the session are not stored in the internal session store immediately, but are accumulated to make a bulk update after the end of the response. While the request is passed through the chain of middlewares, the session object may be modified. Also, when the backend access token is close to expire, the application router may trigger the refresh backend token flow. In both cases, the actual update of the internal session store is done later on, outside of the request context. Timeout \u00b6 There is a time-based job in the application router that basis outside the request context and destroys sessions with an elapsed timeout. Each time the application router reads a session from the session store, the timeout of this session is reset to the initial value that may be retrieved using the getDefaultSessionTimeout() API. Logout \u00b6 When a user agent requests a URL defined as the logoutEndpoint in the xs-app.json file, a central logout process takes place. As part of this process, the application router emits a logout event. More detailed information about the central logout may be found in README.md Security \u00b6 The application router uses session secret to sign session cookies and prevent tampering. The session secret, by default, is generated using a random sequence of bytes at the startup of the application router. It is different for each instance and changed on each restart of the same instance. Using the default session secret generation mechanism for highly available application routers may cause issues in the following scenarios: The user agent is authenticated and the session is stored in a session store. The application router is restarted (due to internal error or triggered by platform) and a new session secret is generated. The authenticated user agent makes a request, which contains the session cookies. However, the cookies are signed using another secret and the application router ignores them. The user agent is authenticated and the session is stored in the session store. The application router instance is unavailable. The authenticated user agent makes a request to the application router and the request contains the session cookies. The load balancer forwards the request to another instance of the application router. However, cookies are signed using another secret and the application router ignores them. In both scenarios, the session in the store is no longer accessible, the cookies sent by the user agent are redundant, and the user agent will be requested to pass authentication once again. To avoid the issues described above, the extension that implements the extended session management mechanism, should make sure to implement the getSessionSecret hook. var ar = AppRouter (); ar . start ({ getSessionSecret : function () { return 'CUSTOM_PERSISTED_SESSION_SECRET' ; }, ... }); It is recommended to have at least 128 characters in the string that replaces CUSTOM_PERSISTED_SESSION_SECRET . Data Privacy \u00b6 The user agent session potentially contains personal data. By implementing the custom session management behaviour, you take the responsibility to be compliant with all personal data protection laws and regulations (e.g. GDPR ) that may be applied in the regions, where the application will be used. API Reference \u00b6 Methods \u00b6 approuter.start(options) \u00b6 options getSessionSecret - returns the session secret to be used by the application router for the signing of the session cookies. approuter.getSessionStore() \u00b6 returns SessionStore instance. sessionStore.getDefaultSessionTimeout() \u00b6 returns the default session timeout in minutes. sessionStore.getSessionTimeout(sessionId, callback) \u00b6 sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null timeout - time, in minutes, until the session times out sessionStore.get(sessionId, callback) \u00b6 sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null session - the session object id - session identifier, immutable sessionStore.set(sessionId, sessionString, timeout, callback) \u00b6 sessionId - an unsigned session identifier sessionString - a session object serialized to string timeout - a timestamp in milliseconds, after which the session should be automatically invalidated callback - a function that is called after the session is saved in the internal session storage of the application router sessionStore.update(sessionId, callback, resetTimeout) \u00b6 sessionId - an unsigned session identifier callback - function(currentSession) function, which returns session object. Callback function may modify and return current session object or create and return brand new session object currentSession - current session object resetTimeout - a boolean that indicates whether to reset the session timeout sessionStore.destroy(sessionId, callback) \u00b6 sessionId - an unsigned session identifier callback - a function that is called after the session is destroyed in the internal session storage of the application router Events \u00b6 Extension may subscribe to application router events using the standard EventEmitter API. var ar = AppRouter (); ar . on ( 'someEvent' , function handler () { // Handle event }); login \u00b6 Emitted when user agent is authenticated. Parameters: * session - session object * id - session identifier, immutable logout \u00b6 Emitted when a user agent session is going to be terminated in the internal session store of the application router. Emitted either when the user agent session is timed-out or when logoutEndpoint was requested. Note: Central logout is an asynchronous process. The order in which the backend and the application router sessions are invalidated, is not guaranteed. Parameters: * session - session object * id - session identifier, immutable Example \u00b6 There may be many various options, how the application router extension decides to store sessions exposed via the session management API. The example below assumes a SessionDataAccessObject to be implemented by the extension developer and to have the following API: Methods: \u00b6 sessionDataAccessObject.create - function(session, timeout) sessionDataAccessObject.update - function(sessionId, timeout) sessionDataAccessObject.delete - function(sessionId) sessionDataAccessObject.load - function() Events: \u00b6 create \u00b6 Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should expire callback - function to be called after session is stored in internal session storage update \u00b6 Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should be expired callback - function to be called after session is stored in internal session storage delete \u00b6 Parameters: sessionId - session identifier load \u00b6 Parameters: sessions[] - array of objects id - session identifier session - session object serialized to string timeout - timestamp, when session should expire var ar = new require ( '@sap/approuter' )(); var dao = new SessionDataAccessObject (); dao . on ( 'load' , function ( data ) { ar . start ({ getSessionSecret : function getSessionSecret () { return process . env . SESSION_SECRET ; } }, function () { var store = ar . getSessionStore (); var defaultTimeout = store . getDefaultSessionTimeout (); // AppRouter -> Persistence ar . on ( 'login' , function ( session ) { dao . create ( session , defaultTimeout ); }); ar . on ( 'update' , function ( sessionId , timeout ) { dao . update ( sessionId , timeout ); }); ar . on ( 'logout' , function ( sessionId ) { dao . delete ( sessionId ); }); // Load Initial Data data . forEach ( function ( item ) { store . set ( item . id , item . session , item . timeout ); }); // Persistence -> AppRouter dao . on ( 'create' , store . set ); dao . on ( 'update' , store . set ); dao . on ( 'delete' , store . destroy ); }); }); dao . load (); Performance \u00b6 Note: The update event of the application router may be potentially triggered thousands of times a second. It is recommended to throttle or debounce calls to the external storage to reduce network and CPU consumption. Here is an example of a throttled dao.update() , where the latest change will be persisted in the external storage no more than once in 500ms for the same session. // Throttled update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( ! this . updateTimers [ sessionId ]) { this . updateTimers [ sessionId ] = setTimeout ( function () { dao . updateTimers [ sessionId ] = null ; }, 500 ); sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); } } else { if ( ! this . timeoutTimers [ sessionId ]) { this . timeoutTimers [ sessionId ] = setTimeout ( function () { dao . timeoutTimers [ sessionId ] = null ; }, 500 ); sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); } } } And here is an example of a debounced dao.update() , where the latest change will be persisted in the external storage only if there were no other changes during the last 500ms for the same session. // Debounced update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( this . updateTimers [ sessionId ]) { clearTimeout ( this . updateTimers [ sessionId ]); } this . updateTimers [ sessionId ] = setTimeout ( function () { sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); }, 500 ); } else { if ( this . timeoutTimers [ sessionId ]) { clearTimeout ( this . timeoutTimers [ sessionId ]); } this . timeoutTimers [ sessionId ] = setTimeout ( function () { sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); }, 500 ); } } To understand the difference between throttling and debouncing, let's consider an example, where requests for the same session come every 100ms for 1sec . In case of 500ms debouncing, changes will be persisted one time. In case of 500ms throttling, changes will be persisted two times. Without any optimisation, changes will be persisted ten times.","title":"sessionManagement"},{"location":"apis/approuter/doc/doc/sessionManagement/#extended-session-management","text":"Abstract Session Lifecycle Security Data Privacy API Reference Example Performance","title":"Extended Session Management"},{"location":"apis/approuter/doc/doc/sessionManagement/#abstract","text":"The application router uses a memory store as a session repository to provide the best runtime performance. However, it is not persisted and it is not shared across multiple instances of the application router. Note: The Limitations above do not prevent the application router from being scaled out, since session stickiness is in place by default. While it is good enough for most of the cases, it may be required to provide a highly-available solution, which may be achieved by storing the state (session) of the application router outside - in durable shared storage. To allow implementing these qualities, the application router exposes the extended session management API described below.","title":"Abstract"},{"location":"apis/approuter/doc/doc/sessionManagement/#session-lifecycle","text":"The application router stores user agent sessions as JavaScript objects serialized to strings. It also stores the session timeout associated with each session, which indicates the amount of time left until session invalidation.","title":"Session Lifecycle"},{"location":"apis/approuter/doc/doc/sessionManagement/#initial-data","text":"During the start of the application router, the internal session store is initiated. It contains an empty list of sessions and their timeouts. The internal session store is not available right after the application router instance is created, but is available in the callback of approuter.start and all the time afterwards until the application router is stopped. In case an external session storage is used, the application router extension should perform the following actions to synchronize the internal session store with the external one: Load existing sessions from external storage Start the application router Populate the application router's internal session store","title":"Initial Data"},{"location":"apis/approuter/doc/doc/sessionManagement/#read","text":"A session identifier may be obtained from the request object req.sessionID . On each request, the application router executes registered middlewares in a certain order and the session is not available to all of them. First it passes the request to approuter.first middleware. At this point, there is no session associated with the incoming request. Afterwards, the application router checks if the user is authenticated, reads the relevant session from the internal session store and puts it into the request context. Next, the application router passes a request to approuter.broforeRequestHandler . At this point, the session object is available and associated with the incoming request. approuter.beforeErrorHandler also has access to session.","title":"Read"},{"location":"apis/approuter/doc/doc/sessionManagement/#login","text":"When a user agent requests a resource, served via a route that requires authentication, the application router will request the user agent to pass authentication first (usually via redirect to XSUAA). At this point, the application router does not create any session. Only after the authentication process is finished, the application router creates a session, stores it in the internal session storage and emits a login event.","title":"Login"},{"location":"apis/approuter/doc/doc/sessionManagement/#update-session","text":"Any changes made to the session are not stored in the internal session store immediately, but are accumulated to make a bulk update after the end of the response. While the request is passed through the chain of middlewares, the session object may be modified. Also, when the backend access token is close to expire, the application router may trigger the refresh backend token flow. In both cases, the actual update of the internal session store is done later on, outside of the request context.","title":"Update Session"},{"location":"apis/approuter/doc/doc/sessionManagement/#timeout","text":"There is a time-based job in the application router that basis outside the request context and destroys sessions with an elapsed timeout. Each time the application router reads a session from the session store, the timeout of this session is reset to the initial value that may be retrieved using the getDefaultSessionTimeout() API.","title":"Timeout"},{"location":"apis/approuter/doc/doc/sessionManagement/#logout","text":"When a user agent requests a URL defined as the logoutEndpoint in the xs-app.json file, a central logout process takes place. As part of this process, the application router emits a logout event. More detailed information about the central logout may be found in README.md","title":"Logout"},{"location":"apis/approuter/doc/doc/sessionManagement/#security","text":"The application router uses session secret to sign session cookies and prevent tampering. The session secret, by default, is generated using a random sequence of bytes at the startup of the application router. It is different for each instance and changed on each restart of the same instance. Using the default session secret generation mechanism for highly available application routers may cause issues in the following scenarios: The user agent is authenticated and the session is stored in a session store. The application router is restarted (due to internal error or triggered by platform) and a new session secret is generated. The authenticated user agent makes a request, which contains the session cookies. However, the cookies are signed using another secret and the application router ignores them. The user agent is authenticated and the session is stored in the session store. The application router instance is unavailable. The authenticated user agent makes a request to the application router and the request contains the session cookies. The load balancer forwards the request to another instance of the application router. However, cookies are signed using another secret and the application router ignores them. In both scenarios, the session in the store is no longer accessible, the cookies sent by the user agent are redundant, and the user agent will be requested to pass authentication once again. To avoid the issues described above, the extension that implements the extended session management mechanism, should make sure to implement the getSessionSecret hook. var ar = AppRouter (); ar . start ({ getSessionSecret : function () { return 'CUSTOM_PERSISTED_SESSION_SECRET' ; }, ... }); It is recommended to have at least 128 characters in the string that replaces CUSTOM_PERSISTED_SESSION_SECRET .","title":"Security"},{"location":"apis/approuter/doc/doc/sessionManagement/#data-privacy","text":"The user agent session potentially contains personal data. By implementing the custom session management behaviour, you take the responsibility to be compliant with all personal data protection laws and regulations (e.g. GDPR ) that may be applied in the regions, where the application will be used.","title":"Data Privacy"},{"location":"apis/approuter/doc/doc/sessionManagement/#api-reference","text":"","title":"API Reference"},{"location":"apis/approuter/doc/doc/sessionManagement/#methods","text":"","title":"Methods"},{"location":"apis/approuter/doc/doc/sessionManagement/#approuterstartoptions","text":"options getSessionSecret - returns the session secret to be used by the application router for the signing of the session cookies.","title":"approuter.start(options)"},{"location":"apis/approuter/doc/doc/sessionManagement/#approutergetsessionstore","text":"returns SessionStore instance.","title":"approuter.getSessionStore()"},{"location":"apis/approuter/doc/doc/sessionManagement/#sessionstoregetdefaultsessiontimeout","text":"returns the default session timeout in minutes.","title":"sessionStore.getDefaultSessionTimeout()"},{"location":"apis/approuter/doc/doc/sessionManagement/#sessionstoregetsessiontimeoutsessionid-callback","text":"sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null timeout - time, in minutes, until the session times out","title":"sessionStore.getSessionTimeout(sessionId, callback)"},{"location":"apis/approuter/doc/doc/sessionManagement/#sessionstoregetsessionid-callback","text":"sessionId - an unsigned session identifier callback - function(error, session) a function that is called when the session object is retrieved from the internal session storage of the application router. error - an error object in case of an error, otherwise null session - the session object id - session identifier, immutable","title":"sessionStore.get(sessionId, callback)"},{"location":"apis/approuter/doc/doc/sessionManagement/#sessionstoresetsessionid-sessionstring-timeout-callback","text":"sessionId - an unsigned session identifier sessionString - a session object serialized to string timeout - a timestamp in milliseconds, after which the session should be automatically invalidated callback - a function that is called after the session is saved in the internal session storage of the application router","title":"sessionStore.set(sessionId, sessionString, timeout, callback)"},{"location":"apis/approuter/doc/doc/sessionManagement/#sessionstoreupdatesessionid-callback-resettimeout","text":"sessionId - an unsigned session identifier callback - function(currentSession) function, which returns session object. Callback function may modify and return current session object or create and return brand new session object currentSession - current session object resetTimeout - a boolean that indicates whether to reset the session timeout","title":"sessionStore.update(sessionId, callback, resetTimeout)"},{"location":"apis/approuter/doc/doc/sessionManagement/#sessionstoredestroysessionid-callback","text":"sessionId - an unsigned session identifier callback - a function that is called after the session is destroyed in the internal session storage of the application router","title":"sessionStore.destroy(sessionId, callback)"},{"location":"apis/approuter/doc/doc/sessionManagement/#events","text":"Extension may subscribe to application router events using the standard EventEmitter API. var ar = AppRouter (); ar . on ( 'someEvent' , function handler () { // Handle event });","title":"Events"},{"location":"apis/approuter/doc/doc/sessionManagement/#login_1","text":"Emitted when user agent is authenticated. Parameters: * session - session object * id - session identifier, immutable","title":"login"},{"location":"apis/approuter/doc/doc/sessionManagement/#logout_1","text":"Emitted when a user agent session is going to be terminated in the internal session store of the application router. Emitted either when the user agent session is timed-out or when logoutEndpoint was requested. Note: Central logout is an asynchronous process. The order in which the backend and the application router sessions are invalidated, is not guaranteed. Parameters: * session - session object * id - session identifier, immutable","title":"logout"},{"location":"apis/approuter/doc/doc/sessionManagement/#example","text":"There may be many various options, how the application router extension decides to store sessions exposed via the session management API. The example below assumes a SessionDataAccessObject to be implemented by the extension developer and to have the following API:","title":"Example"},{"location":"apis/approuter/doc/doc/sessionManagement/#methods_1","text":"sessionDataAccessObject.create - function(session, timeout) sessionDataAccessObject.update - function(sessionId, timeout) sessionDataAccessObject.delete - function(sessionId) sessionDataAccessObject.load - function()","title":"Methods:"},{"location":"apis/approuter/doc/doc/sessionManagement/#events_1","text":"","title":"Events:"},{"location":"apis/approuter/doc/doc/sessionManagement/#create","text":"Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should expire callback - function to be called after session is stored in internal session storage","title":"create"},{"location":"apis/approuter/doc/doc/sessionManagement/#update","text":"Parameters: sessionId - session identifier session - session object serialized to string timeout - timestamp, when session should be expired callback - function to be called after session is stored in internal session storage","title":"update"},{"location":"apis/approuter/doc/doc/sessionManagement/#delete","text":"Parameters: sessionId - session identifier","title":"delete"},{"location":"apis/approuter/doc/doc/sessionManagement/#load","text":"Parameters: sessions[] - array of objects id - session identifier session - session object serialized to string timeout - timestamp, when session should expire var ar = new require ( '@sap/approuter' )(); var dao = new SessionDataAccessObject (); dao . on ( 'load' , function ( data ) { ar . start ({ getSessionSecret : function getSessionSecret () { return process . env . SESSION_SECRET ; } }, function () { var store = ar . getSessionStore (); var defaultTimeout = store . getDefaultSessionTimeout (); // AppRouter -> Persistence ar . on ( 'login' , function ( session ) { dao . create ( session , defaultTimeout ); }); ar . on ( 'update' , function ( sessionId , timeout ) { dao . update ( sessionId , timeout ); }); ar . on ( 'logout' , function ( sessionId ) { dao . delete ( sessionId ); }); // Load Initial Data data . forEach ( function ( item ) { store . set ( item . id , item . session , item . timeout ); }); // Persistence -> AppRouter dao . on ( 'create' , store . set ); dao . on ( 'update' , store . set ); dao . on ( 'delete' , store . destroy ); }); }); dao . load ();","title":"load"},{"location":"apis/approuter/doc/doc/sessionManagement/#performance","text":"Note: The update event of the application router may be potentially triggered thousands of times a second. It is recommended to throttle or debounce calls to the external storage to reduce network and CPU consumption. Here is an example of a throttled dao.update() , where the latest change will be persisted in the external storage no more than once in 500ms for the same session. // Throttled update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( ! this . updateTimers [ sessionId ]) { this . updateTimers [ sessionId ] = setTimeout ( function () { dao . updateTimers [ sessionId ] = null ; }, 500 ); sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); } } else { if ( ! this . timeoutTimers [ sessionId ]) { this . timeoutTimers [ sessionId ] = setTimeout ( function () { dao . timeoutTimers [ sessionId ] = null ; }, 500 ); sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); } } } And here is an example of a debounced dao.update() , where the latest change will be persisted in the external storage only if there were no other changes during the last 500ms for the same session. // Debounced update update ( sessionId , timeout ) { var dao = this ; var sessionStore = this . _sessionStore ; if ( typeof timeout === 'undefined' ) { if ( this . updateTimers [ sessionId ]) { clearTimeout ( this . updateTimers [ sessionId ]); } this . updateTimers [ sessionId ] = setTimeout ( function () { sessionStore . get ( sessionId , function ( err , session ) { dao . _saveSession ( sessionId , session ) }); }, 500 ); } else { if ( this . timeoutTimers [ sessionId ]) { clearTimeout ( this . timeoutTimers [ sessionId ]); } this . timeoutTimers [ sessionId ] = setTimeout ( function () { sessionStore . getSessionTimeout ( sessionId , function ( err , timeout ) { dao . _saveTimeout ( sessionId , timeout ) }); }, 500 ); } } To understand the difference between throttling and debouncing, let's consider an example, where requests for the same session come every 100ms for 1sec . In case of 500ms debouncing, changes will be persisted one time. In case of 500ms throttling, changes will be persisted two times. Without any optimisation, changes will be persisted ten times.","title":"Performance"},{"location":"apis/approuter/doc/doc/sizingGuide/","text":"Sizing Guide for Application Router \u00b6 Idle Test Setup HTTP Traffic Web Socket Traffic Memory Configuration In this guide we provide measurements done in different application router scenarios. You can use them to approximately calculate the amount of memory that would be required by the application router. The tables contain the exact results from the measurements with Node.js v6.9.1. It is a good idea to provide higher numbers for productive usage. All measurements are with authentication. If you have additional session content and want to count the session memory consumption please take a look at what is stored in the session - described in README's Session Contents section. You will need to add the calculated session size taking into account the number of different users and the session timeout. In our tests only the JWT token took ~4KB. Idle \u00b6 The memory consumption for an idle application router is around 50 MB. Test Setup \u00b6 The application router runs in a container with limited amount of memory. Swap is turned off. The test client creates new sessions on the server with a step of 100. No more than 100 users request the application router at a given time (e.g. 100 sessions are initialized and become idle, then 100 more session are created and become idle ...). The test ends when an Out of Memory event occurs, causing the container to be stopped. The number of created sessions before the process ends is taken. HTTP Traffic \u00b6 There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - Scenario (2) - A 'Hello World' static resource is being served. - A static resource of 84.78kb (compressed by application router to 28.36kb) is being served. - A backend which returns a payload of 80kb (compressed by application router to 58kb) is being called. - Another backend which returns a payload of 160kb (compressed by application router to 116kb) is being called. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 5 300 800 512MB 13 300 2 300 1GB 30 100 8 400 2GB 65 500 19 500 4GB 134 900 46 400 8GB 275 500 102 300 Web Socket Traffic \u00b6 There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - A single 'Hello' message is sent and then received through a web socket connection. - Scenario (2) - A 'Hello World' static resource is being served. - A backend which returns a payload of 80kb over a web socket is being called. - Another backend which returns a payload of 160kb over a web socket is being called. Note : Web sockets require a certain amount of file handles to be available to the process - it is approximately two times the number of the sessions. In Cloud Foundry the default value is 16384. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 600 300 512MB 1 100 500 1GB 3 100 800 2GB 6 500 1 400 4GB 13 300 2 900 8GB 20 700 6 100 Note : --max-old-space-size restricts the amount of memory used in the JavaScript heap. Its default value is below 2GB. So in order to use the full resources that has been provided to the application, the value of this restriction should be set to a number equal to the memory limit of the whole application. For example, if the application memory is limited to 2GB, set the V8 heap limit like this in the package.json : \"scripts\": { \"start\": \"node --max-old-space-size=2048 node_modules/@sap/approuter/approuter.js\" } Memory Configuration \u00b6 Application router process should run with at least 256MB memory. It may require more memory depending on the application. These aspects influence memory usage: - concurrent connections - active sessions - JWT token size - backend session cookies","title":"sizingGuide"},{"location":"apis/approuter/doc/doc/sizingGuide/#sizing-guide-for-application-router","text":"Idle Test Setup HTTP Traffic Web Socket Traffic Memory Configuration In this guide we provide measurements done in different application router scenarios. You can use them to approximately calculate the amount of memory that would be required by the application router. The tables contain the exact results from the measurements with Node.js v6.9.1. It is a good idea to provide higher numbers for productive usage. All measurements are with authentication. If you have additional session content and want to count the session memory consumption please take a look at what is stored in the session - described in README's Session Contents section. You will need to add the calculated session size taking into account the number of different users and the session timeout. In our tests only the JWT token took ~4KB.","title":"Sizing Guide for Application Router"},{"location":"apis/approuter/doc/doc/sizingGuide/#idle","text":"The memory consumption for an idle application router is around 50 MB.","title":"Idle"},{"location":"apis/approuter/doc/doc/sizingGuide/#test-setup","text":"The application router runs in a container with limited amount of memory. Swap is turned off. The test client creates new sessions on the server with a step of 100. No more than 100 users request the application router at a given time (e.g. 100 sessions are initialized and become idle, then 100 more session are created and become idle ...). The test ends when an Out of Memory event occurs, causing the container to be stopped. The number of created sessions before the process ends is taken.","title":"Test Setup"},{"location":"apis/approuter/doc/doc/sizingGuide/#http-traffic","text":"There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - Scenario (2) - A 'Hello World' static resource is being served. - A static resource of 84.78kb (compressed by application router to 28.36kb) is being served. - A backend which returns a payload of 80kb (compressed by application router to 58kb) is being called. - Another backend which returns a payload of 160kb (compressed by application router to 116kb) is being called. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 5 300 800 512MB 13 300 2 300 1GB 30 100 8 400 2GB 65 500 19 500 4GB 134 900 46 400 8GB 275 500 102 300","title":"HTTP Traffic"},{"location":"apis/approuter/doc/doc/sizingGuide/#web-socket-traffic","text":"There are 2 separate test scenarios depending on what is done after a session is created: - Scenario (1) - A 'Hello World' static resource is being served. - A single 'Hello' message is sent and then received through a web socket connection. - Scenario (2) - A 'Hello World' static resource is being served. - A backend which returns a payload of 80kb over a web socket is being called. - Another backend which returns a payload of 160kb over a web socket is being called. Note : Web sockets require a certain amount of file handles to be available to the process - it is approximately two times the number of the sessions. In Cloud Foundry the default value is 16384. Memory Limit Max Sessions - Scenario (1) Max Sessions - Scenario (2) 256MB 600 300 512MB 1 100 500 1GB 3 100 800 2GB 6 500 1 400 4GB 13 300 2 900 8GB 20 700 6 100 Note : --max-old-space-size restricts the amount of memory used in the JavaScript heap. Its default value is below 2GB. So in order to use the full resources that has been provided to the application, the value of this restriction should be set to a number equal to the memory limit of the whole application. For example, if the application memory is limited to 2GB, set the V8 heap limit like this in the package.json : \"scripts\": { \"start\": \"node --max-old-space-size=2048 node_modules/@sap/approuter/approuter.js\" }","title":"Web Socket Traffic"},{"location":"apis/approuter/doc/doc/sizingGuide/#memory-configuration","text":"Application router process should run with at least 256MB memory. It may require more memory depending on the application. These aspects influence memory usage: - concurrent connections - active sessions - JWT token size - backend session cookies","title":"Memory Configuration"},{"location":"apis/audit-logging/","text":"@sap/audit-logging \u00b6 Provides audit logging functionalities for Node.js applications. Overview General audit logging principles Prerequisites Versions API - v1 Importing the library Data access messages Data modification messages Update data modification Configuration change messages Update configuration change General security messages Logging a message API - v2 Importing the library Data access messages Data modification messages Configuration change messages General security messages Local development Without Audit log service With Audit log service Overview \u00b6 Audit logging is about writing entries in a specific format to a log storage. Subject to audit logging are events of significant importance. For example, security events which may impact the confidentiality, the integrity or the availability of a system. Another example of such an event would be access to personal data (both reading and altering) like bank accounts, political opinion, health status etc. While the consumer of ordinary logs is a system administrator who would like to keep track of the state of a system, audit logs are read by an auditor. There are legal requirements (in some countries stricter than in others) regarding audit logging. In general the events that are supposed to be audit logged can be grouped in 3 main categories: - changes to system configurations (which may have significant effect on the system itself) - access to personal data (related to data privacy) - general security events (like starting/stopping a system, failed authorization checks etc.) General audit logging principles \u00b6 All attempts to perform an action in a system should be audit logged no matter if they have been successful or not. Audit log entries should be consistent with the state of the system. If, for example, the writing of the audit log entry fails, but the changes to system critical parameters have been applied, then those changes should be reverted. Best practice is to wait for the callback of the logger before continuing with the execution of other code. Especially important is which user (or other agent) has triggered the corresponding event that is being audit logged. For most of the cases the library will validate that such a field is provided in the message. All audit log entries should be in English. Numbers should be converted to strings with English locale. All time fields should be in UTC time in order to avoid timezone and day light saving time issues. Passwords should never be audit logged. Prerequisites \u00b6 An application using the audit log library needs to be bound to an instance of the Audit log service. Versions \u00b6 The Audit log service provides REST APIs that are available to applications for logging relevant messages. The latest Audit log server supports 2 versions of the REST APIs. This library provides JavaScript programming interfaces for both of these versions of the server's APIs. Note: It is recommended to use REST APIs v2 if available on the Audit log server being in use (and respectively the JavaScript v2 APIs). The initial version of the Audit log server REST APIs is deprecated in favor of the v2 version. The same applies to the JavaScript APIs provided by this library. API - v1 \u00b6 The library provides an API for writing audit messages of type configuration changes, data modifications, data accesses and security events. Importing the library \u00b6 var credentials = { \"user\" : \"user\" , \"password\" : \"password\" , \"url\" : \"https://host:port\" }; var auditLog = require ( '@sap/audit-logging' )( credentials ); credentials object is the bound audit log service's credentials. Take a look at @sap/xsenv package for more information on how to retrieve service credentials. Data access messages \u00b6 Let's suppose we need to create an entry for a data access operation over personal data. We can achieve that with the following code: auditLog . read ( 'user123' ) . attribute ( 'username' , true ) . attribute ( 'first name' , true ) . attribute ( 'last name' , true ) . accessChannel ( 'UI' ) . by ( 'John Doe' ) . tenant ( 'tenantId' ) . log (...); read - takes a string which identifies the object which is being accessed . attribute(name, successful) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being accessed. successful - specifies whether the access was successful or not. by - takes a string which identifies the user performing the action. This is mandatory . accessChannel - takes a string which specifies channel of access. attachment(id, name) - if attachments or files are downloaded or displayed, information identifying the attachment shall be logged. id - attachment id name - attachment name tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here Data modification messages \u00b6 Here is how to create an entry for a data modification operation: auditLog . update ( 'userdata' ) . attribute ( 'first name' , 'john' , 'John' ) . by ( 'John Doe' ) . tenant ( 'tenantId' ) . log (...); Note : Specifying an old and a new value for an attribute is only supported in newer versions of the Audit log service. Providing these values while working with an older version of the service results in an error in the callback. In such cases one may use the attribute method with an alternative signature: auditLog . update ( 'userdata' ) . attribute ( 'password' , false ) . by ( 'John Doe' ) . tenant ( 'tenantId' ) . log (...); update - takes a string which identifies the object which is being updated . attribute(name, oldValue, newValue) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being modified. oldValue - is the current value of the attribute. newValue - is the value of the attribute after the change. Note : One may use this signature of the attribute method only if the Audit log service being consumed supports old and new values. attribute(name, successful) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being modified. successful - specifies whether the modification was successful or not. Note : this signature of the method is deprecated . It should be used only if the consumed Audit log service does not support old and new values. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here Update data modification \u00b6 auditLog . updateDataModification ( id , isSuccessful ) . log (...); updateDataModification(id, isSuccessful) - takes two arguments. id - id of the data modification message saved earlier (see log ) isSuccessful - denotes whether the data modification was successful or not. log - See here Note : This function should only be used with an Audit log service that supports old and new values. Configuration change messages \u00b6 Here is how to create an entry for a configuration change operation: auditLog . configurationChange ( 'configuration object' ) . attribute ( 'session timeout' , '5' , '25' ) . by ( 'Application Admin' ) . successful ( true ) . tenant ( 'tenantId' ) . log (...); configurationChange - takes a string which identifies the object which is being configured . attribute(name, oldValue, newValue) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being accessed. oldValue - is the current value of the attribute being changed. newValue - is the value of the attribute after the change. successful(isSuccessful) - used to mark whether the configuration change is finished with success, failure. If not called configuration change will be marked as pending . isSuccessful - should be a valid boolean. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here Update configuration change \u00b6 auditLog . updateConfigurationChange ( id , isSuccessful ) . log (...); updateConfigurationChange(id, isSuccessful) - takes two arguments. id - id of the configuration message saved earlier (see log ) isSuccessful - denotes whether the configuration change was successful or not. log - See here General security messages \u00b6 Here is how to create a general security audit log message: auditLog . securityMessage ( '%d unsuccessful login attempts' , 3 ) . by ( 'John Doe' ) . externalIP ( '127.0.0.1' ) . tenant ( 'tenantId' ) . log (...); securityMessage - takes a formatted string as in util.format() . externalIP - states the IP of the machine that contacts the system. It is not mandatory, but it should be either IPv4 or IPv6. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here Logging a message \u00b6 Use the log method to write a message to the Audit log. It takes one argument - a callback function. Be aware that the state of the audit logs should be consistent with the state of the system. Make sure you handle errors from the audit log writer properly. Application code should wait for the logging to finish before executing any other code. var message = /* any of the above example messages */ ; message . log ( function ( err , id ) { // Do error handling and place all of the remaining logic here }); message - Any of the following: read update configurationChange updateConfigurationChange securityMessage err - error object in case of error. id - Id of the message that is saved. Use it when you want to do updateConfigurationChange . id is undefined in case of updateConfigurationChange . Note : When a message is logged, the library checks for missing properties and will throw an error if some are missing. API - v2 \u00b6 Importing the library \u00b6 var credentials = { \"user\" : \"user\" , \"password\" : \"password\" , \"url\" : \"https://host:port\" }; var auditLogging = require ( '@sap/audit-logging' ); auditLogging . v2 ( credentials , function ( err , auditLog ) { if ( err ) { // if the Audit log server does not support version 2 of the REST APIs // an error in the callback is returned return console . log ( err ); } }); credentials object with credentials for the Audit log service. Take a look at @sap/xsenv package for more information on how to retrieve service credentials. The callback will be called with an error if the Audit log server does not support version 2 of the REST APIs. Data access messages \u00b6 auditLog . read ({ type : 'accessed-object-type' , id : { key : 'value' } }) . attribute ({ name : 'attr-0' }) . attribute ({ name : 'attr-1' , successful : true }) . attachment ({ id : '123' }) . attachment ({ id : '456' , name : 'file.doc' }) . dataSubject ({ type : 'data-subject-type' , id : { key : 'value' }, role : 'role' }) . accessChannel ( 'UI' ) . tenant ( 'tenantId' ) . by ( 'John Doe' ) . log ( function ( err ) { }); read - takes a JavaScript object which identifies the object which contains the data being accessed. Should have type and id properties. attribute(attribute) - takes an object which describes an attribute. Should have a name property and optionally a successful property. It is mandatory to provide at least one attribute. attachment(attachment) - takes an object which describes an attachment (used if attachments or files are downloaded or displayed). Should have an id property and optionally a name property. dataSubject - takes an object describing the owner of the personal data. Should have type and id properties. The role property is optional. dataSubject is mandatory . accessChannel - takes a string which specifies channel of access. tenant - takes a string which specifies the tenant id. by - takes a string which identifies the user performing the action. This is mandatory . log - logs the message. Data modification messages \u00b6 var message = auditLog . update ({ type : 'accessed-object-type' , id : { key : 'value' } }) . attribute ({ name : 'attr-0' }) . attribute ({ name : 'attr-1' }) . attribute ({ name : 'attr-2' , old : 'old value' , new : 'new value' }) . dataSubject ({ type : 'data-subject-type' , id : { key : 'value' }, role : 'role' }) . tenant ( 'tenantId' ) . by ( 'John Doe' ); message . logPrepare ( function ( err ) { message . logSuccess ( function ( err ) { }); // or message . logFailure ( function ( err ) { }); }); update - takes a JavaScript object which identifies the object which contains the data being updated. Should have type and id properties. attribute(attribute) - takes an object which describes an attribute. Should have a name property and optionally - old and new properties. It is mandatory to provide at least one attribute. dataSubject - takes an object describing the owner of the personal data. Should have type and id properties. The role property is optional. dataSubject is mandatory . tenant - takes a string which specifies the tenant id. by - takes a string which identifies the user performing the action. This is mandatory . logPrepare - Used to log that a user has started an operation over the data. logSuccess - Used to log that the operation over the data has been completed successfully. logFailure - Used to log that the operation over the data has not been completed successfully. Configuration change messages \u00b6 var message = auditLog . configurationChange ({ type : 'accessed-object-type' , id : { key : 'value' } }) . attribute ({ name : 'session timeout' , old : '5' , new : '25' }) . tenant ( 'tenantId' ) . by ( 'Application Admin' ); message . logPrepare ( function ( err ) { message . logSuccess ( function ( err ) { }); // or message . logFailure ( function ( err ) { }); }); configurationChange - takes a JavaScript object which identifies the object which contains the data being configured. Should have type and id properties. attribute(attribute) - takes an object which describes an attribute. Should have a name , old and new properties. It is mandatory to provide at least one attribute. tenant - takes a string which specifies the tenant id. by - takes a string which identifies the user performing the action. This is mandatory . logPrepare - Used to log that a user has started a configuration change operation. logSuccess - Used to log that the operation has been completed successfully. logFailure - Used to log that the operation has not been completed successfully. General security messages \u00b6 auditLog . securityMessage ( '%d unsuccessful login attempts' , 3 ) . by ( 'John Doe' ) . externalIP ( '127.0.0.1' ) . tenant ( 'tenantId' ) . log ( function ( err ) { }); securityMessage - takes a formatted string as in util.format() . externalIP - states the IP of the machine that contacts the system. Specifying it is optional, but if provided, should be either IPv4 or IPv6. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. log - logs the message. Local development \u00b6 Without Audit log service \u00b6 var credentials = { logToConsole : true }; var auditLog = require ( '@sap/audit-logging' )( credentials ); // or require ( '@sap/audit-logging' ). v2 ( credentials , function ( err , auditLog ) { }); When logToConsole is true the library will ignore other credential properties and will not use the Audit log service, but will write the messages to the console. Hint: If you use the @sap/xsenv package, you can pass the credentials through the default-services.json file or VCAP_SERVICES environment variable. With Audit log service \u00b6 If your application is not deployed in Cloud Foundry or XS Advanced, but you have a running Audit log service somewhere, you should set the VCAP_APPLICATION environment variable to a string like { \"application_name\" : \"my-app\", \"organization_name\" : \"my-org\", \"space_name\" : \"my-space\" } Hint: If you use the @sap/xsenv package, you can set environment variables like this: var xsenv = require ( '@sap/xsenv' ); xsenv . loadEnv (); var credentials = xsenv . getServices ({ auditlog : 'auditlog-instance-name' }). auditlog ; var auditLog = require ( '@sap/audit-logging' )( credentials ); default-env.json file: { \"VCAP_APPLICATION\" : { \"application_name\" : \"my-app\" , \"organization_name\" : \"my-org\" , \"space_name\" : \"my-space\" }, \"VCAP_SERVICES\" : { \"auditlog\" : [ { \"name\" : \"auditlog-instance-name\" , \"credentials\" : { \"password\" : \"password\" , \"user\" : \"user\" , \"url\" : \"https://host:port\" } } ] } }","title":"@sap/audit-logging"},{"location":"apis/audit-logging/#sapaudit-logging","text":"Provides audit logging functionalities for Node.js applications. Overview General audit logging principles Prerequisites Versions API - v1 Importing the library Data access messages Data modification messages Update data modification Configuration change messages Update configuration change General security messages Logging a message API - v2 Importing the library Data access messages Data modification messages Configuration change messages General security messages Local development Without Audit log service With Audit log service","title":"@sap/audit-logging"},{"location":"apis/audit-logging/#overview","text":"Audit logging is about writing entries in a specific format to a log storage. Subject to audit logging are events of significant importance. For example, security events which may impact the confidentiality, the integrity or the availability of a system. Another example of such an event would be access to personal data (both reading and altering) like bank accounts, political opinion, health status etc. While the consumer of ordinary logs is a system administrator who would like to keep track of the state of a system, audit logs are read by an auditor. There are legal requirements (in some countries stricter than in others) regarding audit logging. In general the events that are supposed to be audit logged can be grouped in 3 main categories: - changes to system configurations (which may have significant effect on the system itself) - access to personal data (related to data privacy) - general security events (like starting/stopping a system, failed authorization checks etc.)","title":"Overview"},{"location":"apis/audit-logging/#general-audit-logging-principles","text":"All attempts to perform an action in a system should be audit logged no matter if they have been successful or not. Audit log entries should be consistent with the state of the system. If, for example, the writing of the audit log entry fails, but the changes to system critical parameters have been applied, then those changes should be reverted. Best practice is to wait for the callback of the logger before continuing with the execution of other code. Especially important is which user (or other agent) has triggered the corresponding event that is being audit logged. For most of the cases the library will validate that such a field is provided in the message. All audit log entries should be in English. Numbers should be converted to strings with English locale. All time fields should be in UTC time in order to avoid timezone and day light saving time issues. Passwords should never be audit logged.","title":"General audit logging principles"},{"location":"apis/audit-logging/#prerequisites","text":"An application using the audit log library needs to be bound to an instance of the Audit log service.","title":"Prerequisites"},{"location":"apis/audit-logging/#versions","text":"The Audit log service provides REST APIs that are available to applications for logging relevant messages. The latest Audit log server supports 2 versions of the REST APIs. This library provides JavaScript programming interfaces for both of these versions of the server's APIs. Note: It is recommended to use REST APIs v2 if available on the Audit log server being in use (and respectively the JavaScript v2 APIs). The initial version of the Audit log server REST APIs is deprecated in favor of the v2 version. The same applies to the JavaScript APIs provided by this library.","title":"Versions"},{"location":"apis/audit-logging/#api-v1","text":"The library provides an API for writing audit messages of type configuration changes, data modifications, data accesses and security events.","title":"API - v1"},{"location":"apis/audit-logging/#importing-the-library","text":"var credentials = { \"user\" : \"user\" , \"password\" : \"password\" , \"url\" : \"https://host:port\" }; var auditLog = require ( '@sap/audit-logging' )( credentials ); credentials object is the bound audit log service's credentials. Take a look at @sap/xsenv package for more information on how to retrieve service credentials.","title":"Importing the library"},{"location":"apis/audit-logging/#data-access-messages","text":"Let's suppose we need to create an entry for a data access operation over personal data. We can achieve that with the following code: auditLog . read ( 'user123' ) . attribute ( 'username' , true ) . attribute ( 'first name' , true ) . attribute ( 'last name' , true ) . accessChannel ( 'UI' ) . by ( 'John Doe' ) . tenant ( 'tenantId' ) . log (...); read - takes a string which identifies the object which is being accessed . attribute(name, successful) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being accessed. successful - specifies whether the access was successful or not. by - takes a string which identifies the user performing the action. This is mandatory . accessChannel - takes a string which specifies channel of access. attachment(id, name) - if attachments or files are downloaded or displayed, information identifying the attachment shall be logged. id - attachment id name - attachment name tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here","title":"Data access messages"},{"location":"apis/audit-logging/#data-modification-messages","text":"Here is how to create an entry for a data modification operation: auditLog . update ( 'userdata' ) . attribute ( 'first name' , 'john' , 'John' ) . by ( 'John Doe' ) . tenant ( 'tenantId' ) . log (...); Note : Specifying an old and a new value for an attribute is only supported in newer versions of the Audit log service. Providing these values while working with an older version of the service results in an error in the callback. In such cases one may use the attribute method with an alternative signature: auditLog . update ( 'userdata' ) . attribute ( 'password' , false ) . by ( 'John Doe' ) . tenant ( 'tenantId' ) . log (...); update - takes a string which identifies the object which is being updated . attribute(name, oldValue, newValue) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being modified. oldValue - is the current value of the attribute. newValue - is the value of the attribute after the change. Note : One may use this signature of the attribute method only if the Audit log service being consumed supports old and new values. attribute(name, successful) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being modified. successful - specifies whether the modification was successful or not. Note : this signature of the method is deprecated . It should be used only if the consumed Audit log service does not support old and new values. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here","title":"Data modification messages"},{"location":"apis/audit-logging/#update-data-modification","text":"auditLog . updateDataModification ( id , isSuccessful ) . log (...); updateDataModification(id, isSuccessful) - takes two arguments. id - id of the data modification message saved earlier (see log ) isSuccessful - denotes whether the data modification was successful or not. log - See here Note : This function should only be used with an Audit log service that supports old and new values.","title":"Update data modification"},{"location":"apis/audit-logging/#configuration-change-messages","text":"Here is how to create an entry for a configuration change operation: auditLog . configurationChange ( 'configuration object' ) . attribute ( 'session timeout' , '5' , '25' ) . by ( 'Application Admin' ) . successful ( true ) . tenant ( 'tenantId' ) . log (...); configurationChange - takes a string which identifies the object which is being configured . attribute(name, oldValue, newValue) - sets object attributes. It is mandatory to provide at least one attribute. name - is the name of the attribute being accessed. oldValue - is the current value of the attribute being changed. newValue - is the value of the attribute after the change. successful(isSuccessful) - used to mark whether the configuration change is finished with success, failure. If not called configuration change will be marked as pending . isSuccessful - should be a valid boolean. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here","title":"Configuration change messages"},{"location":"apis/audit-logging/#update-configuration-change","text":"auditLog . updateConfigurationChange ( id , isSuccessful ) . log (...); updateConfigurationChange(id, isSuccessful) - takes two arguments. id - id of the configuration message saved earlier (see log ) isSuccessful - denotes whether the configuration change was successful or not. log - See here","title":"Update configuration change"},{"location":"apis/audit-logging/#general-security-messages","text":"Here is how to create a general security audit log message: auditLog . securityMessage ( '%d unsuccessful login attempts' , 3 ) . by ( 'John Doe' ) . externalIP ( '127.0.0.1' ) . tenant ( 'tenantId' ) . log (...); securityMessage - takes a formatted string as in util.format() . externalIP - states the IP of the machine that contacts the system. It is not mandatory, but it should be either IPv4 or IPv6. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. The provided value is ignored by older versions of the Audit log service that do not support setting a tenant. log - See here","title":"General security messages"},{"location":"apis/audit-logging/#logging-a-message","text":"Use the log method to write a message to the Audit log. It takes one argument - a callback function. Be aware that the state of the audit logs should be consistent with the state of the system. Make sure you handle errors from the audit log writer properly. Application code should wait for the logging to finish before executing any other code. var message = /* any of the above example messages */ ; message . log ( function ( err , id ) { // Do error handling and place all of the remaining logic here }); message - Any of the following: read update configurationChange updateConfigurationChange securityMessage err - error object in case of error. id - Id of the message that is saved. Use it when you want to do updateConfigurationChange . id is undefined in case of updateConfigurationChange . Note : When a message is logged, the library checks for missing properties and will throw an error if some are missing.","title":"Logging a message"},{"location":"apis/audit-logging/#api-v2","text":"","title":"API - v2"},{"location":"apis/audit-logging/#importing-the-library_1","text":"var credentials = { \"user\" : \"user\" , \"password\" : \"password\" , \"url\" : \"https://host:port\" }; var auditLogging = require ( '@sap/audit-logging' ); auditLogging . v2 ( credentials , function ( err , auditLog ) { if ( err ) { // if the Audit log server does not support version 2 of the REST APIs // an error in the callback is returned return console . log ( err ); } }); credentials object with credentials for the Audit log service. Take a look at @sap/xsenv package for more information on how to retrieve service credentials. The callback will be called with an error if the Audit log server does not support version 2 of the REST APIs.","title":"Importing the library"},{"location":"apis/audit-logging/#data-access-messages_1","text":"auditLog . read ({ type : 'accessed-object-type' , id : { key : 'value' } }) . attribute ({ name : 'attr-0' }) . attribute ({ name : 'attr-1' , successful : true }) . attachment ({ id : '123' }) . attachment ({ id : '456' , name : 'file.doc' }) . dataSubject ({ type : 'data-subject-type' , id : { key : 'value' }, role : 'role' }) . accessChannel ( 'UI' ) . tenant ( 'tenantId' ) . by ( 'John Doe' ) . log ( function ( err ) { }); read - takes a JavaScript object which identifies the object which contains the data being accessed. Should have type and id properties. attribute(attribute) - takes an object which describes an attribute. Should have a name property and optionally a successful property. It is mandatory to provide at least one attribute. attachment(attachment) - takes an object which describes an attachment (used if attachments or files are downloaded or displayed). Should have an id property and optionally a name property. dataSubject - takes an object describing the owner of the personal data. Should have type and id properties. The role property is optional. dataSubject is mandatory . accessChannel - takes a string which specifies channel of access. tenant - takes a string which specifies the tenant id. by - takes a string which identifies the user performing the action. This is mandatory . log - logs the message.","title":"Data access messages"},{"location":"apis/audit-logging/#data-modification-messages_1","text":"var message = auditLog . update ({ type : 'accessed-object-type' , id : { key : 'value' } }) . attribute ({ name : 'attr-0' }) . attribute ({ name : 'attr-1' }) . attribute ({ name : 'attr-2' , old : 'old value' , new : 'new value' }) . dataSubject ({ type : 'data-subject-type' , id : { key : 'value' }, role : 'role' }) . tenant ( 'tenantId' ) . by ( 'John Doe' ); message . logPrepare ( function ( err ) { message . logSuccess ( function ( err ) { }); // or message . logFailure ( function ( err ) { }); }); update - takes a JavaScript object which identifies the object which contains the data being updated. Should have type and id properties. attribute(attribute) - takes an object which describes an attribute. Should have a name property and optionally - old and new properties. It is mandatory to provide at least one attribute. dataSubject - takes an object describing the owner of the personal data. Should have type and id properties. The role property is optional. dataSubject is mandatory . tenant - takes a string which specifies the tenant id. by - takes a string which identifies the user performing the action. This is mandatory . logPrepare - Used to log that a user has started an operation over the data. logSuccess - Used to log that the operation over the data has been completed successfully. logFailure - Used to log that the operation over the data has not been completed successfully.","title":"Data modification messages"},{"location":"apis/audit-logging/#configuration-change-messages_1","text":"var message = auditLog . configurationChange ({ type : 'accessed-object-type' , id : { key : 'value' } }) . attribute ({ name : 'session timeout' , old : '5' , new : '25' }) . tenant ( 'tenantId' ) . by ( 'Application Admin' ); message . logPrepare ( function ( err ) { message . logSuccess ( function ( err ) { }); // or message . logFailure ( function ( err ) { }); }); configurationChange - takes a JavaScript object which identifies the object which contains the data being configured. Should have type and id properties. attribute(attribute) - takes an object which describes an attribute. Should have a name , old and new properties. It is mandatory to provide at least one attribute. tenant - takes a string which specifies the tenant id. by - takes a string which identifies the user performing the action. This is mandatory . logPrepare - Used to log that a user has started a configuration change operation. logSuccess - Used to log that the operation has been completed successfully. logFailure - Used to log that the operation has not been completed successfully.","title":"Configuration change messages"},{"location":"apis/audit-logging/#general-security-messages_1","text":"auditLog . securityMessage ( '%d unsuccessful login attempts' , 3 ) . by ( 'John Doe' ) . externalIP ( '127.0.0.1' ) . tenant ( 'tenantId' ) . log ( function ( err ) { }); securityMessage - takes a formatted string as in util.format() . externalIP - states the IP of the machine that contacts the system. Specifying it is optional, but if provided, should be either IPv4 or IPv6. by - takes a string which identifies the user performing the action. This is mandatory . tenant - takes a string which specifies the tenant id. log - logs the message.","title":"General security messages"},{"location":"apis/audit-logging/#local-development","text":"","title":"Local development"},{"location":"apis/audit-logging/#without-audit-log-service","text":"var credentials = { logToConsole : true }; var auditLog = require ( '@sap/audit-logging' )( credentials ); // or require ( '@sap/audit-logging' ). v2 ( credentials , function ( err , auditLog ) { }); When logToConsole is true the library will ignore other credential properties and will not use the Audit log service, but will write the messages to the console. Hint: If you use the @sap/xsenv package, you can pass the credentials through the default-services.json file or VCAP_SERVICES environment variable.","title":"Without Audit log service"},{"location":"apis/audit-logging/#with-audit-log-service","text":"If your application is not deployed in Cloud Foundry or XS Advanced, but you have a running Audit log service somewhere, you should set the VCAP_APPLICATION environment variable to a string like { \"application_name\" : \"my-app\", \"organization_name\" : \"my-org\", \"space_name\" : \"my-space\" } Hint: If you use the @sap/xsenv package, you can set environment variables like this: var xsenv = require ( '@sap/xsenv' ); xsenv . loadEnv (); var credentials = xsenv . getServices ({ auditlog : 'auditlog-instance-name' }). auditlog ; var auditLog = require ( '@sap/audit-logging' )( credentials ); default-env.json file: { \"VCAP_APPLICATION\" : { \"application_name\" : \"my-app\" , \"organization_name\" : \"my-org\" , \"space_name\" : \"my-space\" }, \"VCAP_SERVICES\" : { \"auditlog\" : [ { \"name\" : \"auditlog-instance-name\" , \"credentials\" : { \"password\" : \"password\" , \"user\" : \"user\" , \"url\" : \"https://host:port\" } } ] } }","title":"With Audit log service"},{"location":"apis/audit-logging/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 3.1.0 - 2019-12-06 \u00b6 Added \u00b6 Node.js 12.x support Retry logic when accessing the auditlog Fixed \u00b6 Update dependencies 3.0.2 - 2019-07-16 \u00b6 Fixed \u00b6 Update dev dependencies 3.0.1 - 2019-05-17 \u00b6 Fixed \u00b6 Transactional messages: uuid and time fields are now updated for each log operation 3.0.0 - 2019-04-23 \u00b6 Removed \u00b6 Node.js v0.12 support Node.js v4 support 2.3.0 - 2018-12-18 \u00b6 Added \u00b6 Node.js version 10 support Fixed \u00b6 Update lodash to 4.17.11 2.2.4 - 2018-08-14 \u00b6 Fixed \u00b6 Update dependencies. 2.2.3 - 2018-07-17 \u00b6 Fixed \u00b6 Update request to v2.87.0. 2.2.2 - 2018-05-18 \u00b6 Fixed \u00b6 Update request to v2.86.0. 2.2.1 - 2018-04-05 \u00b6 Fixed \u00b6 Update dependencies. 2.2.0 - 2018-01-23 \u00b6 Added \u00b6 npm-shrinkwrap.json. Audit log service v2 support. Fixed \u00b6 Documentation for data access messages. 2.1.1 - 2017-10-13 \u00b6 Changed \u00b6 Dependencies' versions 2.1.0 - 2017-08-08 \u00b6 Added \u00b6 Support for old and new values in data modification messages. Support for setting a tenant. Support for Node.js v8. Documentation improvements. 2.0.1 - 2017-05-30 \u00b6 Fixed \u00b6 Improved debug messages. 2.0.0 - 2017-03-13 \u00b6 Added \u00b6 The library requires the application to be bound to an instance of the Audit log service . Instantiating the library now requires a configuration object containing the credentials from the service binding to be provided (see README.md). configurationChange method is added to the API (see README.md). updateConfigurationChange method is added to the API (see README.md). Changed \u00b6 read , update and securityMessage methods have some changes to their argument lists (see README.md). Removed \u00b6 delete method is removed from the API. create method is removed from the API.","title":"Change Log"},{"location":"apis/audit-logging/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/audit-logging/CHANGELOG/#310-2019-12-06","text":"","title":"3.1.0 - 2019-12-06"},{"location":"apis/audit-logging/CHANGELOG/#added","text":"Node.js 12.x support Retry logic when accessing the auditlog","title":"Added"},{"location":"apis/audit-logging/CHANGELOG/#fixed","text":"Update dependencies","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#302-2019-07-16","text":"","title":"3.0.2 - 2019-07-16"},{"location":"apis/audit-logging/CHANGELOG/#fixed_1","text":"Update dev dependencies","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#301-2019-05-17","text":"","title":"3.0.1 - 2019-05-17"},{"location":"apis/audit-logging/CHANGELOG/#fixed_2","text":"Transactional messages: uuid and time fields are now updated for each log operation","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#300-2019-04-23","text":"","title":"3.0.0 - 2019-04-23"},{"location":"apis/audit-logging/CHANGELOG/#removed","text":"Node.js v0.12 support Node.js v4 support","title":"Removed"},{"location":"apis/audit-logging/CHANGELOG/#230-2018-12-18","text":"","title":"2.3.0 - 2018-12-18"},{"location":"apis/audit-logging/CHANGELOG/#added_1","text":"Node.js version 10 support","title":"Added"},{"location":"apis/audit-logging/CHANGELOG/#fixed_3","text":"Update lodash to 4.17.11","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#224-2018-08-14","text":"","title":"2.2.4 - 2018-08-14"},{"location":"apis/audit-logging/CHANGELOG/#fixed_4","text":"Update dependencies.","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#223-2018-07-17","text":"","title":"2.2.3 - 2018-07-17"},{"location":"apis/audit-logging/CHANGELOG/#fixed_5","text":"Update request to v2.87.0.","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#222-2018-05-18","text":"","title":"2.2.2 - 2018-05-18"},{"location":"apis/audit-logging/CHANGELOG/#fixed_6","text":"Update request to v2.86.0.","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#221-2018-04-05","text":"","title":"2.2.1 - 2018-04-05"},{"location":"apis/audit-logging/CHANGELOG/#fixed_7","text":"Update dependencies.","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#220-2018-01-23","text":"","title":"2.2.0 - 2018-01-23"},{"location":"apis/audit-logging/CHANGELOG/#added_2","text":"npm-shrinkwrap.json. Audit log service v2 support.","title":"Added"},{"location":"apis/audit-logging/CHANGELOG/#fixed_8","text":"Documentation for data access messages.","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#211-2017-10-13","text":"","title":"2.1.1 - 2017-10-13"},{"location":"apis/audit-logging/CHANGELOG/#changed","text":"Dependencies' versions","title":"Changed"},{"location":"apis/audit-logging/CHANGELOG/#210-2017-08-08","text":"","title":"2.1.0 - 2017-08-08"},{"location":"apis/audit-logging/CHANGELOG/#added_3","text":"Support for old and new values in data modification messages. Support for setting a tenant. Support for Node.js v8. Documentation improvements.","title":"Added"},{"location":"apis/audit-logging/CHANGELOG/#201-2017-05-30","text":"","title":"2.0.1 - 2017-05-30"},{"location":"apis/audit-logging/CHANGELOG/#fixed_9","text":"Improved debug messages.","title":"Fixed"},{"location":"apis/audit-logging/CHANGELOG/#200-2017-03-13","text":"","title":"2.0.0 - 2017-03-13"},{"location":"apis/audit-logging/CHANGELOG/#added_4","text":"The library requires the application to be bound to an instance of the Audit log service . Instantiating the library now requires a configuration object containing the credentials from the service binding to be provided (see README.md). configurationChange method is added to the API (see README.md). updateConfigurationChange method is added to the API (see README.md).","title":"Added"},{"location":"apis/audit-logging/CHANGELOG/#changed_1","text":"read , update and securityMessage methods have some changes to their argument lists (see README.md).","title":"Changed"},{"location":"apis/audit-logging/CHANGELOG/#removed_1","text":"delete method is removed from the API. create method is removed from the API.","title":"Removed"},{"location":"apis/cds/","text":"@sap/cds \u00b6 The API package for the SAP Cloud Application Programming Model (CAP) . See the API docs for more. License \u00b6 This package is provided under the terms of the SAP Developer License Agreement .","title":"@sap/cds"},{"location":"apis/cds/#sapcds","text":"The API package for the SAP Cloud Application Programming Model (CAP) . See the API docs for more.","title":"@sap/cds"},{"location":"apis/cds/#license","text":"This package is provided under the terms of the SAP Developer License Agreement .","title":"License"},{"location":"apis/cds/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project are documented in this file. The format is based on Keep a Changelog . This project adheres to Semantic Versioning . Version 3.34.2 - 2020-05-30 \u00b6 Changed \u00b6 Use cds.hana.deploy-format = hdbtable instead of cds.hana.syntax to switch deployment from hdbcds to hdbtable for SAP HANA Cloud. cds run now supports relative dataSource URLs in SAP UI5 manifests again, so that UI5 apps can be served w/o approuter. This support is only active in development mode. cds deploy --to hana changes kind to hana only if it is not already sql Fixed \u00b6 The UI.Identification annotation for sap.common.CodeList got a correct value, pointing to its name element. Configuration requires.<foo>.credentials.destination is now preserved again when running with VCAP_SERVICES . In version 3.34.1 it was cleared. Entities annotated with @cds.persistence.skip:if-unused (like sap.common.Languages ) now again are skipped when compiling to HANA output. This got broken in previous versions when using the new compiler APIs. sql_mapping is again written to csn.json as it's required by classic Java runtime. default-env.json is now read even in production, which is in line with the behavior of other modules that honor this file. Real prod environments like CF will still overwrite these defaults. Version 3.34.0 - 2020-04-27 \u00b6 Added \u00b6 cds version option -ls prints an npm ls subtree. cds serve / run now also accept package names as arguments, e.g. cds serve --project @capire/bookshop . cds compile option --parse provides minimal, parsed-only CSN output. New Node.js method cds.compile.cdl() allows compiling CDS sources in-process. cds build now supports cds configuration requires.db.kind:\"sql\" which allows seamless production deployments using HANA db and development deployments using sqlite db. Default maximum query size limit of 1000 (overridable via @cds.query.limit.max ). Improved error message during cds deploy on Windows when SAP CommonCryptoLib is missing. cds build now checks that entity-whitelist and service-whitelist have been defined for SaaS applications - a warning is reported otherwise. cds build will fail if invalid entries exist. Parameter --vcap-file lets cds deploy --to hana use an existing default-env.json file for the deployment credentials, instead of always creating new credentials from Cloud Foundry. Note that this is a beta feature. cds build --log-level allows to choose which messages to see, default log level is warn . Labels of @sap/cds/common texts are now available in many languages Changed \u00b6 Node.js method cds.parse() has been changed to now truely return parsed-only models, with extensions not applied yet. Note: If you'need the former (erroneous) behaviour, please use cds.compile.cdl for that from now on. Node.js method cds.get() now returns parsed-only models; same as cds.parse() . cds serve / run / watch now reduce logging of details for the bound DB on connect, leading to less clutter. Precision for validTo and validFrom defined in the temporal aspect in @sap/cds/common changed from DateTime to Timestamp . Some administrative fields of SAP Fiori draft documents are now hidden on the UI. The rest got labels. Renamed cds configuration setting features.messageLevel to log-level to be consistent with command line option, e.g. cds build --log-level . Fixed \u00b6 cds build - improvements in the area of error handling and error reporting. cds env and Node.js runtime now properly complete configuration like requires.db.kind.sql with VCAP_SERVICES, so that in production an SAP HANA service is bound. cds build now localizes edmx files properly if cds.env.features.snapi is turned on. cds deploy --to hana no longer crashes if called with NODE_ENV=production . Removed \u00b6 Version 3.33.1 - 2020-03-24 \u00b6 Fixed \u00b6 cds build now correctly supports options.model definitions of type string Details navigation in Fiori preview works again since it's pinned to SAP UI5 1.73. Actual cause still needs to be investigated. cds deploy now adds @sap/hana-client to package.json instead of hdb . cds deploy adds kind sql to requires section. Version 3.33.0 - 2020-03-19 \u00b6 Added \u00b6 cds deploy uses information from existing default-env.json . cds version now also lists all dependencies of your local package.json and has an updated CLI commend help, documenting option --all . cds compile option --docs preserve contents of /** ... */ doc comments in CSN output as well as in EDMX outputs (as Core.Description annotations). cds compile option --clean tells the compiler to not add any derived information, but return a CSN which reflects only what was actually found in a .cds source. cds serve option --watch starts the specific serve command in nodemon watch mode Node.js: cds.env now supports camel case env variables as well as dot-notated keys in .env Changed \u00b6 Labels for the createdAt and changedAt in the @sap/cds/common#managed entity have been adjusted to reflect the SAP Fiori design guidelines. cds build now delegates to the modular build system by default (known as cds build/all ). The modular build system is compatible, but supports additional features, e.g. staging build, SAP HANA Cloud Edition support, populating initial data from .csv by generating .hdbtabledata files, etc. The legacy build is still available as a fallback in case of issues - use setting cds.features.build.legacy: true or ENV variable CDS_FEATURES_BUILD_LEGACY=true . Fixed \u00b6 cds build now correctly logs warnings returned by cds compiler. The message log level can be customized using cds configuration setting cds.features.messageLevel - default is warn . cds.env.roots now properly picks up a changed value of cds.env.folders hdbtabledata is no longer generated for entities that are marked with @cds.persistence.skip Removed \u00b6 Version 3.32.0 - 2020-03-06 \u00b6 Fixed \u00b6 An issue where all Node.js runtime sessions where disconnected when one tenant offboarded. Version 3.31.2 - 2020-03-05 \u00b6 Fixed \u00b6 cds deploy does not crash if _texts.csv is provided for skipped entities cds serve foo.cds does no longer load same model twice cds compile --to edmx no longer creates files with csn instead of edmx content in case no language bundles are found Both cds env and cds compile no longer write terminal escape sequences if only stdout is redirected, but not stderr. No longer enforce Node.js version 8 in db/package.json . Cloud Foundry environment does not support it anymore, as this version is out of maintenance. Version 3.31.1 - 2020-02-26 \u00b6 Fixed \u00b6 Removed npm-shrinkwrap.json Version 3.31.0 - 2020-02-25 \u00b6 Added \u00b6 Generation of hdbtabledata files now reports if CSV file names don't match entity names, and if header names don't match element names in an entity. Watch out for such logs in case CSV files are not deployed to SAP HANA. Fixed \u00b6 cds compile --to hdbtabledata no longer crashes with _texts.csv files referring to a non- localized entity cds build/all adds app folder to the list of model folders for hana database builds. Draft tables are missing if the corresponding annotation model is missing. Version 3.30.0 - 2020-02-10 \u00b6 Added \u00b6 cds compile --log-level allows to choose which messages to see cds deploy --dry prints DDL statements to stdout instead of executing them cds deploy --with-mocks also adds tables for required services cds serve --mocked allows mocking individual required services ( \u2192 learn more about these things using cds help ... ) cds.env now also loads from .env files in properties format cds.resolve/load('*') resolves or loads all models in a project including those for required services. It ist controlled and configurable through cds.env.folders and .roots\ufffc``. Try this in cds repl` launched from your project root to see that in action: js cds.env.folders // = folders db, srv, app by default cds.env.roots // + schema and services in cwd cds.resolve('*',false) // + models in cds.env.requires cds.resolve('*') // > the resolved existing files Added cds.debug(<id>) as a convenient helper for debug output controlled by process.env.DEBUG . For example, use it as follows: js const DEBUG = cds.debug('my-module') DEBUG && DEBUG ('my debug info:', foo, ...) sh > DEBUG=my-module cds run Added cds.error(<msg>) as a convenient helper for throwing errors whose stack traces start from the actual point of invocation. For example, use it as follows: js const {error} = cds if (...) throw error `Something's wrong with ${whatever}` const foo = bar || error `Bar is missing!` // short circuit exits Changed \u00b6 This version brings a major refactoring and streamlining of service runtime implementations, which stays fully compatible regarding all documented APIs but in case you used internal not documented (non-)APIs, you should know these: Removed undocumented features Annotation @source from models loaded for runtime Property cds.serve.app \u2192 use cds.app instead Property source from CSN entity/view definition objects It's very unlikely that you ever used these undocumented internal features at all. In case you did, this should never have been done and you should fix that asap. Deprecated features (\u2192 might get removed in upcoming versions) Property cds.session \u2192 use cds.db instead Property cds.options \u2192 use cds.db.options instead Property cds.unfold \u2192 use cds.compile instead Property cds.config \u2192 use cds.env instead These properties actually where duplicates to the mentioned alternatives. cds run and cds watch have been re-implemented as convenience shortcuts to cds serve , which acts as the central orchestrator for bootstrapping now. (\u2192 see cds run ? or cds watch ? to learn more) cds serve now optionally bootstraps from project-local ./server.js or ./srv/server.js , if exist, thus giving more control while still benefitting from cds serve 's intrinsic support for options like --in-memory or --with-mocks . cds serve now uses cds.load('*') to load a single effective model once, assigned to cds.model , and reused for db as well as all provided and required services . As that avoids loading models redundantly, it drastically improves both, bootstrapping performance as well as memory consumption. cds deploy does not (have to) register the default models to package.json anymore. For example, unlike before, cds deploy -2 sqlite will merely add an entry: db:{kind:'sqlite'} , without an additional model property anymore. cds deploy --to hana does not create connection.properties file any longer, but only modify existing one modifiedAt and modifiedBy from @sap/cds/common - Are now mutable for OData, i.e. no longer carry the @Core.Immutable: true annotation. - Are set by the Node.js runtime whenever the respective row was modified, i.e. also during CREATE operations. Support for cds init is now moved to @sap/cds-dk . Fixed \u00b6 There was a bug in that caused a service names FooBarV2 to erroneously be mapped to mount point /foo-barv2 instead of /foo-bar-v2 as intended and was the case before. \u2192 in case you started a project in this interims phase and had a service name with that pattern you may encounter this fix as an incompatible change, but it's actually reverting to the former compatible way. cds.env erroneously overrode profiled entries depending on properties order Fiori preview now uses latest version of SAP UI5 again cds deploy verifies returned service key to ensure target service is not of type managed . Version 3.21.3 - 2020-02-05 \u00b6 Fixed \u00b6 Fiori preview no longer catches service URLs with an arbitrary prefix (e.g. /foo/browse instead of just /browse ). Version 3.21.1 - 2020-01-07 \u00b6 Fixed \u00b6 Fiori preview no longer crashes since it's pinned to SAP UI5 1.72.3. Actual cause still needs to be investigated. Version 3.21.0 - 2019-12-11 \u00b6 cds add , import , and watch now print installation hints if @sap/cds-dk is not installed Experimental option hana.syntax=hdi to create hdbtable files instead of hdbcds . May still change! Changed \u00b6 In development mode, the mock authorization strategy is automatically activated with two fake users alice and bob , which allows for out-of-the-box testing of @requires annotations. This means that, unlike before, the JWT authorization strategy needs to be activated explicitly (through {auth: { passport: { strategy: 'mock' }}} . In production, no change is required. You might see a MODULE_NOT_FOUND error for @sap/xsenv in case you use the JWT strategy but have not bound any xsuaa service. In this case either bind such a service instance, add the @sap/xsenv dependency, or use a different strategy like mock . The trigger of this error is @sap/xssec 2.2.4 no longer requiring @sap/xsenv . Renovated and streamlined cds init . It prints a hint now if it's called with old-style parameters, as well as that it wants to be used from @sap/cds-dk . Check out cds help init for more. Removed the experimental --args parameter of cds compile . This turned out to be cumbersome to use in shells. Replacement is the standard configuration mechanism, e.g. use an environment variable CDS_FOO_BAR to activate option cds.foo.bar . Fixed \u00b6 SELECT.one/distinct(Fool,[...]) failed when passing an array for columns as argument two Version 3.20.1 - 2019-11-26 \u00b6 Fixed \u00b6 Fix 'duplicate versions' errors by loading @sap/cds again from the current project if possible. Version 3.20.0 - 2019-11-19 \u00b6 Added \u00b6 Mention xsuaa in help of cds compile Fixed \u00b6 Typings for UPDATE function no longer contain duplicates. Also see \u00b6 Changes of @sap/cds-compiler 1.20.3 Changes of @sap/cds-ql 1.21.0 Changes of @sap/cds-services 1.21.0 Changes of @sap/cds-messaging 1.4.0 Changes of @sap/generator-cds 2.10.2 Version 3.18.4 - 2019-11-15 \u00b6 Fixed \u00b6 .cfignore files now get created by cds build/all to improve the overall deployment turnaround of cf push . Also, this avoids failures of CF node.js buildpack trying to rebuild sqlite binaries. Generated manifest.yaml files for Cloud Foundry now contain a path attribute that allows pushing from an outside folder. Also, they specify reduced memory requirements. Generated manifest.yaml for HDI deployer does not create a route, and specifies a valid health-check-type . cds deploy --to hana now also includes models in the srv folder. cds deploy no longer writes model folders to package.json that do not exist. Version 3.19.0 - 2019-10-31 \u00b6 Added \u00b6 Deployments for sqlite and SAP HANA now find CSV files in the form _texts_LOCALE.csv , like Books_texts_fr.csv . This file layout allows splitting translated texts into one file per language. Deployment for sqlite now also imports initial data from JSON files cds version has learned about @sap/cds-dk Fixed \u00b6 cds watch --help works again, if used from @sap/cds-dk Version 3.18.3 - 2019-10-28 \u00b6 Fixed \u00b6 Fixed a crash in cds run --watch with changing directories. cds watch is now also found if called from an NPM script. cds watch now uses the same lookup paths for models as cds run Version 3.18.1 - 2019-10-17 \u00b6 Fixed \u00b6 Fixed a crash during sqlite deployment if there were csv files that did not match an entity name cds deploy --to hana now does a build for SAP HANA even if no matching build task is available. cds deploy now tries to add .gitignore entries only once In @source annotations of csn.json files generated for cloud deployments, now posix file paths (with / ) are written, and no Windows paths. cds serve and run now shuts down gracefully in case of SIGHUP signals emitted by e.g. the VS Code terminal. cds watch now is found even if @sap/cds-dk is not installed locally. Also see \u00b6 Changes of @sap/cds-ql 1.19.2 Changes of @sap/cds-services 1.19.1 Changes of @sap/cds-messaging 1.2.1 Version 3.18.0 - 2019-10-09 \u00b6 Added \u00b6 Compiler options for SAP HANA backend can now be set in configuration in the cdsc.toHana block (e.g. cds.cdsc.toHana.joins ) service.tx() as a shortcut for service.transaction() Fixed \u00b6 cds deploy --to hana now adds the tunnel address to the JDBC URL Boolean and number values from default-env.json now are accepted in configuration ( cds env ) For applications deployed to Cloud Foundry, custom handlers are now properly resolved using their names. cds serve / run now properly log $batch requests of OData Also see \u00b6 Changes of @sap/cds-compiler 1.19.1 Changes of @sap/cds-messaging 1.2.0 Changes of @sap/cds-ql 1.19.1 Changes of @sap/cds-reflect 2.8.0 Changes of @sap/cds-rest 1.2.0 Changes of @sap/cds-services 1.19.0 Changes of @sap/generator-cds 2.9.0 Version 3.17.8 - 2019-09-25 \u00b6 Fixed \u00b6 UPDATE(entity, key) statement Version 3.17.7 - 2019-09-24 \u00b6 Fixed \u00b6 cds deploy Version 3.17.6 - 2019-09-23 \u00b6 Changed \u00b6 Improved cds env Version 3.17.5 - 2019-09-20 \u00b6 Fixed \u00b6 cds deploy did not work properly Version 3.17.4 - 2019-09-19 \u00b6 Also see \u00b6 Changes of @sap/cds-rest 1.1.2 Version 3.17.3 - 2019-09-19 \u00b6 Fixed \u00b6 cds deploy --to hana Version 3.17.2 - 2019-09-19 \u00b6 Also see \u00b6 Changes of @sap/cds-services 1.18.2 Changes of @sap/generator-cds 2.8.2 Version 3.17.1 - 2019-09-18 \u00b6 Also see \u00b6 Changes of @sap/cds-compiler 1.18.2 Changes of @sap/cds-ql 1.18.2 Changes of @sap/cds-services 1.18.1 Version 3.17.0 - 2019-09-10 \u00b6 Added \u00b6 cds run has learned a new --watch option, which provides automatic restarts of the server on file changes. nodemon package is required for this to work. Fixed \u00b6 cds deploy now writes true and false values in csv files as boolean to sqlite Console output of cds run now waits until the server is really up and running before it declares success. cds deploy and build/all do not write hdbtabledata files if some are already present. Also see \u00b6 Changes of @sap/cds-compiler 1.18.1 Changes of @sap/cds-ql 1.18.1 Changes of @sap/cds-reflect 2.7.1 Changes of @sap/cds-services 1.18.0 Changes of @sap/generator-cds 2.8.1 Version 3.16.2 - 2019-08-27 \u00b6 Also see \u00b6 Changes of @sap/cds-compiler 1.17.1 Version 3.16.0 - 2019-08-22 \u00b6 Added \u00b6 cds run has learned a new --in-memory option, which connects and deploys to an SQLite in-memory database. There is no need to call cds deploy before. cds deploy --to hana now can also be executed in Java projects cds run 's index.html got a favicon, to give a visual clue in browsers. cds.requires.<datasource>.model configuration can now also point to a node.js module, e.g. @my/module . Previously, only a relative file path was supported. Improved logging of query objects cds compile now understands --to edmx-v2 and --to edmx-v4 to produce OData metadata of versions 2 or 4, respectively. Changed \u00b6 Fiori preview in cds run now is only added if OData services are being served. For other protocols like rest , no Fiori preview is provided. Same holds true for the $metadata link. cds compile now behaves better in non-TTY scenarios (e.g. when piping to files). It writes a proper JSON string instead of a Javascript object. Previously, one had to enforce JSON using the --to json processor. Compare e.g. the output of cds compile model.cds to cds compile model.cds > model.json . Fixed \u00b6 Fiori preview in cds run now also works for services with namespaces In services of CF marketplace, cds deploy --to hana now only accepts services with plan hdi-shared . Previously, it could get confused with services of type hana but of other (non-HDI) plans. Localized edmx files are now produced also for i18n.json files. Also see \u00b6 Changes of @sap/cds-compiler 1.17.0 Changes of @sap/cds-ql 1.17.0 Changes of @sap/cds-services 1.17.0 Changes of @sap/generator-cds 2.7.0 Version 3.15.0 - 2019-07-26 \u00b6 Added \u00b6 hdbtabledata files are now generated automatically as part of cds deploy --to hana for given set of CSV files. CSV file names must follow the pattern <namespace>-entity.csv (same as for SQLite deployment) and be located in db/csv or db/data . For Node.js, multiple configuration profiles can now be activated at the same time, e.g. by setting both NODE_ENV and CDS_ENV , or by setting a multi-value list: CDS_ENV=profile1,profile2 . New labels for sap.common.*.code and sap.common.Currencies.symbol (part of @sap/cds/common ). Better message for Duplicate definition errors, where the same cds file is referenced from different locations. To fix this, check all dependencies to @sap/cds in your package.json and those of reused packages and ensure they allow deduped use of @sap/cds . Also see \u00b6 Changes of @sap/cds-compiler 1.16.1 Changes of @sap/cds-ql 1.16.0 Changes of @sap/cds-services 1.16.0 Changes of @sap/generator-cds 2.6.1 Version 3.14.0 - 2019-07-11 \u00b6 Added \u00b6 Support for SELECT.distinct.from(Foo) and SELECT.one.from(Foo) queries in Node.js [Beta] cds deploy --to hana deploys to SAP HANA on Cloud Foundry For Node.js, cds env now activates the development profile automatically, unless CDS_ENV or NODE_ENV are set. This is in line with NODE_ENV defaulting to development . Also see \u00b6 Changes of @sap/cds-ql 1.15.0 Changes of @sap/cds-services 1.15.0 Changes of @sap/generator-cds 2.5.0 Version 3.13.0 - 2019-06-26 \u00b6 Added \u00b6 cds serve now provides a preview of the services in a list page of SAP Fiori Elements Changed \u00b6 cds serve now yields an error if there are no services defined in the model Also see \u00b6 Changes of @sap/cds-compiler 1.15.0 Changes of @sap/cds-ql 1.14.0 Changes of @sap/cds-services 1.14.0 Changes of @sap/generator-cds 2.4.11 Version 3.12.0 - 2019-06-17 \u00b6 Added \u00b6 On request, cds build/all now generates OData EDMX files for node.js services Performance optimizations for cds build/all Fixed \u00b6 cds deploy no longer fails if data dir is not present cds build/all no longer prints a message if mta.yaml does not exist Also see \u00b6 Changes of @sap/cds-compiler 1.14.1 Changes of @sap/cds-ql 1.13.0 Changes of @sap/cds-services 1.13.0 Version 3.11.1 - 2019-06-03 \u00b6 Fixed \u00b6 cds deploy honors saved datasource configuration again localization works again for sqlite datasources defined in package.json Version 3.11.0 - 2019-06-03 \u00b6 Added \u00b6 cds deploy now also finds .csv files in imported reuse packages Better error messages for various cds CLI calls Changed \u00b6 cds build/all for Node.js projects generates proper CSN in gen/csn.json . A warning is emitted if cds serve is run with the previous format. Rebuild the project if you see this warning. Also see \u00b6 Changes of @sap/cds-compiler 1.14.0 Changes of @sap/cds-ql 1.12.0 Changes of @sap/cds-services 1.12.0 Changes of @sap/generator-cds 2.4.10 Version 3.10.0 - 2019-05-21 \u00b6 Added \u00b6 Tables and view for localized entities are created by default now, both for HANA and SQLite. Internal errors are now marked as such in all CLI commands, with a request to report them. Changed \u00b6 cds compile --service all no longer fails in case no services are found. This better matches higher level commands like cds build that should not fail in this instance. Note that --service Foo fails as before in case Foo is not found. cds run and cds serve now serve the generic index page at / , while previously this was /$index . cds build/all now auto-creates build tasks from mta.yaml definition if no build tasks have been defined in .cdsrc.json . If no mta.yaml file exists, cds configuration data respectively defaults are used for build task configuration. Fixed \u00b6 CLI now shows compilation warnings in all commands, e.g. in build , deploy , or compile . Previously warnings were only shown in case of compilation errors. cds help no longer inserts terminal escape sequences if stdout is redirected to a file. Errors in custom handlers are no longer shadowed in cds serve or cds run . Also see \u00b6 Changes of @sap/cds-compiler 1.13.4 Changes of @sap/cds-ql 1.11.1 Changes of @sap/cds-reflect 2.5.0 Changes of @sap/cds-services 1.11.1 Changes of @sap/generator-cds 2.4.8 Version 3.9.0 - 2019-05-08 \u00b6 Added \u00b6 cds.serve now reads passport for services from auth.passport configuration property Fixed \u00b6 cds.compile now really skips entities marked with if-unused Build tasks are now listed with cds env cds serve now supports the --at , --to , and --with arguments as specified. cds deploy --to sqlite now better handles csv files with empty values Also see \u00b6 Changes of @sap/cds-compiler 1.12.0 Changes of @sap/cds-ql 1.10.2 Changes of @sap/cds-reflect 2.5.0 Changes of @sap/cds-services 1.10.2 Changes of @sap/generator-cds 2.4.6 Version 3.8.1 - 2019-04-30 \u00b6 Fixed \u00b6 Texts in deep annotations, e.g. @UI.Facet , are now properly localized in OData metadata Version 3.8.0 - 2019-04-09 \u00b6 Fixed \u00b6 Make tests run on Windows again Various fixes in cds build/all Adjustments to latest compiler for localizing models .hdbcds and .hdbtabledata files are now copied over in cds build/all Also see \u00b6 Changes of @sap/cds-compiler 1.11.0 Changes of @sap/cds-ql 1.8.1 Changes of @sap/cds-services 1.8.1 Changes of @sap/generator-cds 2.4.4 Version 3.7.1 - 2019-03-25 \u00b6 Fixed \u00b6 cds serve now honors newCsn configuration when serving from precompiled csn.json files. cds init creates samples correctly when project already contains files. cds build for node.js projects will now show up compilation errors. Formatting has been improved as well. Better support for finding cds executable in VSCode. Also see \u00b6 Changes of @sap/cds-compiler 1.10.0 Changes of @sap/cds-ql 1.7.1 Changes of @sap/cds-services 1.7.2 Changes of @sap/generator-cds 2.4.4 Version 3.6.0 - 2019-02-27 \u00b6 Added \u00b6 In cds init : Add modules via cds init --modules to an existing project. Do not allow project creation via cds init outside of current working folder, e.g. init ../../some/where/else is not allowed. No output at all (not even error messages) when using cds init --quiet . Create a module folder using cds init --modules... even if it is empty based on the supplied options. Parameter --modules only supports one folder of each type. Alpha support for @cds.odata.valuelist : Adding @cds.odata.valuelist to @cds.autoexposed entities will automatically equip all associations referring to such entities with a corresponding @Common.ValueList.entity Changed \u00b6 Simplified code lists: removed superfluous types LanguageCode , CountryCode , and CurrencyCode from @sap/cds/common cds build/all now does --clean by default and is less verbose in its output Fixed \u00b6 cds.load no longer fails if reading in a CSN file in version 0.1.0 Also see \u00b6 Changes of @sap/cds-compiler 1.9.0 Changes of @sap/cds-reflect 2.4.0 Changes of @sap/cds-ql 1.6.0 Changes of @sap/cds-services 1.6.0 Changes of @sap/generator-cds 2.4.0 Version 3.5.2 - 2019-02-20 \u00b6 Fixed \u00b6 Node.js projects created with cds init now Bind the service module to an HDI service in mta.yaml . Invoke CDS build when building the database module. No longer create old-style service configuration in package.json . For datasources with kind hana we now also find hanatrial services in trial landscapes by matching their tag hana . Version 3.5.1 - 2019-02-14 \u00b6 Fixed \u00b6 In cds serve service providers where added twice to the express app. This is fixed. In the logs of cds serve false warnings on fiori requests are now gone. cds serve no longer fails on localization for unbound actions. The project template was fixed to properly wire up the connection to SAP HANA. Also see \u00b6 Changes of @sap/cds-compiler 1.8.1 Changes of @sap/cds-ql 1.5.1 Changes of @sap/cds-services 1.5.2 Changes of @sap/generator-cds 2.3.7 Version 3.5.0 - 2019-02-07 \u00b6 Added \u00b6 cds compile -2 xsuaa now generates default values for xsappname and tenant-mode All commands now can be called with --help , where previously only cds help <command> was allowed. Changed \u00b6 The minimum required Node.js version is now set more specifically to 8.9 LTS. Previously, just Node.js 8 was mentioned. The cds build/all (experimental build command for Node.js) emits a warning for existing projects to add build task configuration. Watch out for such a warning in the console and follow its instructions. Fixed \u00b6 Service handlers are now also found on CF if CDS models are served from a csn.json file instead as from .cds sources. An issue where projects w/o db dir could not be built using cds build . Unclear documentation of cds deploy on where it looks up the data source. cds env to load configuration profiles in lower-prio files ( .cdsrc.json ) with higher precedence than default configuration in higher-prio files ( package.json ). Also see \u00b6 Changes of @sap/cds-compiler 1.8.0 Changes of @sap/cds-reflect 2.3.0 Changes of @sap/cds-ql 1.5.0 Changes of @sap/cds-services 1.5.0 Changes of @sap/generator-cds 2.3.6 Version 3.4.1 - 2019-01-24 \u00b6 Fixed \u00b6 Restore cds-compiler .version Also see \u00b6 Changes of @sap/cds-compiler 1.7.1 Changes of @sap/cds-reflect 2.2.1 Changes of @sap/cds-ql 1.4.0 Changes of @sap/cds-services 1.4.0 Changes of @sap/generator-cds 2.2.0 Version 3.4.0 - 2019-01-22 \u00b6 Added \u00b6 cds.env supports loading from default-env.json Support base models for cds compile -2 xsuaa Also see \u00b6 Changes of @sap/cds-compiler 1.7.0 Changes of @sap/cds-reflect 2.2.0 Changes of @sap/cds-ql 1.4.0 Changes of @sap/cds-services 1.4.0 Changes of @sap/generator-cds 2.2.0 Version 3.3.0 - 2019-01-11 \u00b6 Also see \u00b6 Changes of @sap/cds-compiler 1.6.0 Changes of @sap/cds-reflect 2.1.0 Changes of @sap/cds-ql 1.3.0 Changes of @sap/cds-services 1.3.0 Changes of @sap/generator-cds 2.2.0 Version 3.2.0 - 2018-12-21 \u00b6 Changed \u00b6 cdsc 2sql output may also contain .types Add labels to CodeLists in common.cds Improved cds error messages Also see \u00b6 Changes of @sap/cds-compiler 1.6.0 Changes of @sap/cds-reflect 2.1.0 Changes of @sap/cds-ql 1.2.0 Changes of @sap/cds-services 1.2.0 Changes of @sap/generator-cds 2.2.0 Version 3.1.1 - 2018-12-13 \u00b6 Changed \u00b6 Better console output from cds compile Fixed \u00b6 cds.compile ignored configured odata.version Also see \u00b6 Changes of @sap/cds-compiler 1.6.0 Changes of @sap/cds-reflect 2.1.0 Changes of @sap/cds-ql 1.1.0 Changes of @sap/cds-services 1.1.0 Changes of @sap/generator-cds 2.2.0 Version 3.0.0 \u00b6 Changed \u00b6 Reworked configuration options to center around required 'data sources'. As an example see the snippted that e.g. cds deploy --to sqlite:my.db generates into package.json . The former cds options from package.json are deprectated but still supported. Clean up of many Node.js APIs, mainly for cds.serve and cds.connect . See the Javacript APIs documentation for details. Node.js 8 is now the minimum required runtime version. Simplified cds init . By default it creates a plain project suitable for local CDS development. Added \u00b6 cds env allows for inspecting the effective configuration Also see \u00b6 Changes of @sap/cds-compiler 1.5.0 Changes of @sap/cds-reflect 2.0.0 Changes of @sap/cds-ql 1.0.0 Changes of @sap/cds-services 1.0.0 Changes of @sap/generator-cds 2.0.0 Version 2.11.2 \u00b6 Fixes \u00b6 During cds init/new only install @sap/generator-cds 1.x Version 2.11.0 \u00b6 Added \u00b6 Reuse aspect cuid to @sap/cds/common Support for smart to-many Associations finding backlinks automatically (\u2192not for production!) Support to fill DBs with initial data from CSV files (fetched from folder db/csv/ ) New CLI command cds run - today a mere wrapper for cds serve all but meant to serve microservice test scenarios cds deploy can be configured not to modify package.json through the --no-save option. Also see \u00b6 Changes of @sap/cds-compiler 1.2.0 Changes of @sap/cds-reflect 1.8.0 Changes of @sap/cds-ql 0.12.0 Changes of @sap/cds-services 0.12.0 Version 2.10.3 \u00b6 Fixes \u00b6 During cds init/new only install @sap/generator-cds 1.x Version 2.10.0 \u00b6 Added \u00b6 Support for Fiori Draft Fixes \u00b6 Enhanced server.js to also include links to entities Also see \u00b6 Changes of @sap/cds-compiler 1.1.3 Changes of @sap/cds-reflect 1.7.0 Changes of @sap/cds-ql 0.11.0 Changes of @sap/cds-services 0.11.0 Version 2.9.1 \u00b6 Fixes \u00b6 cds build no longer blocks if running inside a Maven build. Version 2.9.0 \u00b6 Added \u00b6 common.cds model got annotations for title, description, and value lists. cds executable now can read from stdin, e.g. echo 'entity Foo {ID:UUID;}' | cds -2 sql cds -2 sql now outputs plain (non-HANA) SQL. Use -2 hana for HANA SQL. cds config shows the current CDS configuration. Use cds help config to learn more. Fixes \u00b6 Entities from common.cds like Languages , Countries , and Currencies are now only persisted to the database if they are actually used. Also see \u00b6 Changes of @sap/cds-compiler 1.1.2 Changes of @sap/cds-reflect 1.6.0 Changes of @sap/cds-ql 0.10.0 Changes of @sap/cds-services 0.10.1 Version 2.8.0 \u00b6 Added \u00b6 Support was added to build node.js service modules cds init has been reimplemented with a better commandline experience, along with updated templates. Plugin @sap/generator-cds , which is required for cds init , is now automatically installed when init is called for the first time. cds new is still available and is now just a synonym for init . Also see \u00b6 Changes of @sap/cds-compiler 1.1.1 Changes of @sap/cds-services 0.9.0 Changes of @sap/cds-ql 0.9.0 Version 2.7.0 \u00b6 Also see \u00b6 Changes of @sap/cds-compiler 1.0.32 Changes of @sap/cds-services 0.8.1 Changes of @sap/cds-ql 0.8.1 Version 2.6.0 \u00b6 Also see \u00b6 Changes of @sap/cds-compiler 1.0.31 Changes of @sap/cds-services 0.7.0 Changes of @sap/cds-ql 0.7.0 Version 2.5.1 \u00b6 Also see \u00b6 Changes of @sap/cds-services 0.6.0 Changes of @sap/cds-ql 0.6.0 Version 2.5.0 \u00b6 Added \u00b6 Instead of compiling each .cds service file separately, cds build now combines all those files from the same folder, creating only one csn.json file for them. Fixes \u00b6 Shortcuts of cds init work again Also see \u00b6 Changes of @sap/cds-compiler 1.0.30 Changes of @sap/cds-services 0.5.0 Changes of @sap/cds-ql 0.5.0 Version 2.4.2 \u00b6 Same as version 2.3.2, but including the generic service provider for Node.js ( @sap/cds-services and @sap/cds-ql ). Version 2.3.2 \u00b6 Changed \u00b6 The default for SQL name mapping is changed to plain . This means that The name of a table/view in the database catalog is obtained from the name of the corresponding entity in the CDS model in the following way: replace all \".\" by \"_\" convert everything to upper case The name of a table/view column in the database catalog is obtained from the name of the corresponding entity element in the csn in the following way: convert everything to upper case Note that this is a breaking change for appliations that rely on the previous value of quoted . In order to get this value back, add the following to package.json : \"cds\": { \"data\": { \"sql_mapping\" : \"quoted\" } } Fixes \u00b6 Special output formatting in CLI is only done for cds eval and cds repl , but not for programmatic usage. Links to external documentation are now point to correct help documents. Also see \u00b6 Changes of @sap/cds-compiler 1.0.30 Version 2.3.0 \u00b6 Added \u00b6 SQL names can now be configured with { data: {sql_mapping: \"plain/quoted\"} } . Default is quoted , but will be changed to plain soon. If you need to stay with quoted in the futute, e.g. due to data compatibility reasons, you can configure this mode already now. Fixes \u00b6 The csn.json file produced by cds build now contains the properly unfolded model for OData. Previously this was the normalized model, which led to runtime errors in the Java service provider. Invalid configuration data in package.json now leads to a build error again. Console output of cds build now presents files paths sorted. Also see \u00b6 Changes of CDS compiler 1.0.27 Version 2.2.0 \u00b6 Added \u00b6 CDS configuration in package.json can now be omitted if you follow the standard project layout, i.e. if you place your model files in db/ , srv/ , and app/ folders. Changed \u00b6 Previously data models needed to include import statements to the service models (e.g. using from '../srv' ), so that the Java runtime could use these service views on the DB to execute queries. The views are now included automatically, so that you can remove the explict using clauses. Calling just cds on the command line now prints its help. The previously started REPL is now available with cds repl (or just cds r ). Fixes \u00b6 Some cds commands failed on Windows. This is fixed. Also see \u00b6 Changes of CDS compiler 1.0.24 Version 2.1.0 \u00b6 Added \u00b6 Service edmx files are now written to UI app folders if their manifest.json contains a reference to the service. This allows Web IDE's annotation modeler to work on up to date service files. The results of cds.compile.to... commands are now automatically formatted if called in cds -e... or cds repl. You don't need to append console.log to the call chain. Fixes \u00b6 Language properties are now found in all folders, also ones that are outside of the current module csn.json is written with line breaks and indentation Also see \u00b6 Changes of CDS compiler 1.0.21 Version 2.0.0 \u00b6 Added \u00b6 All-new command-line interface. See cds help for information on the available commands. cds compile exposes CDS model transformations with various options. cds build automatically writes localized edmx files. cds build now writes the version to the build log. cds version does the usual thing. cds init scaffolds CDS projects. CDS repl (read-eval-print-loop): just type cds and play with CDS API. Fixes \u00b6 Too many to mention :) Also see \u00b6 Changes of CDS compiler 1.0.19","title":"Change Log"},{"location":"apis/cds/CHANGELOG/#change-log","text":"All notable changes to this project are documented in this file. The format is based on Keep a Changelog . This project adheres to Semantic Versioning .","title":"Change Log"},{"location":"apis/cds/CHANGELOG/#version-3342-2020-05-30","text":"","title":"Version 3.34.2 - 2020-05-30"},{"location":"apis/cds/CHANGELOG/#changed","text":"Use cds.hana.deploy-format = hdbtable instead of cds.hana.syntax to switch deployment from hdbcds to hdbtable for SAP HANA Cloud. cds run now supports relative dataSource URLs in SAP UI5 manifests again, so that UI5 apps can be served w/o approuter. This support is only active in development mode. cds deploy --to hana changes kind to hana only if it is not already sql","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed","text":"The UI.Identification annotation for sap.common.CodeList got a correct value, pointing to its name element. Configuration requires.<foo>.credentials.destination is now preserved again when running with VCAP_SERVICES . In version 3.34.1 it was cleared. Entities annotated with @cds.persistence.skip:if-unused (like sap.common.Languages ) now again are skipped when compiling to HANA output. This got broken in previous versions when using the new compiler APIs. sql_mapping is again written to csn.json as it's required by classic Java runtime. default-env.json is now read even in production, which is in line with the behavior of other modules that honor this file. Real prod environments like CF will still overwrite these defaults.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3340-2020-04-27","text":"","title":"Version 3.34.0 - 2020-04-27"},{"location":"apis/cds/CHANGELOG/#added","text":"cds version option -ls prints an npm ls subtree. cds serve / run now also accept package names as arguments, e.g. cds serve --project @capire/bookshop . cds compile option --parse provides minimal, parsed-only CSN output. New Node.js method cds.compile.cdl() allows compiling CDS sources in-process. cds build now supports cds configuration requires.db.kind:\"sql\" which allows seamless production deployments using HANA db and development deployments using sqlite db. Default maximum query size limit of 1000 (overridable via @cds.query.limit.max ). Improved error message during cds deploy on Windows when SAP CommonCryptoLib is missing. cds build now checks that entity-whitelist and service-whitelist have been defined for SaaS applications - a warning is reported otherwise. cds build will fail if invalid entries exist. Parameter --vcap-file lets cds deploy --to hana use an existing default-env.json file for the deployment credentials, instead of always creating new credentials from Cloud Foundry. Note that this is a beta feature. cds build --log-level allows to choose which messages to see, default log level is warn . Labels of @sap/cds/common texts are now available in many languages","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_1","text":"Node.js method cds.parse() has been changed to now truely return parsed-only models, with extensions not applied yet. Note: If you'need the former (erroneous) behaviour, please use cds.compile.cdl for that from now on. Node.js method cds.get() now returns parsed-only models; same as cds.parse() . cds serve / run / watch now reduce logging of details for the bound DB on connect, leading to less clutter. Precision for validTo and validFrom defined in the temporal aspect in @sap/cds/common changed from DateTime to Timestamp . Some administrative fields of SAP Fiori draft documents are now hidden on the UI. The rest got labels. Renamed cds configuration setting features.messageLevel to log-level to be consistent with command line option, e.g. cds build --log-level .","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_1","text":"cds build - improvements in the area of error handling and error reporting. cds env and Node.js runtime now properly complete configuration like requires.db.kind.sql with VCAP_SERVICES, so that in production an SAP HANA service is bound. cds build now localizes edmx files properly if cds.env.features.snapi is turned on. cds deploy --to hana no longer crashes if called with NODE_ENV=production .","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#removed","text":"","title":"Removed"},{"location":"apis/cds/CHANGELOG/#version-3331-2020-03-24","text":"","title":"Version 3.33.1 - 2020-03-24"},{"location":"apis/cds/CHANGELOG/#fixed_2","text":"cds build now correctly supports options.model definitions of type string Details navigation in Fiori preview works again since it's pinned to SAP UI5 1.73. Actual cause still needs to be investigated. cds deploy now adds @sap/hana-client to package.json instead of hdb . cds deploy adds kind sql to requires section.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3330-2020-03-19","text":"","title":"Version 3.33.0 - 2020-03-19"},{"location":"apis/cds/CHANGELOG/#added_1","text":"cds deploy uses information from existing default-env.json . cds version now also lists all dependencies of your local package.json and has an updated CLI commend help, documenting option --all . cds compile option --docs preserve contents of /** ... */ doc comments in CSN output as well as in EDMX outputs (as Core.Description annotations). cds compile option --clean tells the compiler to not add any derived information, but return a CSN which reflects only what was actually found in a .cds source. cds serve option --watch starts the specific serve command in nodemon watch mode Node.js: cds.env now supports camel case env variables as well as dot-notated keys in .env","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_2","text":"Labels for the createdAt and changedAt in the @sap/cds/common#managed entity have been adjusted to reflect the SAP Fiori design guidelines. cds build now delegates to the modular build system by default (known as cds build/all ). The modular build system is compatible, but supports additional features, e.g. staging build, SAP HANA Cloud Edition support, populating initial data from .csv by generating .hdbtabledata files, etc. The legacy build is still available as a fallback in case of issues - use setting cds.features.build.legacy: true or ENV variable CDS_FEATURES_BUILD_LEGACY=true .","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_3","text":"cds build now correctly logs warnings returned by cds compiler. The message log level can be customized using cds configuration setting cds.features.messageLevel - default is warn . cds.env.roots now properly picks up a changed value of cds.env.folders hdbtabledata is no longer generated for entities that are marked with @cds.persistence.skip","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#removed_1","text":"","title":"Removed"},{"location":"apis/cds/CHANGELOG/#version-3320-2020-03-06","text":"","title":"Version 3.32.0 - 2020-03-06"},{"location":"apis/cds/CHANGELOG/#fixed_4","text":"An issue where all Node.js runtime sessions where disconnected when one tenant offboarded.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3312-2020-03-05","text":"","title":"Version 3.31.2 - 2020-03-05"},{"location":"apis/cds/CHANGELOG/#fixed_5","text":"cds deploy does not crash if _texts.csv is provided for skipped entities cds serve foo.cds does no longer load same model twice cds compile --to edmx no longer creates files with csn instead of edmx content in case no language bundles are found Both cds env and cds compile no longer write terminal escape sequences if only stdout is redirected, but not stderr. No longer enforce Node.js version 8 in db/package.json . Cloud Foundry environment does not support it anymore, as this version is out of maintenance.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3311-2020-02-26","text":"","title":"Version 3.31.1 - 2020-02-26"},{"location":"apis/cds/CHANGELOG/#fixed_6","text":"Removed npm-shrinkwrap.json","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3310-2020-02-25","text":"","title":"Version 3.31.0 - 2020-02-25"},{"location":"apis/cds/CHANGELOG/#added_2","text":"Generation of hdbtabledata files now reports if CSV file names don't match entity names, and if header names don't match element names in an entity. Watch out for such logs in case CSV files are not deployed to SAP HANA.","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixed_7","text":"cds compile --to hdbtabledata no longer crashes with _texts.csv files referring to a non- localized entity cds build/all adds app folder to the list of model folders for hana database builds. Draft tables are missing if the corresponding annotation model is missing.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3300-2020-02-10","text":"","title":"Version 3.30.0 - 2020-02-10"},{"location":"apis/cds/CHANGELOG/#added_3","text":"cds compile --log-level allows to choose which messages to see cds deploy --dry prints DDL statements to stdout instead of executing them cds deploy --with-mocks also adds tables for required services cds serve --mocked allows mocking individual required services ( \u2192 learn more about these things using cds help ... ) cds.env now also loads from .env files in properties format cds.resolve/load('*') resolves or loads all models in a project including those for required services. It ist controlled and configurable through cds.env.folders and .roots\ufffc``. Try this in cds repl` launched from your project root to see that in action: js cds.env.folders // = folders db, srv, app by default cds.env.roots // + schema and services in cwd cds.resolve('*',false) // + models in cds.env.requires cds.resolve('*') // > the resolved existing files Added cds.debug(<id>) as a convenient helper for debug output controlled by process.env.DEBUG . For example, use it as follows: js const DEBUG = cds.debug('my-module') DEBUG && DEBUG ('my debug info:', foo, ...) sh > DEBUG=my-module cds run Added cds.error(<msg>) as a convenient helper for throwing errors whose stack traces start from the actual point of invocation. For example, use it as follows: js const {error} = cds if (...) throw error `Something's wrong with ${whatever}` const foo = bar || error `Bar is missing!` // short circuit exits","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_3","text":"This version brings a major refactoring and streamlining of service runtime implementations, which stays fully compatible regarding all documented APIs but in case you used internal not documented (non-)APIs, you should know these: Removed undocumented features Annotation @source from models loaded for runtime Property cds.serve.app \u2192 use cds.app instead Property source from CSN entity/view definition objects It's very unlikely that you ever used these undocumented internal features at all. In case you did, this should never have been done and you should fix that asap. Deprecated features (\u2192 might get removed in upcoming versions) Property cds.session \u2192 use cds.db instead Property cds.options \u2192 use cds.db.options instead Property cds.unfold \u2192 use cds.compile instead Property cds.config \u2192 use cds.env instead These properties actually where duplicates to the mentioned alternatives. cds run and cds watch have been re-implemented as convenience shortcuts to cds serve , which acts as the central orchestrator for bootstrapping now. (\u2192 see cds run ? or cds watch ? to learn more) cds serve now optionally bootstraps from project-local ./server.js or ./srv/server.js , if exist, thus giving more control while still benefitting from cds serve 's intrinsic support for options like --in-memory or --with-mocks . cds serve now uses cds.load('*') to load a single effective model once, assigned to cds.model , and reused for db as well as all provided and required services . As that avoids loading models redundantly, it drastically improves both, bootstrapping performance as well as memory consumption. cds deploy does not (have to) register the default models to package.json anymore. For example, unlike before, cds deploy -2 sqlite will merely add an entry: db:{kind:'sqlite'} , without an additional model property anymore. cds deploy --to hana does not create connection.properties file any longer, but only modify existing one modifiedAt and modifiedBy from @sap/cds/common - Are now mutable for OData, i.e. no longer carry the @Core.Immutable: true annotation. - Are set by the Node.js runtime whenever the respective row was modified, i.e. also during CREATE operations. Support for cds init is now moved to @sap/cds-dk .","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_8","text":"There was a bug in that caused a service names FooBarV2 to erroneously be mapped to mount point /foo-barv2 instead of /foo-bar-v2 as intended and was the case before. \u2192 in case you started a project in this interims phase and had a service name with that pattern you may encounter this fix as an incompatible change, but it's actually reverting to the former compatible way. cds.env erroneously overrode profiled entries depending on properties order Fiori preview now uses latest version of SAP UI5 again cds deploy verifies returned service key to ensure target service is not of type managed .","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3213-2020-02-05","text":"","title":"Version 3.21.3 - 2020-02-05"},{"location":"apis/cds/CHANGELOG/#fixed_9","text":"Fiori preview no longer catches service URLs with an arbitrary prefix (e.g. /foo/browse instead of just /browse ).","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3211-2020-01-07","text":"","title":"Version 3.21.1 - 2020-01-07"},{"location":"apis/cds/CHANGELOG/#fixed_10","text":"Fiori preview no longer crashes since it's pinned to SAP UI5 1.72.3. Actual cause still needs to be investigated.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3210-2019-12-11","text":"cds add , import , and watch now print installation hints if @sap/cds-dk is not installed Experimental option hana.syntax=hdi to create hdbtable files instead of hdbcds . May still change!","title":"Version 3.21.0 - 2019-12-11"},{"location":"apis/cds/CHANGELOG/#changed_4","text":"In development mode, the mock authorization strategy is automatically activated with two fake users alice and bob , which allows for out-of-the-box testing of @requires annotations. This means that, unlike before, the JWT authorization strategy needs to be activated explicitly (through {auth: { passport: { strategy: 'mock' }}} . In production, no change is required. You might see a MODULE_NOT_FOUND error for @sap/xsenv in case you use the JWT strategy but have not bound any xsuaa service. In this case either bind such a service instance, add the @sap/xsenv dependency, or use a different strategy like mock . The trigger of this error is @sap/xssec 2.2.4 no longer requiring @sap/xsenv . Renovated and streamlined cds init . It prints a hint now if it's called with old-style parameters, as well as that it wants to be used from @sap/cds-dk . Check out cds help init for more. Removed the experimental --args parameter of cds compile . This turned out to be cumbersome to use in shells. Replacement is the standard configuration mechanism, e.g. use an environment variable CDS_FOO_BAR to activate option cds.foo.bar .","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_11","text":"SELECT.one/distinct(Fool,[...]) failed when passing an array for columns as argument two","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3201-2019-11-26","text":"","title":"Version 3.20.1 - 2019-11-26"},{"location":"apis/cds/CHANGELOG/#fixed_12","text":"Fix 'duplicate versions' errors by loading @sap/cds again from the current project if possible.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3200-2019-11-19","text":"","title":"Version 3.20.0 - 2019-11-19"},{"location":"apis/cds/CHANGELOG/#added_4","text":"Mention xsuaa in help of cds compile","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixed_13","text":"Typings for UPDATE function no longer contain duplicates.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see","text":"Changes of @sap/cds-compiler 1.20.3 Changes of @sap/cds-ql 1.21.0 Changes of @sap/cds-services 1.21.0 Changes of @sap/cds-messaging 1.4.0 Changes of @sap/generator-cds 2.10.2","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3184-2019-11-15","text":"","title":"Version 3.18.4 - 2019-11-15"},{"location":"apis/cds/CHANGELOG/#fixed_14","text":".cfignore files now get created by cds build/all to improve the overall deployment turnaround of cf push . Also, this avoids failures of CF node.js buildpack trying to rebuild sqlite binaries. Generated manifest.yaml files for Cloud Foundry now contain a path attribute that allows pushing from an outside folder. Also, they specify reduced memory requirements. Generated manifest.yaml for HDI deployer does not create a route, and specifies a valid health-check-type . cds deploy --to hana now also includes models in the srv folder. cds deploy no longer writes model folders to package.json that do not exist.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3190-2019-10-31","text":"","title":"Version 3.19.0 - 2019-10-31"},{"location":"apis/cds/CHANGELOG/#added_5","text":"Deployments for sqlite and SAP HANA now find CSV files in the form _texts_LOCALE.csv , like Books_texts_fr.csv . This file layout allows splitting translated texts into one file per language. Deployment for sqlite now also imports initial data from JSON files cds version has learned about @sap/cds-dk","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixed_15","text":"cds watch --help works again, if used from @sap/cds-dk","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3183-2019-10-28","text":"","title":"Version 3.18.3 - 2019-10-28"},{"location":"apis/cds/CHANGELOG/#fixed_16","text":"Fixed a crash in cds run --watch with changing directories. cds watch is now also found if called from an NPM script. cds watch now uses the same lookup paths for models as cds run","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3181-2019-10-17","text":"","title":"Version 3.18.1 - 2019-10-17"},{"location":"apis/cds/CHANGELOG/#fixed_17","text":"Fixed a crash during sqlite deployment if there were csv files that did not match an entity name cds deploy --to hana now does a build for SAP HANA even if no matching build task is available. cds deploy now tries to add .gitignore entries only once In @source annotations of csn.json files generated for cloud deployments, now posix file paths (with / ) are written, and no Windows paths. cds serve and run now shuts down gracefully in case of SIGHUP signals emitted by e.g. the VS Code terminal. cds watch now is found even if @sap/cds-dk is not installed locally.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_1","text":"Changes of @sap/cds-ql 1.19.2 Changes of @sap/cds-services 1.19.1 Changes of @sap/cds-messaging 1.2.1","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3180-2019-10-09","text":"","title":"Version 3.18.0 - 2019-10-09"},{"location":"apis/cds/CHANGELOG/#added_6","text":"Compiler options for SAP HANA backend can now be set in configuration in the cdsc.toHana block (e.g. cds.cdsc.toHana.joins ) service.tx() as a shortcut for service.transaction()","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixed_18","text":"cds deploy --to hana now adds the tunnel address to the JDBC URL Boolean and number values from default-env.json now are accepted in configuration ( cds env ) For applications deployed to Cloud Foundry, custom handlers are now properly resolved using their names. cds serve / run now properly log $batch requests of OData","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_2","text":"Changes of @sap/cds-compiler 1.19.1 Changes of @sap/cds-messaging 1.2.0 Changes of @sap/cds-ql 1.19.1 Changes of @sap/cds-reflect 2.8.0 Changes of @sap/cds-rest 1.2.0 Changes of @sap/cds-services 1.19.0 Changes of @sap/generator-cds 2.9.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3178-2019-09-25","text":"","title":"Version 3.17.8 - 2019-09-25"},{"location":"apis/cds/CHANGELOG/#fixed_19","text":"UPDATE(entity, key) statement","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3177-2019-09-24","text":"","title":"Version 3.17.7 - 2019-09-24"},{"location":"apis/cds/CHANGELOG/#fixed_20","text":"cds deploy","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3176-2019-09-23","text":"","title":"Version 3.17.6 - 2019-09-23"},{"location":"apis/cds/CHANGELOG/#changed_5","text":"Improved cds env","title":"Changed"},{"location":"apis/cds/CHANGELOG/#version-3175-2019-09-20","text":"","title":"Version 3.17.5 - 2019-09-20"},{"location":"apis/cds/CHANGELOG/#fixed_21","text":"cds deploy did not work properly","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3174-2019-09-19","text":"","title":"Version 3.17.4 - 2019-09-19"},{"location":"apis/cds/CHANGELOG/#also-see_3","text":"Changes of @sap/cds-rest 1.1.2","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3173-2019-09-19","text":"","title":"Version 3.17.3 - 2019-09-19"},{"location":"apis/cds/CHANGELOG/#fixed_22","text":"cds deploy --to hana","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3172-2019-09-19","text":"","title":"Version 3.17.2 - 2019-09-19"},{"location":"apis/cds/CHANGELOG/#also-see_4","text":"Changes of @sap/cds-services 1.18.2 Changes of @sap/generator-cds 2.8.2","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3171-2019-09-18","text":"","title":"Version 3.17.1 - 2019-09-18"},{"location":"apis/cds/CHANGELOG/#also-see_5","text":"Changes of @sap/cds-compiler 1.18.2 Changes of @sap/cds-ql 1.18.2 Changes of @sap/cds-services 1.18.1","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3170-2019-09-10","text":"","title":"Version 3.17.0 - 2019-09-10"},{"location":"apis/cds/CHANGELOG/#added_7","text":"cds run has learned a new --watch option, which provides automatic restarts of the server on file changes. nodemon package is required for this to work.","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixed_23","text":"cds deploy now writes true and false values in csv files as boolean to sqlite Console output of cds run now waits until the server is really up and running before it declares success. cds deploy and build/all do not write hdbtabledata files if some are already present.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_6","text":"Changes of @sap/cds-compiler 1.18.1 Changes of @sap/cds-ql 1.18.1 Changes of @sap/cds-reflect 2.7.1 Changes of @sap/cds-services 1.18.0 Changes of @sap/generator-cds 2.8.1","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3162-2019-08-27","text":"","title":"Version 3.16.2 - 2019-08-27"},{"location":"apis/cds/CHANGELOG/#also-see_7","text":"Changes of @sap/cds-compiler 1.17.1","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3160-2019-08-22","text":"","title":"Version 3.16.0 - 2019-08-22"},{"location":"apis/cds/CHANGELOG/#added_8","text":"cds run has learned a new --in-memory option, which connects and deploys to an SQLite in-memory database. There is no need to call cds deploy before. cds deploy --to hana now can also be executed in Java projects cds run 's index.html got a favicon, to give a visual clue in browsers. cds.requires.<datasource>.model configuration can now also point to a node.js module, e.g. @my/module . Previously, only a relative file path was supported. Improved logging of query objects cds compile now understands --to edmx-v2 and --to edmx-v4 to produce OData metadata of versions 2 or 4, respectively.","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_6","text":"Fiori preview in cds run now is only added if OData services are being served. For other protocols like rest , no Fiori preview is provided. Same holds true for the $metadata link. cds compile now behaves better in non-TTY scenarios (e.g. when piping to files). It writes a proper JSON string instead of a Javascript object. Previously, one had to enforce JSON using the --to json processor. Compare e.g. the output of cds compile model.cds to cds compile model.cds > model.json .","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_24","text":"Fiori preview in cds run now also works for services with namespaces In services of CF marketplace, cds deploy --to hana now only accepts services with plan hdi-shared . Previously, it could get confused with services of type hana but of other (non-HDI) plans. Localized edmx files are now produced also for i18n.json files.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_8","text":"Changes of @sap/cds-compiler 1.17.0 Changes of @sap/cds-ql 1.17.0 Changes of @sap/cds-services 1.17.0 Changes of @sap/generator-cds 2.7.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3150-2019-07-26","text":"","title":"Version 3.15.0 - 2019-07-26"},{"location":"apis/cds/CHANGELOG/#added_9","text":"hdbtabledata files are now generated automatically as part of cds deploy --to hana for given set of CSV files. CSV file names must follow the pattern <namespace>-entity.csv (same as for SQLite deployment) and be located in db/csv or db/data . For Node.js, multiple configuration profiles can now be activated at the same time, e.g. by setting both NODE_ENV and CDS_ENV , or by setting a multi-value list: CDS_ENV=profile1,profile2 . New labels for sap.common.*.code and sap.common.Currencies.symbol (part of @sap/cds/common ). Better message for Duplicate definition errors, where the same cds file is referenced from different locations. To fix this, check all dependencies to @sap/cds in your package.json and those of reused packages and ensure they allow deduped use of @sap/cds .","title":"Added"},{"location":"apis/cds/CHANGELOG/#also-see_9","text":"Changes of @sap/cds-compiler 1.16.1 Changes of @sap/cds-ql 1.16.0 Changes of @sap/cds-services 1.16.0 Changes of @sap/generator-cds 2.6.1","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3140-2019-07-11","text":"","title":"Version 3.14.0 - 2019-07-11"},{"location":"apis/cds/CHANGELOG/#added_10","text":"Support for SELECT.distinct.from(Foo) and SELECT.one.from(Foo) queries in Node.js [Beta] cds deploy --to hana deploys to SAP HANA on Cloud Foundry For Node.js, cds env now activates the development profile automatically, unless CDS_ENV or NODE_ENV are set. This is in line with NODE_ENV defaulting to development .","title":"Added"},{"location":"apis/cds/CHANGELOG/#also-see_10","text":"Changes of @sap/cds-ql 1.15.0 Changes of @sap/cds-services 1.15.0 Changes of @sap/generator-cds 2.5.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3130-2019-06-26","text":"","title":"Version 3.13.0 - 2019-06-26"},{"location":"apis/cds/CHANGELOG/#added_11","text":"cds serve now provides a preview of the services in a list page of SAP Fiori Elements","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_7","text":"cds serve now yields an error if there are no services defined in the model","title":"Changed"},{"location":"apis/cds/CHANGELOG/#also-see_11","text":"Changes of @sap/cds-compiler 1.15.0 Changes of @sap/cds-ql 1.14.0 Changes of @sap/cds-services 1.14.0 Changes of @sap/generator-cds 2.4.11","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3120-2019-06-17","text":"","title":"Version 3.12.0 - 2019-06-17"},{"location":"apis/cds/CHANGELOG/#added_12","text":"On request, cds build/all now generates OData EDMX files for node.js services Performance optimizations for cds build/all","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixed_25","text":"cds deploy no longer fails if data dir is not present cds build/all no longer prints a message if mta.yaml does not exist","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_12","text":"Changes of @sap/cds-compiler 1.14.1 Changes of @sap/cds-ql 1.13.0 Changes of @sap/cds-services 1.13.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3111-2019-06-03","text":"","title":"Version 3.11.1 - 2019-06-03"},{"location":"apis/cds/CHANGELOG/#fixed_26","text":"cds deploy honors saved datasource configuration again localization works again for sqlite datasources defined in package.json","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-3110-2019-06-03","text":"","title":"Version 3.11.0 - 2019-06-03"},{"location":"apis/cds/CHANGELOG/#added_13","text":"cds deploy now also finds .csv files in imported reuse packages Better error messages for various cds CLI calls","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_8","text":"cds build/all for Node.js projects generates proper CSN in gen/csn.json . A warning is emitted if cds serve is run with the previous format. Rebuild the project if you see this warning.","title":"Changed"},{"location":"apis/cds/CHANGELOG/#also-see_13","text":"Changes of @sap/cds-compiler 1.14.0 Changes of @sap/cds-ql 1.12.0 Changes of @sap/cds-services 1.12.0 Changes of @sap/generator-cds 2.4.10","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-3100-2019-05-21","text":"","title":"Version 3.10.0 - 2019-05-21"},{"location":"apis/cds/CHANGELOG/#added_14","text":"Tables and view for localized entities are created by default now, both for HANA and SQLite. Internal errors are now marked as such in all CLI commands, with a request to report them.","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_9","text":"cds compile --service all no longer fails in case no services are found. This better matches higher level commands like cds build that should not fail in this instance. Note that --service Foo fails as before in case Foo is not found. cds run and cds serve now serve the generic index page at / , while previously this was /$index . cds build/all now auto-creates build tasks from mta.yaml definition if no build tasks have been defined in .cdsrc.json . If no mta.yaml file exists, cds configuration data respectively defaults are used for build task configuration.","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_27","text":"CLI now shows compilation warnings in all commands, e.g. in build , deploy , or compile . Previously warnings were only shown in case of compilation errors. cds help no longer inserts terminal escape sequences if stdout is redirected to a file. Errors in custom handlers are no longer shadowed in cds serve or cds run .","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_14","text":"Changes of @sap/cds-compiler 1.13.4 Changes of @sap/cds-ql 1.11.1 Changes of @sap/cds-reflect 2.5.0 Changes of @sap/cds-services 1.11.1 Changes of @sap/generator-cds 2.4.8","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-390-2019-05-08","text":"","title":"Version 3.9.0 - 2019-05-08"},{"location":"apis/cds/CHANGELOG/#added_15","text":"cds.serve now reads passport for services from auth.passport configuration property","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixed_28","text":"cds.compile now really skips entities marked with if-unused Build tasks are now listed with cds env cds serve now supports the --at , --to , and --with arguments as specified. cds deploy --to sqlite now better handles csv files with empty values","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_15","text":"Changes of @sap/cds-compiler 1.12.0 Changes of @sap/cds-ql 1.10.2 Changes of @sap/cds-reflect 2.5.0 Changes of @sap/cds-services 1.10.2 Changes of @sap/generator-cds 2.4.6","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-381-2019-04-30","text":"","title":"Version 3.8.1 - 2019-04-30"},{"location":"apis/cds/CHANGELOG/#fixed_29","text":"Texts in deep annotations, e.g. @UI.Facet , are now properly localized in OData metadata","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-380-2019-04-09","text":"","title":"Version 3.8.0 - 2019-04-09"},{"location":"apis/cds/CHANGELOG/#fixed_30","text":"Make tests run on Windows again Various fixes in cds build/all Adjustments to latest compiler for localizing models .hdbcds and .hdbtabledata files are now copied over in cds build/all","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_16","text":"Changes of @sap/cds-compiler 1.11.0 Changes of @sap/cds-ql 1.8.1 Changes of @sap/cds-services 1.8.1 Changes of @sap/generator-cds 2.4.4","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-371-2019-03-25","text":"","title":"Version 3.7.1 - 2019-03-25"},{"location":"apis/cds/CHANGELOG/#fixed_31","text":"cds serve now honors newCsn configuration when serving from precompiled csn.json files. cds init creates samples correctly when project already contains files. cds build for node.js projects will now show up compilation errors. Formatting has been improved as well. Better support for finding cds executable in VSCode.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_17","text":"Changes of @sap/cds-compiler 1.10.0 Changes of @sap/cds-ql 1.7.1 Changes of @sap/cds-services 1.7.2 Changes of @sap/generator-cds 2.4.4","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-360-2019-02-27","text":"","title":"Version 3.6.0 - 2019-02-27"},{"location":"apis/cds/CHANGELOG/#added_16","text":"In cds init : Add modules via cds init --modules to an existing project. Do not allow project creation via cds init outside of current working folder, e.g. init ../../some/where/else is not allowed. No output at all (not even error messages) when using cds init --quiet . Create a module folder using cds init --modules... even if it is empty based on the supplied options. Parameter --modules only supports one folder of each type. Alpha support for @cds.odata.valuelist : Adding @cds.odata.valuelist to @cds.autoexposed entities will automatically equip all associations referring to such entities with a corresponding @Common.ValueList.entity","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_10","text":"Simplified code lists: removed superfluous types LanguageCode , CountryCode , and CurrencyCode from @sap/cds/common cds build/all now does --clean by default and is less verbose in its output","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_32","text":"cds.load no longer fails if reading in a CSN file in version 0.1.0","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_18","text":"Changes of @sap/cds-compiler 1.9.0 Changes of @sap/cds-reflect 2.4.0 Changes of @sap/cds-ql 1.6.0 Changes of @sap/cds-services 1.6.0 Changes of @sap/generator-cds 2.4.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-352-2019-02-20","text":"","title":"Version 3.5.2 - 2019-02-20"},{"location":"apis/cds/CHANGELOG/#fixed_33","text":"Node.js projects created with cds init now Bind the service module to an HDI service in mta.yaml . Invoke CDS build when building the database module. No longer create old-style service configuration in package.json . For datasources with kind hana we now also find hanatrial services in trial landscapes by matching their tag hana .","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#version-351-2019-02-14","text":"","title":"Version 3.5.1 - 2019-02-14"},{"location":"apis/cds/CHANGELOG/#fixed_34","text":"In cds serve service providers where added twice to the express app. This is fixed. In the logs of cds serve false warnings on fiori requests are now gone. cds serve no longer fails on localization for unbound actions. The project template was fixed to properly wire up the connection to SAP HANA.","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_19","text":"Changes of @sap/cds-compiler 1.8.1 Changes of @sap/cds-ql 1.5.1 Changes of @sap/cds-services 1.5.2 Changes of @sap/generator-cds 2.3.7","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-350-2019-02-07","text":"","title":"Version 3.5.0 - 2019-02-07"},{"location":"apis/cds/CHANGELOG/#added_17","text":"cds compile -2 xsuaa now generates default values for xsappname and tenant-mode All commands now can be called with --help , where previously only cds help <command> was allowed.","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_11","text":"The minimum required Node.js version is now set more specifically to 8.9 LTS. Previously, just Node.js 8 was mentioned. The cds build/all (experimental build command for Node.js) emits a warning for existing projects to add build task configuration. Watch out for such a warning in the console and follow its instructions.","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_35","text":"Service handlers are now also found on CF if CDS models are served from a csn.json file instead as from .cds sources. An issue where projects w/o db dir could not be built using cds build . Unclear documentation of cds deploy on where it looks up the data source. cds env to load configuration profiles in lower-prio files ( .cdsrc.json ) with higher precedence than default configuration in higher-prio files ( package.json ).","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_20","text":"Changes of @sap/cds-compiler 1.8.0 Changes of @sap/cds-reflect 2.3.0 Changes of @sap/cds-ql 1.5.0 Changes of @sap/cds-services 1.5.0 Changes of @sap/generator-cds 2.3.6","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-341-2019-01-24","text":"","title":"Version 3.4.1 - 2019-01-24"},{"location":"apis/cds/CHANGELOG/#fixed_36","text":"Restore cds-compiler .version","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_21","text":"Changes of @sap/cds-compiler 1.7.1 Changes of @sap/cds-reflect 2.2.1 Changes of @sap/cds-ql 1.4.0 Changes of @sap/cds-services 1.4.0 Changes of @sap/generator-cds 2.2.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-340-2019-01-22","text":"","title":"Version 3.4.0 - 2019-01-22"},{"location":"apis/cds/CHANGELOG/#added_18","text":"cds.env supports loading from default-env.json Support base models for cds compile -2 xsuaa","title":"Added"},{"location":"apis/cds/CHANGELOG/#also-see_22","text":"Changes of @sap/cds-compiler 1.7.0 Changes of @sap/cds-reflect 2.2.0 Changes of @sap/cds-ql 1.4.0 Changes of @sap/cds-services 1.4.0 Changes of @sap/generator-cds 2.2.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-330-2019-01-11","text":"","title":"Version 3.3.0 - 2019-01-11"},{"location":"apis/cds/CHANGELOG/#also-see_23","text":"Changes of @sap/cds-compiler 1.6.0 Changes of @sap/cds-reflect 2.1.0 Changes of @sap/cds-ql 1.3.0 Changes of @sap/cds-services 1.3.0 Changes of @sap/generator-cds 2.2.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-320-2018-12-21","text":"","title":"Version 3.2.0 - 2018-12-21"},{"location":"apis/cds/CHANGELOG/#changed_12","text":"cdsc 2sql output may also contain .types Add labels to CodeLists in common.cds Improved cds error messages","title":"Changed"},{"location":"apis/cds/CHANGELOG/#also-see_24","text":"Changes of @sap/cds-compiler 1.6.0 Changes of @sap/cds-reflect 2.1.0 Changes of @sap/cds-ql 1.2.0 Changes of @sap/cds-services 1.2.0 Changes of @sap/generator-cds 2.2.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-311-2018-12-13","text":"","title":"Version 3.1.1 - 2018-12-13"},{"location":"apis/cds/CHANGELOG/#changed_13","text":"Better console output from cds compile","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixed_37","text":"cds.compile ignored configured odata.version","title":"Fixed"},{"location":"apis/cds/CHANGELOG/#also-see_25","text":"Changes of @sap/cds-compiler 1.6.0 Changes of @sap/cds-reflect 2.1.0 Changes of @sap/cds-ql 1.1.0 Changes of @sap/cds-services 1.1.0 Changes of @sap/generator-cds 2.2.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-300","text":"","title":"Version 3.0.0"},{"location":"apis/cds/CHANGELOG/#changed_14","text":"Reworked configuration options to center around required 'data sources'. As an example see the snippted that e.g. cds deploy --to sqlite:my.db generates into package.json . The former cds options from package.json are deprectated but still supported. Clean up of many Node.js APIs, mainly for cds.serve and cds.connect . See the Javacript APIs documentation for details. Node.js 8 is now the minimum required runtime version. Simplified cds init . By default it creates a plain project suitable for local CDS development.","title":"Changed"},{"location":"apis/cds/CHANGELOG/#added_19","text":"cds env allows for inspecting the effective configuration","title":"Added"},{"location":"apis/cds/CHANGELOG/#also-see_26","text":"Changes of @sap/cds-compiler 1.5.0 Changes of @sap/cds-reflect 2.0.0 Changes of @sap/cds-ql 1.0.0 Changes of @sap/cds-services 1.0.0 Changes of @sap/generator-cds 2.0.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-2112","text":"","title":"Version 2.11.2"},{"location":"apis/cds/CHANGELOG/#fixes","text":"During cds init/new only install @sap/generator-cds 1.x","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#version-2110","text":"","title":"Version 2.11.0"},{"location":"apis/cds/CHANGELOG/#added_20","text":"Reuse aspect cuid to @sap/cds/common Support for smart to-many Associations finding backlinks automatically (\u2192not for production!) Support to fill DBs with initial data from CSV files (fetched from folder db/csv/ ) New CLI command cds run - today a mere wrapper for cds serve all but meant to serve microservice test scenarios cds deploy can be configured not to modify package.json through the --no-save option.","title":"Added"},{"location":"apis/cds/CHANGELOG/#also-see_27","text":"Changes of @sap/cds-compiler 1.2.0 Changes of @sap/cds-reflect 1.8.0 Changes of @sap/cds-ql 0.12.0 Changes of @sap/cds-services 0.12.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-2103","text":"","title":"Version 2.10.3"},{"location":"apis/cds/CHANGELOG/#fixes_1","text":"During cds init/new only install @sap/generator-cds 1.x","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#version-2100","text":"","title":"Version 2.10.0"},{"location":"apis/cds/CHANGELOG/#added_21","text":"Support for Fiori Draft","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixes_2","text":"Enhanced server.js to also include links to entities","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_28","text":"Changes of @sap/cds-compiler 1.1.3 Changes of @sap/cds-reflect 1.7.0 Changes of @sap/cds-ql 0.11.0 Changes of @sap/cds-services 0.11.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-291","text":"","title":"Version 2.9.1"},{"location":"apis/cds/CHANGELOG/#fixes_3","text":"cds build no longer blocks if running inside a Maven build.","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#version-290","text":"","title":"Version 2.9.0"},{"location":"apis/cds/CHANGELOG/#added_22","text":"common.cds model got annotations for title, description, and value lists. cds executable now can read from stdin, e.g. echo 'entity Foo {ID:UUID;}' | cds -2 sql cds -2 sql now outputs plain (non-HANA) SQL. Use -2 hana for HANA SQL. cds config shows the current CDS configuration. Use cds help config to learn more.","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixes_4","text":"Entities from common.cds like Languages , Countries , and Currencies are now only persisted to the database if they are actually used.","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_29","text":"Changes of @sap/cds-compiler 1.1.2 Changes of @sap/cds-reflect 1.6.0 Changes of @sap/cds-ql 0.10.0 Changes of @sap/cds-services 0.10.1","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-280","text":"","title":"Version 2.8.0"},{"location":"apis/cds/CHANGELOG/#added_23","text":"Support was added to build node.js service modules cds init has been reimplemented with a better commandline experience, along with updated templates. Plugin @sap/generator-cds , which is required for cds init , is now automatically installed when init is called for the first time. cds new is still available and is now just a synonym for init .","title":"Added"},{"location":"apis/cds/CHANGELOG/#also-see_30","text":"Changes of @sap/cds-compiler 1.1.1 Changes of @sap/cds-services 0.9.0 Changes of @sap/cds-ql 0.9.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-270","text":"","title":"Version 2.7.0"},{"location":"apis/cds/CHANGELOG/#also-see_31","text":"Changes of @sap/cds-compiler 1.0.32 Changes of @sap/cds-services 0.8.1 Changes of @sap/cds-ql 0.8.1","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-260","text":"","title":"Version 2.6.0"},{"location":"apis/cds/CHANGELOG/#also-see_32","text":"Changes of @sap/cds-compiler 1.0.31 Changes of @sap/cds-services 0.7.0 Changes of @sap/cds-ql 0.7.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-251","text":"","title":"Version 2.5.1"},{"location":"apis/cds/CHANGELOG/#also-see_33","text":"Changes of @sap/cds-services 0.6.0 Changes of @sap/cds-ql 0.6.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-250","text":"","title":"Version 2.5.0"},{"location":"apis/cds/CHANGELOG/#added_24","text":"Instead of compiling each .cds service file separately, cds build now combines all those files from the same folder, creating only one csn.json file for them.","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixes_5","text":"Shortcuts of cds init work again","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_34","text":"Changes of @sap/cds-compiler 1.0.30 Changes of @sap/cds-services 0.5.0 Changes of @sap/cds-ql 0.5.0","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-242","text":"Same as version 2.3.2, but including the generic service provider for Node.js ( @sap/cds-services and @sap/cds-ql ).","title":"Version 2.4.2"},{"location":"apis/cds/CHANGELOG/#version-232","text":"","title":"Version 2.3.2"},{"location":"apis/cds/CHANGELOG/#changed_15","text":"The default for SQL name mapping is changed to plain . This means that The name of a table/view in the database catalog is obtained from the name of the corresponding entity in the CDS model in the following way: replace all \".\" by \"_\" convert everything to upper case The name of a table/view column in the database catalog is obtained from the name of the corresponding entity element in the csn in the following way: convert everything to upper case Note that this is a breaking change for appliations that rely on the previous value of quoted . In order to get this value back, add the following to package.json : \"cds\": { \"data\": { \"sql_mapping\" : \"quoted\" } }","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixes_6","text":"Special output formatting in CLI is only done for cds eval and cds repl , but not for programmatic usage. Links to external documentation are now point to correct help documents.","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_35","text":"Changes of @sap/cds-compiler 1.0.30","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-230","text":"","title":"Version 2.3.0"},{"location":"apis/cds/CHANGELOG/#added_25","text":"SQL names can now be configured with { data: {sql_mapping: \"plain/quoted\"} } . Default is quoted , but will be changed to plain soon. If you need to stay with quoted in the futute, e.g. due to data compatibility reasons, you can configure this mode already now.","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixes_7","text":"The csn.json file produced by cds build now contains the properly unfolded model for OData. Previously this was the normalized model, which led to runtime errors in the Java service provider. Invalid configuration data in package.json now leads to a build error again. Console output of cds build now presents files paths sorted.","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_36","text":"Changes of CDS compiler 1.0.27","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-220","text":"","title":"Version 2.2.0"},{"location":"apis/cds/CHANGELOG/#added_26","text":"CDS configuration in package.json can now be omitted if you follow the standard project layout, i.e. if you place your model files in db/ , srv/ , and app/ folders.","title":"Added"},{"location":"apis/cds/CHANGELOG/#changed_16","text":"Previously data models needed to include import statements to the service models (e.g. using from '../srv' ), so that the Java runtime could use these service views on the DB to execute queries. The views are now included automatically, so that you can remove the explict using clauses. Calling just cds on the command line now prints its help. The previously started REPL is now available with cds repl (or just cds r ).","title":"Changed"},{"location":"apis/cds/CHANGELOG/#fixes_8","text":"Some cds commands failed on Windows. This is fixed.","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_37","text":"Changes of CDS compiler 1.0.24","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-210","text":"","title":"Version 2.1.0"},{"location":"apis/cds/CHANGELOG/#added_27","text":"Service edmx files are now written to UI app folders if their manifest.json contains a reference to the service. This allows Web IDE's annotation modeler to work on up to date service files. The results of cds.compile.to... commands are now automatically formatted if called in cds -e... or cds repl. You don't need to append console.log to the call chain.","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixes_9","text":"Language properties are now found in all folders, also ones that are outside of the current module csn.json is written with line breaks and indentation","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_38","text":"Changes of CDS compiler 1.0.21","title":"Also see"},{"location":"apis/cds/CHANGELOG/#version-200","text":"","title":"Version 2.0.0"},{"location":"apis/cds/CHANGELOG/#added_28","text":"All-new command-line interface. See cds help for information on the available commands. cds compile exposes CDS model transformations with various options. cds build automatically writes localized edmx files. cds build now writes the version to the build log. cds version does the usual thing. cds init scaffolds CDS projects. CDS repl (read-eval-print-loop): just type cds and play with CDS API.","title":"Added"},{"location":"apis/cds/CHANGELOG/#fixes_10","text":"Too many to mention :)","title":"Fixes"},{"location":"apis/cds/CHANGELOG/#also-see_39","text":"Changes of CDS compiler 1.0.19","title":"Also see"},{"location":"apis/cds-compiler/","text":"Getting started \u00b6 Table of Contents \u00b6 Installation and Usage Command invocation Build from source Documentation Installation and Usage \u00b6 Install via npm: npm install \"@sap/cds-compiler\" Or maintain your package.json dependencies as follows: \"dependencies\": { \"@sap/cds-compiler\": \"latest\" } Command Invocation \u00b6 The compiler with its options is invoked like any other npm/Unix command: cdsc <command> [ options ] <file...> See cdsc --help for commands and options. The exit code of the process is: 0 : successful compilation 1 : compiled with error (the command invocation itself is ok) 2 : commmand invocation error (invalid options, repeated file name) Build from source \u00b6 We recommend to install cds-compiler using npm. However, if you want to use the latest master (e.g. for testing purposes) then you need to set up the compiler first: git clone git@github.wdf.sap.corp:cdx/cds-compiler.git cd cds-compiler npm install npm run download # Downloads Antlr (Java Dependency) npm run gen # Generates the parser ./bin/cdsc.js --help Documentation \u00b6 Please refer to the official CDS documentation .","title":"Getting started"},{"location":"apis/cds-compiler/#getting-started","text":"","title":"Getting started"},{"location":"apis/cds-compiler/#table-of-contents","text":"Installation and Usage Command invocation Build from source Documentation","title":"Table of Contents"},{"location":"apis/cds-compiler/#installation-and-usage","text":"Install via npm: npm install \"@sap/cds-compiler\" Or maintain your package.json dependencies as follows: \"dependencies\": { \"@sap/cds-compiler\": \"latest\" }","title":"Installation and Usage"},{"location":"apis/cds-compiler/#command-invocation","text":"The compiler with its options is invoked like any other npm/Unix command: cdsc <command> [ options ] <file...> See cdsc --help for commands and options. The exit code of the process is: 0 : successful compilation 1 : compiled with error (the command invocation itself is ok) 2 : commmand invocation error (invalid options, repeated file name)","title":"Command Invocation"},{"location":"apis/cds-compiler/#build-from-source","text":"We recommend to install cds-compiler using npm. However, if you want to use the latest master (e.g. for testing purposes) then you need to set up the compiler first: git clone git@github.wdf.sap.corp:cdx/cds-compiler.git cd cds-compiler npm install npm run download # Downloads Antlr (Java Dependency) npm run gen # Generates the parser ./bin/cdsc.js --help","title":"Build from source"},{"location":"apis/cds-compiler/#documentation","text":"Please refer to the official CDS documentation .","title":"Documentation"},{"location":"apis/cds-compiler/CHANGELOG/","text":"ChangeLog for cdx compiler and backends \u00b6 Note: beta fixes, changes and features are usually not listed in this ChangeLog. The compiler behaviour concerning beta features can change at any time without notice. Version 1.26.2 - 2020-04-24 \u00b6 Added \u00b6 The client tool cdsc has got a new option --beta <list> which may be used to specify a comma separated list of experimental features to be enabled. CSN in parse-cdl mode now has a requires property that represents using s from CDL. Fixed \u00b6 OData: Change foreign key creation order for associations to respect their dependencies. Use correct path during on-condition flattening. Report error when using elements without types for array of type of (element) and similar definitions. HANA/SQL: Fix references to null enum values in default clauses. Type arguments are now properly set in CSN when using parse-cdl mode. Avoid unjust warning if the extensions property of an input CSN contain extend statements. Version 1.26.0 - 2020-04-17 \u00b6 Added \u00b6 The client tool cdsc has got a new command parseCdl which returns a CSN that is close to the original CDL file. It does not resolve imports and does not apply extensions. Unmanaged associations as primary keys are now warned about. localized in combination with key is now warned about. Enum values are now checked to only be either numbers or a strings - a warning is raised. Elements in mixin clauses that are not unmanaged associations now produce an error. Changed \u00b6 HANA/SQL: Raise warnings rewrite-not-supported and rewrite-undefined-key to errors. Compiler: Empty elements are now kept along for the propagation. OData: Annotate all elements of DraftAdministrativeData with @Common.Label: '{i18n>\"Draft_<elementName>\"}' and elements 'DraftUUID', 'DraftIsCreatedByMe' and 'DraftIsProcessedByMe' with @UI.Hidden . Fixed \u00b6 Compiler: type of <unmanaged assocation> is now handled correctly by raising an error. Version 1.25.0 - 2020-04-09 \u00b6 Changed \u00b6 Downgrade chained array of -error to a warning SQLite: Don't render implicit casts Version 1.24.6 - 2020-04-08 \u00b6 Changed \u00b6 OData: Improve messages for misaligned forward/backlink associations in EDM generator For V2 add annotations @sap.creatable: false , @sap.updatable: false , @sap.deletable: false , @sap.pageable: false to the Parameter EntityType and @sap.creatable: false , @sap.updatable: false , @sap.deletable: false , @sap.addressable: false to the Result EntityType. Update vocabularies 'Common' and 'Graph' and 'ODM'. Fixed \u00b6 Various messages mention more appropriate source locations. Improve messages for array of OData: Render 'array of' for ReturnType correctly Report error for view fields with no type information early Handle associations in structures with an association as explicit key Removed \u00b6 The client tool cdsc does not offer the option --std-json-parser anymore, as it had no effect. Version 1.24.4 - 2020-03-25 \u00b6 Added \u00b6 Changed \u00b6 doc comment propagation can now also be stopped by comments that only contain whitespace (including newlines) like /** */ . OData: Remove redundant service name and __ prefix out of dynamically exposed substructures. Update vocabularies 'Capabilities' and 'Graph'. Fixed \u00b6 OData: Process correctly \"type of\". Process correctly elements with underscore as prefix. Preserve parameter list in localized convenience views. Version 1.24.3 - 2020-03-16 \u00b6 Added \u00b6 Changed \u00b6 Fixed \u00b6 Force usage of resolve@1.8.1 instead of semver to avoid issues with file cache Version 1.24.2 - 2020-03-13 \u00b6 Added \u00b6 Support function calls like count( distinct ... ) and count( all ... ) . With option --doc-comment comments of the form /**...*/ are preserved, if these comments appear at positions where annotation assignments are allowed. doc comments are propagated like annotations until an empty comment /***/ disrupts the propagation. OData: Add new OData vocabularies com.sap.vocabularies.Graph.v1 and com.sap.vocabularies.ODM.v1 With option --odata-containment , parent association and inferred key elements for composition of <aspect> as well as inferred keys of _texts entities are not rendered. OData V4: Produce primary key paths with length limited alias names. Changed \u00b6 Fixed \u00b6 When not disabled by @cds.autoexpose:false , an entity used as composition target is auto-exposed in the current service; this did not work always if the target was a query entity. Foreign key creation in odata flat-mode when following associations. Rename @description to @Core.Description in all cases as part of the OData transformation of a CSN. When generating extensions from EDMX annotations, handle correctly targets from an EntityContainer. Apply service annotations in EDMX generation. Removed \u00b6 Warning 'Service should not have more then one draft root artifact' Experimental annotation '@cds.odata.{v2|v4}.ignore` OData vocabulary com.sap.vocabularies.odm.v1 (lowercase 'odm') --beta-mode from option --odata-containment . Version 1.24.1 - 2020-03-06 \u00b6 Added \u00b6 Add new OData vocabulary com.sap.vocabularies.odm.v1 Changed \u00b6 Expressions in mixin-definitions are now validated. OData: Redirect inbound associations to entities with parameters to corresponding Parameter EntityType. Update vocabulary UI Use semver for dependencies Fixed \u00b6 Resolve backlink mixin association usages uniformly in association to join translation. Version 1.24.0 - 2020-02-28 \u00b6 Added \u00b6 If an entity E with localized elements has the annotation @fiori.draft.enabled , a new element ID_texts of type cds.UUID is added to E_texts as the only key and the annotation @odata.draft.enabled will not be set to false for E.texts . A comment of the form /**\u2026*/ at \"annotation positions\" is now considered a doc comment; its \"cleaned-up\" text is put into the CSN as value of the property doc . In the OData/EDMX, it appears as value for the annotation @Core.Description . Fixed \u00b6 HANA CDS: When casting a column to an enum type, don't render it as an enum Ignore top-level CSN \"annotations\" like @sql_mapping in the CSN frontend. OData: Key constraint checks for Draft enabled entities consider EDM exposed keys only. Message level for draft key checks is raised to 'warning' again. Action and function calls are checked for missing arguments. All references are correctly transformed in flatten mode. Older Versions \u00b6 The change log for older entries can be found at doc/CHANGELOG_ARCHIVE.md .","title":"ChangeLog for cdx compiler and backends"},{"location":"apis/cds-compiler/CHANGELOG/#changelog-for-cdx-compiler-and-backends","text":"Note: beta fixes, changes and features are usually not listed in this ChangeLog. The compiler behaviour concerning beta features can change at any time without notice.","title":"ChangeLog for cdx compiler and backends"},{"location":"apis/cds-compiler/CHANGELOG/#version-1262-2020-04-24","text":"","title":"Version 1.26.2 - 2020-04-24"},{"location":"apis/cds-compiler/CHANGELOG/#added","text":"The client tool cdsc has got a new option --beta <list> which may be used to specify a comma separated list of experimental features to be enabled. CSN in parse-cdl mode now has a requires property that represents using s from CDL.","title":"Added"},{"location":"apis/cds-compiler/CHANGELOG/#fixed","text":"OData: Change foreign key creation order for associations to respect their dependencies. Use correct path during on-condition flattening. Report error when using elements without types for array of type of (element) and similar definitions. HANA/SQL: Fix references to null enum values in default clauses. Type arguments are now properly set in CSN when using parse-cdl mode. Avoid unjust warning if the extensions property of an input CSN contain extend statements.","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1260-2020-04-17","text":"","title":"Version 1.26.0 - 2020-04-17"},{"location":"apis/cds-compiler/CHANGELOG/#added_1","text":"The client tool cdsc has got a new command parseCdl which returns a CSN that is close to the original CDL file. It does not resolve imports and does not apply extensions. Unmanaged associations as primary keys are now warned about. localized in combination with key is now warned about. Enum values are now checked to only be either numbers or a strings - a warning is raised. Elements in mixin clauses that are not unmanaged associations now produce an error.","title":"Added"},{"location":"apis/cds-compiler/CHANGELOG/#changed","text":"HANA/SQL: Raise warnings rewrite-not-supported and rewrite-undefined-key to errors. Compiler: Empty elements are now kept along for the propagation. OData: Annotate all elements of DraftAdministrativeData with @Common.Label: '{i18n>\"Draft_<elementName>\"}' and elements 'DraftUUID', 'DraftIsCreatedByMe' and 'DraftIsProcessedByMe' with @UI.Hidden .","title":"Changed"},{"location":"apis/cds-compiler/CHANGELOG/#fixed_1","text":"Compiler: type of <unmanaged assocation> is now handled correctly by raising an error.","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1250-2020-04-09","text":"","title":"Version 1.25.0 - 2020-04-09"},{"location":"apis/cds-compiler/CHANGELOG/#changed_1","text":"Downgrade chained array of -error to a warning SQLite: Don't render implicit casts","title":"Changed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1246-2020-04-08","text":"","title":"Version 1.24.6 - 2020-04-08"},{"location":"apis/cds-compiler/CHANGELOG/#changed_2","text":"OData: Improve messages for misaligned forward/backlink associations in EDM generator For V2 add annotations @sap.creatable: false , @sap.updatable: false , @sap.deletable: false , @sap.pageable: false to the Parameter EntityType and @sap.creatable: false , @sap.updatable: false , @sap.deletable: false , @sap.addressable: false to the Result EntityType. Update vocabularies 'Common' and 'Graph' and 'ODM'.","title":"Changed"},{"location":"apis/cds-compiler/CHANGELOG/#fixed_2","text":"Various messages mention more appropriate source locations. Improve messages for array of OData: Render 'array of' for ReturnType correctly Report error for view fields with no type information early Handle associations in structures with an association as explicit key","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#removed","text":"The client tool cdsc does not offer the option --std-json-parser anymore, as it had no effect.","title":"Removed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1244-2020-03-25","text":"","title":"Version 1.24.4 - 2020-03-25"},{"location":"apis/cds-compiler/CHANGELOG/#added_2","text":"","title":"Added"},{"location":"apis/cds-compiler/CHANGELOG/#changed_3","text":"doc comment propagation can now also be stopped by comments that only contain whitespace (including newlines) like /** */ . OData: Remove redundant service name and __ prefix out of dynamically exposed substructures. Update vocabularies 'Capabilities' and 'Graph'.","title":"Changed"},{"location":"apis/cds-compiler/CHANGELOG/#fixed_3","text":"OData: Process correctly \"type of\". Process correctly elements with underscore as prefix. Preserve parameter list in localized convenience views.","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1243-2020-03-16","text":"","title":"Version 1.24.3 - 2020-03-16"},{"location":"apis/cds-compiler/CHANGELOG/#added_3","text":"","title":"Added"},{"location":"apis/cds-compiler/CHANGELOG/#changed_4","text":"","title":"Changed"},{"location":"apis/cds-compiler/CHANGELOG/#fixed_4","text":"Force usage of resolve@1.8.1 instead of semver to avoid issues with file cache","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1242-2020-03-13","text":"","title":"Version 1.24.2 - 2020-03-13"},{"location":"apis/cds-compiler/CHANGELOG/#added_4","text":"Support function calls like count( distinct ... ) and count( all ... ) . With option --doc-comment comments of the form /**...*/ are preserved, if these comments appear at positions where annotation assignments are allowed. doc comments are propagated like annotations until an empty comment /***/ disrupts the propagation. OData: Add new OData vocabularies com.sap.vocabularies.Graph.v1 and com.sap.vocabularies.ODM.v1 With option --odata-containment , parent association and inferred key elements for composition of <aspect> as well as inferred keys of _texts entities are not rendered. OData V4: Produce primary key paths with length limited alias names.","title":"Added"},{"location":"apis/cds-compiler/CHANGELOG/#changed_5","text":"","title":"Changed"},{"location":"apis/cds-compiler/CHANGELOG/#fixed_5","text":"When not disabled by @cds.autoexpose:false , an entity used as composition target is auto-exposed in the current service; this did not work always if the target was a query entity. Foreign key creation in odata flat-mode when following associations. Rename @description to @Core.Description in all cases as part of the OData transformation of a CSN. When generating extensions from EDMX annotations, handle correctly targets from an EntityContainer. Apply service annotations in EDMX generation.","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#removed_1","text":"Warning 'Service should not have more then one draft root artifact' Experimental annotation '@cds.odata.{v2|v4}.ignore` OData vocabulary com.sap.vocabularies.odm.v1 (lowercase 'odm') --beta-mode from option --odata-containment .","title":"Removed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1241-2020-03-06","text":"","title":"Version 1.24.1 - 2020-03-06"},{"location":"apis/cds-compiler/CHANGELOG/#added_5","text":"Add new OData vocabulary com.sap.vocabularies.odm.v1","title":"Added"},{"location":"apis/cds-compiler/CHANGELOG/#changed_6","text":"Expressions in mixin-definitions are now validated. OData: Redirect inbound associations to entities with parameters to corresponding Parameter EntityType. Update vocabulary UI Use semver for dependencies","title":"Changed"},{"location":"apis/cds-compiler/CHANGELOG/#fixed_6","text":"Resolve backlink mixin association usages uniformly in association to join translation.","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#version-1240-2020-02-28","text":"","title":"Version 1.24.0 - 2020-02-28"},{"location":"apis/cds-compiler/CHANGELOG/#added_6","text":"If an entity E with localized elements has the annotation @fiori.draft.enabled , a new element ID_texts of type cds.UUID is added to E_texts as the only key and the annotation @odata.draft.enabled will not be set to false for E.texts . A comment of the form /**\u2026*/ at \"annotation positions\" is now considered a doc comment; its \"cleaned-up\" text is put into the CSN as value of the property doc . In the OData/EDMX, it appears as value for the annotation @Core.Description .","title":"Added"},{"location":"apis/cds-compiler/CHANGELOG/#fixed_7","text":"HANA CDS: When casting a column to an enum type, don't render it as an enum Ignore top-level CSN \"annotations\" like @sql_mapping in the CSN frontend. OData: Key constraint checks for Draft enabled entities consider EDM exposed keys only. Message level for draft key checks is raised to 'warning' again. Action and function calls are checked for missing arguments. All references are correctly transformed in flatten mode.","title":"Fixed"},{"location":"apis/cds-compiler/CHANGELOG/#older-versions","text":"The change log for older entries can be found at doc/CHANGELOG_ARCHIVE.md .","title":"Older Versions"},{"location":"apis/cds-compiler/doc/ApiMigration/","text":"API Migration \u00b6 With revision 1.0.24, the CDS compiler offers new API backend functions, i.e. new functions for the generation of output from (augmented) CSN models. The new functions and their options are closely aligned with the new command line interface cdsc . The old backend functions are deprecated, will not be extended with new features, and will be removed in a subsequent release. Note that only these API functions from lib/main.js are supported - all internal functions are subject to change without notice . Please see the function headers in lib/backends.js for a description of the new API functions (for a snapshot of the current version, see below). Some helpful hints \u00b6 Please note the following general concepts regarding the new API functions: - The behavior of the compiler and of all backend API functions is controlled by a common options object, with subsections for each backend function, e.g. options: {toHana: {src: true}, toOdata: {version: 'v2'}} . - Options can either be specified with one of the compile functions (transported within the model to the backends), or explicitly at the invocation of a backend API function. - Options are merged, with precedence given to those specified explicitly at the backend API functions. - When invoking a backend function with options that all belong to this backend function, the subsection wrapper can be omitted, i.e. toHana(model, {toHana: {src: true}}) is equivalent to toHana(model, {src: true}) . - Most backend API functions have a combination of options controlling what is generated (e.g. toHana: {src: true} ) and options modifying how things are generated (e.g. toOdata: {version: 'v2'} ). Migration guide \u00b6 The following table shows replacements for the deprecated API functions (relying on default options where possible): Deprecated function call New function call toHanaCdl(model) toHana(model) forHana(model) toHana(model, {csn: true}) toOdataOutput(model, {oDataVersion: 'v2'} toOdata(model, {version: 'v2', xml: true, json: true, separate: true, combined: true, csn: true}) toSqlDdl(model) toSql(model) compactJson(model) toCsn(model) Changes in behavior \u00b6 The following changes have been made to the behavior of toOdata in comparison to toOdataOutput : - Output is now generated either for ODATA V2 or for V4. The old toOdataOutput function produced the annotations output with an extra invocation of the backend using oDataVersion: 'v4' even if the original invocation specified oDataVersion: 'v2' , resulting in slightly different output. The combined output always had the correct versioning. - The metadata_json output is now an object, not a string. Snapshot of backend API function documentation \u00b6 Note that these backend API functions are all exposed in lib/main.js (which is the only external API ), but their documentation is currently located in lib/backends.js (this will likely change). toHana(model, options) \u00b6 // Transform an augmented CSN 'model' into HANA-compatible CDS source. // The following options control what is actually generated: // options : { // toHana.names : either 'plain' (generate uppercased flattened entity names with // underscores) or 'quoted' (default, generate entity names with nested // contexts as in CDL) // toHana.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toHana.src : if true, generate HANA CDS source files (default) // toHana.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toHana.names' is not provided, 'quoted' is used. // If 'toHana.associations' is not provided, 'assocs' is used. // If neither 'toHana.src' nor 'toHana.csn' are provided, the default is to generate only HANA CDS // source files. // If all provided options are part of 'toHana', the 'toHana' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // hdbcds : a dictionary of top-level artifact names, containing for each name 'X': // <X> : the HANA CDS source string of the artifact 'X'. Please note that the // name of 'X' may contain characters that are not legal for filenames on // all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } function toHana(model, options) { ... } toOdata(model, options) \u00b6 // Generate ODATA for augmented CSN `model` using `options` . // Before anything is generated , the following transformations are applied to 'model' : // FIXME : Verify that this is still correct // - Flatten structured elements ( and foreign keys of managed associations pointing to // keys that are themselves managed associations ). // - Generate foreign key fields for entities with managed associations ( annotated with // '@odata.foreignKey4' ). Propagate along projections accordingly . Names are built using // < assoc > _ < key > , conflicts are checked . // - Complete the 'foreignKeys' property for all managed associations , so that there // is always a 'generatedFieldName' for the corresponding generated foreign key field . // - Implicitly redirect associations based on exposure // - Check that exposed associations do not point to non - exposed targets // - Unravel derived type chains , propagating annotations upwards . // - Rename annotations according to a fixed list of short - hands // The following options control what is actually generated : // options : { // toOdata . version : either 'v2' or 'v4' ( default ) // toOdata . xml : if true , generate XML output ( default ) // toOdata . json : if true , generate JSON output ( not available for ODATA V2 ) // toOdata . separate : if true , generate XML 'metadata' and XML 'annotations' separately // toOdata . combined : if true , generate XML metadata and XML annotations together as // 'combined' ( default ) // toOdata . csn : if true , generate the transformed CSN model // } // Options provided here are merged with ( and take precedence over ) options from 'model' . // If 'toOdata.version' is not provided , 'v4' is used . // If neither 'toOdata.xml' nor 'toOdata.json' nor 'toOdata.csn' are provided , the default is // to generate only XML output . If neither 'toOdata.separate' nor 'toOdata.combined' are provided , // the default is to generate only combined XML output . // If all provided options are part of 'toOdata' , the 'toOdata' wrapper can be omitted . // // The result object contains the generation results as follows ( as enabled in 'options' ): // result : { // csn : the ( compact ) transformed CSN model including all services // _augmentedCsn : ( subject to change ): the augmented CSN model including all services // services : a dictionary of service names , containing for each name : // < servicename > : { // annotations : an XML string with EDMX annotations for service 'svc' // metadata : an XML string with EDMX metadata for service 'svc' // combined : an XML string with both EDMX metadata and annotations for service 'svc' // metadata_json : a JSON object ( not a string ! ) with EDM metadata for service 'svc' // } // messages : an array of strings with warnings ( if any ) // } // If 'model' does not contain any services , 'csn' will still contain the transformed model , but // 'services' will be an empty dictionary . // // Throws a CompilationError on errors . function toOdata ( model , options ) { ... } toCdl(model, options) \u00b6 // Generate CDS source text for augmented CSN model 'model' . // The following options control what is actually generated : // options : { // FIXME : This option should be removed and something like 'toCdl.dialect: 'hana' be // used instead. // hanaFlavor : if true, HANA-specific source dialect is generated (affects e.g. the // translation of ' $ self . foo ' in paths and ::-ish namespace declarations ) // } // One source is created per top - level artifact . // Return a dictionary of top - level artifacts // by their names , like this : // { \"foo\" : \"using XY; context foo {...};\" , // \"bar::wiz\" : \"namespace bar::; entity wiz {...};\" // } // Throws a CompilationError on errors . function toCdl ( model , options ) { ... } toSwagger(model, options) \u00b6 // Generate OpenAPI JSON version 3 for the augmented CSN 'model'. // Return an object representing the Swagger JSON: // { // openapi: '3.0.0', // info: { ... }, // paths: { ...}, // components: { // schemas: { ... } // } // } // // Throws a CompilationError on errors. function toSwagger(model, options) { ... } toSql(model, options) \u00b6 // Generate SQL DDL statements for augmented CSN 'model'. // The following options control what is actually generated: // options : { // toSql.names : either 'plain' (generate uppercased flattened table/view names with // underscores) or 'quoted' (default, generate quoted table/view names // with dots as in CDL) // toSql.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toSql.src : if true, generate SQL DDL source files (default) // toSql.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toSql.names' is not provided, 'quoted' is used. // If 'toSql.associations' is not provided, 'assocs' is used. // If neither 'toSql.src' nor 'toSql.csn' are provided, the default is to generate only SQL DDL // source files. // If all provided options are part of 'toSql', the 'toSql' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // sql : a dictionary of top-level artifact names, containing for each name 'X': // <X> : a string with SQL DDL statements for artifact 'X', terminated with ';'. // Please note that the name of 'X' may contain characters that are not // legal for filenames on all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } // Throws a CompilationError on errors. toCsn(model, options) \u00b6 // Generate compact CSN for augmented CSN 'model' // The following options control what is actually generated: // options : { // testMode : if true, the result is extra-stable for automated tests (sorted, no 'version') // } // Options provided here are merged with (and take precedence over) options from 'model'. function toCsn(model, options) { ... }","title":"API Migration"},{"location":"apis/cds-compiler/doc/ApiMigration/#api-migration","text":"With revision 1.0.24, the CDS compiler offers new API backend functions, i.e. new functions for the generation of output from (augmented) CSN models. The new functions and their options are closely aligned with the new command line interface cdsc . The old backend functions are deprecated, will not be extended with new features, and will be removed in a subsequent release. Note that only these API functions from lib/main.js are supported - all internal functions are subject to change without notice . Please see the function headers in lib/backends.js for a description of the new API functions (for a snapshot of the current version, see below).","title":"API Migration"},{"location":"apis/cds-compiler/doc/ApiMigration/#some-helpful-hints","text":"Please note the following general concepts regarding the new API functions: - The behavior of the compiler and of all backend API functions is controlled by a common options object, with subsections for each backend function, e.g. options: {toHana: {src: true}, toOdata: {version: 'v2'}} . - Options can either be specified with one of the compile functions (transported within the model to the backends), or explicitly at the invocation of a backend API function. - Options are merged, with precedence given to those specified explicitly at the backend API functions. - When invoking a backend function with options that all belong to this backend function, the subsection wrapper can be omitted, i.e. toHana(model, {toHana: {src: true}}) is equivalent to toHana(model, {src: true}) . - Most backend API functions have a combination of options controlling what is generated (e.g. toHana: {src: true} ) and options modifying how things are generated (e.g. toOdata: {version: 'v2'} ).","title":"Some helpful hints"},{"location":"apis/cds-compiler/doc/ApiMigration/#migration-guide","text":"The following table shows replacements for the deprecated API functions (relying on default options where possible): Deprecated function call New function call toHanaCdl(model) toHana(model) forHana(model) toHana(model, {csn: true}) toOdataOutput(model, {oDataVersion: 'v2'} toOdata(model, {version: 'v2', xml: true, json: true, separate: true, combined: true, csn: true}) toSqlDdl(model) toSql(model) compactJson(model) toCsn(model)","title":"Migration guide"},{"location":"apis/cds-compiler/doc/ApiMigration/#changes-in-behavior","text":"The following changes have been made to the behavior of toOdata in comparison to toOdataOutput : - Output is now generated either for ODATA V2 or for V4. The old toOdataOutput function produced the annotations output with an extra invocation of the backend using oDataVersion: 'v4' even if the original invocation specified oDataVersion: 'v2' , resulting in slightly different output. The combined output always had the correct versioning. - The metadata_json output is now an object, not a string.","title":"Changes in behavior"},{"location":"apis/cds-compiler/doc/ApiMigration/#snapshot-of-backend-api-function-documentation","text":"Note that these backend API functions are all exposed in lib/main.js (which is the only external API ), but their documentation is currently located in lib/backends.js (this will likely change).","title":"Snapshot of backend API function documentation"},{"location":"apis/cds-compiler/doc/ApiMigration/#tohanamodel-options","text":"// Transform an augmented CSN 'model' into HANA-compatible CDS source. // The following options control what is actually generated: // options : { // toHana.names : either 'plain' (generate uppercased flattened entity names with // underscores) or 'quoted' (default, generate entity names with nested // contexts as in CDL) // toHana.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toHana.src : if true, generate HANA CDS source files (default) // toHana.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toHana.names' is not provided, 'quoted' is used. // If 'toHana.associations' is not provided, 'assocs' is used. // If neither 'toHana.src' nor 'toHana.csn' are provided, the default is to generate only HANA CDS // source files. // If all provided options are part of 'toHana', the 'toHana' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // hdbcds : a dictionary of top-level artifact names, containing for each name 'X': // <X> : the HANA CDS source string of the artifact 'X'. Please note that the // name of 'X' may contain characters that are not legal for filenames on // all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } function toHana(model, options) { ... }","title":"toHana(model, options)"},{"location":"apis/cds-compiler/doc/ApiMigration/#toodatamodel-options","text":"// Generate ODATA for augmented CSN `model` using `options` . // Before anything is generated , the following transformations are applied to 'model' : // FIXME : Verify that this is still correct // - Flatten structured elements ( and foreign keys of managed associations pointing to // keys that are themselves managed associations ). // - Generate foreign key fields for entities with managed associations ( annotated with // '@odata.foreignKey4' ). Propagate along projections accordingly . Names are built using // < assoc > _ < key > , conflicts are checked . // - Complete the 'foreignKeys' property for all managed associations , so that there // is always a 'generatedFieldName' for the corresponding generated foreign key field . // - Implicitly redirect associations based on exposure // - Check that exposed associations do not point to non - exposed targets // - Unravel derived type chains , propagating annotations upwards . // - Rename annotations according to a fixed list of short - hands // The following options control what is actually generated : // options : { // toOdata . version : either 'v2' or 'v4' ( default ) // toOdata . xml : if true , generate XML output ( default ) // toOdata . json : if true , generate JSON output ( not available for ODATA V2 ) // toOdata . separate : if true , generate XML 'metadata' and XML 'annotations' separately // toOdata . combined : if true , generate XML metadata and XML annotations together as // 'combined' ( default ) // toOdata . csn : if true , generate the transformed CSN model // } // Options provided here are merged with ( and take precedence over ) options from 'model' . // If 'toOdata.version' is not provided , 'v4' is used . // If neither 'toOdata.xml' nor 'toOdata.json' nor 'toOdata.csn' are provided , the default is // to generate only XML output . If neither 'toOdata.separate' nor 'toOdata.combined' are provided , // the default is to generate only combined XML output . // If all provided options are part of 'toOdata' , the 'toOdata' wrapper can be omitted . // // The result object contains the generation results as follows ( as enabled in 'options' ): // result : { // csn : the ( compact ) transformed CSN model including all services // _augmentedCsn : ( subject to change ): the augmented CSN model including all services // services : a dictionary of service names , containing for each name : // < servicename > : { // annotations : an XML string with EDMX annotations for service 'svc' // metadata : an XML string with EDMX metadata for service 'svc' // combined : an XML string with both EDMX metadata and annotations for service 'svc' // metadata_json : a JSON object ( not a string ! ) with EDM metadata for service 'svc' // } // messages : an array of strings with warnings ( if any ) // } // If 'model' does not contain any services , 'csn' will still contain the transformed model , but // 'services' will be an empty dictionary . // // Throws a CompilationError on errors . function toOdata ( model , options ) { ... }","title":"toOdata(model, options)"},{"location":"apis/cds-compiler/doc/ApiMigration/#tocdlmodel-options","text":"// Generate CDS source text for augmented CSN model 'model' . // The following options control what is actually generated : // options : { // FIXME : This option should be removed and something like 'toCdl.dialect: 'hana' be // used instead. // hanaFlavor : if true, HANA-specific source dialect is generated (affects e.g. the // translation of ' $ self . foo ' in paths and ::-ish namespace declarations ) // } // One source is created per top - level artifact . // Return a dictionary of top - level artifacts // by their names , like this : // { \"foo\" : \"using XY; context foo {...};\" , // \"bar::wiz\" : \"namespace bar::; entity wiz {...};\" // } // Throws a CompilationError on errors . function toCdl ( model , options ) { ... }","title":"toCdl(model, options)"},{"location":"apis/cds-compiler/doc/ApiMigration/#toswaggermodel-options","text":"// Generate OpenAPI JSON version 3 for the augmented CSN 'model'. // Return an object representing the Swagger JSON: // { // openapi: '3.0.0', // info: { ... }, // paths: { ...}, // components: { // schemas: { ... } // } // } // // Throws a CompilationError on errors. function toSwagger(model, options) { ... }","title":"toSwagger(model, options)"},{"location":"apis/cds-compiler/doc/ApiMigration/#tosqlmodel-options","text":"// Generate SQL DDL statements for augmented CSN 'model'. // The following options control what is actually generated: // options : { // toSql.names : either 'plain' (generate uppercased flattened table/view names with // underscores) or 'quoted' (default, generate quoted table/view names // with dots as in CDL) // toSql.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toSql.src : if true, generate SQL DDL source files (default) // toSql.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toSql.names' is not provided, 'quoted' is used. // If 'toSql.associations' is not provided, 'assocs' is used. // If neither 'toSql.src' nor 'toSql.csn' are provided, the default is to generate only SQL DDL // source files. // If all provided options are part of 'toSql', the 'toSql' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // sql : a dictionary of top-level artifact names, containing for each name 'X': // <X> : a string with SQL DDL statements for artifact 'X', terminated with ';'. // Please note that the name of 'X' may contain characters that are not // legal for filenames on all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } // Throws a CompilationError on errors.","title":"toSql(model, options)"},{"location":"apis/cds-compiler/doc/ApiMigration/#tocsnmodel-options","text":"// Generate compact CSN for augmented CSN 'model' // The following options control what is actually generated: // options : { // testMode : if true, the result is extra-stable for automated tests (sorted, no 'version') // } // Options provided here are merged with (and take precedence over) options from 'model'. function toCsn(model, options) { ... }","title":"toCsn(model, options)"},{"location":"apis/cds-compiler/doc/CommandLineMigration/","text":"Command Line Migration \u00b6 With revision 1.5.1, the cdsc command line interface has been adapted to use commands with options. Usage is now cdsc <command> [options] <file...> instead of cdsc [options] <file...> . The generation options ( --toHana , --toSql , ...) have been replaced by commands ( toHana , toSql , ...). This allows for better per-command options, which can now be optional, can use more single-letter abbreviations, and now match those from the options object in the API. Some examples: Old command line New command line cdsc --new-csn --toHana csn,plain foo.cds cdsc --new-csn toHana --csn --names plain foo.cds cdsc -R --H csn,plain foo.cds cdsc -R H -c -n plain foo.cds cdsc --toOdata xml,v2,separate foo.cds cdsc toOdata --xml --version v2 --separate foo.cds cdsc --toSql src foo.cds cdsc toSql foo.cds cdsc foo.cds cdsc foo.cds List of commands (as of v1.5.1): Commands H , toHana [ options ] < file ... > Generate HANA CDS source files O , toOdata [ options ] < file ... > Generate ODATA metadata and annotations C , toCdl < file ... > Generate CDS source files S , toSwagger [ options ] < file ... > Generate Swagger ( OpenAPI ) JSON Q , toSql [ options ] < file ... > Generate SQL DDL statements toCsn [ options ] < file ... > ( default ) Generate original model as CSN toTntSpecificOutput < file ... > ( internal ) Generate TNT - specific post - processed CSN toRename [ options ] < file ... > ( internal ) Generate SQL DDL rename statements Please see cdsc --help for the list of commands and general options, or cdsc <command> --help for help regarding a specific command. Some helpful hints \u00b6 Please note the following general concepts regarding the new command line: - General options can be placed anywhere, command specific options must appear after the command. - In the unlikely case that a file name starts with - , please use -- to indicate the end of options. - The src argument of toHana , toCdl , toSql is now optional (and it would now be --src ). - If no command is specified, the default is toCsn --flavor client (as before). - When no --out option is provided or if - is specified as output directory , all output will go to <stdout> instead of being written to files (like before). - The --raw-output option also affects all commands where a CSN file is generated. Instead of ...csn.json , a ...csn_raw.txt will be produced (like before).","title":"Command Line Migration"},{"location":"apis/cds-compiler/doc/CommandLineMigration/#command-line-migration","text":"With revision 1.5.1, the cdsc command line interface has been adapted to use commands with options. Usage is now cdsc <command> [options] <file...> instead of cdsc [options] <file...> . The generation options ( --toHana , --toSql , ...) have been replaced by commands ( toHana , toSql , ...). This allows for better per-command options, which can now be optional, can use more single-letter abbreviations, and now match those from the options object in the API. Some examples: Old command line New command line cdsc --new-csn --toHana csn,plain foo.cds cdsc --new-csn toHana --csn --names plain foo.cds cdsc -R --H csn,plain foo.cds cdsc -R H -c -n plain foo.cds cdsc --toOdata xml,v2,separate foo.cds cdsc toOdata --xml --version v2 --separate foo.cds cdsc --toSql src foo.cds cdsc toSql foo.cds cdsc foo.cds cdsc foo.cds List of commands (as of v1.5.1): Commands H , toHana [ options ] < file ... > Generate HANA CDS source files O , toOdata [ options ] < file ... > Generate ODATA metadata and annotations C , toCdl < file ... > Generate CDS source files S , toSwagger [ options ] < file ... > Generate Swagger ( OpenAPI ) JSON Q , toSql [ options ] < file ... > Generate SQL DDL statements toCsn [ options ] < file ... > ( default ) Generate original model as CSN toTntSpecificOutput < file ... > ( internal ) Generate TNT - specific post - processed CSN toRename [ options ] < file ... > ( internal ) Generate SQL DDL rename statements Please see cdsc --help for the list of commands and general options, or cdsc <command> --help for help regarding a specific command.","title":"Command Line Migration"},{"location":"apis/cds-compiler/doc/CommandLineMigration/#some-helpful-hints","text":"Please note the following general concepts regarding the new command line: - General options can be placed anywhere, command specific options must appear after the command. - In the unlikely case that a file name starts with - , please use -- to indicate the end of options. - The src argument of toHana , toCdl , toSql is now optional (and it would now be --src ). - If no command is specified, the default is toCsn --flavor client (as before). - When no --out option is provided or if - is specified as output directory , all output will go to <stdout> instead of being written to files (like before). - The --raw-output option also affects all commands where a CSN file is generated. Instead of ...csn.json , a ...csn_raw.txt will be produced (like before).","title":"Some helpful hints"},{"location":"apis/cds-compiler/doc/ErrorMessages/","text":"Error Messages Explained \u00b6 This document tries to explain some of the less-obvious error messages. Common Compiler Messages (Independent From Backend) \u00b6 Duplicate definitions \u00b6 node_modules/Base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/dep/node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" Here, the CDS Compiler does consider \u2026/Base/index.cds to be different to \u2026/base/index.cds , and also considers the two \u2026/model/index.cds files to be the different files. Why is that the case? Consider the following \"top-level\" file using from 'Base'; // upper-case 'B'! using from 'model'; using from 'dep'; File node_modules/dep/index.cds` looks like: using from 'base'; // lower-case 'b'! using from 'model'; node_modules/Base/index.cds is the same file as node_modules/base/index.cds on case-insensitive file systems (Windows, Mac): type T: Integer; We have node_modules/model/index.cds and a copy of it in node_modules/dep/node_modules/model/index.cds : entity E { i: Integer; } The technical explanation is that the CDS Compiler considers two file names pointing to the same file if their fs.realpath is equal. That means that we properly recognize symlinks (Linux, Mac), but we do not recognize two files to be equal if: the same file is referred to with different name casing, which does not work on case-sensitive file systems (Linux) anyway (yes, we might issue a better message when node v9.2 is widely adopted), a file is copied within the NPM package (or when hardlinks are used). The CDL code/package can be corrected as follows: Use consistent casing when referring to file and modules in using from (if in doubt, please check the error output provided by the CDS compiler client tool). Clean up a dirty NPM installation . Then, the file node_modules/dep/node_modules/model/index.cds should disappear (or be a symlink to node_modules/model/index.cds ). Extensions \u00b6 e.cds:3:20-26: Error: No `EXTEND artifact` within CONTEXT extensions e.cds:4:20-28: Error: No `ANNOTATE artifact` within SERVICE extensions e.cds:5:14-22: Error: Elements only exist in entities, types or typed constructs e.cds:6:12-36: Error: Elements only exist in entities, types or typed constructs Artifacts (entities, types, \u2026) should not be extended within other extensions \u2013 just elements (and other members) are to be extended within an artifact extension. The above messages are reported for the following CDL code: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend context C { extend C.E { e: Integer; } } extend service S { annotate S.E @Anno; } annotate C { E @Anno; } extend S { extend E { e: Integer; } } The reason for these messages is \u2013 if we would allow it: If we follow the normal name resolution rules , people would have to refer to the entity the same way as outside extend context / extend service . Most people would probably expect being able to write just E instead C.E / S.E in line 3 and 4, but this not only require special rules, but leads to other surprises \u2013 see below. Using { \u2026 } inside a plain annotate or extend statement is supposed to annotate/extend elements (or enums), not containing artifacts. The CDL code can be corrected as follows: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend C.E { e: Integer; } annotate S.E @Anno; annotate C.E @Anno; extend S.E { e: Integer; } Now consider that you could use the following to extend the entity C.E : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E } extend context C { entity F { a: association to E; } // target: E, not C.E (normal name resolution) } What about combining the two extend context : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E entity F { a: association to E; } // target: E or C.E ? } In summary, allowing artifact extensions inside extend context / extend service would provide little benefit, but would add complexity and confusion.","title":"Error Messages Explained"},{"location":"apis/cds-compiler/doc/ErrorMessages/#error-messages-explained","text":"This document tries to explain some of the less-obvious error messages.","title":"Error Messages Explained"},{"location":"apis/cds-compiler/doc/ErrorMessages/#common-compiler-messages-independent-from-backend","text":"","title":"Common Compiler Messages (Independent From Backend)"},{"location":"apis/cds-compiler/doc/ErrorMessages/#duplicate-definitions","text":"node_modules/Base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/dep/node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" Here, the CDS Compiler does consider \u2026/Base/index.cds to be different to \u2026/base/index.cds , and also considers the two \u2026/model/index.cds files to be the different files. Why is that the case? Consider the following \"top-level\" file using from 'Base'; // upper-case 'B'! using from 'model'; using from 'dep'; File node_modules/dep/index.cds` looks like: using from 'base'; // lower-case 'b'! using from 'model'; node_modules/Base/index.cds is the same file as node_modules/base/index.cds on case-insensitive file systems (Windows, Mac): type T: Integer; We have node_modules/model/index.cds and a copy of it in node_modules/dep/node_modules/model/index.cds : entity E { i: Integer; } The technical explanation is that the CDS Compiler considers two file names pointing to the same file if their fs.realpath is equal. That means that we properly recognize symlinks (Linux, Mac), but we do not recognize two files to be equal if: the same file is referred to with different name casing, which does not work on case-sensitive file systems (Linux) anyway (yes, we might issue a better message when node v9.2 is widely adopted), a file is copied within the NPM package (or when hardlinks are used). The CDL code/package can be corrected as follows: Use consistent casing when referring to file and modules in using from (if in doubt, please check the error output provided by the CDS compiler client tool). Clean up a dirty NPM installation . Then, the file node_modules/dep/node_modules/model/index.cds should disappear (or be a symlink to node_modules/model/index.cds ).","title":"Duplicate definitions"},{"location":"apis/cds-compiler/doc/ErrorMessages/#extensions","text":"e.cds:3:20-26: Error: No `EXTEND artifact` within CONTEXT extensions e.cds:4:20-28: Error: No `ANNOTATE artifact` within SERVICE extensions e.cds:5:14-22: Error: Elements only exist in entities, types or typed constructs e.cds:6:12-36: Error: Elements only exist in entities, types or typed constructs Artifacts (entities, types, \u2026) should not be extended within other extensions \u2013 just elements (and other members) are to be extended within an artifact extension. The above messages are reported for the following CDL code: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend context C { extend C.E { e: Integer; } } extend service S { annotate S.E @Anno; } annotate C { E @Anno; } extend S { extend E { e: Integer; } } The reason for these messages is \u2013 if we would allow it: If we follow the normal name resolution rules , people would have to refer to the entity the same way as outside extend context / extend service . Most people would probably expect being able to write just E instead C.E / S.E in line 3 and 4, but this not only require special rules, but leads to other surprises \u2013 see below. Using { \u2026 } inside a plain annotate or extend statement is supposed to annotate/extend elements (or enums), not containing artifacts. The CDL code can be corrected as follows: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend C.E { e: Integer; } annotate S.E @Anno; annotate C.E @Anno; extend S.E { e: Integer; } Now consider that you could use the following to extend the entity C.E : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E } extend context C { entity F { a: association to E; } // target: E, not C.E (normal name resolution) } What about combining the two extend context : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E entity F { a: association to E; } // target: E or C.E ? } In summary, allowing artifact extensions inside extend context / extend service would provide little benefit, but would add complexity and confusion.","title":"Extensions"},{"location":"apis/cds-compiler/doc/FioriAnnotations/","text":"Translation of Fiori annotations \u00b6 Fiori annotations are translated in a generic way. Essentially, write down in CDS precisely what you want to get in edmx. A more detailed description will follow soon, for the time being we hope the following example will give the idea: These CDS annotations @( UI.Chart : { ChartType: #Bullet, Measures: [ Revenue ], MeasureAttributes: [ { Measure: Revenue, Role: #Axis1, DataPoint: '@UI.DataPoint#BulletChartDataPoint' } ] }, UI.DataPoint#BulletChartDataPoint: { Title: 'Product', Value: Revenue, TargetValue: TargetRevenue, ForecastValue: ForecastRevenue, MinimumValue: MinValue, MaximumValue: MaxValue, CriticalityCalculation: { ImprovementDirection: #Target, ToleranceRangeLowValue: ToleranceRangeLow, ToleranceRangeHighValue: ToleranceRangeHigh, DeviationRangeLowValue: DeviationRangeLow, DeviationRangeHighValue: DeviationRangeHigh } } ) Something ...; are translated into the following edmx: <Annotations Target= \"Something\" > <Annotation Term= \"UI.Chart\" > <Record> <PropertyValue EnumMember= \"UI.ChartType/Bullet\" Property= \"ChartType\" /> <PropertyValue Property= \"Measures\" > <Collection> <PropertyPath> Revenue </PropertyPath> </Collection> </PropertyValue> <PropertyValue Property= \"MeasureAttributes\" > <Collection> <Record Type= \"UI.ChartMeasureAttributeType\" > <PropertyValue Property= \"Measure\" PropertyPath= \"Revenue\" /> <PropertyValue Property= \"Role\" EnumMember= \"UI.ChartMeasureRoleType/Axis1\" /> <PropertyValue Property= \"DataPoint\" AnnotationPath= \"@UI.DataPoint#BulletChartDataPoint\" /> </Record> </Collection> </PropertyValue> </Record> </Annotation> <Annotation Term= \"UI.DataPoint\" Qualifier= \"BulletChartDataPoint\" > <Record> <PropertyValue String= \"Product\" Property= \"Title\" /> <PropertyValue Path= \"Revenue\" Property= \"Value\" /> <PropertyValue Path= \"TargetRevenue\" Property= \"TargetValue\" /> <PropertyValue Path= \"ForecastRevenue\" Property= \"ForecastValue\" /> <PropertyValue Path= \"MinValue\" Property= \"MinimumValue\" /> <PropertyValue Path= \"MaxValue\" Property= \"MaximumValue\" /> <PropertyValue Property= \"CriticalityCalculation\" > <Record> <PropertyValue Property= \"ImprovementDirection\" EnumMember= \"UI.ImprovementDirectionType/Target\" /> <PropertyValue Path= \"ToleranceRangeLow\" Property= \"ToleranceRangeLowValue\" /> <PropertyValue Path= \"ToleranceRangeHigh\" Property= \"ToleranceRangeHighValue\" /> <PropertyValue Path= \"DeviationRangeLow\" Property= \"DeviationRangeLowValue\" /> <PropertyValue Path= \"DeviationRangeHigh\" Property= \"DeviationRangeHighValue\" /> </Record> </PropertyValue> </Record> </Annotation> </Annotations> All suppoted Fiori annotations are defined in the following vocabularies: * Core * Measures * Capabilities * Aggregation * Common * Communication * UI","title":"Translation of Fiori annotations"},{"location":"apis/cds-compiler/doc/FioriAnnotations/#translation-of-fiori-annotations","text":"Fiori annotations are translated in a generic way. Essentially, write down in CDS precisely what you want to get in edmx. A more detailed description will follow soon, for the time being we hope the following example will give the idea: These CDS annotations @( UI.Chart : { ChartType: #Bullet, Measures: [ Revenue ], MeasureAttributes: [ { Measure: Revenue, Role: #Axis1, DataPoint: '@UI.DataPoint#BulletChartDataPoint' } ] }, UI.DataPoint#BulletChartDataPoint: { Title: 'Product', Value: Revenue, TargetValue: TargetRevenue, ForecastValue: ForecastRevenue, MinimumValue: MinValue, MaximumValue: MaxValue, CriticalityCalculation: { ImprovementDirection: #Target, ToleranceRangeLowValue: ToleranceRangeLow, ToleranceRangeHighValue: ToleranceRangeHigh, DeviationRangeLowValue: DeviationRangeLow, DeviationRangeHighValue: DeviationRangeHigh } } ) Something ...; are translated into the following edmx: <Annotations Target= \"Something\" > <Annotation Term= \"UI.Chart\" > <Record> <PropertyValue EnumMember= \"UI.ChartType/Bullet\" Property= \"ChartType\" /> <PropertyValue Property= \"Measures\" > <Collection> <PropertyPath> Revenue </PropertyPath> </Collection> </PropertyValue> <PropertyValue Property= \"MeasureAttributes\" > <Collection> <Record Type= \"UI.ChartMeasureAttributeType\" > <PropertyValue Property= \"Measure\" PropertyPath= \"Revenue\" /> <PropertyValue Property= \"Role\" EnumMember= \"UI.ChartMeasureRoleType/Axis1\" /> <PropertyValue Property= \"DataPoint\" AnnotationPath= \"@UI.DataPoint#BulletChartDataPoint\" /> </Record> </Collection> </PropertyValue> </Record> </Annotation> <Annotation Term= \"UI.DataPoint\" Qualifier= \"BulletChartDataPoint\" > <Record> <PropertyValue String= \"Product\" Property= \"Title\" /> <PropertyValue Path= \"Revenue\" Property= \"Value\" /> <PropertyValue Path= \"TargetRevenue\" Property= \"TargetValue\" /> <PropertyValue Path= \"ForecastRevenue\" Property= \"ForecastValue\" /> <PropertyValue Path= \"MinValue\" Property= \"MinimumValue\" /> <PropertyValue Path= \"MaxValue\" Property= \"MaximumValue\" /> <PropertyValue Property= \"CriticalityCalculation\" > <Record> <PropertyValue Property= \"ImprovementDirection\" EnumMember= \"UI.ImprovementDirectionType/Target\" /> <PropertyValue Path= \"ToleranceRangeLow\" Property= \"ToleranceRangeLowValue\" /> <PropertyValue Path= \"ToleranceRangeHigh\" Property= \"ToleranceRangeHighValue\" /> <PropertyValue Path= \"DeviationRangeLow\" Property= \"DeviationRangeLowValue\" /> <PropertyValue Path= \"DeviationRangeHigh\" Property= \"DeviationRangeHighValue\" /> </Record> </PropertyValue> </Record> </Annotation> </Annotations> All suppoted Fiori annotations are defined in the following vocabularies: * Core * Measures * Capabilities * Aggregation * Common * Communication * UI","title":"Translation of Fiori annotations"},{"location":"apis/cds-compiler/doc/NameResolution/","text":"Name Resolution in CDL (CDx/Language) \u00b6 Name resolution refers to the resolution of names (identifiers) within expressions of the source to the intended artifact or member in the model. As CDL is related to SQL, its name resolution strategy must be natural to SQL programmers. This forbids us to use the simple lexical scoping name resolution for all language constructs. This document presents the exact semantics of the resolution in CDL, especially how it is influenced by the language constructs where the reference is embedded in. The overall goal is that the name resolution is low on surprises throughout the complete life-cycle of any CDS model, and robust concerning any model extensions. Remark: this is the intended behavior, the code must still be adapted at some places. The impatient reader might want to jump to the summary , others might want to skip the introduction . Table of Contents \u00b6 Introduction \u2013 Background: SQL \u2013 Background: modern programming languages Design Principles Name Resolution - the Basics \u2013 Common rules \u2013 Resolving paths \u2013 Navigation environment References to main artifacts Values and references to elements \u2013 References in queries \u2013 References to sibling elements \u2013 Other element references Paths as Annotation Values Differences to HANA-CDS Summary Introduction \u00b6 If you look at typical examples given in introductionary documents about CDS, you might wonder why there is a lengthy document about the name resolution in CDL. So, let us start with such an example: nameprefix sap . core ; context types { type Price { amount : Amount ; currency : CurrencySymbol ; } type Amount : Decimal ( 5 , 3 ); } type CurrencySymbol : String ( 3 ); entity ProductsInternal { productId : Integer ; retailPrice : types . Price ; salesPrice = retailPrice ; // we give no reduction } view Products as select from ProductsInternal { productId, salesPrice } Let us first go a step backwards: in CDS, all entities and other main artifacts (short: artifacts) have a unique name , which we call absolute name . Why don't we just use that name, like we do in SQL and in CSN? As we want to support a hierarchical naming convention, it should be easy to define and to refer to artifacts sharing a common name prefix. In the example above, we have 3 types with the absolute names sap.core.types.Price , sap.core.types.Amount and sap.core.CurrencySymbol . For convenience , we do not use these lengthy names in CDL, but shorter names without the common prefix. These are then \"translated\" by the name resolution into the absolute names. This also allow us to easily change the common name prefix in the development phase. In which area of the code do we assume which common name prefix? In the example above, we refer to these 3 types by types.Price , just Amount , and CurrencySymbol . The first observation is: name resolution (and the new name introduced by an artifact definition) depends on the block structure . In the view, we also refer to elements of (another) artifact. There is no special language construct for such references \u2013 it is a simple identifier (or path) like the references to the types and the source entity of the view. The second observation is: name resolution in CDL depends on the argument position , i.e. the place of the reference relative to the statement (e.g. in the from or where clause of a select statement). This is not only valid in SQL and related languages like CDL, but also in languages like C (for labels after goto ). Let is now see why the name resolution is not as obvious as it might seem to be\u2026 What happens if an inner block introduces the same name as an outer block? Do we have name shadowing (we cannot access the artifact defined in the outer block by its simple name)? Consider that we have defined a type CurrencySymbol inside the block of the context types \u2026 Is the same true for nested element definitions? How do we refer to elements and subelements inside the definition of a subelement? Does a simple name refer to a subelement of the same parent element, or an element of the corresponding main artifact? How do we access artifacts which are defined in another file? That is an easy one: the using declarations introduce a file-local alias name to an absolute name for accessing artifacts in other files or in the current files (useful to refer to shadowd definitions). Can something bad happen if extensions come into play? Yes, extensions must be used with care. Extensions might break existing models \u2013 if two extensions decide to add an element with the same name to the same entity, there is nothing we can do about it. But we make sure that something real bad cannot happen: an extension cannot silently changes the semantics of a model \u2013 the name resolution is defined in such a way that a valid reference does not silently (without errors or warnings) point to another artifact when the extension is applied to the model. Background: SQL \u00b6 In this section, we look at the heritage from SQL. Given is the following SQL query: SELECT a , a . b as e FROM a as x , tab as a The identifier a refers to different objects: at the \"select item\" position in line 1, a refers to a column in one of the tables, at the \"select item\" position in line 2, a refers to the table alias introduced in line 4, at the \"table reference\" position in line 3, a refers to the table a , and in line 4, we define a table alias with name a ( a is no reference here). Our task is to generalize the semantics to make it applicable for CDS features not found in SQL: sub structures, associations, extensions, \u2026 find argument positions which are \"similar\" to arguments positions with a given name resolution semantics \u2013 we then apply the same semantics to the \"new\" argument positions As an example for the latter, let us consider an SQL view which is a projection on a given table and additionally exposes one of its column under an extra name: entity B { a: Integer; } view E as select from B { *, a as e }; In CDS, we can define a table which uses the same layout as a given table and additionally exposes one of its elements under an extra name: entity B { a: Integer; } entity E : B { e = a; } As the situation is very similar, the name resolution strategy for the referred column/element should be the same (the syntax is unfortunately not the same due to the SQL syntax of select items). In SQL, we have silent semantic changes, but only with subqueries \u2013 see the first example in Section \"Design Principles\" . To avoid this situation in CDx/Language, we are a bit incompatible in this case. Background: modern programming languages \u00b6 Modern programming languages (try to) use just one name resolution strategy: lexical scoping. Assuming that the \"free-floating\" column a was defined in table a , the SELECT query from the beginning of previous section would look like the following in JavaScript: select ( [ a , tab ], ( x , a ) => ({ a : x . a , e : a . b }) ) Apart from the syntax and expression structure, the difference to SQL is that there are no \"free-floating\" references : the column a in (the line of) table a must be prefixed by the corresponding table alias x (parameter name of the anonymous function in JavaScript). This is not only a good thing for itself (the original SQL query would be considered incorrect if a column a is added later to table tab ) it also enables lexical scoping, as the table alias names are defined in the query expression itself. Any \"convenience\" declaration which \"extends\" lexical scoping is usually soon be declared as obsolute, because its little convenience benefit of is not worth the addition issues . As an example, see the fate of the with statement in JavaScript. If sold with the label \"OO\", the convenience is often considered to be more important. Given is the following Java program: class T { int C = 0 ; } class B { // class T { int C = 1; } } class J extends B { int go () { return ( new T ()). C ; } public static void main ( String [] args ) { System . out . println (( new J ()). go ()); } } Uncomment the definition of B.T \u2192 the output changes from 0 to 1 (silent semantic change). Now consider that class B is usually defined somewhere else \u2192 same kind of convenience, same kind of issues. Design Principles \u00b6 The name resolution rules in the following sections are based on the following design principles: Applications/customers can safely add new artifacts without silently changing the semantics of other applications. A valid SQL SELECT should be a valid CDL SELECT with the same semantics (modulo changes in the concrete syntax), as CDL uses CQL \u2013 an \"official\" extension of SQL SELECT. Applications/customers can safely add new artifacts without inducing other applications to compile with an error. The name resolution does not depend on package definitions and its dependencies. The chosen name resolution strategy for an argument position should not come at a surprise. Convenience: there must be a more convenient solution than always using absolute names. Please note that these principles are ordered. There are many cases where one principle cannot be fulfilled in order to fulfil a higher prioritized design principles. The first design principle is therefore always fulfilled. This can be seen in the following examples. For (1), CDL compiles the following source with an error: entity A { a: String(20); j: Integer; x: Integer; } entity B { b: String(20); j: Integer; } view V as select from A { a, x } where // x is valid here j = (select from B { j + x }); // invalid: use A.x instead of x (ok: j) It contradicts (2), because SQL would compile the subquery. But there would be a silent semantic change when column x is added to table B . For (2), CDL needs to support unqualified element (column) names in the SELECT clause even if a JOIN is used - we might issue a warning for this case, though. entity A { a: String(20); j: Integer; x: Integer; } // from Partner A entity B { b: String(20); j: Integer; } // from Partner B view V as select from A join B {a, b, x} ON A.j = B.j; // valid customer view It contradicts (3), as the unchanged customer view compiles with an error when partner B adds an element x to their table B . Principle (3) is also contradicted for specific features like (multiple) entity includes. Principle (4) is not part of the name resolution rules in HANA-CDS. As we never allow to break Principle (1), we have the following guideline: It is fine if definitions in the own source shadow other definitions (in the own source or others), because the programmer is aware (and in control) of all these definitions. It is evil if definitions made in other sources shadow other definitions (in the own source or others). Name Resolution - the Basics \u00b6 We start with some terminology: An environment is a dictionary binding/mapping (local) names to language constructs (e.g. entities or elements). An navigation environment of a construct is the dictionary for definitions within that construct or a type/entity referred by that construct. For contexts (and services), these are the sub artifacts defined within that context. For types, entities, elements, these are the elements (or enum symbols) defined within that object or the object's (direct or indirect) type; for association types, these are the elements of the target entity. (The actions and parameters of an object cannot be accessed this way.) context C { type X: Integer; }; // context \"C\" supplies env{ X: type(\"C.X\") } type S { E: Integer; } extend S with { F: Integer; }; // type \"S\" supplies env{ E: elem(\"S\",\"E\"), F: \u2026 } type T: S; // type \"T\" supplies the same env as type \"S\" Common rules \u00b6 Name resolution name is case sensitive . In general, a model can contain artifacts and members whose name differ in case only; there might be an linter check which informs model writers if they make use of this \"feature\". While being case sensitive might be against the original intention of SQL, it actually conforms to the SQL Specification after abstraction from the lexical syntax, see e.g. SQL-92, \u00a75.2.10 and 5.2.12\u202614 for the semantics of quoted and non-quoted identifiers. In CDL, we just do not transform non-quoted identifiers to all-upper names. Also, CSN-processors are cumbersome to write if they have to deal with (partial/feigned) case-insensitivity. In a future version of this project, we or others might provide a \"use at your own risk\" backend which produce SQL DDL statements without quoted identifiers In CDL, an identifier may be used before its definitions, there is no need of forward declarations Thus, the sequence of definitions inside a block does not matter for the scope rules: using T as OuterT; // introduced to have a name for the shadowed \"T\" type T: String(20); context C { type D: T; // -> C.T -> cds.Integer type T: Integer; type O: OuterT; // -> T -> String(20) } // type C.O: T; // alternative: define \"C.O\" outside the block of \"C\" There are two reasons to do so: When using associations, (mutually) recursive usage is quote common, and forward references are cumbersome. (We can always access shadowed artifacts.) Real-world models will very likely reside in multiple files/resources \u2013 there is no natural order in which the definitions are to be processed. Resolving paths \u00b6 The algorithm for resolution of paths (consisting of dot-connected names) is as follows: First, we try to find the language construct O for the first name in the path; this language construct is called the path base . We resolve the next name in the path by inspecting the navigation environment of O . The found language artifact is our next O . We repeat Step 2 until the complete path is resolved. Even the algorithm for finding the path base follows the same pattern: We have a list of search environments, which we inspect in order. The first hit is the path base. It is an error if the name (the first name of the path) cannot be found in any environment of the list. All but the last environment are constructed from definitions in the current source following the lexical block structure of the source, or a small, fixed number of predefined names (e.g. $projection .) We will call such an environment a lexical search environment . Only the last environment contains bindings defined externally , at least potentially. It can be the environment for predefined artifacts (like cds.Integer ), or the navigation environment of the \"current artifact/member of interest\" (like the elements of the projection source). So the guideline at the end of the previous section essentially becomes lexical scoping first, search in one externally provided environment last . The basic difference between the name resolution strategies is the relevance of the lexical and the last environments, and how they are build. Navigation environment \u00b6 The navigation environment might depend on on the argument position. If an object is typed with an array, the environment supplied by that object is usually considered to be empty. For type of references and the to-be-extended element referenced in an inner extend, it is the environment supplied by the array item type: @ A . e : 1 // warning : cannot find `e` for annotation assignments annotation A : array of { e : Integer ; } ; annotate A with { annotate e with @ lineElement ; } annotation B : type of : A . e ; // valid = Integer For the to-be-extended element referenced in an inner extend, we consider the environment supplied by an association to be empty: type A: association to E; entity E { i: Integer; } annotate A with { @targetElem i; // error: do not follow associations } type S { e: Integer; } type T : S; annotate T with { @derivedElem e; // ok: follow derived type } References to main artifacts \u00b6 When we have an argument position where we expect a main artifact, the list of lexical search environments depends on the blocks containing the current statement, and the last, non-lexical search environment is independent from the block structure or a current object of interest. A reference to a main artifact can be a references to a projection or view source (table reference after SELECT \u2026 FROM in SQL), association target , type (but not the reference after type of , see below) annotation for a annotation assignment, to-be-extended main artifact of an outer extend structure include , type parameter (should be a constant, not yet). The construction of the list of lexical search environments starts at the innermost block containing the current statement, and then continue to the next outer block: As opposed to HANA-CDS, we skip blocks containing just element definitions (or generally definitions of members like actions). For blocks of context and service definitions, we add the definition inside that block (all definitions in the environment supplied by the context or service can contain more definitions). For the top-level block of the current source, we add the top-level definitions and the bindings for the using declarations. The last, non-lexical search environment is the environments for built-in artifacts. Currently, it contains String for cds.String , similarly LargeString , Integer , Integer64 , Binary , LargeBinary , Decimal , DecimalFloat , Double , Date , Time , Timestamp , DateTime , and Boolean . More artifacts are defined with the options --hana-flavor . When searching for an annotation (after the initial @ ), the last search environment are the model definitions. We conclude this section with a little weird example \u2013 nobody would write models like that, but it demonstrates the exact semantics. nameprefix test; using cds.Boolean as Integer; type Time { @Date // @Date: true, not @cds.Date: true Date: Date; // typeOf(test.Time,Date) = cds.Date, no error C: C.Date; // typeOf(test.Time,C) = test.C.Date, no error } @C.Anno // @test.C.Anno: true define context C { type Date: Time; // test.C.Date -> test.C.Time, not test.Time type Time: Integer; // test.C.Time -> alias Integer -> cds.Boolean type CC: C.Integer; // test.C.CC -> test.C.Integer } @Integer // @cds.Boolean: true (warning: is no annotation) type C.Integer: Time; // test.C.Integer -> test.Time, not test.C.Time In this example, we have the following two lexical search environments: The search environment containing definitions directly inside the block after define context C : Date , Time and CC , but not Integer (but which is in the environment supplied by test.C ). Used as first search environment when resolving main artifact references in the block after define context C , the next search environment is the environment containing top-level definitions. The search environment containing the top-level definitions and using declarations of the source: Integer , Time and C . Used as first search environment when resolving main artifact references outside the block after define context C , the next search environment is the non-lexical environment containing built-in artifacts. There is no lexical search environment for the element definitions supplied by test.Time . We allow paths for names in top-level definitions. All but the last name in the paths are (on-the-fly) contexts, which do not introduce blocks for the lexical scoping: entity N.mid.E { key i: Integer; to1: association to E; // invalid to2: association to mid.E; // invalid to3: association to N.mid.E; // valid } context C { context mid { entity E { key i: Integer; to1: association to E; // valid to2: association to mid.E; // valid to3: association to C.mid.E; // valid } } } Values and references to elements \u00b6 When we have an argument position where we expect a value or a reference to an element, We usually have just one lexical search environment which is sometimes only inpected if the path consists of at least two identifiers. This basically introduces an escape mechanism . The last, non-lexical environments is usually the environment either supplied from an artifact referred by the current statement or supplied by the object containing the current definition. It is often allowed to switch to the \"main artifact name resolution\" by prefixing the path with a : , used usually to refer to constants. The semantics is best explained separately for the diffent groups of argument positions. References in queries \u00b6 We start with the most complicated group, because it is known from SQL: references in SELECT item positions \u2013 similar: WHERE , ON , TODO : GROUP BY , ORDER BY (or special?), \u2026 TODO : do the same for as projection on ? TODO : names in mixins The list of search environments is created as follows: The (first) lexical search environment is build from the explicit and implicit alias names for the sources (table references after from ); we also bind $projection to the resulting view/projection elements of the current SELECT if not already used as a table alias. If the current SELECT is a sub-SELECT, we have additional lexical search environments containing alias names for the corresponding outer SELECTs; their $projection bindings are shadowed. For compatibility with ABAP CDS, we have another environment with one entry: we bind $parameters to the parameters of the current view \u2013 the SQL way is to use :param1 instead of $parameters.param1 , see below. The last, non-lexical environment is the environent containing the elements from all source entities of the current SELECT; if an element with the same name is contained in more than one source, this search environment binds the name to an \"ambiguity\" entry (i.e. a reference to it leads to an error) There are no additional non-lexical search environments for the elements of outer SELECTs. The lexical search environments are only inspected if the path consists of at least two identifiers. The above mentioned : -escape mechanism leads to the following name resolution: The first lexical search environment is the the environment containing all parameter names of the current view. The following search environments are the usual ones from the \"main artifact name resolution\"; constant values can be accessed this way ( TODO : probably not now). References to sibling elements \u00b6 The next group is for references in member definitions to other elements of the same main artifact. Such a reference can be a reference to a: calculated field , references in the default value (HANA SQL does not allow this) references in the ON condition of an unmanaged association * reference after type of \u2013 can also be a references to an element of another main artifact The list of search environments is created as follows: There is one lexical search environment, it has one entry: we bind $self to the main artifact, or to be exact: to the current instance of that artifact, e.g. the current line of an entity. This environment is also inspecteded if the path consists of just $self \u2013 useful for on conditions of unmanaged associations. The second and last, the non-lexical search environment is the environment supplied by the object (main artifact or element) where the current member is defined in. The above mentioned : -escape mechanism leads to the \"main artifact name resolution\"; it can be used to access constants, or \u2013for references after type of \u2013 elements of other artifacts. The reason for the $self references is visible in an example with subelements: type T { a: Integer; b = a; // b = a c = $self.a; // c = a } entity E { a: Integer; x: T; // x.b = x.a, x.c = x.a y { a: Integer; b = a; // y.b = y.a c = $self.a; // y.c = a }; } entity S { $self: Integer; // we might complain about such an element name x = $self.$self; // x = $self (the element) } Other element references \u00b6 A foreign key in the definition of a managed association, is just searched in the environment supplied by the target entity. No lexical search environment is inspected first. In an inner extend , we just search in the navigation environment of the current language construct. No lexical search environment is inspected first. These are actually not necessary references to elements, but also sub artifacts (e.g. extend in extend context ), actions (in the actions clause of extend entity ), or parameters (in the parameters clause of extend action ). TODO : more use cases, like references inside filter conditions of paths. Paths as annotation values \u00b6 We can also use paths as annotation assignment values. If there is no annotation definition (there might be a warning for this), then the path cannot be resolved at all. The same is true if the annotation type does not allow path values (then there might be a warning for this) or just a cds.UnspecifiedRef . If there is a annotation definition which allows to use paths by specifying the type cds.ArtifactRef (or a variant of it), then the path resolution works as described in Section \"References to Main Artifacts\" . If there is a annotation definition which allows to use paths by specifying the type cds.ElementRef , then the path resolution works as described in Section \"References sibling elements\" . If that annotation is assigned to a main artifact, then same main artifact mean the main artifact itself. Differences to HANA-CDS \u00b6 The most visible differences in the name resolution semantics of CDx/Language compared to HANA CDS are: Using constant values requires to prefix the path (referring to the constant) with a : . There is a new semantics for paths (without initial : ) used in annotation assignments. In the definitions of sub elements, accessing elements supplied by the corresponding main artifact requires to prefix the path with $self. . Accessing sibling elements works the same as in HANA CDS. It is no problem to define elements which have the same (local) name as the referenced type. In views with more than one source entity, selecting an element e from one source without the use of a table alias (which is not recommented anyway!) suddenly does not compile anymore if another source entity is extended by a new element e . In HANA-CDS, the name resolution works quite uniformly for all argument positions, with most clauses of SELECT being the main exception. It is also compatible to the \"pre-extension\" name resolution semantics of HANA-CDS. This is nice! Why do we specify a different name resolution semantics for CDx/Language? The reason is: we do not want to have the \"extended\" lexical scoping semantics of HANA CDS concerning elements, which heavily relies on the package hierchy. To avoid silent semantic changes with extensions, the HANA-CDS compiler enforces the following properties: Every source belongs to a package; packages can depend on other packages, no cycles are allowed. No language construct can be extended in the same package where it is defined in, no language construct can be extended twice in the same package Artifacts can only be extended by top-level extend statements, elements can only be extended by inner extends (the second is true for CDx/Language, too). These are properties which do not hold for consumers of the CDx Compiler. Additionally, while direct changes in base packages can always lead to semantic changes, the following example shows that this unwanted effect is more likely in HANA-CDS: // BaseApp.cds --- entity E { a: String(20); b { // a: Integer; // CHANGE: introduce sub element x: Integer; }; } // MyExtension.cds --- extend E with { extend b with { z = a; // in CDx/Language: $self.a } } In HANA-CDS, both files compile before and after the change in BaseApp.cds : the element b.z of E refers to element a of E , but after the change to b.a of E , because that element is visible in the base package and all its extensions (we would not see the problem if b.a would have been introduced by an extension in another package). In CDx/Language, the files only compile after the change in BaseApp.cds : (with the same semantics as in HANA-CDS). To make it work before the change, element b.z of E can refer to element a of E by writing this references as $self.a \u2013 with this path, b.z still refers to a of E after the change in BaseApp.cds . Summary \u00b6 To avoid silent semantic changes with extensions or new CDL versions, we follow the following principle: After we have tried to find a local name in an environment containing artifacts or elements which are potentially defined somewhere else (e.g. via an extension), we do not inspect any other environment. In CDx/Language, we basically have two search strategies. But let us start with Strategy 0: Resolving a name in the tail of a path . For a path a.b , we only inspect one environment when resolving b : the environment supplied by a . For example, if a is a structured element, we try to find b in all sub elements of a \u2013 it does not matter whether the sub element b has been directly defined with the definition of element a , or whether is has been defined externally: via an extensions or as an element of the referenced type. Resolving the first name of a path when looking for artifacts . We apply lexical scoping when we refer to types, entities and similar artifacts. When looking for an artifact A , we search in the blocks of surrounding context , service and top-level definitions, starting at the innermost block and ending at the top-level block of the source. To make it clear: we do not search in blocks of type, entity or other definitions, just blocks of contexts (and similar constructs). We only consider definitions within these blocks, not all sub artifacts of the contexts, which might have been introduced by context extensions, or by using a path in the definition, e.g. type MyContext.A: \u2026 . If the search is not successful so far, we finally inpect an environment containing artifacts which are normally not defined in our own source: For the @A of an annotation assignment , we look for A in the definitions property of the model. For all other references, we look for A in the built-in environment, where we define things like cds.Integer . This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ArtifactRef (or variants, future). Resolving the first name of a path when looking for values or elements . We search for elements supplied by the current \"language construct of interest\", which depends on the argument position. The most relevant ones are: The element or artifact where the current (sub) artifact is defined in, i.e. we access sibling elements. The source of the current projection or view. Depending on the argument position, there is an escape mechanism \u2013 which is tried first \u2013 to access also other elements. The most relevant ones are: If the paths starts with the identifier $self , we look for the next name of the path in the environment supplied by the corresponding main artifact of the current element. This is useful for element references inside sub elements to access siblings of ancestors. If a path in most clauses of a view starts with a , and a is an explicit or implicit table alias (which we always see in our source), we look for the next identifier of the path in the environment supplied by the corresponding entity. If the path is prefixed by a : , we actually switch to the other search strategy: looking for artifacts like types. This is useful to access constant values (or for type of ). This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ElementRef (future).","title":"Name Resolution in CDL (CDx/Language)"},{"location":"apis/cds-compiler/doc/NameResolution/#name-resolution-in-cdl-cdxlanguage","text":"Name resolution refers to the resolution of names (identifiers) within expressions of the source to the intended artifact or member in the model. As CDL is related to SQL, its name resolution strategy must be natural to SQL programmers. This forbids us to use the simple lexical scoping name resolution for all language constructs. This document presents the exact semantics of the resolution in CDL, especially how it is influenced by the language constructs where the reference is embedded in. The overall goal is that the name resolution is low on surprises throughout the complete life-cycle of any CDS model, and robust concerning any model extensions. Remark: this is the intended behavior, the code must still be adapted at some places. The impatient reader might want to jump to the summary , others might want to skip the introduction .","title":"Name Resolution in CDL (CDx/Language)"},{"location":"apis/cds-compiler/doc/NameResolution/#table-of-contents","text":"Introduction \u2013 Background: SQL \u2013 Background: modern programming languages Design Principles Name Resolution - the Basics \u2013 Common rules \u2013 Resolving paths \u2013 Navigation environment References to main artifacts Values and references to elements \u2013 References in queries \u2013 References to sibling elements \u2013 Other element references Paths as Annotation Values Differences to HANA-CDS Summary","title":"Table of Contents"},{"location":"apis/cds-compiler/doc/NameResolution/#introduction","text":"If you look at typical examples given in introductionary documents about CDS, you might wonder why there is a lengthy document about the name resolution in CDL. So, let us start with such an example: nameprefix sap . core ; context types { type Price { amount : Amount ; currency : CurrencySymbol ; } type Amount : Decimal ( 5 , 3 ); } type CurrencySymbol : String ( 3 ); entity ProductsInternal { productId : Integer ; retailPrice : types . Price ; salesPrice = retailPrice ; // we give no reduction } view Products as select from ProductsInternal { productId, salesPrice } Let us first go a step backwards: in CDS, all entities and other main artifacts (short: artifacts) have a unique name , which we call absolute name . Why don't we just use that name, like we do in SQL and in CSN? As we want to support a hierarchical naming convention, it should be easy to define and to refer to artifacts sharing a common name prefix. In the example above, we have 3 types with the absolute names sap.core.types.Price , sap.core.types.Amount and sap.core.CurrencySymbol . For convenience , we do not use these lengthy names in CDL, but shorter names without the common prefix. These are then \"translated\" by the name resolution into the absolute names. This also allow us to easily change the common name prefix in the development phase. In which area of the code do we assume which common name prefix? In the example above, we refer to these 3 types by types.Price , just Amount , and CurrencySymbol . The first observation is: name resolution (and the new name introduced by an artifact definition) depends on the block structure . In the view, we also refer to elements of (another) artifact. There is no special language construct for such references \u2013 it is a simple identifier (or path) like the references to the types and the source entity of the view. The second observation is: name resolution in CDL depends on the argument position , i.e. the place of the reference relative to the statement (e.g. in the from or where clause of a select statement). This is not only valid in SQL and related languages like CDL, but also in languages like C (for labels after goto ). Let is now see why the name resolution is not as obvious as it might seem to be\u2026 What happens if an inner block introduces the same name as an outer block? Do we have name shadowing (we cannot access the artifact defined in the outer block by its simple name)? Consider that we have defined a type CurrencySymbol inside the block of the context types \u2026 Is the same true for nested element definitions? How do we refer to elements and subelements inside the definition of a subelement? Does a simple name refer to a subelement of the same parent element, or an element of the corresponding main artifact? How do we access artifacts which are defined in another file? That is an easy one: the using declarations introduce a file-local alias name to an absolute name for accessing artifacts in other files or in the current files (useful to refer to shadowd definitions). Can something bad happen if extensions come into play? Yes, extensions must be used with care. Extensions might break existing models \u2013 if two extensions decide to add an element with the same name to the same entity, there is nothing we can do about it. But we make sure that something real bad cannot happen: an extension cannot silently changes the semantics of a model \u2013 the name resolution is defined in such a way that a valid reference does not silently (without errors or warnings) point to another artifact when the extension is applied to the model.","title":"Introduction"},{"location":"apis/cds-compiler/doc/NameResolution/#background-sql","text":"In this section, we look at the heritage from SQL. Given is the following SQL query: SELECT a , a . b as e FROM a as x , tab as a The identifier a refers to different objects: at the \"select item\" position in line 1, a refers to a column in one of the tables, at the \"select item\" position in line 2, a refers to the table alias introduced in line 4, at the \"table reference\" position in line 3, a refers to the table a , and in line 4, we define a table alias with name a ( a is no reference here). Our task is to generalize the semantics to make it applicable for CDS features not found in SQL: sub structures, associations, extensions, \u2026 find argument positions which are \"similar\" to arguments positions with a given name resolution semantics \u2013 we then apply the same semantics to the \"new\" argument positions As an example for the latter, let us consider an SQL view which is a projection on a given table and additionally exposes one of its column under an extra name: entity B { a: Integer; } view E as select from B { *, a as e }; In CDS, we can define a table which uses the same layout as a given table and additionally exposes one of its elements under an extra name: entity B { a: Integer; } entity E : B { e = a; } As the situation is very similar, the name resolution strategy for the referred column/element should be the same (the syntax is unfortunately not the same due to the SQL syntax of select items). In SQL, we have silent semantic changes, but only with subqueries \u2013 see the first example in Section \"Design Principles\" . To avoid this situation in CDx/Language, we are a bit incompatible in this case.","title":"Background: SQL"},{"location":"apis/cds-compiler/doc/NameResolution/#background-modern-programming-languages","text":"Modern programming languages (try to) use just one name resolution strategy: lexical scoping. Assuming that the \"free-floating\" column a was defined in table a , the SELECT query from the beginning of previous section would look like the following in JavaScript: select ( [ a , tab ], ( x , a ) => ({ a : x . a , e : a . b }) ) Apart from the syntax and expression structure, the difference to SQL is that there are no \"free-floating\" references : the column a in (the line of) table a must be prefixed by the corresponding table alias x (parameter name of the anonymous function in JavaScript). This is not only a good thing for itself (the original SQL query would be considered incorrect if a column a is added later to table tab ) it also enables lexical scoping, as the table alias names are defined in the query expression itself. Any \"convenience\" declaration which \"extends\" lexical scoping is usually soon be declared as obsolute, because its little convenience benefit of is not worth the addition issues . As an example, see the fate of the with statement in JavaScript. If sold with the label \"OO\", the convenience is often considered to be more important. Given is the following Java program: class T { int C = 0 ; } class B { // class T { int C = 1; } } class J extends B { int go () { return ( new T ()). C ; } public static void main ( String [] args ) { System . out . println (( new J ()). go ()); } } Uncomment the definition of B.T \u2192 the output changes from 0 to 1 (silent semantic change). Now consider that class B is usually defined somewhere else \u2192 same kind of convenience, same kind of issues.","title":"Background: modern programming languages"},{"location":"apis/cds-compiler/doc/NameResolution/#design-principles","text":"The name resolution rules in the following sections are based on the following design principles: Applications/customers can safely add new artifacts without silently changing the semantics of other applications. A valid SQL SELECT should be a valid CDL SELECT with the same semantics (modulo changes in the concrete syntax), as CDL uses CQL \u2013 an \"official\" extension of SQL SELECT. Applications/customers can safely add new artifacts without inducing other applications to compile with an error. The name resolution does not depend on package definitions and its dependencies. The chosen name resolution strategy for an argument position should not come at a surprise. Convenience: there must be a more convenient solution than always using absolute names. Please note that these principles are ordered. There are many cases where one principle cannot be fulfilled in order to fulfil a higher prioritized design principles. The first design principle is therefore always fulfilled. This can be seen in the following examples. For (1), CDL compiles the following source with an error: entity A { a: String(20); j: Integer; x: Integer; } entity B { b: String(20); j: Integer; } view V as select from A { a, x } where // x is valid here j = (select from B { j + x }); // invalid: use A.x instead of x (ok: j) It contradicts (2), because SQL would compile the subquery. But there would be a silent semantic change when column x is added to table B . For (2), CDL needs to support unqualified element (column) names in the SELECT clause even if a JOIN is used - we might issue a warning for this case, though. entity A { a: String(20); j: Integer; x: Integer; } // from Partner A entity B { b: String(20); j: Integer; } // from Partner B view V as select from A join B {a, b, x} ON A.j = B.j; // valid customer view It contradicts (3), as the unchanged customer view compiles with an error when partner B adds an element x to their table B . Principle (3) is also contradicted for specific features like (multiple) entity includes. Principle (4) is not part of the name resolution rules in HANA-CDS. As we never allow to break Principle (1), we have the following guideline: It is fine if definitions in the own source shadow other definitions (in the own source or others), because the programmer is aware (and in control) of all these definitions. It is evil if definitions made in other sources shadow other definitions (in the own source or others).","title":"Design Principles"},{"location":"apis/cds-compiler/doc/NameResolution/#name-resolution-the-basics","text":"We start with some terminology: An environment is a dictionary binding/mapping (local) names to language constructs (e.g. entities or elements). An navigation environment of a construct is the dictionary for definitions within that construct or a type/entity referred by that construct. For contexts (and services), these are the sub artifacts defined within that context. For types, entities, elements, these are the elements (or enum symbols) defined within that object or the object's (direct or indirect) type; for association types, these are the elements of the target entity. (The actions and parameters of an object cannot be accessed this way.) context C { type X: Integer; }; // context \"C\" supplies env{ X: type(\"C.X\") } type S { E: Integer; } extend S with { F: Integer; }; // type \"S\" supplies env{ E: elem(\"S\",\"E\"), F: \u2026 } type T: S; // type \"T\" supplies the same env as type \"S\"","title":"Name Resolution - the Basics"},{"location":"apis/cds-compiler/doc/NameResolution/#common-rules","text":"Name resolution name is case sensitive . In general, a model can contain artifacts and members whose name differ in case only; there might be an linter check which informs model writers if they make use of this \"feature\". While being case sensitive might be against the original intention of SQL, it actually conforms to the SQL Specification after abstraction from the lexical syntax, see e.g. SQL-92, \u00a75.2.10 and 5.2.12\u202614 for the semantics of quoted and non-quoted identifiers. In CDL, we just do not transform non-quoted identifiers to all-upper names. Also, CSN-processors are cumbersome to write if they have to deal with (partial/feigned) case-insensitivity. In a future version of this project, we or others might provide a \"use at your own risk\" backend which produce SQL DDL statements without quoted identifiers In CDL, an identifier may be used before its definitions, there is no need of forward declarations Thus, the sequence of definitions inside a block does not matter for the scope rules: using T as OuterT; // introduced to have a name for the shadowed \"T\" type T: String(20); context C { type D: T; // -> C.T -> cds.Integer type T: Integer; type O: OuterT; // -> T -> String(20) } // type C.O: T; // alternative: define \"C.O\" outside the block of \"C\" There are two reasons to do so: When using associations, (mutually) recursive usage is quote common, and forward references are cumbersome. (We can always access shadowed artifacts.) Real-world models will very likely reside in multiple files/resources \u2013 there is no natural order in which the definitions are to be processed.","title":"Common rules"},{"location":"apis/cds-compiler/doc/NameResolution/#resolving-paths","text":"The algorithm for resolution of paths (consisting of dot-connected names) is as follows: First, we try to find the language construct O for the first name in the path; this language construct is called the path base . We resolve the next name in the path by inspecting the navigation environment of O . The found language artifact is our next O . We repeat Step 2 until the complete path is resolved. Even the algorithm for finding the path base follows the same pattern: We have a list of search environments, which we inspect in order. The first hit is the path base. It is an error if the name (the first name of the path) cannot be found in any environment of the list. All but the last environment are constructed from definitions in the current source following the lexical block structure of the source, or a small, fixed number of predefined names (e.g. $projection .) We will call such an environment a lexical search environment . Only the last environment contains bindings defined externally , at least potentially. It can be the environment for predefined artifacts (like cds.Integer ), or the navigation environment of the \"current artifact/member of interest\" (like the elements of the projection source). So the guideline at the end of the previous section essentially becomes lexical scoping first, search in one externally provided environment last . The basic difference between the name resolution strategies is the relevance of the lexical and the last environments, and how they are build.","title":"Resolving paths"},{"location":"apis/cds-compiler/doc/NameResolution/#navigation-environment","text":"The navigation environment might depend on on the argument position. If an object is typed with an array, the environment supplied by that object is usually considered to be empty. For type of references and the to-be-extended element referenced in an inner extend, it is the environment supplied by the array item type: @ A . e : 1 // warning : cannot find `e` for annotation assignments annotation A : array of { e : Integer ; } ; annotate A with { annotate e with @ lineElement ; } annotation B : type of : A . e ; // valid = Integer For the to-be-extended element referenced in an inner extend, we consider the environment supplied by an association to be empty: type A: association to E; entity E { i: Integer; } annotate A with { @targetElem i; // error: do not follow associations } type S { e: Integer; } type T : S; annotate T with { @derivedElem e; // ok: follow derived type }","title":"Navigation environment"},{"location":"apis/cds-compiler/doc/NameResolution/#references-to-main-artifacts","text":"When we have an argument position where we expect a main artifact, the list of lexical search environments depends on the blocks containing the current statement, and the last, non-lexical search environment is independent from the block structure or a current object of interest. A reference to a main artifact can be a references to a projection or view source (table reference after SELECT \u2026 FROM in SQL), association target , type (but not the reference after type of , see below) annotation for a annotation assignment, to-be-extended main artifact of an outer extend structure include , type parameter (should be a constant, not yet). The construction of the list of lexical search environments starts at the innermost block containing the current statement, and then continue to the next outer block: As opposed to HANA-CDS, we skip blocks containing just element definitions (or generally definitions of members like actions). For blocks of context and service definitions, we add the definition inside that block (all definitions in the environment supplied by the context or service can contain more definitions). For the top-level block of the current source, we add the top-level definitions and the bindings for the using declarations. The last, non-lexical search environment is the environments for built-in artifacts. Currently, it contains String for cds.String , similarly LargeString , Integer , Integer64 , Binary , LargeBinary , Decimal , DecimalFloat , Double , Date , Time , Timestamp , DateTime , and Boolean . More artifacts are defined with the options --hana-flavor . When searching for an annotation (after the initial @ ), the last search environment are the model definitions. We conclude this section with a little weird example \u2013 nobody would write models like that, but it demonstrates the exact semantics. nameprefix test; using cds.Boolean as Integer; type Time { @Date // @Date: true, not @cds.Date: true Date: Date; // typeOf(test.Time,Date) = cds.Date, no error C: C.Date; // typeOf(test.Time,C) = test.C.Date, no error } @C.Anno // @test.C.Anno: true define context C { type Date: Time; // test.C.Date -> test.C.Time, not test.Time type Time: Integer; // test.C.Time -> alias Integer -> cds.Boolean type CC: C.Integer; // test.C.CC -> test.C.Integer } @Integer // @cds.Boolean: true (warning: is no annotation) type C.Integer: Time; // test.C.Integer -> test.Time, not test.C.Time In this example, we have the following two lexical search environments: The search environment containing definitions directly inside the block after define context C : Date , Time and CC , but not Integer (but which is in the environment supplied by test.C ). Used as first search environment when resolving main artifact references in the block after define context C , the next search environment is the environment containing top-level definitions. The search environment containing the top-level definitions and using declarations of the source: Integer , Time and C . Used as first search environment when resolving main artifact references outside the block after define context C , the next search environment is the non-lexical environment containing built-in artifacts. There is no lexical search environment for the element definitions supplied by test.Time . We allow paths for names in top-level definitions. All but the last name in the paths are (on-the-fly) contexts, which do not introduce blocks for the lexical scoping: entity N.mid.E { key i: Integer; to1: association to E; // invalid to2: association to mid.E; // invalid to3: association to N.mid.E; // valid } context C { context mid { entity E { key i: Integer; to1: association to E; // valid to2: association to mid.E; // valid to3: association to C.mid.E; // valid } } }","title":"References to main artifacts"},{"location":"apis/cds-compiler/doc/NameResolution/#values-and-references-to-elements","text":"When we have an argument position where we expect a value or a reference to an element, We usually have just one lexical search environment which is sometimes only inpected if the path consists of at least two identifiers. This basically introduces an escape mechanism . The last, non-lexical environments is usually the environment either supplied from an artifact referred by the current statement or supplied by the object containing the current definition. It is often allowed to switch to the \"main artifact name resolution\" by prefixing the path with a : , used usually to refer to constants. The semantics is best explained separately for the diffent groups of argument positions.","title":"Values and references to elements"},{"location":"apis/cds-compiler/doc/NameResolution/#references-in-queries","text":"We start with the most complicated group, because it is known from SQL: references in SELECT item positions \u2013 similar: WHERE , ON , TODO : GROUP BY , ORDER BY (or special?), \u2026 TODO : do the same for as projection on ? TODO : names in mixins The list of search environments is created as follows: The (first) lexical search environment is build from the explicit and implicit alias names for the sources (table references after from ); we also bind $projection to the resulting view/projection elements of the current SELECT if not already used as a table alias. If the current SELECT is a sub-SELECT, we have additional lexical search environments containing alias names for the corresponding outer SELECTs; their $projection bindings are shadowed. For compatibility with ABAP CDS, we have another environment with one entry: we bind $parameters to the parameters of the current view \u2013 the SQL way is to use :param1 instead of $parameters.param1 , see below. The last, non-lexical environment is the environent containing the elements from all source entities of the current SELECT; if an element with the same name is contained in more than one source, this search environment binds the name to an \"ambiguity\" entry (i.e. a reference to it leads to an error) There are no additional non-lexical search environments for the elements of outer SELECTs. The lexical search environments are only inspected if the path consists of at least two identifiers. The above mentioned : -escape mechanism leads to the following name resolution: The first lexical search environment is the the environment containing all parameter names of the current view. The following search environments are the usual ones from the \"main artifact name resolution\"; constant values can be accessed this way ( TODO : probably not now).","title":"References in queries"},{"location":"apis/cds-compiler/doc/NameResolution/#references-to-sibling-elements","text":"The next group is for references in member definitions to other elements of the same main artifact. Such a reference can be a reference to a: calculated field , references in the default value (HANA SQL does not allow this) references in the ON condition of an unmanaged association * reference after type of \u2013 can also be a references to an element of another main artifact The list of search environments is created as follows: There is one lexical search environment, it has one entry: we bind $self to the main artifact, or to be exact: to the current instance of that artifact, e.g. the current line of an entity. This environment is also inspecteded if the path consists of just $self \u2013 useful for on conditions of unmanaged associations. The second and last, the non-lexical search environment is the environment supplied by the object (main artifact or element) where the current member is defined in. The above mentioned : -escape mechanism leads to the \"main artifact name resolution\"; it can be used to access constants, or \u2013for references after type of \u2013 elements of other artifacts. The reason for the $self references is visible in an example with subelements: type T { a: Integer; b = a; // b = a c = $self.a; // c = a } entity E { a: Integer; x: T; // x.b = x.a, x.c = x.a y { a: Integer; b = a; // y.b = y.a c = $self.a; // y.c = a }; } entity S { $self: Integer; // we might complain about such an element name x = $self.$self; // x = $self (the element) }","title":"References to sibling elements"},{"location":"apis/cds-compiler/doc/NameResolution/#other-element-references","text":"A foreign key in the definition of a managed association, is just searched in the environment supplied by the target entity. No lexical search environment is inspected first. In an inner extend , we just search in the navigation environment of the current language construct. No lexical search environment is inspected first. These are actually not necessary references to elements, but also sub artifacts (e.g. extend in extend context ), actions (in the actions clause of extend entity ), or parameters (in the parameters clause of extend action ). TODO : more use cases, like references inside filter conditions of paths.","title":"Other element references"},{"location":"apis/cds-compiler/doc/NameResolution/#paths-as-annotation-values","text":"We can also use paths as annotation assignment values. If there is no annotation definition (there might be a warning for this), then the path cannot be resolved at all. The same is true if the annotation type does not allow path values (then there might be a warning for this) or just a cds.UnspecifiedRef . If there is a annotation definition which allows to use paths by specifying the type cds.ArtifactRef (or a variant of it), then the path resolution works as described in Section \"References to Main Artifacts\" . If there is a annotation definition which allows to use paths by specifying the type cds.ElementRef , then the path resolution works as described in Section \"References sibling elements\" . If that annotation is assigned to a main artifact, then same main artifact mean the main artifact itself.","title":"Paths as annotation values"},{"location":"apis/cds-compiler/doc/NameResolution/#differences-to-hana-cds","text":"The most visible differences in the name resolution semantics of CDx/Language compared to HANA CDS are: Using constant values requires to prefix the path (referring to the constant) with a : . There is a new semantics for paths (without initial : ) used in annotation assignments. In the definitions of sub elements, accessing elements supplied by the corresponding main artifact requires to prefix the path with $self. . Accessing sibling elements works the same as in HANA CDS. It is no problem to define elements which have the same (local) name as the referenced type. In views with more than one source entity, selecting an element e from one source without the use of a table alias (which is not recommented anyway!) suddenly does not compile anymore if another source entity is extended by a new element e . In HANA-CDS, the name resolution works quite uniformly for all argument positions, with most clauses of SELECT being the main exception. It is also compatible to the \"pre-extension\" name resolution semantics of HANA-CDS. This is nice! Why do we specify a different name resolution semantics for CDx/Language? The reason is: we do not want to have the \"extended\" lexical scoping semantics of HANA CDS concerning elements, which heavily relies on the package hierchy. To avoid silent semantic changes with extensions, the HANA-CDS compiler enforces the following properties: Every source belongs to a package; packages can depend on other packages, no cycles are allowed. No language construct can be extended in the same package where it is defined in, no language construct can be extended twice in the same package Artifacts can only be extended by top-level extend statements, elements can only be extended by inner extends (the second is true for CDx/Language, too). These are properties which do not hold for consumers of the CDx Compiler. Additionally, while direct changes in base packages can always lead to semantic changes, the following example shows that this unwanted effect is more likely in HANA-CDS: // BaseApp.cds --- entity E { a: String(20); b { // a: Integer; // CHANGE: introduce sub element x: Integer; }; } // MyExtension.cds --- extend E with { extend b with { z = a; // in CDx/Language: $self.a } } In HANA-CDS, both files compile before and after the change in BaseApp.cds : the element b.z of E refers to element a of E , but after the change to b.a of E , because that element is visible in the base package and all its extensions (we would not see the problem if b.a would have been introduced by an extension in another package). In CDx/Language, the files only compile after the change in BaseApp.cds : (with the same semantics as in HANA-CDS). To make it work before the change, element b.z of E can refer to element a of E by writing this references as $self.a \u2013 with this path, b.z still refers to a of E after the change in BaseApp.cds .","title":"Differences to HANA-CDS"},{"location":"apis/cds-compiler/doc/NameResolution/#summary","text":"To avoid silent semantic changes with extensions or new CDL versions, we follow the following principle: After we have tried to find a local name in an environment containing artifacts or elements which are potentially defined somewhere else (e.g. via an extension), we do not inspect any other environment. In CDx/Language, we basically have two search strategies. But let us start with Strategy 0: Resolving a name in the tail of a path . For a path a.b , we only inspect one environment when resolving b : the environment supplied by a . For example, if a is a structured element, we try to find b in all sub elements of a \u2013 it does not matter whether the sub element b has been directly defined with the definition of element a , or whether is has been defined externally: via an extensions or as an element of the referenced type. Resolving the first name of a path when looking for artifacts . We apply lexical scoping when we refer to types, entities and similar artifacts. When looking for an artifact A , we search in the blocks of surrounding context , service and top-level definitions, starting at the innermost block and ending at the top-level block of the source. To make it clear: we do not search in blocks of type, entity or other definitions, just blocks of contexts (and similar constructs). We only consider definitions within these blocks, not all sub artifacts of the contexts, which might have been introduced by context extensions, or by using a path in the definition, e.g. type MyContext.A: \u2026 . If the search is not successful so far, we finally inpect an environment containing artifacts which are normally not defined in our own source: For the @A of an annotation assignment , we look for A in the definitions property of the model. For all other references, we look for A in the built-in environment, where we define things like cds.Integer . This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ArtifactRef (or variants, future). Resolving the first name of a path when looking for values or elements . We search for elements supplied by the current \"language construct of interest\", which depends on the argument position. The most relevant ones are: The element or artifact where the current (sub) artifact is defined in, i.e. we access sibling elements. The source of the current projection or view. Depending on the argument position, there is an escape mechanism \u2013 which is tried first \u2013 to access also other elements. The most relevant ones are: If the paths starts with the identifier $self , we look for the next name of the path in the environment supplied by the corresponding main artifact of the current element. This is useful for element references inside sub elements to access siblings of ancestors. If a path in most clauses of a view starts with a , and a is an explicit or implicit table alias (which we always see in our source), we look for the next identifier of the path in the environment supplied by the corresponding entity. If the path is prefixed by a : , we actually switch to the other search strategy: looking for artifacts like types. This is useful to access constant values (or for type of ). This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ElementRef (future).","title":"Summary"},{"location":"apis/cds-compiler/doc/ODataTransformation/","text":"ODATA Transformation \u00b6 Prior to the generation of EDMX (Entity Data Model XML) files from a CDS model, the following transformations are applied to the model. Most (but not all) of them become visible both in Augmented CSN and in Plain CSN: Generated foreign key fields for managed associations \u00b6 Managed associations do not have ON-conditions. Instead, they implicitly compare fields (usually the key fields) of the association's target entity with foreign key fields automatically generated into the entity containing the association. Creating the generated fields \u00b6 The ODATA transformation adds the generated foreign key fields to the model. The names of the generated foreign key fields are a concatenation of the association element name, an underscore, and the key name or its alias. Each generated foreign key field gets the name of the corresponding association as an annotation @odata.foreignKey4 . FIXME : Do we want to keep that? For example, for the three association elements a1 , a2 and a3 in the following snippet: service S { entity FromEntity { a1 : association to ToEntity ; // Use target ' s keys a2 : association to ToEntity { x } ; // Explicitly specified key a3 : association to ToEntity { x as z } ; // Key with alias } entity ToEntity { key x : Integer ; key y : Integer ; } } the ODATA transformation would generate foreign key fields in the resulting CSN as follows (shown here in CDS source form): entity FromEntity { a1 : association to ToEntity; a2 : association to ToEntity {x}; @odata.foreignKey4: 'a1' a1_x : Integer; // Generated foreign key @odata.foreignKey4: 'a1' a1_y : Integer; // Generated foreign key @odata.foreignKey4: 'a2' a2_x : Integer; // Generated foreign key @odata.foreignKey4: 'a3' a3_z : Integer; // Generated foreign key } It is an error if the generated fields conflict with existing fields. Annotation propagation \u00b6 The ODATA transformation propagates all annotations from the association to all its generated foreign key fields. FIXME : Do we want to keep that? Connecting the associations with the generated fields \u00b6 The CSN for the managed association elements contains a foreignKeys property, which is a dictionary of foreign key names (taken from the target key names, or from explicitly specified keys resp. their aliases) to the foreign key properties. The ODATA transformation adds a generatedFieldName property to each foreign key, containing the name of the generated foreign key field. Together with the @odata.foreignKey4 annotation described above, this provides a bi-directional link between the association and its generated field. For the example shown above, the CSN for the three association elements a1 , a2 and a3 would look as follows: \"a1\": { \"indexNo\": 1, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"indexNo\": 1, \"path\": \"x\", \"generatedFieldName\": \"a1_x\" }, \"y\": { \"indexNo\": 2, \"path\": \"y\", \"generatedFieldName\": \"a1_y\" } } }, \"a2\": { \"indexNo\": 2, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a2_x\" } } }, \"a3\": { \"indexNo\": 3, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"z\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a3_z\" } } }, (Augmented CSN only): Adding _service to exposed artifacts \u00b6 For each artifact that is exposed by a service (including the service itself), the ODATA transformation adds a non-enumerable property _service to the artifact in the Augmented CSN model, containing a link to the corresponding service artifact. This is convenient for EDMX processors that want to process only exposed artifacts or only artifacts belonging to a specific service. Implicit redirection for non-exposed association targets \u00b6 For each exposed artifact that contains associations, it is checked that the association target is also exposed by the same service. If this is not the case, the ODATA transformation tries to find an \"exposed representative\" of the target, i.e. an exposed projection or view on the target, or an exposed entity that includes the target. If such a representative is found and unique, the association is implicitly redirected to the exposed representative. Note that only projections and projection-like views (i.e. those that have a single from source without union , join or nested queries) are considered as implicit redirection targets. Example: // All these entities are used as association targets below // Simple target entity E1 { key id : Integer ; } // Base target included by E2a entity E2 { key id : Integer ; } entity E2a : E2 { s : String ( 10 ); } // Base target included by S . E3a entity E3 { key id : Integer ; } // Exposure in service service S { entity P1 as projection on E1 ; // Exposes simple target E1 entity P2a as projection on E2a ; // Exposes E2a but also its included E2 entity E3a : E3 { } ; // Exposes included E3 entity Redirected { toE1 : association to E1 ; // Implicitly redirected to P1 ( projection exposes E1 ) toE2 : association to E2 ; // Implicitly redirected to P2a ( projection exposes something that includes E2 ) toE3 : association to E3 ; // Implicitly redirected to E3a ( entity includes E3 ) } } Exposure checking \u00b6 Currently, it is assumed that services must be self-contained, i.e. that all associations within a service must point to targets also exposed by this service. This is checked by the ODATA transformation. FIXME: The same restriction will probably apply when structured types are allowed as element types within exposed entities. Unraveling derived scalar types \u00b6 The ODATA transformation unravels derived scalar types, i.e. primitive types for which the user has provided a custom name (possibly multiple times in a chain) are replaced by the original primitive type. Annotations are propagated upwards in the chain from the primitive type to the most derived type. For example, the following CDS source @IsName : true type Name : String ( 20 ); @IsCustomer : true type CustomerName : Name ; service S { entity E { name : CustomerName ; } } essentially behaves as if the user had written service S { entity E { @IsCustomer: true @IsName: true name : String(20); } } (Tentative): Checking ON-conditions \u00b6 Currently, the ODATA transformation checks for various restrictions regarding ON-conditions of unmanaged associations: only = and AND operators may be used operands may only be paths or values (not expressions) exactly one of the operands must traverse the association The intention behind this restriction is to produce a meaningful value for the ReferentialConstraint of the resulting NavigationProperty . FIXME : Do we want to keep that? (Tentative): Renaming annotations \u00b6 Currently, the ODATA transformation renames various \"shorthand\" annotations to their more elaborate \"long form\". Original name New name @label @Common.Label @label @Common.Label @title @Common.Label @ValueList.entity @Common.ValueList.entity @ValueList.type @Common.ValueList.type @Capabilities.Deletable @Capabilities.DeleteRestrictions.Deletable @Capabilities.Insertable @Capabilities.InsertRestrictions.Insertable @Capabilities.Updatable @Capabilities.UpdateRestrictions.Updatable @readonly @Core.Immutable @important @UI.Importance For the annotation @important (which is renamed to @UI.Importance ), the values true / false are also replaced by the enum constants #High / #Low . FIXME : Do we want to keep that?","title":"ODATA Transformation"},{"location":"apis/cds-compiler/doc/ODataTransformation/#odata-transformation","text":"Prior to the generation of EDMX (Entity Data Model XML) files from a CDS model, the following transformations are applied to the model. Most (but not all) of them become visible both in Augmented CSN and in Plain CSN:","title":"ODATA Transformation"},{"location":"apis/cds-compiler/doc/ODataTransformation/#generated-foreign-key-fields-for-managed-associations","text":"Managed associations do not have ON-conditions. Instead, they implicitly compare fields (usually the key fields) of the association's target entity with foreign key fields automatically generated into the entity containing the association.","title":"Generated foreign key fields for managed associations"},{"location":"apis/cds-compiler/doc/ODataTransformation/#creating-the-generated-fields","text":"The ODATA transformation adds the generated foreign key fields to the model. The names of the generated foreign key fields are a concatenation of the association element name, an underscore, and the key name or its alias. Each generated foreign key field gets the name of the corresponding association as an annotation @odata.foreignKey4 . FIXME : Do we want to keep that? For example, for the three association elements a1 , a2 and a3 in the following snippet: service S { entity FromEntity { a1 : association to ToEntity ; // Use target ' s keys a2 : association to ToEntity { x } ; // Explicitly specified key a3 : association to ToEntity { x as z } ; // Key with alias } entity ToEntity { key x : Integer ; key y : Integer ; } } the ODATA transformation would generate foreign key fields in the resulting CSN as follows (shown here in CDS source form): entity FromEntity { a1 : association to ToEntity; a2 : association to ToEntity {x}; @odata.foreignKey4: 'a1' a1_x : Integer; // Generated foreign key @odata.foreignKey4: 'a1' a1_y : Integer; // Generated foreign key @odata.foreignKey4: 'a2' a2_x : Integer; // Generated foreign key @odata.foreignKey4: 'a3' a3_z : Integer; // Generated foreign key } It is an error if the generated fields conflict with existing fields.","title":"Creating the generated fields"},{"location":"apis/cds-compiler/doc/ODataTransformation/#annotation-propagation","text":"The ODATA transformation propagates all annotations from the association to all its generated foreign key fields. FIXME : Do we want to keep that?","title":"Annotation propagation"},{"location":"apis/cds-compiler/doc/ODataTransformation/#connecting-the-associations-with-the-generated-fields","text":"The CSN for the managed association elements contains a foreignKeys property, which is a dictionary of foreign key names (taken from the target key names, or from explicitly specified keys resp. their aliases) to the foreign key properties. The ODATA transformation adds a generatedFieldName property to each foreign key, containing the name of the generated foreign key field. Together with the @odata.foreignKey4 annotation described above, this provides a bi-directional link between the association and its generated field. For the example shown above, the CSN for the three association elements a1 , a2 and a3 would look as follows: \"a1\": { \"indexNo\": 1, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"indexNo\": 1, \"path\": \"x\", \"generatedFieldName\": \"a1_x\" }, \"y\": { \"indexNo\": 2, \"path\": \"y\", \"generatedFieldName\": \"a1_y\" } } }, \"a2\": { \"indexNo\": 2, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a2_x\" } } }, \"a3\": { \"indexNo\": 3, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"z\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a3_z\" } } },","title":"Connecting the associations with the generated fields"},{"location":"apis/cds-compiler/doc/ODataTransformation/#augmented-csn-only-adding-_service-to-exposed-artifacts","text":"For each artifact that is exposed by a service (including the service itself), the ODATA transformation adds a non-enumerable property _service to the artifact in the Augmented CSN model, containing a link to the corresponding service artifact. This is convenient for EDMX processors that want to process only exposed artifacts or only artifacts belonging to a specific service.","title":"(Augmented CSN only): Adding _service to exposed artifacts"},{"location":"apis/cds-compiler/doc/ODataTransformation/#implicit-redirection-for-non-exposed-association-targets","text":"For each exposed artifact that contains associations, it is checked that the association target is also exposed by the same service. If this is not the case, the ODATA transformation tries to find an \"exposed representative\" of the target, i.e. an exposed projection or view on the target, or an exposed entity that includes the target. If such a representative is found and unique, the association is implicitly redirected to the exposed representative. Note that only projections and projection-like views (i.e. those that have a single from source without union , join or nested queries) are considered as implicit redirection targets. Example: // All these entities are used as association targets below // Simple target entity E1 { key id : Integer ; } // Base target included by E2a entity E2 { key id : Integer ; } entity E2a : E2 { s : String ( 10 ); } // Base target included by S . E3a entity E3 { key id : Integer ; } // Exposure in service service S { entity P1 as projection on E1 ; // Exposes simple target E1 entity P2a as projection on E2a ; // Exposes E2a but also its included E2 entity E3a : E3 { } ; // Exposes included E3 entity Redirected { toE1 : association to E1 ; // Implicitly redirected to P1 ( projection exposes E1 ) toE2 : association to E2 ; // Implicitly redirected to P2a ( projection exposes something that includes E2 ) toE3 : association to E3 ; // Implicitly redirected to E3a ( entity includes E3 ) } }","title":"Implicit redirection for non-exposed association targets"},{"location":"apis/cds-compiler/doc/ODataTransformation/#exposure-checking","text":"Currently, it is assumed that services must be self-contained, i.e. that all associations within a service must point to targets also exposed by this service. This is checked by the ODATA transformation. FIXME: The same restriction will probably apply when structured types are allowed as element types within exposed entities.","title":"Exposure checking"},{"location":"apis/cds-compiler/doc/ODataTransformation/#unraveling-derived-scalar-types","text":"The ODATA transformation unravels derived scalar types, i.e. primitive types for which the user has provided a custom name (possibly multiple times in a chain) are replaced by the original primitive type. Annotations are propagated upwards in the chain from the primitive type to the most derived type. For example, the following CDS source @IsName : true type Name : String ( 20 ); @IsCustomer : true type CustomerName : Name ; service S { entity E { name : CustomerName ; } } essentially behaves as if the user had written service S { entity E { @IsCustomer: true @IsName: true name : String(20); } }","title":"Unraveling derived scalar types"},{"location":"apis/cds-compiler/doc/ODataTransformation/#tentative-checking-on-conditions","text":"Currently, the ODATA transformation checks for various restrictions regarding ON-conditions of unmanaged associations: only = and AND operators may be used operands may only be paths or values (not expressions) exactly one of the operands must traverse the association The intention behind this restriction is to produce a meaningful value for the ReferentialConstraint of the resulting NavigationProperty . FIXME : Do we want to keep that?","title":"(Tentative): Checking ON-conditions"},{"location":"apis/cds-compiler/doc/ODataTransformation/#tentative-renaming-annotations","text":"Currently, the ODATA transformation renames various \"shorthand\" annotations to their more elaborate \"long form\". Original name New name @label @Common.Label @label @Common.Label @title @Common.Label @ValueList.entity @Common.ValueList.entity @ValueList.type @Common.ValueList.type @Capabilities.Deletable @Capabilities.DeleteRestrictions.Deletable @Capabilities.Insertable @Capabilities.InsertRestrictions.Insertable @Capabilities.Updatable @Capabilities.UpdateRestrictions.Updatable @readonly @Core.Immutable @important @UI.Importance For the annotation @important (which is renamed to @UI.Importance ), the values true / false are also replaced by the enum constants #High / #Low . FIXME : Do we want to keep that?","title":"(Tentative): Renaming annotations"},{"location":"apis/cds-compiler/doc/toSwagger/","text":"To Swagger transformation \u00b6 \"The OpenAPI Specification, originally known as the Swagger Specification, is a specification for machine-readable interface files for describing, producing, consuming, and visualizing RESTful Web services.\" - Wikipedia In 2015 the Swagger specification was renamed to the OpenAPI specification. The compiler's functionality provides an output as per the OpenAPI 3.0.0 specification, regardless of being called 'to Swagger'. Transform a CDS model to a swagger json file \u00b6 Executing the compiler with the --to-swagger option or in short -S gives the opportunity based on your CDS model an OpenAPI json file(s) to be produced. In addition to the option, a mandatory flag(s) needs to be added. The flags can be a comma-separated combination of \"json\" and \"csn\". The json flag generate output for each service in the model, the csn flag the preprocessed model with to swagger specifics. Basic information \u00b6 Multiple services generation is supported as for each service in the input CDS model a separate swagger document is created. Every OpenAPI 3.0.0 document should have an \"openapi\" property, which specifies the version of the specification followed, in our case the \"3.0.0\" value is assigned. Also, the document receives a property \"info\" with \"title\" and value is the name of the corresponding service for the swagger document. Paths \u00b6 The \"paths\" property of the OpenAPI document describes the available paths and operations for the API in question. The unbound actions and functions play a role as a feeder for the information in the paths property of the swagger model. As the paths property is a mandatory one, if no content for generation is found in the model, then an empty object will be generated. HTTP method \u00b6 The corresponding definitions of paths in CDS model are the (un)bound actions and functions. Such an action or a function must be annotated with the specified annotation so the generator takes it in mind. The annotation declares the desired HTTP method and the response code. Three different syntaxes are available: 1. @Swagger.GET : 200 - a GET operation with response code 200 is generated 2. @Swagger.POST - a POST operation with the default response code is generated 3. @Swagger.DELETE : [202, 204, 200] - a DELETE operation with responses for every of 202, 204 and 200 codes or the three variants can be combined in: @Swagger : { GET : 200, POST, DELETE : [202, 204, 200] } To define a range of response codes, you may use the following range definitions: 1XX , 2XX , 3XX , 4XX , and 5XX . By the OpenAPI specification GET , PUT , POST , DELETE , OPTIONS , HEAD , PATCH and TRACE are the supported http verbs. Still not supported in the CDS compiler are only OPTIONS and TRACE . If the user decides not to specify a response code(using the @Swagger. method ), then an operation with default code will be generated. The default code for a PATCH operation is 204 , for the rest of the operations is 200 . Path to an individual endpoint \u00b6 If a relative path to an individual endpoint is not specified by the user, then the default one is assigned. This default path is composed from the service name, the entity name(if the action/function is bound) and the name of the action. An example for bound action will be: /com.test.MyService.MyEntyty/myAction and for unbound: /com.test.MyService/myFunction . For the case when the user wants an operation to serves under a specific path, that can be arranged with the @Swagger.path annotation. The custom path can include parameters e.g. @Swagger.path : '/MyPath/bookByName/{bookName}' . In this case the user has to take care the names of the parameters to correspond to the name of parameters specified in the action/function declaration. Operations parameters \u00b6 The OpenAPI specification states that a parameter can have location( the property 'in' of a parameter object ) with one of the following values: - query - header - path - cookie With the @Swagger.parameter annotation applied to a parameter this location can be specified. If not specified - query is taken as value. If a value path is given for the @Swagger.parameter annotation, this means that automatically the name of the parameter is prepended to the path name. This is valid only if a @Swagger.path annotation is not used. The parameter location resolving is illustrated with the following example: Given is the CDS model ... actions { @Swagger.GET action bookById(@Swagger.parameter: 'path' bookId : Integer) returns Book; @Swagger.GET action bookByName(@Swagger.parameter: 'cookie' bookName: String) returns Book; @Swagger.GET action booksByAuthor(authorName: String) returns array of Book; }; ... the result will look like: ... \"paths\" : { \"/Bookstore/Book/bookById/{bookId}\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookId\" , \"in\" : \"path\" , \"description\" : \"\" , \"required\" : true , \"schema\" : { \"type\" : \"integer\" , \"format\" : \"int32\" } } ] } }, \"/Bookstore/Book/bookByName\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookName\" , \"in\" : \"cookie\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } }, \"/Bookstore/Book/booksByAuthor\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"authorName\" , \"in\" : \"query\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } } } ... Request body \u00b6 For the @Swagger.parameter annotation can be given one more value - requestBody . This value can be used in a POST , PUT or PATCH requests. It indicates that for the specified parameter a requestBody property will be generated for the path object. Only one parameter can be annotated with this value - the first found will be taken in mind. The annotated parameter will not be included in the parameters property. Arrayed responses \u00b6 As seen in the example above, if an action/function has a return type ... returns array of <entity_name> , then for the OpenAPI document the schema for this specific response is of type array with items of type the pointed entity and a header, which is a link to the next page of responses, or: \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/<entity_name>\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } } , Schemas \u00b6 One of the major components in an OpenAPI interface file is the components' schemas. The corresponding artifacts to schemas in the OpenAPI file from a CDS model are the definitions. Executing the following model: service Petstore { entity Pet { id : Integer64 not null; name : String not null; tag : String(10); }; }; will result in: ... \"components\" : { \"schemas\" : { \"Petstore.Pet\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"tag\" : { \"maxLength\" : 10 , \"type\" : \"string\" } } } ... In short, all the artifacts enclosed in a service definition of a CDS model are transformed into a top-level definitions into the schemas part of an OpenAPI json file, except for the services/contexts, unbound actions and functions, namespaces. A service declaration in a CDS model should be self-containing, which means that is declarations outside of the service are used, an error will be thrown. The only case that is an exception here is when an element is of a type which is user-defined and the user-defined type is builtin and outside of the service, then the type of the element is expanded to the builtin type. When we have an association the target should be from the current service or exposed in the current service via projection. Every top-level artifact is represented like a Schema Object as described in the OpenAPI specification The associations are treated regarding their cardinality respectively: - to-one leads to a single object response with schema as the target - to-many is represented as an array with items of a type the corresponding target Association redirection in projections \u00b6 This redirection is expressed in switching the target of an association, which is part of a projection to the corresponding projection(on the target of the association in the underlying context) from the current service. For example the following model: service Bookstore { entity Book as projection on BookstoreContext . Book ; entity Author as projection on BookstoreContext . Author ; @Swagger . GET action books () returns array of Book ; } ; context BookstoreContext { entity Book { id : Integer64 not null ; name : String not null ; author : association to Author ; } ; entity Author { key id : Integer ; firstName : String ; lastName : String ; } ; } ; will result in: { \"openapi\" : \"3.0.0\" , \"info\" : { \"version\" : \"\" , \"title\" : \"Bookstore\" }, \"paths\" : { \"/Bookstore/books\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } } } } }, \"components\" : { \"schemas\" : { \"Bookstore.Book\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"author\" : { \"$ref\" : \"#/components/schemas/Bookstore.Author\" } } }, \"Bookstore.Author\" : { \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"firstName\" : { \"type\" : \"string\" }, \"lastName\" : { \"type\" : \"string\" } } }, \"Error\" : { \"required\" : [ \"code\" , \"message\" ], \"properties\" : { \"code\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"message\" : { \"type\" : \"string\" } } } } } } The same redirection is performed for user-defined types, as the type declaration should be also exposed to the service in question. CDS Views \u00b6 From a view declared in the CDS model is generated a schema similar to the one coming from an entity, as the logic from the view is not applicable for describe in the API spec. Enums \u00b6 Declared in the CDS model enums are generated as the values are taken in mind. ... entity MyEntity { elem : String enum { foo = 'bar'; }; }; ... The output: ... \"components\" : { \"schemas\" : { \"MyEntity\" : { \"properties\" : { \"elem\" : { \"enum\" : [ \"bar\" ], \"type\" : \"string\" } } }, ...","title":"To Swagger transformation"},{"location":"apis/cds-compiler/doc/toSwagger/#to-swagger-transformation","text":"\"The OpenAPI Specification, originally known as the Swagger Specification, is a specification for machine-readable interface files for describing, producing, consuming, and visualizing RESTful Web services.\" - Wikipedia In 2015 the Swagger specification was renamed to the OpenAPI specification. The compiler's functionality provides an output as per the OpenAPI 3.0.0 specification, regardless of being called 'to Swagger'.","title":"To Swagger transformation"},{"location":"apis/cds-compiler/doc/toSwagger/#transform-a-cds-model-to-a-swagger-json-file","text":"Executing the compiler with the --to-swagger option or in short -S gives the opportunity based on your CDS model an OpenAPI json file(s) to be produced. In addition to the option, a mandatory flag(s) needs to be added. The flags can be a comma-separated combination of \"json\" and \"csn\". The json flag generate output for each service in the model, the csn flag the preprocessed model with to swagger specifics.","title":"Transform a CDS model to a swagger json file"},{"location":"apis/cds-compiler/doc/toSwagger/#basic-information","text":"Multiple services generation is supported as for each service in the input CDS model a separate swagger document is created. Every OpenAPI 3.0.0 document should have an \"openapi\" property, which specifies the version of the specification followed, in our case the \"3.0.0\" value is assigned. Also, the document receives a property \"info\" with \"title\" and value is the name of the corresponding service for the swagger document.","title":"Basic information"},{"location":"apis/cds-compiler/doc/toSwagger/#paths","text":"The \"paths\" property of the OpenAPI document describes the available paths and operations for the API in question. The unbound actions and functions play a role as a feeder for the information in the paths property of the swagger model. As the paths property is a mandatory one, if no content for generation is found in the model, then an empty object will be generated.","title":"Paths"},{"location":"apis/cds-compiler/doc/toSwagger/#http-method","text":"The corresponding definitions of paths in CDS model are the (un)bound actions and functions. Such an action or a function must be annotated with the specified annotation so the generator takes it in mind. The annotation declares the desired HTTP method and the response code. Three different syntaxes are available: 1. @Swagger.GET : 200 - a GET operation with response code 200 is generated 2. @Swagger.POST - a POST operation with the default response code is generated 3. @Swagger.DELETE : [202, 204, 200] - a DELETE operation with responses for every of 202, 204 and 200 codes or the three variants can be combined in: @Swagger : { GET : 200, POST, DELETE : [202, 204, 200] } To define a range of response codes, you may use the following range definitions: 1XX , 2XX , 3XX , 4XX , and 5XX . By the OpenAPI specification GET , PUT , POST , DELETE , OPTIONS , HEAD , PATCH and TRACE are the supported http verbs. Still not supported in the CDS compiler are only OPTIONS and TRACE . If the user decides not to specify a response code(using the @Swagger. method ), then an operation with default code will be generated. The default code for a PATCH operation is 204 , for the rest of the operations is 200 .","title":"HTTP method"},{"location":"apis/cds-compiler/doc/toSwagger/#path-to-an-individual-endpoint","text":"If a relative path to an individual endpoint is not specified by the user, then the default one is assigned. This default path is composed from the service name, the entity name(if the action/function is bound) and the name of the action. An example for bound action will be: /com.test.MyService.MyEntyty/myAction and for unbound: /com.test.MyService/myFunction . For the case when the user wants an operation to serves under a specific path, that can be arranged with the @Swagger.path annotation. The custom path can include parameters e.g. @Swagger.path : '/MyPath/bookByName/{bookName}' . In this case the user has to take care the names of the parameters to correspond to the name of parameters specified in the action/function declaration.","title":"Path to an individual endpoint"},{"location":"apis/cds-compiler/doc/toSwagger/#operations-parameters","text":"The OpenAPI specification states that a parameter can have location( the property 'in' of a parameter object ) with one of the following values: - query - header - path - cookie With the @Swagger.parameter annotation applied to a parameter this location can be specified. If not specified - query is taken as value. If a value path is given for the @Swagger.parameter annotation, this means that automatically the name of the parameter is prepended to the path name. This is valid only if a @Swagger.path annotation is not used. The parameter location resolving is illustrated with the following example: Given is the CDS model ... actions { @Swagger.GET action bookById(@Swagger.parameter: 'path' bookId : Integer) returns Book; @Swagger.GET action bookByName(@Swagger.parameter: 'cookie' bookName: String) returns Book; @Swagger.GET action booksByAuthor(authorName: String) returns array of Book; }; ... the result will look like: ... \"paths\" : { \"/Bookstore/Book/bookById/{bookId}\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookId\" , \"in\" : \"path\" , \"description\" : \"\" , \"required\" : true , \"schema\" : { \"type\" : \"integer\" , \"format\" : \"int32\" } } ] } }, \"/Bookstore/Book/bookByName\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookName\" , \"in\" : \"cookie\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } }, \"/Bookstore/Book/booksByAuthor\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"authorName\" , \"in\" : \"query\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } } } ...","title":"Operations parameters"},{"location":"apis/cds-compiler/doc/toSwagger/#request-body","text":"For the @Swagger.parameter annotation can be given one more value - requestBody . This value can be used in a POST , PUT or PATCH requests. It indicates that for the specified parameter a requestBody property will be generated for the path object. Only one parameter can be annotated with this value - the first found will be taken in mind. The annotated parameter will not be included in the parameters property.","title":"Request body"},{"location":"apis/cds-compiler/doc/toSwagger/#arrayed-responses","text":"As seen in the example above, if an action/function has a return type ... returns array of <entity_name> , then for the OpenAPI document the schema for this specific response is of type array with items of type the pointed entity and a header, which is a link to the next page of responses, or: \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/<entity_name>\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } } ,","title":"Arrayed responses"},{"location":"apis/cds-compiler/doc/toSwagger/#schemas","text":"One of the major components in an OpenAPI interface file is the components' schemas. The corresponding artifacts to schemas in the OpenAPI file from a CDS model are the definitions. Executing the following model: service Petstore { entity Pet { id : Integer64 not null; name : String not null; tag : String(10); }; }; will result in: ... \"components\" : { \"schemas\" : { \"Petstore.Pet\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"tag\" : { \"maxLength\" : 10 , \"type\" : \"string\" } } } ... In short, all the artifacts enclosed in a service definition of a CDS model are transformed into a top-level definitions into the schemas part of an OpenAPI json file, except for the services/contexts, unbound actions and functions, namespaces. A service declaration in a CDS model should be self-containing, which means that is declarations outside of the service are used, an error will be thrown. The only case that is an exception here is when an element is of a type which is user-defined and the user-defined type is builtin and outside of the service, then the type of the element is expanded to the builtin type. When we have an association the target should be from the current service or exposed in the current service via projection. Every top-level artifact is represented like a Schema Object as described in the OpenAPI specification The associations are treated regarding their cardinality respectively: - to-one leads to a single object response with schema as the target - to-many is represented as an array with items of a type the corresponding target","title":"Schemas"},{"location":"apis/cds-compiler/doc/toSwagger/#association-redirection-in-projections","text":"This redirection is expressed in switching the target of an association, which is part of a projection to the corresponding projection(on the target of the association in the underlying context) from the current service. For example the following model: service Bookstore { entity Book as projection on BookstoreContext . Book ; entity Author as projection on BookstoreContext . Author ; @Swagger . GET action books () returns array of Book ; } ; context BookstoreContext { entity Book { id : Integer64 not null ; name : String not null ; author : association to Author ; } ; entity Author { key id : Integer ; firstName : String ; lastName : String ; } ; } ; will result in: { \"openapi\" : \"3.0.0\" , \"info\" : { \"version\" : \"\" , \"title\" : \"Bookstore\" }, \"paths\" : { \"/Bookstore/books\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } } } } }, \"components\" : { \"schemas\" : { \"Bookstore.Book\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"author\" : { \"$ref\" : \"#/components/schemas/Bookstore.Author\" } } }, \"Bookstore.Author\" : { \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"firstName\" : { \"type\" : \"string\" }, \"lastName\" : { \"type\" : \"string\" } } }, \"Error\" : { \"required\" : [ \"code\" , \"message\" ], \"properties\" : { \"code\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"message\" : { \"type\" : \"string\" } } } } } } The same redirection is performed for user-defined types, as the type declaration should be also exposed to the service in question.","title":"Association redirection in projections"},{"location":"apis/cds-compiler/doc/toSwagger/#cds-views","text":"From a view declared in the CDS model is generated a schema similar to the one coming from an entity, as the logic from the view is not applicable for describe in the API spec.","title":"CDS Views"},{"location":"apis/cds-compiler/doc/toSwagger/#enums","text":"Declared in the CDS model enums are generated as the values are taken in mind. ... entity MyEntity { elem : String enum { foo = 'bar'; }; }; ... The output: ... \"components\" : { \"schemas\" : { \"MyEntity\" : { \"properties\" : { \"elem\" : { \"enum\" : [ \"bar\" ], \"type\" : \"string\" } } }, ...","title":"Enums"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/","text":"API Migration \u00b6 Status Oct 2019: this document is still valid, but the recommended API will change (again) in the near future. The future version of this document (renamed to API.md ) will basically explain the recommended API, the migration will only be a minor aspect and explained in a later section. With revision 1.0.24, the CDS compiler offers new API backend functions, i.e. new functions for the generation of output from (augmented) CSN models. The new functions and their options are closely aligned with the new command line interface cdsc . The old backend functions are deprecated, will not be extended with new features, and will be removed in a subsequent release. Note that only these API functions from lib/main.js are supported - all internal functions are subject to change without notice . Please see the function headers in lib/backends.js for a description of the new API functions (for a snapshot of the current version, see below). Some helpful hints \u00b6 Please note the following general concepts regarding the new API functions: - The behavior of the compiler and of all backend API functions is controlled by a common options object, with subsections for each backend function, e.g. options: {toHana: {src: true}, toOdata: {version: 'v2'}} . - Options can either be specified with one of the compile functions (transported within the model to the backends), or explicitly at the invocation of a backend API function. - Options are merged, with precedence given to those specified explicitly at the backend API functions. - When invoking a backend function with options that all belong to this backend function, the subsection wrapper can be omitted, i.e. toHana(model, {toHana: {src: true}}) is equivalent to toHana(model, {src: true}) . - Most backend API functions have a combination of options controlling what is generated (e.g. toHana: {src: true} ) and options modifying how things are generated (e.g. toOdata: {version: 'v2'} ). Migration guide \u00b6 The following table shows replacements for the deprecated API functions (relying on default options where possible): Deprecated function call New function call toHanaCdl(model) toHana(model) forHana(model) toHana(model, {csn: true}) toOdataOutput(model, {oDataVersion: 'v2'} toOdata(model, {version: 'v2', xml: true, json: true, separate: true, combined: true, csn: true}) toSqlDdl(model) toSql(model) compactJson(model) toCsn(model) Changes in behavior \u00b6 The following changes have been made to the behavior of toOdata in comparison to toOdataOutput : - Output is now generated either for ODATA V2 or for V4. The old toOdataOutput function produced the annotations output with an extra invocation of the backend using oDataVersion: 'v4' even if the original invocation specified oDataVersion: 'v2' , resulting in slightly different output. The combined output always had the correct versioning. - The metadata_json output is now an object, not a string. Snapshot of backend API function documentation \u00b6 Note that these backend API functions are all exposed in lib/main.js (which is the only external API ), but their documentation is currently located in lib/backends.js (this will likely change). toHana(model, options) \u00b6 // Transform an augmented CSN 'model' into HANA-compatible CDS source. // The following options control what is actually generated: // options : { // toHana.names : either 'plain' (generate uppercased flattened entity names with // underscores) or 'quoted' (default, generate entity names with nested // contexts as in CDL) // toHana.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toHana.src : if true, generate HANA CDS source files (default) // toHana.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toHana.names' is not provided, 'quoted' is used. // If 'toHana.associations' is not provided, 'assocs' is used. // If neither 'toHana.src' nor 'toHana.csn' are provided, the default is to generate only HANA CDS // source files. // If all provided options are part of 'toHana', the 'toHana' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // hdbcds : a dictionary of top-level artifact names, containing for each name 'X': // <X> : the HANA CDS source string of the artifact 'X'. Please note that the // name of 'X' may contain characters that are not legal for filenames on // all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } function toHana(model, options) { ... } toOdata(model, options) \u00b6 // Generate ODATA for augmented CSN `model` using `options` . // Before anything is generated , the following transformations are applied to 'model' : // FIXME : Verify that this is still correct // - Flatten structured elements ( and foreign keys of managed associations pointing to // keys that are themselves managed associations ). // - Generate foreign key fields for entities with managed associations ( annotated with // '@odata.foreignKey4' ). Propagate along projections accordingly . Names are built using // < assoc > _ < key > , conflicts are checked . // - Complete the 'foreignKeys' property for all managed associations , so that there // is always a 'generatedFieldName' for the corresponding generated foreign key field . // - Implicitly redirect associations based on exposure // - Check that exposed associations do not point to non - exposed targets // - Unravel derived type chains , propagating annotations upwards . // - Rename annotations according to a fixed list of short - hands // The following options control what is actually generated : // options : { // toOdata . version : either 'v2' or 'v4' ( default ) // toOdata . xml : if true , generate XML output ( default ) // toOdata . json : if true , generate JSON output ( not available for ODATA V2 ) // toOdata . separate : if true , generate XML 'metadata' and XML 'annotations' separately // toOdata . combined : if true , generate XML metadata and XML annotations together as // 'combined' ( default ) // toOdata . csn : if true , generate the transformed CSN model // } // Options provided here are merged with ( and take precedence over ) options from 'model' . // If 'toOdata.version' is not provided , 'v4' is used . // If neither 'toOdata.xml' nor 'toOdata.json' nor 'toOdata.csn' are provided , the default is // to generate only XML output . If neither 'toOdata.separate' nor 'toOdata.combined' are provided , // the default is to generate only combined XML output . // If all provided options are part of 'toOdata' , the 'toOdata' wrapper can be omitted . // // The result object contains the generation results as follows ( as enabled in 'options' ): // result : { // csn : the ( compact ) transformed CSN model including all services // _augmentedCsn : ( subject to change ): the augmented CSN model including all services // services : a dictionary of service names , containing for each name : // < servicename > : { // annotations : an XML string with EDMX annotations for service 'svc' // metadata : an XML string with EDMX metadata for service 'svc' // combined : an XML string with both EDMX metadata and annotations for service 'svc' // metadata_json : a JSON object ( not a string ! ) with EDM metadata for service 'svc' // } // messages : an array of strings with warnings ( if any ) // } // If 'model' does not contain any services , 'csn' will still contain the transformed model , but // 'services' will be an empty dictionary . // // Throws a CompilationError on errors . function toOdata ( model , options ) { ... } toCdl(model, options) \u00b6 // Generate CDS source text for augmented CSN model 'model' . // The following options control what is actually generated : // options : { // FIXME : This option should be removed and something like 'toCdl.dialect: 'hana' be // used instead. // hanaFlavor : if true, HANA-specific source dialect is generated (affects e.g. the // translation of ' $ self . foo ' in paths and ::-ish namespace declarations ) // } // One source is created per top - level artifact . // Return a dictionary of top - level artifacts // by their names , like this : // { \"foo\" : \"using XY; context foo {...};\" , // \"bar::wiz\" : \"namespace bar::; entity wiz {...};\" // } // Throws a CompilationError on errors . function toCdl ( model , options ) { ... } toSwagger(model, options) \u00b6 // Generate OpenAPI JSON version 3 for the augmented CSN 'model'. // Return an object representing the Swagger JSON: // { // openapi: '3.0.0', // info: { ... }, // paths: { ...}, // components: { // schemas: { ... } // } // } // // Throws a CompilationError on errors. function toSwagger(model, options) { ... } toSql(model, options) \u00b6 // Generate SQL DDL statements for augmented CSN 'model'. // The following options control what is actually generated: // options : { // toSql.names : either 'plain' (generate uppercased flattened table/view names with // underscores) or 'quoted' (default, generate quoted table/view names // with dots as in CDL) // toSql.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toSql.src : if true, generate SQL DDL source files (default) // toSql.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toSql.names' is not provided, 'quoted' is used. // If 'toSql.associations' is not provided, 'assocs' is used. // If neither 'toSql.src' nor 'toSql.csn' are provided, the default is to generate only SQL DDL // source files. // If all provided options are part of 'toSql', the 'toSql' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // sql : a dictionary of top-level artifact names, containing for each name 'X': // <X> : a string with SQL DDL statements for artifact 'X', terminated with ';'. // Please note that the name of 'X' may contain characters that are not // legal for filenames on all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } // Throws a CompilationError on errors. toCsn(model, options) \u00b6 // Generate compact CSN for augmented CSN 'model' // The following options control what is actually generated: // options : { // testMode : if true, the result is extra-stable for automated tests (sorted, no 'version') // } // Options provided here are merged with (and take precedence over) options from 'model'. function toCsn(model, options) { ... }","title":"API Migration"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#api-migration","text":"Status Oct 2019: this document is still valid, but the recommended API will change (again) in the near future. The future version of this document (renamed to API.md ) will basically explain the recommended API, the migration will only be a minor aspect and explained in a later section. With revision 1.0.24, the CDS compiler offers new API backend functions, i.e. new functions for the generation of output from (augmented) CSN models. The new functions and their options are closely aligned with the new command line interface cdsc . The old backend functions are deprecated, will not be extended with new features, and will be removed in a subsequent release. Note that only these API functions from lib/main.js are supported - all internal functions are subject to change without notice . Please see the function headers in lib/backends.js for a description of the new API functions (for a snapshot of the current version, see below).","title":"API Migration"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#some-helpful-hints","text":"Please note the following general concepts regarding the new API functions: - The behavior of the compiler and of all backend API functions is controlled by a common options object, with subsections for each backend function, e.g. options: {toHana: {src: true}, toOdata: {version: 'v2'}} . - Options can either be specified with one of the compile functions (transported within the model to the backends), or explicitly at the invocation of a backend API function. - Options are merged, with precedence given to those specified explicitly at the backend API functions. - When invoking a backend function with options that all belong to this backend function, the subsection wrapper can be omitted, i.e. toHana(model, {toHana: {src: true}}) is equivalent to toHana(model, {src: true}) . - Most backend API functions have a combination of options controlling what is generated (e.g. toHana: {src: true} ) and options modifying how things are generated (e.g. toOdata: {version: 'v2'} ).","title":"Some helpful hints"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#migration-guide","text":"The following table shows replacements for the deprecated API functions (relying on default options where possible): Deprecated function call New function call toHanaCdl(model) toHana(model) forHana(model) toHana(model, {csn: true}) toOdataOutput(model, {oDataVersion: 'v2'} toOdata(model, {version: 'v2', xml: true, json: true, separate: true, combined: true, csn: true}) toSqlDdl(model) toSql(model) compactJson(model) toCsn(model)","title":"Migration guide"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#changes-in-behavior","text":"The following changes have been made to the behavior of toOdata in comparison to toOdataOutput : - Output is now generated either for ODATA V2 or for V4. The old toOdataOutput function produced the annotations output with an extra invocation of the backend using oDataVersion: 'v4' even if the original invocation specified oDataVersion: 'v2' , resulting in slightly different output. The combined output always had the correct versioning. - The metadata_json output is now an object, not a string.","title":"Changes in behavior"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#snapshot-of-backend-api-function-documentation","text":"Note that these backend API functions are all exposed in lib/main.js (which is the only external API ), but their documentation is currently located in lib/backends.js (this will likely change).","title":"Snapshot of backend API function documentation"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#tohanamodel-options","text":"// Transform an augmented CSN 'model' into HANA-compatible CDS source. // The following options control what is actually generated: // options : { // toHana.names : either 'plain' (generate uppercased flattened entity names with // underscores) or 'quoted' (default, generate entity names with nested // contexts as in CDL) // toHana.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toHana.src : if true, generate HANA CDS source files (default) // toHana.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toHana.names' is not provided, 'quoted' is used. // If 'toHana.associations' is not provided, 'assocs' is used. // If neither 'toHana.src' nor 'toHana.csn' are provided, the default is to generate only HANA CDS // source files. // If all provided options are part of 'toHana', the 'toHana' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // hdbcds : a dictionary of top-level artifact names, containing for each name 'X': // <X> : the HANA CDS source string of the artifact 'X'. Please note that the // name of 'X' may contain characters that are not legal for filenames on // all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } function toHana(model, options) { ... }","title":"toHana(model, options)"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#toodatamodel-options","text":"// Generate ODATA for augmented CSN `model` using `options` . // Before anything is generated , the following transformations are applied to 'model' : // FIXME : Verify that this is still correct // - Flatten structured elements ( and foreign keys of managed associations pointing to // keys that are themselves managed associations ). // - Generate foreign key fields for entities with managed associations ( annotated with // '@odata.foreignKey4' ). Propagate along projections accordingly . Names are built using // < assoc > _ < key > , conflicts are checked . // - Complete the 'foreignKeys' property for all managed associations , so that there // is always a 'generatedFieldName' for the corresponding generated foreign key field . // - Implicitly redirect associations based on exposure // - Check that exposed associations do not point to non - exposed targets // - Unravel derived type chains , propagating annotations upwards . // - Rename annotations according to a fixed list of short - hands // The following options control what is actually generated : // options : { // toOdata . version : either 'v2' or 'v4' ( default ) // toOdata . xml : if true , generate XML output ( default ) // toOdata . json : if true , generate JSON output ( not available for ODATA V2 ) // toOdata . separate : if true , generate XML 'metadata' and XML 'annotations' separately // toOdata . combined : if true , generate XML metadata and XML annotations together as // 'combined' ( default ) // toOdata . csn : if true , generate the transformed CSN model // } // Options provided here are merged with ( and take precedence over ) options from 'model' . // If 'toOdata.version' is not provided , 'v4' is used . // If neither 'toOdata.xml' nor 'toOdata.json' nor 'toOdata.csn' are provided , the default is // to generate only XML output . If neither 'toOdata.separate' nor 'toOdata.combined' are provided , // the default is to generate only combined XML output . // If all provided options are part of 'toOdata' , the 'toOdata' wrapper can be omitted . // // The result object contains the generation results as follows ( as enabled in 'options' ): // result : { // csn : the ( compact ) transformed CSN model including all services // _augmentedCsn : ( subject to change ): the augmented CSN model including all services // services : a dictionary of service names , containing for each name : // < servicename > : { // annotations : an XML string with EDMX annotations for service 'svc' // metadata : an XML string with EDMX metadata for service 'svc' // combined : an XML string with both EDMX metadata and annotations for service 'svc' // metadata_json : a JSON object ( not a string ! ) with EDM metadata for service 'svc' // } // messages : an array of strings with warnings ( if any ) // } // If 'model' does not contain any services , 'csn' will still contain the transformed model , but // 'services' will be an empty dictionary . // // Throws a CompilationError on errors . function toOdata ( model , options ) { ... }","title":"toOdata(model, options)"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#tocdlmodel-options","text":"// Generate CDS source text for augmented CSN model 'model' . // The following options control what is actually generated : // options : { // FIXME : This option should be removed and something like 'toCdl.dialect: 'hana' be // used instead. // hanaFlavor : if true, HANA-specific source dialect is generated (affects e.g. the // translation of ' $ self . foo ' in paths and ::-ish namespace declarations ) // } // One source is created per top - level artifact . // Return a dictionary of top - level artifacts // by their names , like this : // { \"foo\" : \"using XY; context foo {...};\" , // \"bar::wiz\" : \"namespace bar::; entity wiz {...};\" // } // Throws a CompilationError on errors . function toCdl ( model , options ) { ... }","title":"toCdl(model, options)"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#toswaggermodel-options","text":"// Generate OpenAPI JSON version 3 for the augmented CSN 'model'. // Return an object representing the Swagger JSON: // { // openapi: '3.0.0', // info: { ... }, // paths: { ...}, // components: { // schemas: { ... } // } // } // // Throws a CompilationError on errors. function toSwagger(model, options) { ... }","title":"toSwagger(model, options)"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#tosqlmodel-options","text":"// Generate SQL DDL statements for augmented CSN 'model'. // The following options control what is actually generated: // options : { // toSql.names : either 'plain' (generate uppercased flattened table/view names with // underscores) or 'quoted' (default, generate quoted table/view names // with dots as in CDL) // toSql.associations : either 'assocs' (default, keep associations as they are if possible) // or 'joins' (replace associations by joins) // toSql.src : if true, generate SQL DDL source files (default) // toSql.csn : if true, generate the transformed CSN model // } // Options provided here are merged with (and take precedence over) options from 'model'. // If 'toSql.names' is not provided, 'quoted' is used. // If 'toSql.associations' is not provided, 'assocs' is used. // If neither 'toSql.src' nor 'toSql.csn' are provided, the default is to generate only SQL DDL // source files. // If all provided options are part of 'toSql', the 'toSql' wrapper can be omitted. // The result object contains the generation results as follows (as enabled in 'options'): // result : { // csn : the (compact) transformed CSN model // _augmentedCsn : (subject to change): the augmented CSN model // sql : a dictionary of top-level artifact names, containing for each name 'X': // <X> : a string with SQL DDL statements for artifact 'X', terminated with ';'. // Please note that the name of 'X' may contain characters that are not // legal for filenames on all operating systems (e.g. ':', '\\' or '/'). // messages : an array of strings with warnings (if any) // } // Throws a CompilationError on errors.","title":"toSql(model, options)"},{"location":"apis/cds-compiler/doc/doc/ApiMigration/#tocsnmodel-options","text":"// Generate compact CSN for augmented CSN 'model' // The following options control what is actually generated: // options : { // testMode : if true, the result is extra-stable for automated tests (sorted, no 'version') // } // Options provided here are merged with (and take precedence over) options from 'model'. function toCsn(model, options) { ... }","title":"toCsn(model, options)"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/","text":"ChangeLog for cdx compiler and backends (Archive) \u00b6 Note: beta fixes, changes and features are usually not listed in this ChangeLog. The compiler behaviour concerning beta features can change at any time without notice. Version 1.23.2 \u00b6 Changes Association to Join Transformation: Validate paths of an expression in the projection to be compliant with the ON condition path constraints if such an expression is used in a mixin. Reject recursive or non-bijective $self expressions. Reject casting of a structured select item to a different type. OData: Update vocabularies Capabilities , Common , UI , Validation Fixes Association to Join Transformation: Resolve compound ON conditions with multiple logical terms and/or references to different associations via $self . Remove temporary property viaTransformation from published CSN. Do not complain about unaligned $syntax attribute in CSN frontend. Version 1.23.1 \u00b6 Changes OData: Lower message for unknown vocabulary annotations from warning to info. Lower message for @Analytics.Measure expects @Aggregation.default from warning to info. Remove empty EntityContainer and raise warning if Schema is empty. Fixes Correctly calculate code completion candidates for projection items in all circumstances (regression introduced in v1.22.0). In the Hana/Sql backend, correctly resolve forward on condition when using mixin association that backlinks to an unrelated 3rd party entity and association. Raise a warning if the element of the forward association and the element of the query source do not not originate from the same defining entity. Raise an error if the element of the forward association cannot be found in the query source or is ambiguous. Correctly create localization views with compiled model as input; it was wrong previously in a model with a high view hierarchy. Version 1.23.0 \u00b6 Features Introduce ![identifier body] in the CDL source for delimited identifiers. (The ! is inspired by ABAP's identifier tag, [] by the delimited identifier syntax in Microsoft SQL Server and Sybase; we cannot use [] alone, because brackets are used for filter conditions.) When generating SQL or HDBVIEW, explicit CASTs are now rendered Changes Signal a warning for all uses of \"identifier body\" in the CDL source, as most uses of double-quotes in actual CDS models were likely meant for strings. (Yes, we do not adhere strictly to the lexical rules of the SQL Standard with this change\u2026) Issue a warning for an aspect definition without {\u2026} . In the CSN, aspect definitions have a $syntax property with value \"aspect\" . A future incompatible change will set the kind of aspect definitions to value \"aspect\" . Removed old CSN frontend and the corresponding options: stdJsonParser and oldCsnFrontend . Fix check for arguments and filters in references ( might introduce new errors ). Issue an error if explicit keys are provided when redirecting un managed associations. File paths given to cdsc which contain symbolic links are now resolved before being passed to the compiler. Annotating elements with @Core.Computed now always overwrites computed value; also expressions in parentheses will now induce to set @Core.Computed to true . Update OData vocabulary UI Increase the length of the element locale in generated _texts entities from String(5) to String(14) . Do not overwrite annotations with generated annotations (such as shortcuts and other convenience annotations). Fixes Automatically calculate keys also for published secondary managed associations, i.e., associations in a select column which is reached by following another association. The compiler doest not yet calculate the on condition of published secondary unmanaged associations \u2013 provide it explicitly. Entities/Views without elements are now detected correctly. Fix check for action/function parameters in services. OData: Correctly apply annotations to parameters. Version 1.22.0 \u00b6 Features With redirected to , model designers can now explicitly provide the on condition / foreign keys for \"consumers\" of the current query (entity). This is useful for situations (usually mentioned as message) where the compiler does not calculate on / keys (automatically yet). Add OData vocabularies: com.sap.vocabularies.CodeList.v1 , Org.OData.Repeatability.V1 and com.sap.vocabularies.Session.v1 Changes In the sql , hdi and hdbcds backends with SQL dialect HANA, $user.id is translated to SESSION_CONTEXT('APPLICATIONUSER') , not SESSION_CONTEXT('XS_APPLICATIONUSER') anymore. As with the SQL dialect SQLite, it can now be configured. The client tool cdsc now prints a source excerpt for each message by default; use cdsc --no-message-context to get the previous behavior. Increase severity to Warning of messages for a situation where the compiler cannot calculate an on condition / foreign keys automatically. Issues warnings for annotation definitions, as their CSN representation will be moved from definitions into an new property vocabularies in a future change. OData: Update vocabularies: Analytics , Common , Communication , Core , PersonalData , UI Set reference base URI for SAP Vocabularies to https://sap.github.io/odata-vocabularies/vocabularies Fixes In the sql , hdi and hdbcds backends, correctly ignore contexts containing just actions, In all backends, correctly handle models where an on condition of a join contains a sub query. Avoid infloop for cyclic dependencies on select items with explicit redirections. Version 1.21.1 \u00b6 Features OData: Support annotation @insertonly at an entity which translates to @Capabilities.DeleteRestrictions.Deletable: false , @Capabilities.ReadRestrictions.Readable:false , @Capabilities.UpdateRestrictions.Updatable: false . A warning is raised if @insertonly and @readonly are applied at the same entity and no mapping is done. Version 1.21.0 \u00b6 Features Support cds.Decimal without type facets precision and scale as substitute for the deprecated cds.DecimalFloat . Mapping is as follows: HANA CDS HANA SQL SQLite Odata V4 Odata V2 DecimalFloat DECIMAL DECIMAL Decimal Decimal OData: Expand shorthand annotation @mandatory to Common.FieldControl: #Mandatory . Support edm:Singleton by annotating an entity with either @odata.singleton: Boolean or @odata.singleton.nullable: Boolean . @odata.singleton.nullable is a shorthand for @odata.singleton: true and sets the value for attribute Nullable (default is false). If odata.singleton is false , no singleton is generated regardless of the existence of @odata.singleton.nullable . + Option odataContainment: true renders compositions as edm:NavigationProperty with containment. This option is only available for OData V4 and with --beta-mode . Changes CSN frontend: use faster implementation by default. CDL frontend: issue warning for suspicious-looking delimited identifiers; some people think that they have written strings when they use double-quotes. Models delivered with @sap/cds are now resolved from cds.home ; e.g. using ... from '@sap/cds/common' . This allows working without locally inst# ChangeLog for cdx compiler and backends This allows working without locally installed @sap/cds , for example in Java projects. In that case, respective models will be fetched from a globally installed @sap/cds-dk . OData: Improve array of checks and reject anonymous types and types that are not service members. Set draft properties HasActiveEntity and HasDraftEntity to Nullable: false . Reject old-style CSN from all CSN based transformers and renderers toHana and toSql : Allow aliasing for foreign keys Fixes OData: Fix Nullable attribute for parameters in EDM JSON V4. Do not annotate edm:NavigationProperty for term definitions with AppliesTo: Property and vice versa. Fix bug in ON Condition rendering during transformation of associations to joins for stream based $self expressions. toHana : Only render and allow keys in the leading query toHana and toSql : When following an association, explicitly set the implicit alias to work around a HANA limitation Version 1.20.3 \u00b6 Changes Core Compiler: Forbid navigating associations (to non foreign key elements) in the ON condition of an association definition. OData: Do not generate OnDelete for Containment Navigation Propertie, as this is redundant. Fixes In toSql for Sqlite generate current_timestamp for $at Version 1.20.1 \u00b6 Changes Associations to 'abstract' artifacts and the usage of abstract entities in queries are now rejected. Fixes OData: Raise level from 'info' to 'warning' for excluded NavigationProperties due to targets outside the service. Fix a bug in mapping of @Capabilities (see Version 1.20.0) Flattening of structured elements - @cds.persistence.name was semi-flattened CSN Input: Support views with parameters in queries Support views with parameters in on-conditions of unmanaged associations Support 'not null' for enum elements Version 1.20.0 \u00b6 Changes Issue error (instead of a warning) if a projected association uses a non-projected element in its on condition (message id rewrite-not-projected ). Issue error (instead of a warning) if the redirected target does not originate from the original target of an association (message id redirected-to-unrelated ). In --beta-mode remove the annotation @odata.draft.enabled: false from generated _texts entities. Annotate the technical foreign keys of a _texts entity with @cds.odata.v4.ignore: true to allow containment in OData V4 for _texts . In toHana and toSql associations to entities annotated with @cds.persistence.exists are removed from the generated model. This is an extension to the change introduced with version 1.15.0. If a proxy artifact shall be an association target, another 1:1 projection entity shall be created wich then can act as the association target. OData: Reject non specification compliant CSN as input to csn2edmx Add annotation @cds.odata.{v2|v4}.ignore in --beta-mode Rewrite @Capabilities annotation to @Capabilities.NavigationRestrictions at the containment association in case an entity set has been omitted due to containment in OData V4. Update vocabularies Common and UI Improve error message when not generating a navigation property for association targets outside the same service. Draft: Raise an info message if a draft root has not exactly one primary key element of type cds.UUID Raise an info message if a draft node (subordinate to a draft root) has not exactly one primary key element of type cds.UUID and optionally one more additional primary key. Raise an error message if the same draft node is reachable from two separate draft roots. Raise an info message if a service contains more than one draft root entities. Annotate technical elements IsActiveEntity , HasActiveEntity , HasDraftEntity , DraftAdministrativeData and DraftAdministrativeData_DraftUUID with @UI.Hidden CSN Input: New simplified parsing of CSN, can be enabled via compiler option stdJsonParser or command line option --std-json-parser Support for $location Fixes * Compiler: + Correctly reject the Promise if errors occur during parsing OData: Correctly render annotations with null values in arrays. Correctly render annotations with records of complex types. Correctly annotate artifacts with parameters. Annotations are assigned to the resulting EntityType <name>Type Correctly flatten substructures when used as types CSN Validation: Correctly process views with parameters in unmanaged associations Make parseToCqn() use filter in FROM clause as hint for (recommended) colon, i.e. never discard the filter. Version 1.19.2 \u00b6 Changes Improve the semantic checks for Association to many with a partial key, not complaining about a missing ON condition anymore. HANA: When using names: quoted , raise a warning when artifacts with @cds.persistence.exists belong to a CDS namespace, context or service. OData: Raise an info message on the usage of deprectated OData vocabulary terms. Raise a warning message when applying @odata.Type with another type as Edm.String , Edm.Int16 , Edm.Int32 , Edm.Int64 . Support shorthand annotation @description for @Core.Description . Never complain about localization views when recompiling a CSN file that has localized convenience views already expanded. If the definition's absolute name is localized , it must be a context. If the definition's absolute name starts with localized. , it must either be a context or a query entity. An error message is raised in all other cases. In all cases, definitions in the namespace localized are ignored for further processing. Fixes Fix a dump when compiling from CSN for query elements without a key property that have no column counterpart. Version 1.19.1 \u00b6 Fixes Make sure that we really create all localized convenience views for entities which have localized elements, select localized elements or can directly or indirectly reach (via navigation along associations and compositions) such entities. Features Allow annotations with @odata.Type: 'Edm.Int16' and likewise with value 'Edm.Int32' and 'Edm.Int64' to influence the type which is chosen in the generated EDMX. Version 1.19.0 \u00b6 Changes Event definitions are now properly listed in the CSN: the kind is event , the property for its members is called payload . Omit redundant kind: 'param' for parameters in the params dictionary of a CSN. Fixes Do not use upcoming OData v4.01 facet values for cds.DecimalFloat , i.e. revert v1.18.0 change which had added Scale: floating and Precision: 34 . In CSN frontend, support direct {func: \u2026} objects in orderBy and groupBy . Version 1.18.2 \u00b6 Fixes Issue warning instead error when CDS type cds.DecimalFloat is used with OData v2. Also issue the warning for CDS type cds.hana.SMALLDECIMAL . Properly render n-ary cross join s, typically produced by select from A, B, C . Features Allow to provide HANA-specific magic variables like current_utctimestamp via the function syntax current_utctimestamp() . Similar for sysuuid , current_connection , current_schema , current_transaction_isolation_level , current_utcdate and current_utctime . Support SQL Standard magic variable system_user (without parentheses); be aware that it is not supported (by that syntax) in HANA. Version 1.18.1 \u00b6 Changes Hide the experimental swagger backend behind betaMode and issue a warning even then. Fixes Properly establish EDMX partnership again between forward and backward association even in the presense of \"hidden\" associations (v1.18.0 had introduced a bug). Issue a warning if there are multiple (non hidden) partnership candidates. Features using from <module> also tries file extensions .csn and .csn.json . Version 1.18.0 \u00b6 Changes OData: add type facet Scale: floating , Precision: 34 to Edm.Decimal for mapped CDS type cds.DecimalFloat . Issue error if cds.DecimalFloat is used with OData v2 . Fixes If a projection in a service selects from a source in a model, associations in the projection source are implicitly redirected to a target in the service. The corresponding redirection must also happen for the localized convenience view for the projection in the service: the new target should be the localized convenience view for the \"original\" redirection target (if it does not exist: the \"original\" redirection target itself). Version 1.17.3 \u00b6 Changes OData: Disable proxy generation again due to too many runtime conflicts. This effectively auto-excludes the associations as navigation properties from the service that reference targets outside the service; properties from the foreign keys of managed associations remain. As opposed to the pre-v1.16.2 behaviour, this only affects the OData backend. OData: Raise error if EntityType has no primary key. Raise warning if compiler is invoked in --beta-mode Fixes Make annotate statements on members of autoexposed entities and automatically created text entities work. Version 1.17.2 \u00b6 Fixes Fix stack overflow bug in EDM Preprocessing Version 1.17.1 \u00b6 Changes OData: Add type facet Precision=7 to Edm.DataTimeOffset if CDS type is cds.Timestamp . Add semantic check to prevent the usage of hana.ST_POINT and hana.ST_GEOMETRY as primary key types. Fixes OData: Do not generate NavigationPropertyBinding (V4) or AssociationSet (V2) for non-existing EntitySet of the Proxy EntityType s introduced with Version 1.16.2. Version 1.17.0 \u00b6 Features OData V4: With --beta-mode enabled, compositions become containment navigation properties. This is performed by annotating all compositions with @odata.contained . Existing assignments are not overwritten. Enabling containment is an incompatible change to existing OData metadata documents as all composition targets are no longer accessible as EntitySets but only through their container. Release keyword event . Changes OData: Update all known Odata vocabularies, this also includes SAP vocabularies which now may contain Term definitions marked as experimental . HANA Datatype Support in SQLite: Render ST_GEOMETRY and ST_POINT as CHAR(5000) . Use association names as table aliases during the association to join transformation instead of using the association target (this makes the transformed view more comprehensible). Fixes Parameter lists and filters in ON condition paths are rejected in association to join transformation. Append the temporal WHERE clause to views that already have a WHERE clause. View elements with @cds.valid.from/@cds.valid.key are no longer marked as key in the columns. CSN validator accepts select statements with a having or a group by clause containing a function call. Version 1.16.2 \u00b6 Features Introduce builtin-types for the (HANA) SQL types SMALLINT , TINYINT , SMALLDECIMAL , REAL , CHAR , NCHAR , VARCHAR , CLOB , BINARY , ST_POINT , ST_GEOMETRY . In the CSN, they appear as cds.hana.SMALLINT , \u2026. In CDL, they can be referred to by hana.SMALLINT , \u2026. Mapping of the types is as follows: CDS HANA SQLite OData V4 OData V2 SMALLINT SMALLINT INT Edm.Int16 Edm.Int16 TINYINT TINYINT INT Edm.Byte Edm.Byte SMALLDECIMAL SMALLDECIMAL DECIMAL Edm.Decimal Scale=\"floating\" Precision=\"16\" Edm.Decimal REAL REAL FLOAT Edm.Single Edm.Single CHAR CHAR CHAR Edm.String Edm.String NCHAR NCHAR CHAR Edm.String Edm.String VARCHAR VARCHAR CHAR Edm.String Edm.String CLOB CLOB CHAR Edm.String Edm.String BINARY BINARY CHAR Edm.Binary Edm.Binary ST_POINT ST_POINT CHAR Edm.GeometryPoint n/a ST_GEOMETRY ST_GEOMETRY CHAR Edm.Geometry n/a Changes Associations in services with targets outside the service are not auto-excluded anymore. OData: Create proxy EntityType s for association targets that are not part of the current service. This maintains the navigation path in the EDM model and exposes the primary key tuple of the otherwise unreachable target. The primary keys of a proxy entity must be scalar types. No complex types are supported. Also all outbound navigations are removed from a proxy. The package require node version 8 or higher. Fixes Forbid publishing associations inside unions. Fix a bug in the creation of localized convenience views that lead to an erroneously JOIN expression if such a view gets transformed into a SQL query with toSql --assoc joins . OData: be robust against erroneoulsy assigned @odata.foreignKey4 annotation. Improve ON condition path checks in Association to Join transformation. Fix crash in forHana generation when determining the type of an enum. Version 1.16.1 \u00b6 Features API: If the compiler frontend reports messages and the compile function had been called without options having a messages property, then the resulting CSN contains a non-enumerable messages property containing the messages. Changes Removed TNT specific behaviours for HANA CDS, SQL and OData from the code. Perform usage check of entities annotated with @cds.persistence.skip if using entity really exists on the database (not annotated with cds.persistence.table ). Remove mixin associations with a target entity annotated with @cds.persistence.skip and its select item that eventually expose this association. csn2edm: Produce all services in a given model in one pass removing the requirement to call the EDM transformation for each service individually. The existing API is still compatible. If an EDM for only one service is requested, only this EDM will be produced. Odata: Don't omit containee's foreign keys if they are also primary key. Remove warning that containment association must be NOT NULL . Support annotation @cds.etag as (backward compabible) replacement for @odata.etag . Update broken UI vocabulary. Fixes Make property propagation from query sources using associations work. Consider associations in from clause for on condition rewrite. Make the CSN parser always produce the correct result for null . Propagate @cds.autoexpose along primary query source in all circumstances. Make annotate statements on autoexposed entities work in circumstances. Do not dump when magic variables like $now or current_date had been used in an entitiy for which the compiler creates a localized convenience view. Fix order problem in creation of association DraftAdministrativeData for draft enabled entities. Fix runtime error in forHana in handling of mixin forward and backward associations. Version 1.15.0 \u00b6 Features Release aspect temporal . Changes Improve handling for entities are either abstract or annotated with @cds.persistence.skip in toHana and toSql : Such entities are not part of the generated database model and thus non-existing in the database schema. Associations/compositions to non-existing entities are removed from the generated model but not their eventually generated foreign keys (for managed associations). An info message is raised for each removal. An error message is raised if a non-existing entity is used (either directly or indirectly through an association). Fixes OData Do not assign @Core.AlternateKeys for temporal aspects if the annotation already assigned. Resolve primitive return types for actions Mark localized _texts entities and convenience views with @odata.draft.enabled: false JSON parser Allow JavaScript objects as input, as well as JSON Version 1.14.1 \u00b6 Changes Primary key definitions are only allowed in first union . Raise an error if primary keys are defined in subordinate union clauses when generating toHana . Fixes HANA CDS Don't generate primary keys in subordinate union clauses if the element is a key-element of the source entity. In case of multiple chained union s, generate all union clauses correctly. OData Generate unique Names for <edmx:Association> elements in Version 2 to avoid name clashes with other entries in <edmx:Schema> . Raise error for duplicate definitions in <edmx:Schema> . CSN Input validation - joins can have value literals in the on condition Version 1.14.0 \u00b6 Features Support aspect temporal with option --beta-mode : Support magic variables $at.from and $at.to . OData: Add element annotated with @cds.valid.from to the key in the metadata document but not in the CSN, requiring a valid primary key in the projection to exist. An element annotated with @cds.valid.key becomes the sole primary key in the EntityType. Add an @Core.AlternateKeys annotation that lists the original primary key tuple as well as the element annotated with @cds.valid.from . SQL/HANA CDS: Translate $at.from to SESSION_CONTEXT('VALID-FROM') in HANA and current_time in Sqlite. Translate $at.to to SESSION_CONTEXT('VALID-TO') in HANA and current_time in Sqlite. A WHERE claues that allows time travel queries is generated for projection that contain exactly one element annotated with @cds.valid.from and @cds.valid.to that stem from the same origin. An entity elementannotated with @cds.valid.from is added to the primary key tuple of the resulting database table. If an entity element is annotated with @cds.valid.key , it becomes the sole primary key of the resulting database table. Redirect targets of associations in localized convenience views to their respective localized convenience views. In addition to that, create a localized convenience view for all entities that contain associations that lead directly or indirectly (via n other association steps) to a localized entity, so that these associations can also be redirected. Localized convenience views are only created in case the model is error free. Changes Allow to extend an entity with an empty structure OData: An error is raised for entities that have become empty (no elements) due to automatic exclusion of associations. Update the vocabulary UI Allow multiple 'backlink' associations via $self ON condition, first 'backlink' establishes the partnership Allow 'backlink' associations to define their own target multiplicity. Raise a warning if the forward association is not included in the service (due to autoexclusion). Reclassify error on containment association to be NOT NULL down to a warning. @cds.api.ignore suppresses annotations. Fixes OData: Fix issues with @cds.odata.bindingparameter.collection : Correct $Collection to Collection in EDMX No referential constraints for NavigationProperties with target multiplicity '*' Avoid internal errors on cyclic view definitions Strengthen checks on reserved names Version 1.13.4 \u00b6 Feature extend projection with elements extend entity with aspect, i.e. not by specifying new elements, but via a definition which has elements. Changes Localized convenience views (introduced in Version 1.12.0 as beta feature) are now available. The convenience views for views and projections are created as a copy of the regular artifact in the localized namespace which selects from the corresponding localized artifacts. Associations within localized convenience views aren't redirected yet; they still point to their original non-localized target. Convenience views for views containing associations in their FROM clause aren't supported yet. For those views an Info message is produced stating that no convenience view could be created for the given view. In contrast to the beta feature it isn't required anymore to expose the localized association or the primary key. The automatic exposure of entities, redirection and exclusion of associations has been moved from forHana and forOdata post-processing into the core compiler: When an association is projected, the compiler checks whether all elements are propagated which are referred to in the on condition of the projected association. Please reexamine warnings for your model. The compiler checks whether a redirection target (directly or indirectly) projects from the original target (and/or uses the original target as structure include). Elements can be renamed in the redirected target and the on condition is rewritten correspondingly (currently not if the projected association is an indirect one, i.e. if we project assoc1.assoc2 , which was an Error in v1.12.0 ) \u2192 this means that those DB artifacts can be deployed. When following an implicitily redirected association, potentially renamed elements are taken into account. Implicit redirections fail less often as the compiler tries to find a \"minimal\" exposure. Auto-exposure via Composition of now works in all circumstances. Other features like \"localized\" work for auto-exposed entity and/or with implicitly redirected association. Redirections for associations which are sub elements do not work . The name of an autoexposed entity now looks like <Service>.<LastNamePart> where <LastNamePart> is the part of the name of the original entity after the final dot. If you get an error because of name clashes, just expose one entity explicitly (or use the option longAutoexposed ). Multiple backlink associations for one forward association make the OData backend report an error. Fixes Forward the key property to the select items of generated HANA CDS views. Remove some issues of the $projection and $self handling in the association to join translation. Add alias for select items that are primary key in HANA CDS. Fix support for union queries in localized convenience views. Version 1.12.1 \u00b6 Changes * With option --beta-mode , automatic exposure of entities, redirection and exclusion of associations has been moved from forHana and forOdata post-processing into the core compiler. Fixes * With option --beta-mode in v1.12.0, a just inherited @cds.autoexpose had not been considered. * With option --beta-mode in v1.12.0, projecting indirect associations ( assoc1.assoc2 ) lead to an error. Version 1.12.0 \u00b6 Features * With option --beta-mode , support localized convenience views: Create a view named localized.<EntityName> for an entity with localized elements. This view allows a coalesced access to localized elements and either returns the default or translated content, depending on the locale setting. + A convencience view is only created if both the localized association and some localized elements are exposed in the entity. + When exposing the localized association in an entity, also the complete primary key has to be exposed, otherwise an error is thrown. * Mark calculated and virtual elements as @Core.Computed:true . If @Core.Computed has been set manually, it remains unchanged. Changes With option --beta-mode , automatic exposure of entities, redirection and exclusion of associations has been moved from forHana and forOdata post-processing into the core compiler. Update to v1.12.1 if you experience problems \u2013 an inherited @cds.autoexpose had not been considered. In toSql and toHana errors are raised for duplicate definitions of elements that differ only in spelling, if the the entity is not abstract or annotated with any @cds.persistence set to true and an element is typed to be an array of a type , an implicit managed composition has cardinality to many. Raise a warning if an element is to be localized which is not of type cds.String . Fixes * OData: + On @Aggregation.ApplySupported.PropertyRestrictions apply @sap.sortable':false, '@sap.filterable':false at new ID__ property. + Allow @Core.OperationAvailable: null + Abstract entities and all inbound navigation properties are removed from the metadata document. + Non-properties are not considered as referential constraints. * Correct annotation cds.autoexposed . Version 1.11.0 \u00b6 Features * Support localized elements: + Add sibling entity <entityName>_texts to store the localized content. + Add two associations texts and localized to the original entity. + Add view localized.<entityName> to retrieve either the translated or original content. * Annotate elements that are virtual or annotated with @odata.on.insert or @odata.on.update with @Core.Computed . * Support OData @Common.ValueList by either + annotating an element for which a value help entity shall be used with @Common.ValueList.viaAssociation . The value is the association to the value list entity. + annotating an entity with @cds.odata.valuelist . All associations targeting to this entity are then annotated with @Common.ValueList.viaAssociation . + annotating an element statically with @Common.ValueList.entity . The annotation value is a static entity name and cannot be dynamically adapted during autoexposure. * Add annotation @cds.odata.bindingparameter: {name: String, collection: Boolean } which allows overriding the binding parameter name and cardinality of a bound action in OData V4. Default is: name='in' , collection=false . * Allow a colon in FROM and TYPE OF references. * Support using and publishing a mixin association in the same view when activating for HANA CDS. Changes * Produce all CSN output in version 1.0 by default. * Virtual elements cannot be used in expressions. * Command toRename creates a stored procedure instead of individual statements. * Don't autoexpose composition target which is annotated with @cds.autoexpose: false . Fixes * OData: + Rename OData annotation vocabulary Auth to Authorization . + Correct exposure of entities with parameters: - Set attribute EntityType of element edm:EntitySet to the correct type - Set attribute EntitySet of element edm:End in edm:AssociationSet to the correct set. + EnumMember in element edm:Annotation has only one delimiting slash * Rewrite ON condition of a mixin backlink association for an inferred and redirected forward association. Version 1.10.0 \u00b6 Features * Annotate entities with @cds.autoexposed that are autoexposed in a service. * Always autoexpose composition targets without annotating them with @cds.autoexpose . * For associations in a service with targets which are not in a service: + automatically exclude them if the associaiton is inferred (via select * or include), + signal an error if the association is explicitly defined in the service. * Support the OData annotation vocabulary Authorization . Changes * Generate null as \u2026 for virtual view elements. * Update OData annotation vocabulary Core . * Change the tranlation of annotation @readonly at an element from @Core.Immutable to @Core.Computed when processing for OData. Fixes * Avoid unnecessary aliases for paths that terminate on an association in the FROM clause. * Fix an issue with table alias handling in Association to Join translation. * Translate type Cds.DateTime to SQL type TIMESTAMP for Sqlite. * Fix an internal error when parsing view V as select distinct from E * Raise an error that an empty service cannot be used to generate an OData metadata document * Correctly set the OData principal in a referential constraint for compositions with free defined ON conditions. Version 1.9.0 \u00b6 Changes * Always use quotes around identifiers for toSql and toHana with quoted or hdbcds names. * Never use quotes around identifiers for toSql and toHana with plain names. Issue a warning if an identifier may conflict with a language keyword. * Generate .hdbtable , .hdbview etc. files if option toSql.src is hdi (default sql generates .sql files). Features * Allow select clauses with standard SQL syntax (i.e. also accept select ... from ... in addition to the CDS-specific form select from ... { ... } ). * Support count(*) etc. * Support function calls with names arguments. * Support aspect definitions. Fixes * Omit unused vocabularies in OData-generated EDMX files. * For toOdata , handle nested anonymous types correctly (also with arrays, e.g. in action/function parameters) * Handle mixins correctly when transforming associations to joins. Version 1.8.1 \u00b6 Changes * With --new-redirect-impl , associations and compositions in services are implicitely redirected to a (unique) projection of the original target if the projection is \"simple and similar enough\" and defined in the service. This is now always done, not only by the toOdata backend; association targets explicitly provided in the service are not implicitly redirected. * With option --new-csn (or --beta-mode ) alone, we do not properly rewrite the on condition or keys anymore. Use option --assoc-on-rewrite and --new-redirect-impl to do so. Fixes * With --new-redirect-impl , the navigation along implicitly redirected associations now properly considers that elements could have been renamed in the new association target. * With --new-redirect-impl , the code completion candidates are the elements of the new association target calculated by the implicit redirection. * With --new-redirect-impl and --assoc-on-rewrite , the on condition or keys are rewritten with implicit redirections. * With toSwagger , enum constants without values are now correctly rendered. * With toSql in sqlite dialect, a warning is now issued if an identifier collides with a known SQL keyword. * For OData, annotations with null values are now ignored (this can also be used to \"delete\" an annotation in an extension). * In OData, structured types that are anonymous or not exposed in a service are now automatically exposed (unless used as an entity element - in that case they are still flattened). * For OData v2, the namespace for service annotations is now correctly set. * For toHana with plain names, all type properties (including length ...) are now propagated correctly when derived types are used explicitly in view columns. * CSN version 0.2.0 is now accepted by the compiler. Version 1.8.0 \u00b6 Features * Support the OData annotation vocabularies PersonalData and Aggregation . The vocabulary for PersonalData contains a number of annotations that are flagged as \"experimental\". Their usage will result in a warning. * New option for specifying the locale in SQLite dialect. As part of the toSql command is now available the options '-l, --locale <locale>' for specifying value for the \"$user.locale\" variable. Changes * Entity definitions with elements of type array and structure type definitions with association elements will now lead to an error message when generating edmx for OData v2. These constructs are not allowed in OData v2, but there was no corresponding check in the cds compiler yet. Version 1.7.1 \u00b6 Fixes * Restore version function which was deleted by accident Version 1.7.0 \u00b6 Features * Allow entities to have parameters. They can be referred to inside the query with :Param . Entites with parameters are not allowed in toSql for dialect \"sqlite\". When generating for HANA, parameters cannot be used in combination with associations: an entity with parameters cannot have associations, and an association must not point to an entity with parameters. * The parameters and return value of actions and functions can now have structured types. * In the annotation translation for OData, falsy values of the special variable $value (that is used to provide nested annotations for scalar values) are correctly handled. * When (new-style) csn is used as input, the compiler ignores unknown attributes. * Implicit redirection and auto-exposure are now applied recursively, i.e. the associations of an auto-exposed entity are considered for implicit redirection and auto-exposure, if necessary. Changes * With --new-csn , consider redirected to on projected associations and adapt the on condition and the keys specification accordingly. There are also Info messages if an element referred to in the on condition or keys specification has not been projected to the new association target. The severity of these messages will be increased if implicit redirections will have been performed by the core compiler. * toHana and toSql now reject entities that only contain unmanaged associations. Such entites would lead to a deployment error later. * SQL name mapping modes quoted and hdbcds are only allowed when generating for HANA. * In the csn, the csn language version is now stored in the top level attribute $version . The version information via version.csn is deprecated and will be removed in a future release. The information about the creator of the csn has been moved inside the new top level attribute meta . Fixes * Provide code completion for references in complex select item expressions not (yet) having an alias (complex = not consisting of just a reference). * With --new-csn , avoid internal error while rewriting the on condition from an element of a source entity which refers to a mixin definition with an on condition containing a reference like $projection.<elem> . * OData, edmx generation: correctly escape the characters < , > , & , and \" . * When an entity is auto-exposed, it's annotations are transferred to the generated projection. Version 1.6.0 \u00b6 Features * Provide code completion for using declarations. * Support the OData annotation vocabulary \"Validation\". * For compositions in EDM, add <OnDelete Action=\"Cascade\"/> to the navigation property where required. Changes * With --new-csn , complain more often about projected associations whose on condition could not be rewritten correctly. * Make associations: 'joins' the default for toSql (because the default for dialect is already sqlite , which requires joins). * Adapt the command line interface to use commands instead of the --to... generation options (e.g. cdsc toHana --src --names plain instead of cdsc --toHana src,plain ). Please see the Command Line Migration guide for details. * Add a generated by cds-compiler version x.y.z comment to all generated SQL and hdbcds sources. * Replace the CSN validator (formerly ajv ) with a new own implementation. Fixes * With --new-csn , do not change references to magic variables like $user.id while rewriting the on conditition of a projected association. * Apply OData specific checks (e.g. that all elements of an entity must have a type) applied only to objects that are exposed in a service. * When generating SQL for SQLite, replace the the special variables $now , $user.id and $user.locale by CURRENT_TIMESTAMP , '$user.id' , and 'EN' , respectively. * Issue a warning for conflicting cardinality declarations (e.g. association[1] to many ... ). * Handle filters with cardinality correctly when translating associations to joins. * Avoid crash when checking structured action parameters. * Handle $self as the first of multiple path steps correctly in toOdata . * In toHana , render the combination of enums and type of correctly. * In mixins generated by toHana , handle special variables starting with $ correctly. Version 1.5.0 \u00b6 Features * The DDL statements in the output of toSql are now sorted according to kind (views after tables), so that they can be deployed sequentially to HANA (view dependencies not yet considered). * (Still work in progress): The output of toSql now also contains kind-specific dictionaries for hdbtable , hdbview etc., which should be directly deployable to HDI. Changes * Element definitions in multiple entity/structure extensions are now sorted according to the layer hierarchy \u2013 elements from highest layers come last. Report such multiple extensions only if they are potentially problematic. * The values for the names option of toSql , toHana and toOdata have been renamed: flat (default) is now plain , deep is now quoted . The old values are still accepted (with a warning) but will be removed in a subsequent release . Fixes * OData, annotation processing for v2: In a view where translation of analytical annotations is switched on, the annotations @Common.Text , @Common.Label , and @Measures.ISOCurrency/@Measures.Unit are now translated into the corresponding v2-style annotations sap:label , sap:text , and sap:unit , respectively, even if the value is a path or has a nested annotation. * OData V2, generation of EDMX: The Parameters of a FunctionImport now always have an attribute Nullable=\"true\" if not specified as not null in CDS. * Produce better parentheses for nested set operations ( union , intersect , ...) in views for SQL output. * Correctly strip off the enum property of types for HANA CDS, even when derived types are involved. Version 1.4.0 \u00b6 Features * OData, annotation processing: Provide a shortcut for the nesting of the TextArrangement annotation: In order to annotate a @Common.Text annotation, just put an annotation @Common.TextArrangement next to it. * Parameters can now be referred to with :param , :1 or ? in the parse API functions. Changes * More checks for the correct usage of $self and associations as values in expressions. * Backlink-Associations: When transforming an ON-condition on $self = foo.bar , check that the association bar really points to the entity enclosing association foo . * Allow and transform multiple $self -comparisons in one association ON-condition (but a true backlink association still requires exactly one such comparison). * Warn if a \"to many\" association or composition does not have an ON-condition (likely not intended because the resulting managed association will at most match a single item) Fixes * Add missing as for flattened structured elements. * Allow using cds; to make the namespace cds explicitly known, which is useful if that had been shadowed by a namespace declaration ending with cds . * OData: don't generate empty <Annotations ...> elements any more. * Draft for OData v2: in the DraftRoot and DraftNode annotations, the path to the draft annotations now contains EntityContainer . * Improved checks for parameters of actions and functions. Inappropriate warnings like \"The type of input parameter ... must be from the current service\" and \"The action ... can only return an array of entities\" don't appear any more. * Correctly generate foreign key fields for associations in structured types. * For toHana() and toSql() , enclose the artificial condition resulting from $self -comparisons in parentheses. * Warn properly when draft-enabled artifacts are not exposed in a service. * Do not render a full entity name for paths like $self.foo to SQL (just skip $self ). Version 1.3.0 \u00b6 Features * The using declaration can now appear top-level also after artifact definitions. * Support for $user.locale and $user.id with HANA generation SESSION_CONTEXT(\u2026) . * For entities annotated with @odata.draft.enabled , the generated DraftAdministrativeData association for ODATA is now annotated with @odata.contained: true (avoiding the generation of an <Attribute> for its foreign key in ODATA V4). Changes * Having just $user in CDL is now rendered as {ref:['$user','id'], as:'$user'} in new-style CSN. * Using SQL's parameter-less functions not having parentheses (like current_date ) is now rendered as {func:'current_date'} in new-style CSN. * betaMode is currently required for entities with parameters. * In old-style CSN, the on condition as source text has been removed. * Explicit redirection of an association to a target that is completely unrelated to the original target is now an error, not just a warning. * The API function toI18n() and the corresponding command line option --to-i18n have been removed. * Annotation assignments after sub structure definitions, enum definitions, and parameters are now considered an error instead of just a warning. * For bound actions and functions, the name of the corresponding function import in OData v2 edmx is now prefixed with the name of the entity. Fixes * For ODATA V2, create correct <Principal> and <Dependent> for backlink associations having @odata.navigable:false . * Avoid the Expecting artifact to be part of a service error that occurred when generating multiple entities with @odata.draft.enabled to SQL. * Generate correct (fully qualified) action names into the @Common.DraftRoot and @Common.DraftNode annotations. * When generating the DRAFT.DraftAdministrativeData entity for SQL, provide proper lengths for all NVARCHAR fields. Version 1.2.0 \u00b6 Features * Provide semantic code completion for the excluding clause. * Add support for \"deep drafts\", i.e. follow compositions from entities annotated with @odata.draft.enabled (\"draft roots\") and draft-enable them as \"draft nodes\". Changes * Finalize the propagation of the key property. Provide Info messages if it is not obvious why it has not been propagated. * Finalize the propagation of the keys property and items property. * Check for illegal use of $self and associations in expressions (may only occur as values in an expression as part of the ON-condition in a backlink association). Fixes * Produce warnings instead of errors in the translation of OData annotations. * For ODATA, in case of managed associations to draft-enabled entities, do not add an extra foreign key for the ODATA-generated key field IsActiveEntity . * For HANA, in the generated draft shadow entities, redirect all associations (not just compositions) so that they point to the draft shadow entities. * For ODATA V2, produce an <EntitySet> for DraftAdministrativeData , too. Ignore the @cds.odata.NoEntitySet annotation. * For ODATA V4, do not generate <Nullable> for <NavigationProperty> s that are collections. Version 1.1.3 \u00b6 Features * A ; is now always optional before } and more often optional after a } . Changes * In toOdata() for v2, in the edmx the names of bound actions and functions now are prefixed with the corresponding entity's name in order to disambiguate actions and functions with the same name at two or more entities. The corresponding implementation code in the CDS runtime needs to be adapted. * Check redirected to target. Fixes * Make the compiler more robust wrt/ parse errors and redefinitions. * Correctly propagate properties inside returns and items . * Some corrections to EDM ActionImport and FunctionImport in ODATA V2 and V4. * Generate correct joins for mixin associations that are traversed with different filters. * Generate joins not only for views, but also for projections. * For entities annotated with @odata.draft.enabled , make all non-key fields nullable in toOdata() . Version 1.1.2 \u00b6 Features * Allow reserved names for annotations/properties in assignments. * Allow final , for much more \"lists\" (e.g. arguments). * It is now possible to omit the select list in a view definition, which is the same as writing select from <name> {*} . * Allow array of as type spec for a parameter definition. * SQL generation for sqlite now supports a mode where associations are resolved to joins. Changes * Improved messages for syntax errors. * where now is a reserved keyword and so cannot be used anymore as name at many places. Fixes * In toOdata() with the hdbcds naming convention, the value of the @cds.persistence.name annotation now uses . rather than _ as separator for the names of flattened structured entity elements. * Numeric values in OData annotations are now correctly mapped to edmx. Version 1.1.1 \u00b6 Fixes * Ignore unapplied extensions when generating HANA CDS source. * Make sure the combination of collectSources() and compileSources() has the same effect as compile() , especially regarding annotation precedence. * Render annotations of edm:Schema correctly in for ODATA V4. Version 1.1.0 \u00b6 Features * Support @odata.draft.enabled without the need for option { betaMode: true } ). Fixes * Return result of collectSources() as promise. Version 1.0.33 \u00b6 Features * Allow to extend query entites with actions. * Allow select distinct . * With --tnt-flavor only: allow to specify (a restricted version of) service include via syntax. * (Work in progress): New option { dialect: 'hana'|'sqlite' } for toSql() , allowing generation of SQL statements without HANA-specific constructs (e.g. without WITH ASSOCIATION ). * For ODATA V4, handle associations to parameterized entities correctly. * Allow specifying key for projection elements (important in case of partial keys not being propagated, see below). * Annotate entities and elements in the CSN with @cds.persistence.name , the name generated for the persistence layer according to the naming convention chosen ( flat , deep , hdbcds ). * (Work in progress, only available with option { betaMode: true } ): Support @odata.draft.enabled with toHana() , toOdata() and toSql() . Only draft roots so far, no compositions. Fixes * Put table alias for from into CSN even without having it explicitly provided in CDL if necessary (the table has been referred via a using with alias). * Do not assume a specific min cardinality if none was provided. * For SQL, provide table aliases when required because of flat naming. * Handle @readonly annotation correctly when applied to entities. * Various fixes to the handling of @odata.contained . Changes in the property propagation, see internalDoc/Propagation.md: * Propagate properties along primary sources in includes, especially actions/functions. * The propagation of key is more restrictive now, most notably: only if all keys are selected (selecting sub elements of a structured key is not enough), only if there is no navigation along a to-many association in a select item. * The propagation of notNull has been corrected. * The propagation of virtual has been corrected. * The propagation of an array type has been corrected. Other changes * For ODATA, provide min cardinality 1 for non-null associations. * Remove obsolete option --check-model . Instead, always perform all checks previously hidden behind that option, possibly resulting in more warnings (but not more errors). * Actions and functions are no longer restricted to entities within services. Version 1.0.32 \u00b6 Features * The toHana() , toSql() and toRename() backends now also support a naming convention that is backward compatible to HANA CDS, with option { names: 'hdbcds' } . * New API function collectSources() to conserve a set of compiled sources with its hierarchy relations. * Avoid unnecessary quoting of names generated by toHana() , toSql() and toRename() . * Implement handling of @cds.persistence.table . * Support \"term casts\" in paths of ODATA annotations. * Support the @odata.contained annotation. Changes that only have an effect if the --new-csn option is set * With --disable-propagate , produce CSN in gensrc flavor: + omit inferred elements and keys, + omit propagated properties (like annotation assignments), + supply annotation assignments on inferred and propagated members with an extra annotate statement in the model's extensions property if necessary. * Without --disable-propagate , produce CSN in client flavor: + provide inferred elements and keys, + provide propagated properties (like annotation assignments), + supply annotation assignments directly with the inferred member. * The $inferred property has been removed. * Rename foreignKeys to keys for the keys to target elements of associations. * Rename filter to where in ref s and omit the surrounding {xpr:\u2026} of the condition. * Do not render query columns if no columns have been provided (only implicit * ). * Render technical configuration correctly. * Render select distinct correctly. * Let also those backends that produce CSN as a by-product (e.g. toHana() , toOdata() , ...) produce new-style CSN if the --new-csn option is set. Other changes * The property propagation has been changed, except with --tnt-flavor . See internalDoc/Propagation.md, it is still work in progress. * Remove the special handling of namespaces ending with :: * Sort the output of toHana() and toCdl (also within contexts and services). * When @cds.autoexpose is set for entities that are already exposed, use the existing exposure for implicit redirection. Fixes * An annotate statement on an enum symbol now has the expected effect. * Annotation @cds.autoexposure is renamed to @cds.autoexpose (like it is used in documentation) * EDM Nullable and Cardinality now handled correctly for ODATA V2. * Correctly check that elements must have a type for ODATA. * Handle structured annotation assignments and # -variants correctly with toCdl() . * For toHana , generate correct aliases for foreign key fields in views if the corresponding association has an alias. * Do not propagate @cds.persistence.table and @cds.persistence.exists . * Render artifact paths in from correctly with toSql() . * In EDM, do not render OpenType and Abstract if they have default values. * For EDM annotations, correctly set Target according to vocabulary's AppliesTo . * In EDM, only set Nullable=false if not null was explicitly specified (i.e. not just for all keys). * In EDM, handle entities with parameters correctly regarding the entity type that is generated for the parameters. Version 1.0.31 \u00b6 Features * Support multiple imported names in using declaration: using { foo.bar, this as that } from './othermodule'; * Add new command line option --to-rename , generates SQL DDL statements renaming existing HANA tables for migration (work in progress, subject to change). * For ODATA, allow backlink associations on unmanaged associations. Changes * New error for extending views (query entities) with new elements. * Allow annotations of unknown artifacts - slightly change the name resolution in CDL for references in top-level extend and annotate statements. * Make the client tool display info messages by default. * Make keywords new and aspect to be non-reserved. With this change, the set of reserved keywords of CDL is a real subset of the reserved keywords of SQL. * Remove command line options and API functions deprecated with v1.0.24. * In ODATA V2, reuse the edm::Association of the original association for backlink associations. Fixes * Miscellaneous fixes for CSN with option --new-csn . * Avoid internal error by not running extra checks after compilation with error. * Propagate defaults and @odata.Type annotations from keys to generated foreign key fields of associations. * Do not render annotations of subqueries to HANA CDS. * Suppress $projection in ON-conditions for ODATA. * When looking for candidates for implicit redirection, follow FROM sources of views/projections and : -includes of entities transitively, not just for one level. (Please note that this fix may uncover errors in existing models where implicit redirection now fails because of multiple candidates. Use explicit redirection to resolve this to one of the candidates, as suggested in the error message). * For ODATA and HANA CDS, recognize and transform backlink associations also if the condition is in (redundant) parentheses. * For HANA CDS, replace enum literals in defaults by their values. * Reject paths in defaults. Version 1.0.30 \u00b6 Features * Complex queries (with joins, sub-selects etc.) are now supported. Changes * Both toHana() and toSql() now use flat names by default (specify options { names: 'deep' } to get the old behavior). The CSN version currently starts with 0.1 for flat names, with 0.0 for deep . This is likely to be adapted again later. * Using Annotate on unknown artifacts or members now only leads to an info message, not an error anymore. The CSN with option --new-csn then has an extensions property containing the effective assignments. * Downward compatibility for @cds.odata.navigable was finally removed (see 1.0.11, use @odata.navigable instead). Fixes * Render table aliases correctly for HANA CDS when an entity is used in from that is aliased by a using declaration. Version 1.0.29 \u00b6 Features * Support the generation of multiple services with --to-swagger . * Support SELECT DISTINCT . Changes * Improve smart wildcard handling: simple projections with just redirections now have the original element order of the source. * Restrict limit and offset value to number (and null ). * There is a warning for key elements outside entities or views, as an inner key specification would be ignored for implicit foreign keys and propagation. * Change propagation of the key property: see internalDoc/Propagation.md. Most notably, in a view/projection the key property is no longer propagated along association navigation. Fixes * Entities that contain only virtual elements or are empty (recursively) are now rejected for HANA CDS, unless they are abstract (was only partly checked before). * Multiply nested structs in views or projections are now correctly rendered to HANA CDS (avoiding a completely unrelated error message complaining about extensions). Version 1.0.28 \u00b6 Features * The mapping of cds to edm types can be overridden by the annotations @odata.Type and @odata.MaxLength . Currently only Edm.String can be used as target type. This is intended for exceptional cases, where the standard type mapping is not wanted (e.g. if UUID should be mapped to Edm.String rather than Edm.Guid ). Fixes * Issue an error, if an association element that is defined in a mixin of the same view is explicitly redirected. Up to now this modelling error was not recognized and led to the generation of incorrect HANA CDS models. * We now also allow query entities and their elements to use as type, relaxing a check introduces with v1.0.26. It needs to be seen whether we allow entites as type only for actions. Version 1.0.27 \u00b6 Changes * The implemented in clause of entity definitions has been removed and will now cause a syntax error (this clause is obsolete since version 1.0.21, see corresponding changelog entry). Replace it by one of these annotations: + use @cds.persistence.exists to indicate that an object should not be created in the database because the database object already exists. + use @cds.persistence.skip to indicate that an object should not be created in the database because it is implemented in the service layer. Version 1.0.26 \u00b6 Features * For annotation assignments outside array values, allow paths and variants, not just identifiers as keys in structure values. Changes * In flat mode, the toHana channel will reject quoted identifiers in definitions. * Smart * : just issue a warning if a select item \"overwrites\" an element coming from the wildcard. Might even be downgraded to an Info message in the future. * Artifact references are checked for plausibility: only allow entities as association and composition target and for the select from clause (allow to navigate along associations there, too), only allow (non-query) structures for structure includes, only allow types (and entities) and their elements as types. * Implicit redirection of associations is now also performed for HANA CDS (as it was already for ODATA). Fixes * IDE support: improve syntactic code completion, and messages for parse errors. * OData: correctly escape special xml characters in generated edmx. Version 1.0.25 \u00b6 Changes * Better command line error reporting for cdsc . Fixes * Render anonymous structured types correctly to HANA CDS (no : ). * Handle structured elements with aliases in views and projections correctly. * Flatten structured view elements for ODATA (like for HANA CDS). Version 1.0.24 \u00b6 Features * The toHana() channel now also supports the option flag toHana.names:'flat' . This option affects how the names of database objects and their columns are built. This option will become the default in one of the next versions . The old behavior can then be enforced with option flag toHana.names:'deep' . With option flag flat , ... + all names are converted to uppercase + in object names, _ is used as separator instead of . Changes * The new command line tool cdsc is going to replace the old cdsv , which is deprecated and will be removed soon . Please see the Command Line Migration guide for details. * New API \"backend\" functions (i.e. those that generate output from a CSN model) are going to replace the existing ones. The old API functions toHanaCdl , forHana , toOdataOutput , exportAnnotations , exportAnnosUi5Style and toSqlDdl , are deprecated and will be removed soon . Please see the API Migration guide for details. * ODATA JSON output can no longer be generated for V2 (there is no valid V2 JSON format). * When generating the CSDL JSON for OData v4, enum values now have an additional attribute $EnumMember@odata.type . This addition reflects an amendment of the specification of CSDL JSON. Fixes * Do not try to find table aliases for references consisting of a single identifier, i.e., a column named x in the select list is also found if the table alias or the table itself has been named x , too. * Fix unjustified message about a undefined reference in mixin definitions when a reference starting with $projection accesses a nested element or an element which has been added to the query via * . * Check that ON-conditions of unmanaged associations do not traverse other unmanaged associations. * When generating EDM, ignore aliased elements in ON conditions of redirected associations. * Guarantee a deterministic artifact processing order even if async calls are involved. * When generating edmx for OData v2, referential constraints for entities with multi-part keys are now correctly rendered. Version 1.0.23 \u00b6 Changes * When generating for Swagger, handle TNT-specific features more gracefully. Version 1.0.22 \u00b6 Fixes * IDE support: improve syntactic code completion, and messages for parse errors. * Fix behavior of @cds.persistence.exists for HANA CDS (generate correct using , avoid empty contexts). * Strip key from structured type elements when generating for HANA CDS. Version 1.0.21 \u00b6 Changes * The CSN element property notNull is not inherited anymore if the select / projection items whose path refering the source element navigates along associations or compositions. * Annotation assignments which are placed after the name of context or service definitions must now use the @(...) syntax variant if a value is supplied, the same restriction already applies for all other definitions. This new syntax restriction can be disabled with option tntFlavor , and re-enabled with its new sub option skipSloppyAnnoAssignments . * The syntax implemented in is deprecated. It is replaced by two new annotations: + use @cds.persistence.exists to indicate that an object should not be created in the database because the database object already exists. + use @cds.persistence.skip to indicate that an object should not be created in the database because it is implemented in the service layer. * The shortcut for the value list annotation has been simplified, you now can just type @Common.ValueList.entity:'SomeValueList' Fixes * IDE support: improve semantic code completion. * Self-associations are now handled correctly in the ODATA generation. Version 1.0.20 \u00b6 Features * For Swagger, one parameter of an action or function can now be selected to become the request body, by annotating it with @Swagger.parameter: 'requestBody' . * The shortcut for value help annotation @Common.ValueList:{ type:#fixed, entity:'SomeValueList' } is now generally available. * For associations in ODATA that have targets outside the service, projection-like views are now also considered as implicit redirection targets (not just projections). Fixes * Type properties like length are now omitted when generating an ODATA property Edm.Stream . * Nested annotations for ODATA are now handled correctly. * The transformation of backlink associations for HANA CDS is now more robust against artifact processing order. Version 1.0.19 \u00b6 Changes * Allow aliases in projections for HANA CDS (although not 100% watertight in all cases). Features * Entities annotated with @cds.autoexposure are now automatically exposed in a service (by means of a full projection) when they are used as association targets within that service. Fixes * The $user variable is now correctly expanded to SESSION_CONTEXT('XS_APPLICATIONUSER') , with only one underscore. * The --check-model option is now more robust against the order of artifacts in the model. * Enum types are now always reduced to their base type for HANA CDS. * Options given to the compiler or one of the post-processing functions are now always handed down together with the model. * The query clauses LIMIT and OFFSET are now really enabled (were accidentally still left in beta). Version 1.0.18 \u00b6 Changes * Compiler now complains if an entity exposed for ODATA has an element without a type. * View and projection elements in CSN now always have a value property (possibly with a path). Features * For ODATA, now also the annotations from the Analytics vocabulary are translated. Fixes * Workaround for a HANA CDS issue: When providing LargeString or LargeBinary as explicit type for a view element, HANA CDS runs into an error during the deployment of the generated HANA CDS (fix pending). This error can be prevented by annotating the corresponding elements in CDX with @cds.workaround.noExplicitTypeForHANA . * not null at a managed association is no longer added to the corresponding unmanaged association in HANA CDS, but only to the foreign keys. * When a redirected association is used as a view element, the select item for the corresponding MIXIN is now correctly rendered for HANA CDS and CDL (accidentally had an explicit association type). * MIXINs that are explicitly added to views are now correctly generated for HANA CDS (were accidentally duplicated). * Do not complain about @Core.MediaType for key-less entities. Version 1.0.17 \u00b6 Changes * Correct license in package.json * toSwagger takes in mind only artifacts from services Fixes * Handle type cds.UUID correctly when generating SQL. * Handle associations in GROUP BY and ORDER BY correctly when generating HANA CDS. * When generating MIXINs for associations in HANA CDS views, use an alias to avoid conflicts with association usage in the SELECT. * Wrap bound action and function definitions in an array when generating EDMX. Version 1.0.16 \u00b6 Changes * Allow artifacts to be defined in namespace cds.foundation . Features * Support the remaining query clauses group by , having , order by (with optional asc / desc and optional nulls first / nulls last ), and limit (with optional offset ). * Support the magic variables $now and $user . Fixes * Complain about artifact extensions inside context/service extensions. * For ODATA, add a $Partner attribute to edm:NavigationProperty when appropriate for bi-directional asociations. There is a new document which explains some error messages (more messages will be added in the future). Version 1.0.15 \u00b6 Changes * More checks for correct ODATA input (element names, keys, ...). Features * Allow redirected to in select items of views. * Support the @Core.MediaType annotation for ODATA. Fixes * Correct bug in the calculation of the _finalType , which could lead to an internal error within the odata backend. * Properly resolve filter conditions in the from clause of select , as we do in value expressions/conditions. * Translate associations and filters in FROM correctly to HANA CDS. * Avoid error with undefined when checking annotations with structs in arrays. * Provide correct defaults for $Nullable in ODATA V4. Version 1.0.14 \u00b6 Changes * Preserve the key properties of elements selected in a view (like we do in projections). * Improve the CSN representation for views. Represent the where and on condition of select s like other conditions. * Project name in github is now cdx/cds-compiler . Features * Support select * in views. * First version of transformation into OpenAPI json with --to-swagger option, more about it here Fixes * Resolve the on condition for associations defined in the mixin clause of a select . * Produce correct using directives with --to-hana for artifacts with implemented in . * Handle mixins and expression elements in views correctly with --to-hana . * Improve annotation assigment checks with --check-model . * Check that type declarations for ODATA do not contain anonymous struct types. Version 1.0.13 \u00b6 Changes * Rename project from @sap/cdsv to @sap/cds-compiler . Note that you will likely need to adapt your package.json because of that. * Check that no sub- select s are used in expression and conditions (currently: path filters and on -conditions of unmanaged associations); in views, they are only allowed with option --beta-mode . Features * Support the mixin clause in select s (to add unmanaged associations to a view ). * Support extending enum types (and elements where the enum type has been defined in-place), and annotating existing enum symbols. Fixes * Recognize function calls without parentheses (like current_data ) in all expressions and conditions (not just in select items and the where condition). * Make layer computation respect all using from -dependencies. * Make the compiler more robust regarding incomplete/unexpected sources. * During annotation propagation in the ODATA preprocessing, handle overwriting of annotations correctly. * Fix foreign key checks with --toHana . * The key generated for analytical views now has the name ID__ . Version 1.0.12 \u00b6 Changes * The --odata-and-hana-output no longer contains the plain compiled CSN but the result of the ODATA-specific preprocessing step. Dito for the API function cdsv.toOdataOutput . Features * For analytical views (those annotated with @Aggregation.ApplySupported.PropertyRestrictions ), transform keys appropriately. Fixes * Views are now handled like projections by --toHana (regarding struct flattening and transformation of association-typed elements into mixins). Version 1.0.11 \u00b6 Changes * Check that user code does not define artifacts in namespace cds . * It is an error to have two assignment for the same annotation on the same artifact/member in the same file/layer (see Features below), even if one is via extend and the other via annotate (both still overwrite assignments provided with a definition). Features * Allow arbitrary expressions and comparison operators in ON-condition of unmanaged associations (note: in EDMX, SQL functions that are called without parentheses like CURRENT_DATE are not yet supported) * Annotation assignments are now layer -aware: an annotation assignment in file A overwrites a annotation assignment in file B if file A directly or indirectly depends (via using\u2026from ) on file B , but not the other way round. * New syntax variant using from '<module>' (without an artifact name) to just add <module> to the model (and introduce a dependency between the two files). Fixes * Reintroduced attribute nullable for function import parameters in edmx generation for OData V2 * Better handling of paths for --to-hana in views and projections by using aliases. * SQL functions without parentheses (like CURRENT_DATE etc.) now correctly rendered with --to-hana . * TNT only: Handle @odata.navigable like @cds.odata.navigable Version 1.0.10 \u00b6 Changes * When using the command line tool to generate edmx files, the file names have changed: + the file name now contains the exact service name (dots are preserved and no longer replaced by underscore) + suffix default has been removed * Removed obsolete command line options --old-cdl and --new-cdl Features * Backlink associations now also work for unmanaged associations * Support for WHERE condition in views Fixes * Views are now rendered as EntitySet/EntityType in edmx * Abstract entites do not appear as EntitySet/EntityType in the generated edmx * --to-hana now correctly handles type casts in view definitions * In the generated edmx for OData V2, inside a ReferentialConstraint , the elements Dependent and Principal now have the correct order * Remove attribute nullable for function import parameters in edmx generation for OData V2 Version 1.0.9 \u00b6 Changes * With --to-hana the $self identifier is replaced by the absolute name of the current artifact, when it is part of a path. * TNT only: Remove obsolete skip options, add new skip options for remaining special cases. * Check that non-abstract entities must have a key for ODATA. Features * (experimental) Introduce shortcut for the value help annotation: @Common.ValueList:{ type:#fixed, entity:'DeliveryStatus' } Fixes * Also consider annotations of bound actions in the edmx generation. * Detect illegal cycles with managed associations. * Remove key property from a managed association which is transformed into an unmanaged one. * Do not swallow key in select items of views. * Handle backlink associations correctly in projections and structs. * For HANA and ODATA, correctly flatten paths starting within structs. * With --export-annotations , also export view annotations. * For nullable keys, let corresponding association foreign keys be nullable, too. * Handle implicit redirections within structs correctly * Render included (inherited) types and projections with implemented in correctly with --cdl-output Version 1.0.8 \u00b6 Changes * The namespace declaration now constructs a . -connected namespace, use (final) :: to construct a :: -connected namespace. The nameprefix declaration is considered obsolete (and leads to a warning). * Non-context/service artifacts cannot be named like a namespace. * New implementation of --to-hana , --cdl-output and --odata-and-hana-output produces one hdbcds file per top-level artifact (instead of trying to emulate the input source structure). Old implementation can still be used by specifying --old-cdl (will be removed in next version ). Features * Allow path when defining new artifacts. You can refer to a namespace in a using declaration . * Support simple single-source views, which can have expressions in select items * With option --beta-mode , support multi-source views without union and join - work in progress. * Support more expressions: Path filters, case , is null , not , parentheses, unary - , quantifiers ( any , all , ...), between , like , SQL functions. * Allow CDL files without definitions or extensions. * Initial support for semantic code completion. * Annotation assignments can be written at more places (consistently). * Support structured elements in entities (flattened for ODATA and HANA CDS). * Support backlink associations for --to-hana and --odata-and-hana-output` Fixes * All redefinitions in a source now lead to an error message. * Always do --to-hana checks when necessary. * With the new implementation, --to-hana , --cdl-output and --odata-and-hana-output now handle namespaces, using aliases, associations in projections, enums in entities, default values, strings without length, structured types, managed associations and quoted identifiers correctly. * Keys can now have the attribute null (unless generating for HANA, which does not support that) * Correctly determine multiplicity for backlink associations. Version 1.0.7 \u00b6 Features * Support for analytical annotations in ODATA V2 * Deprecated Common.FilterExpressionRestrictions in favor of Capabilities.FilterRestrictions.FilterExpressionRestrictions * --to-hana : Transform managed associations to unmanaged associations (with foreign key fields generated with _ and appropriate ON-conditions). Please note that this results in different field names on generated HANA tables . Fixes * Handle annotations @Analytics.Measures and @Semantics.* annotations correctly * Check that services and contexts are not illegally nested Version 1.0.6 \u00b6 Features * Support for the from clause of the using declaration, see the README file . Fixes * EDMX generation for annotations: if an annotation value is an expression that is not a CDS path, dots are no longer replaced by slashes * --to-hana : Handle the target of associations inside views with mixins correctly, when redirected to is used * Handle enums and structured types correctly in ODATA transformation * TNT only: Apply implicit redirection also to CSN output of ODATA translation * TNT only: Fix options skipGeneratedFKsWithout_ and skipAssociationSetsWithTo Version 1.0.5 \u00b6 Fixes * Added new dependency on npm module \"resolver\" to npm-shrinkwrap.json Version 1.0.4 \u00b6 Features * Support for function SESSION_CONTEXT in the on ON-condition of unmanaged associations * The keyword annotate can be used to annotate actions and functions * Annotation translation mechanism works for annotations at actions/functions and their parameters * Error messages that refer to csn files as input have position information Version 1.0.3 \u00b6 Features * Automatic redirection of associations: When a service contains a projection on an entity with an association with a target that is not part of the service, the association is now automatically redirected to a corresponding entity/projection in the service, if this new target can be determined uniquely (via following projections or includes) * --to-hana : now correctly handles elements of type Composition , they are translated to Association * Support for annotation @odata.etag for enabling optimistic concurrency handling in the (v2) OData provider * Support for managed associations as foreign keys of managed associations Fixes * Generated foreign key elements are now correctly marked as key if their association is a key element Other * Removed the message \"compiled successfully\" * A service can now be extended by extend service instead of extend context (the latter still works, but might lead to a compiler warning in the future ) Version 1.0.3-RC3 \u00b6 Fixes * Disable EDMX schema aliases again (apparently, not all consumers can properly digest them) * TNT-specific @extends : Multiple services exposing the same inherited context with different redirections Version 1.0.3-RC2 \u00b6 Features * Support for virtual elements * More semantic checks for actions, functions and managed associations * Generation of CSDL JSON (work in progress) Fixes * CDS annotations with \"inline CSDL JSON\" now also support $LabeledElement * Version number now consistent with suffix like -RC2 in all places * EDMX schema aliases now use last part of service name (no dots allowed) Version 1.0.3-RC1 \u00b6 Features * Command line parameter --new-odata' is deprecated and has no effect any more (it is ignored). Providing this parameter __will lead to an error in future versions__, so please don't use it anymore * New command line parameter --odata-preprocessing : For internal testing only (displays intermediate CSN). * CSN now contains a version attribute (no strict semantic versioning yet, though) * Allow \"inline CSDL JSON\" attributes to be transported through CSN to EDM annotations (still limited to a few use cases) * Allow managed associations with --to-hana (work in progress) * More semantic checks for actions and functions * Support for multiple services in one model. This results in changes to the return value of cdsv.toOdataOutput resp. toTntSpecificOutput . EDMX results (metadata and annotations) are now provided per-service in a dictionary services`. For backward compatibility, the old return value attributes are additionally provided if there is only one service. This will be abandoned in future versions . * Support for entities with parameters in EDMX Fixes * Fiori annotation translation for OData v2: Correctly set xmlns attribute for EntitySet annotations * EDMX generation for actions/functions: Correctly set attribute EntitySet in FunctionImport or ActionImport if the return type is entity or array of entity * TNT-specific: Ignore annotation \"CoreModel\" in the translation to EDMX * Various fixes for ReferentialConstraints in EDMX Version 1.0.2 \u00b6 Features * implemented in <id> : Allow wider range of identifier; using calcview as identifier is deprecated and will lead to an error in one of the next versions , please change to another identifier * Allow literals in ON-condition of unmanaged associations * Name resolution in association definition Fixes * Alerts are now sent to stderr * Correct rendering of type Time in EDMX v2 Version 1.0.1-MS1 \u00b6 Features * New implementation of name resolution (according to spec * Support for bound and unbound actions and functions * More semantic checks * Support for implemented in (HANA) * EDMX generation now also for ODATA V4 Fixes * skip options of TNT-flavor now working correctly (TNT only) * Fixed bug affecting elements called items (TNT only) * Correctly handle TypeDefinition in annotations EDMX Version 1.0.0-MS9 \u00b6 Features * Support for bound functions * EDMX annotations: Support pseudo-nested annotations, multiple enum values * New option --export-annos-ui5-style for localized annotations Fixes * Various fixes for annotation assignment checks * HANA CDS output now with source files like original (fixes issues with using ) * Fixed multiplicity for EDMX V2 * EDMX output: Reject ON-conditions that cannot be expressed in EDMX, reject structured elements, allow service-less input * EDMX annotation generation: More checks, better error messages * Compiler: Better handling of errors on top of errors Version 1.0.0-MS8 \u00b6 Features * First primitive type checks with '--check-model' Fixes * TNT-specific: It is in fact @com.sap.gtt.core.CoreModel.Indexable that should not be propagated Version 1.0.0-MS7 \u00b6 Fixes * Render view target paths in HANA CDS output like in original source * Various fixes for EDMX generation (XML namespace headers, EntitySet , EntityType , multiplicity, ...) * Structured elements in projections not yet supported for --to-hana Features * TNT-specific: Do not propagate @CoreModel.Indexable * New primitive datatype UUID * New option --check-model (work in progress, starting with annotations) * Option --odata-and-hana-output now also produces combined V4 EDMX file Version 1.0.0-MS6 \u00b6 Fixes * Really do not use plural form of entity names anywhere in ODATA * Properly complain about (most) incomplete/unsupported features Version 1.0.0-MS5 \u00b6 Fixes * Use all using declarations for HANA CDS * Do not use plural form of entity names for EntitySet in ODATA Version 1.0.0-MS4 \u00b6 Features * Allow multiple ReferentialConstraint nodes for ODATA ( --new-odata only) * Support abstract , BaseType , TypeDefinition for ODATA ( --new-odata only) * Digest association ON -conditions properly * Support default values for entity elements * Allow projections with actions * Support implemented in for entities * Produce combined EDMX file, too (containing both metadata and annotations) * Support redirected to for associations in projections * Allow CSN files as compiler input Fixes * Preserve original order for elements and actions in EDMX * Handle association cardinality properly for HANA CDS output * New implementation of EDMX annotation processor * Handle HANA-specific primitive types correctly ( LocalDate , UTCDateTime , ...) Version 1.0.0-MS3 \u00b6 Delivery * Now available as scoped module @sap/cdsv Features * New command line option --odata-and-hana-output <dir> to produce EDMX, HANA CDS and CSN output * New command line option --new-odata to select the new ODATA backend implementation * New command line option --odatav4 to produce EDMX metadata with ODADA V4 Version 1.0.0-MS2 \u00b6 Features: * Allow property files as compiler input (for i18n) * Support managed associations with explicit foreign keys (for ODATA) Fixes: * Improved automatic re-targeting of associations based on exposure * Correct EDMX annotations for Communication.Contact * Complete EDMX primitive type support * Handle one/many cardinality correctly in HANA CDS output * Provide complete type properties for projection elements * Add indexNo also for action parameters * Handle self -associations correctly in EDMX Version 1.0.0-MS1 \u00b6 Features: * Allow multiple includes for entities Miscellaneous: * Improvements for delivery * Cleanup of TNT-specific and not-yet-really-supported features Version 0.0.5: Make cdsv usable for early adopters like TNT \u00b6 Make TNT usage case work: * Produce special output for TNT: annotations.xml , metadata.xml and csn.json . * Add full TNT model, and smaller TNT examples as tests \u2192 produce same output as produced by prototype. * Adopt CSN format to a format expected by TNT (with option --tnt-flavor ) Extended functionality: * Support property files for internationalization (export and import). * Support generation of CDL (CDS language source) from CSN, with or without transformations to make it HANA-CDS compatible. * Started support to compile CSN files together with CDL files. General compiler things: * Introduce options for (temporary) language variants: --tnt-flavor , --hana-flavor . * Support extend and annotate , and includes. * Support projections. * Support actions with their parameters. * Support annotation variants and all syntax variants for annotation assignments. Support propagation of annotation assignments. * Support all type expressions with potential errors. * Parse DCL constructs (no further processing yet). Miscellaneous: * Provide Promise -less API. * Start with some (internal) documentation. * Much more tests. * Remove RND-inspired grammar. * Miscellaneous fixes and improvements. Version 0.0.4: Adapt ANTLR4 error strategy, use all HANA-CDS tests \u00b6 Adapt ANTLR4 error strategy and related things: * Allow unreserved keywords as identifier without listing them in error messages if an identifier is expected (but do list those which are to be matched as keywords!). * Match even reserved keywords as identifier (with message in the future?) if there is no alternative. * Avoid excessive use of ANTLR's adaptive prediction, as it would slow down the parser (done in grammar, there is a test which ensure that it stays that way). * Proper xmake configuration to generate lexer and parser. * PEG.js-based parser is discontinued. Use all HANA-CDS standalone tests: * Cover the complete HANA-CDS language. The main grammar use wildcards just for the SERIES and TECHNICAL CONFIGURATION section of entity definitions. (There is currently a second, much slower, grammar without wildcards, which is a one-to-one transformation of the RND grammar for HANA-CDS.) * Tests show completeness of parsing (except the wildcard use, see above), CSN-output equivalence (on specified parts) for 80% of the test cases. Version 0.0.3: ANTLR4-based Parser and Lexer \u00b6 PEG.js-based parser still used by default, because it does not need Java to build. Currently, we have a small ANTLR grammar in \"final style\", and a full ANTLR grammar in \"HANA-CDS style\". Version 0.0.2: Define and Resolve \u2013 Augmented CSN \u00b6 Functionality: Multi-file support with namespace / nameprefix and using declarations Context, entity, type, annotation, and element definitions Types: builtin (also with parameters), derived, structure types Unchecked annotation assignments (with absolute name calculation according to spec) All values: null, bool, number, string and other quoted literals ( x , date , time , timestamp ), enum symbols, structure (top-level are flattened for annotation assignments) and arrays \"Define\": merge source ASTs, set name.absolute and _parent links, \"Resolve\" for main artifacts: set type.absolute and _artifact links Dependency cycle detection with exact error positioning Compact JSON: for \"official\" CSN and tests Environment: Integration with xmake Checked accoding to our eslint rules Full tests: invocation, negative, positive Version 0.0.1: Package Setup & Initial Grammar \u00b6 Done: * Promise orchestration for asynchronous file processing, * avoid checking-in the generated parser, * proper whitespace handling in the grammar, * source location in AST, location includes filename * easy-to-use standard AST creation Our Promise orchestration must support the intended error policy: * We do not mix error categories, e.g., we do not output syntax/semantic errors in CDS files if the command invocation itself is wrong. * Inside one error category, we (intend to) list as many errors as possible, e.g. when two given files do not exist and another one is provided repeatedly, we report all these 3 errors at once. We do not include the generated parser : * As we have no npm publish phase at the moment, we list the parser generator pegjs in package.json \u2192 dependencies and run the parser generation in package.json \u2192 scripts/postinstall . * If the product is published, we list the parser generator pegjs in package.json \u2192 devDependencies and run the parser generation in package.json \u2192 scripts/prepublish . Parsers generated by PEG.js are without tokenizer \u2013 this looks cool at first, but leads to some problems: Still open: Error reporting is less then ideal \u2013 if the intended top-level context definition start with contxt , you just see one char after but : Expected \"context\", \u2026 but \"c\" found. See the grammar for a potential future hack to cover at least the most common occurrences. We always need to think about correct whitespace handling. See the initial comment in the grammar for details and common patterns. ( Solved ). In rules ending with optional whitespaces, we need to adjust the end location \u2013 it should not include the final whitespaces! See the initial comment in the grammar for details. ( Solved ). As an alternative , we could look at Antlr3.JavaScript, Antlr4.JavaScript, or RND.JavaScript.","title":"ChangeLog for cdx compiler and backends (Archive)"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#changelog-for-cdx-compiler-and-backends-archive","text":"Note: beta fixes, changes and features are usually not listed in this ChangeLog. The compiler behaviour concerning beta features can change at any time without notice.","title":"ChangeLog for cdx compiler and backends (Archive)"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1232","text":"Changes Association to Join Transformation: Validate paths of an expression in the projection to be compliant with the ON condition path constraints if such an expression is used in a mixin. Reject recursive or non-bijective $self expressions. Reject casting of a structured select item to a different type. OData: Update vocabularies Capabilities , Common , UI , Validation Fixes Association to Join Transformation: Resolve compound ON conditions with multiple logical terms and/or references to different associations via $self . Remove temporary property viaTransformation from published CSN. Do not complain about unaligned $syntax attribute in CSN frontend.","title":"Version 1.23.2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1231","text":"Changes OData: Lower message for unknown vocabulary annotations from warning to info. Lower message for @Analytics.Measure expects @Aggregation.default from warning to info. Remove empty EntityContainer and raise warning if Schema is empty. Fixes Correctly calculate code completion candidates for projection items in all circumstances (regression introduced in v1.22.0). In the Hana/Sql backend, correctly resolve forward on condition when using mixin association that backlinks to an unrelated 3rd party entity and association. Raise a warning if the element of the forward association and the element of the query source do not not originate from the same defining entity. Raise an error if the element of the forward association cannot be found in the query source or is ambiguous. Correctly create localization views with compiled model as input; it was wrong previously in a model with a high view hierarchy.","title":"Version 1.23.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1230","text":"Features Introduce ![identifier body] in the CDL source for delimited identifiers. (The ! is inspired by ABAP's identifier tag, [] by the delimited identifier syntax in Microsoft SQL Server and Sybase; we cannot use [] alone, because brackets are used for filter conditions.) When generating SQL or HDBVIEW, explicit CASTs are now rendered Changes Signal a warning for all uses of \"identifier body\" in the CDL source, as most uses of double-quotes in actual CDS models were likely meant for strings. (Yes, we do not adhere strictly to the lexical rules of the SQL Standard with this change\u2026) Issue a warning for an aspect definition without {\u2026} . In the CSN, aspect definitions have a $syntax property with value \"aspect\" . A future incompatible change will set the kind of aspect definitions to value \"aspect\" . Removed old CSN frontend and the corresponding options: stdJsonParser and oldCsnFrontend . Fix check for arguments and filters in references ( might introduce new errors ). Issue an error if explicit keys are provided when redirecting un managed associations. File paths given to cdsc which contain symbolic links are now resolved before being passed to the compiler. Annotating elements with @Core.Computed now always overwrites computed value; also expressions in parentheses will now induce to set @Core.Computed to true . Update OData vocabulary UI Increase the length of the element locale in generated _texts entities from String(5) to String(14) . Do not overwrite annotations with generated annotations (such as shortcuts and other convenience annotations). Fixes Automatically calculate keys also for published secondary managed associations, i.e., associations in a select column which is reached by following another association. The compiler doest not yet calculate the on condition of published secondary unmanaged associations \u2013 provide it explicitly. Entities/Views without elements are now detected correctly. Fix check for action/function parameters in services. OData: Correctly apply annotations to parameters.","title":"Version 1.23.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1220","text":"Features With redirected to , model designers can now explicitly provide the on condition / foreign keys for \"consumers\" of the current query (entity). This is useful for situations (usually mentioned as message) where the compiler does not calculate on / keys (automatically yet). Add OData vocabularies: com.sap.vocabularies.CodeList.v1 , Org.OData.Repeatability.V1 and com.sap.vocabularies.Session.v1 Changes In the sql , hdi and hdbcds backends with SQL dialect HANA, $user.id is translated to SESSION_CONTEXT('APPLICATIONUSER') , not SESSION_CONTEXT('XS_APPLICATIONUSER') anymore. As with the SQL dialect SQLite, it can now be configured. The client tool cdsc now prints a source excerpt for each message by default; use cdsc --no-message-context to get the previous behavior. Increase severity to Warning of messages for a situation where the compiler cannot calculate an on condition / foreign keys automatically. Issues warnings for annotation definitions, as their CSN representation will be moved from definitions into an new property vocabularies in a future change. OData: Update vocabularies: Analytics , Common , Communication , Core , PersonalData , UI Set reference base URI for SAP Vocabularies to https://sap.github.io/odata-vocabularies/vocabularies Fixes In the sql , hdi and hdbcds backends, correctly ignore contexts containing just actions, In all backends, correctly handle models where an on condition of a join contains a sub query. Avoid infloop for cyclic dependencies on select items with explicit redirections.","title":"Version 1.22.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1211","text":"Features OData: Support annotation @insertonly at an entity which translates to @Capabilities.DeleteRestrictions.Deletable: false , @Capabilities.ReadRestrictions.Readable:false , @Capabilities.UpdateRestrictions.Updatable: false . A warning is raised if @insertonly and @readonly are applied at the same entity and no mapping is done.","title":"Version 1.21.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1210","text":"Features Support cds.Decimal without type facets precision and scale as substitute for the deprecated cds.DecimalFloat . Mapping is as follows: HANA CDS HANA SQL SQLite Odata V4 Odata V2 DecimalFloat DECIMAL DECIMAL Decimal Decimal OData: Expand shorthand annotation @mandatory to Common.FieldControl: #Mandatory . Support edm:Singleton by annotating an entity with either @odata.singleton: Boolean or @odata.singleton.nullable: Boolean . @odata.singleton.nullable is a shorthand for @odata.singleton: true and sets the value for attribute Nullable (default is false). If odata.singleton is false , no singleton is generated regardless of the existence of @odata.singleton.nullable . + Option odataContainment: true renders compositions as edm:NavigationProperty with containment. This option is only available for OData V4 and with --beta-mode . Changes CSN frontend: use faster implementation by default. CDL frontend: issue warning for suspicious-looking delimited identifiers; some people think that they have written strings when they use double-quotes. Models delivered with @sap/cds are now resolved from cds.home ; e.g. using ... from '@sap/cds/common' . This allows working without locally inst# ChangeLog for cdx compiler and backends This allows working without locally installed @sap/cds , for example in Java projects. In that case, respective models will be fetched from a globally installed @sap/cds-dk . OData: Improve array of checks and reject anonymous types and types that are not service members. Set draft properties HasActiveEntity and HasDraftEntity to Nullable: false . Reject old-style CSN from all CSN based transformers and renderers toHana and toSql : Allow aliasing for foreign keys Fixes OData: Fix Nullable attribute for parameters in EDM JSON V4. Do not annotate edm:NavigationProperty for term definitions with AppliesTo: Property and vice versa. Fix bug in ON Condition rendering during transformation of associations to joins for stream based $self expressions. toHana : Only render and allow keys in the leading query toHana and toSql : When following an association, explicitly set the implicit alias to work around a HANA limitation","title":"Version 1.21.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1203","text":"Changes Core Compiler: Forbid navigating associations (to non foreign key elements) in the ON condition of an association definition. OData: Do not generate OnDelete for Containment Navigation Propertie, as this is redundant. Fixes In toSql for Sqlite generate current_timestamp for $at","title":"Version 1.20.3"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1201","text":"Changes Associations to 'abstract' artifacts and the usage of abstract entities in queries are now rejected. Fixes OData: Raise level from 'info' to 'warning' for excluded NavigationProperties due to targets outside the service. Fix a bug in mapping of @Capabilities (see Version 1.20.0) Flattening of structured elements - @cds.persistence.name was semi-flattened CSN Input: Support views with parameters in queries Support views with parameters in on-conditions of unmanaged associations Support 'not null' for enum elements","title":"Version 1.20.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1200","text":"Changes Issue error (instead of a warning) if a projected association uses a non-projected element in its on condition (message id rewrite-not-projected ). Issue error (instead of a warning) if the redirected target does not originate from the original target of an association (message id redirected-to-unrelated ). In --beta-mode remove the annotation @odata.draft.enabled: false from generated _texts entities. Annotate the technical foreign keys of a _texts entity with @cds.odata.v4.ignore: true to allow containment in OData V4 for _texts . In toHana and toSql associations to entities annotated with @cds.persistence.exists are removed from the generated model. This is an extension to the change introduced with version 1.15.0. If a proxy artifact shall be an association target, another 1:1 projection entity shall be created wich then can act as the association target. OData: Reject non specification compliant CSN as input to csn2edmx Add annotation @cds.odata.{v2|v4}.ignore in --beta-mode Rewrite @Capabilities annotation to @Capabilities.NavigationRestrictions at the containment association in case an entity set has been omitted due to containment in OData V4. Update vocabularies Common and UI Improve error message when not generating a navigation property for association targets outside the same service. Draft: Raise an info message if a draft root has not exactly one primary key element of type cds.UUID Raise an info message if a draft node (subordinate to a draft root) has not exactly one primary key element of type cds.UUID and optionally one more additional primary key. Raise an error message if the same draft node is reachable from two separate draft roots. Raise an info message if a service contains more than one draft root entities. Annotate technical elements IsActiveEntity , HasActiveEntity , HasDraftEntity , DraftAdministrativeData and DraftAdministrativeData_DraftUUID with @UI.Hidden CSN Input: New simplified parsing of CSN, can be enabled via compiler option stdJsonParser or command line option --std-json-parser Support for $location Fixes * Compiler: + Correctly reject the Promise if errors occur during parsing OData: Correctly render annotations with null values in arrays. Correctly render annotations with records of complex types. Correctly annotate artifacts with parameters. Annotations are assigned to the resulting EntityType <name>Type Correctly flatten substructures when used as types CSN Validation: Correctly process views with parameters in unmanaged associations Make parseToCqn() use filter in FROM clause as hint for (recommended) colon, i.e. never discard the filter.","title":"Version 1.20.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1192","text":"Changes Improve the semantic checks for Association to many with a partial key, not complaining about a missing ON condition anymore. HANA: When using names: quoted , raise a warning when artifacts with @cds.persistence.exists belong to a CDS namespace, context or service. OData: Raise an info message on the usage of deprectated OData vocabulary terms. Raise a warning message when applying @odata.Type with another type as Edm.String , Edm.Int16 , Edm.Int32 , Edm.Int64 . Support shorthand annotation @description for @Core.Description . Never complain about localization views when recompiling a CSN file that has localized convenience views already expanded. If the definition's absolute name is localized , it must be a context. If the definition's absolute name starts with localized. , it must either be a context or a query entity. An error message is raised in all other cases. In all cases, definitions in the namespace localized are ignored for further processing. Fixes Fix a dump when compiling from CSN for query elements without a key property that have no column counterpart.","title":"Version 1.19.2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1191","text":"Fixes Make sure that we really create all localized convenience views for entities which have localized elements, select localized elements or can directly or indirectly reach (via navigation along associations and compositions) such entities. Features Allow annotations with @odata.Type: 'Edm.Int16' and likewise with value 'Edm.Int32' and 'Edm.Int64' to influence the type which is chosen in the generated EDMX.","title":"Version 1.19.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1190","text":"Changes Event definitions are now properly listed in the CSN: the kind is event , the property for its members is called payload . Omit redundant kind: 'param' for parameters in the params dictionary of a CSN. Fixes Do not use upcoming OData v4.01 facet values for cds.DecimalFloat , i.e. revert v1.18.0 change which had added Scale: floating and Precision: 34 . In CSN frontend, support direct {func: \u2026} objects in orderBy and groupBy .","title":"Version 1.19.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1182","text":"Fixes Issue warning instead error when CDS type cds.DecimalFloat is used with OData v2. Also issue the warning for CDS type cds.hana.SMALLDECIMAL . Properly render n-ary cross join s, typically produced by select from A, B, C . Features Allow to provide HANA-specific magic variables like current_utctimestamp via the function syntax current_utctimestamp() . Similar for sysuuid , current_connection , current_schema , current_transaction_isolation_level , current_utcdate and current_utctime . Support SQL Standard magic variable system_user (without parentheses); be aware that it is not supported (by that syntax) in HANA.","title":"Version 1.18.2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1181","text":"Changes Hide the experimental swagger backend behind betaMode and issue a warning even then. Fixes Properly establish EDMX partnership again between forward and backward association even in the presense of \"hidden\" associations (v1.18.0 had introduced a bug). Issue a warning if there are multiple (non hidden) partnership candidates. Features using from <module> also tries file extensions .csn and .csn.json .","title":"Version 1.18.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1180","text":"Changes OData: add type facet Scale: floating , Precision: 34 to Edm.Decimal for mapped CDS type cds.DecimalFloat . Issue error if cds.DecimalFloat is used with OData v2 . Fixes If a projection in a service selects from a source in a model, associations in the projection source are implicitly redirected to a target in the service. The corresponding redirection must also happen for the localized convenience view for the projection in the service: the new target should be the localized convenience view for the \"original\" redirection target (if it does not exist: the \"original\" redirection target itself).","title":"Version 1.18.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1173","text":"Changes OData: Disable proxy generation again due to too many runtime conflicts. This effectively auto-excludes the associations as navigation properties from the service that reference targets outside the service; properties from the foreign keys of managed associations remain. As opposed to the pre-v1.16.2 behaviour, this only affects the OData backend. OData: Raise error if EntityType has no primary key. Raise warning if compiler is invoked in --beta-mode Fixes Make annotate statements on members of autoexposed entities and automatically created text entities work.","title":"Version 1.17.3"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1172","text":"Fixes Fix stack overflow bug in EDM Preprocessing","title":"Version 1.17.2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1171","text":"Changes OData: Add type facet Precision=7 to Edm.DataTimeOffset if CDS type is cds.Timestamp . Add semantic check to prevent the usage of hana.ST_POINT and hana.ST_GEOMETRY as primary key types. Fixes OData: Do not generate NavigationPropertyBinding (V4) or AssociationSet (V2) for non-existing EntitySet of the Proxy EntityType s introduced with Version 1.16.2.","title":"Version 1.17.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1170","text":"Features OData V4: With --beta-mode enabled, compositions become containment navigation properties. This is performed by annotating all compositions with @odata.contained . Existing assignments are not overwritten. Enabling containment is an incompatible change to existing OData metadata documents as all composition targets are no longer accessible as EntitySets but only through their container. Release keyword event . Changes OData: Update all known Odata vocabularies, this also includes SAP vocabularies which now may contain Term definitions marked as experimental . HANA Datatype Support in SQLite: Render ST_GEOMETRY and ST_POINT as CHAR(5000) . Use association names as table aliases during the association to join transformation instead of using the association target (this makes the transformed view more comprehensible). Fixes Parameter lists and filters in ON condition paths are rejected in association to join transformation. Append the temporal WHERE clause to views that already have a WHERE clause. View elements with @cds.valid.from/@cds.valid.key are no longer marked as key in the columns. CSN validator accepts select statements with a having or a group by clause containing a function call.","title":"Version 1.17.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1162","text":"Features Introduce builtin-types for the (HANA) SQL types SMALLINT , TINYINT , SMALLDECIMAL , REAL , CHAR , NCHAR , VARCHAR , CLOB , BINARY , ST_POINT , ST_GEOMETRY . In the CSN, they appear as cds.hana.SMALLINT , \u2026. In CDL, they can be referred to by hana.SMALLINT , \u2026. Mapping of the types is as follows: CDS HANA SQLite OData V4 OData V2 SMALLINT SMALLINT INT Edm.Int16 Edm.Int16 TINYINT TINYINT INT Edm.Byte Edm.Byte SMALLDECIMAL SMALLDECIMAL DECIMAL Edm.Decimal Scale=\"floating\" Precision=\"16\" Edm.Decimal REAL REAL FLOAT Edm.Single Edm.Single CHAR CHAR CHAR Edm.String Edm.String NCHAR NCHAR CHAR Edm.String Edm.String VARCHAR VARCHAR CHAR Edm.String Edm.String CLOB CLOB CHAR Edm.String Edm.String BINARY BINARY CHAR Edm.Binary Edm.Binary ST_POINT ST_POINT CHAR Edm.GeometryPoint n/a ST_GEOMETRY ST_GEOMETRY CHAR Edm.Geometry n/a Changes Associations in services with targets outside the service are not auto-excluded anymore. OData: Create proxy EntityType s for association targets that are not part of the current service. This maintains the navigation path in the EDM model and exposes the primary key tuple of the otherwise unreachable target. The primary keys of a proxy entity must be scalar types. No complex types are supported. Also all outbound navigations are removed from a proxy. The package require node version 8 or higher. Fixes Forbid publishing associations inside unions. Fix a bug in the creation of localized convenience views that lead to an erroneously JOIN expression if such a view gets transformed into a SQL query with toSql --assoc joins . OData: be robust against erroneoulsy assigned @odata.foreignKey4 annotation. Improve ON condition path checks in Association to Join transformation. Fix crash in forHana generation when determining the type of an enum.","title":"Version 1.16.2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1161","text":"Features API: If the compiler frontend reports messages and the compile function had been called without options having a messages property, then the resulting CSN contains a non-enumerable messages property containing the messages. Changes Removed TNT specific behaviours for HANA CDS, SQL and OData from the code. Perform usage check of entities annotated with @cds.persistence.skip if using entity really exists on the database (not annotated with cds.persistence.table ). Remove mixin associations with a target entity annotated with @cds.persistence.skip and its select item that eventually expose this association. csn2edm: Produce all services in a given model in one pass removing the requirement to call the EDM transformation for each service individually. The existing API is still compatible. If an EDM for only one service is requested, only this EDM will be produced. Odata: Don't omit containee's foreign keys if they are also primary key. Remove warning that containment association must be NOT NULL . Support annotation @cds.etag as (backward compabible) replacement for @odata.etag . Update broken UI vocabulary. Fixes Make property propagation from query sources using associations work. Consider associations in from clause for on condition rewrite. Make the CSN parser always produce the correct result for null . Propagate @cds.autoexpose along primary query source in all circumstances. Make annotate statements on autoexposed entities work in circumstances. Do not dump when magic variables like $now or current_date had been used in an entitiy for which the compiler creates a localized convenience view. Fix order problem in creation of association DraftAdministrativeData for draft enabled entities. Fix runtime error in forHana in handling of mixin forward and backward associations.","title":"Version 1.16.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1150","text":"Features Release aspect temporal . Changes Improve handling for entities are either abstract or annotated with @cds.persistence.skip in toHana and toSql : Such entities are not part of the generated database model and thus non-existing in the database schema. Associations/compositions to non-existing entities are removed from the generated model but not their eventually generated foreign keys (for managed associations). An info message is raised for each removal. An error message is raised if a non-existing entity is used (either directly or indirectly through an association). Fixes OData Do not assign @Core.AlternateKeys for temporal aspects if the annotation already assigned. Resolve primitive return types for actions Mark localized _texts entities and convenience views with @odata.draft.enabled: false JSON parser Allow JavaScript objects as input, as well as JSON","title":"Version 1.15.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1141","text":"Changes Primary key definitions are only allowed in first union . Raise an error if primary keys are defined in subordinate union clauses when generating toHana . Fixes HANA CDS Don't generate primary keys in subordinate union clauses if the element is a key-element of the source entity. In case of multiple chained union s, generate all union clauses correctly. OData Generate unique Names for <edmx:Association> elements in Version 2 to avoid name clashes with other entries in <edmx:Schema> . Raise error for duplicate definitions in <edmx:Schema> . CSN Input validation - joins can have value literals in the on condition","title":"Version 1.14.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1140","text":"Features Support aspect temporal with option --beta-mode : Support magic variables $at.from and $at.to . OData: Add element annotated with @cds.valid.from to the key in the metadata document but not in the CSN, requiring a valid primary key in the projection to exist. An element annotated with @cds.valid.key becomes the sole primary key in the EntityType. Add an @Core.AlternateKeys annotation that lists the original primary key tuple as well as the element annotated with @cds.valid.from . SQL/HANA CDS: Translate $at.from to SESSION_CONTEXT('VALID-FROM') in HANA and current_time in Sqlite. Translate $at.to to SESSION_CONTEXT('VALID-TO') in HANA and current_time in Sqlite. A WHERE claues that allows time travel queries is generated for projection that contain exactly one element annotated with @cds.valid.from and @cds.valid.to that stem from the same origin. An entity elementannotated with @cds.valid.from is added to the primary key tuple of the resulting database table. If an entity element is annotated with @cds.valid.key , it becomes the sole primary key of the resulting database table. Redirect targets of associations in localized convenience views to their respective localized convenience views. In addition to that, create a localized convenience view for all entities that contain associations that lead directly or indirectly (via n other association steps) to a localized entity, so that these associations can also be redirected. Localized convenience views are only created in case the model is error free. Changes Allow to extend an entity with an empty structure OData: An error is raised for entities that have become empty (no elements) due to automatic exclusion of associations. Update the vocabulary UI Allow multiple 'backlink' associations via $self ON condition, first 'backlink' establishes the partnership Allow 'backlink' associations to define their own target multiplicity. Raise a warning if the forward association is not included in the service (due to autoexclusion). Reclassify error on containment association to be NOT NULL down to a warning. @cds.api.ignore suppresses annotations. Fixes OData: Fix issues with @cds.odata.bindingparameter.collection : Correct $Collection to Collection in EDMX No referential constraints for NavigationProperties with target multiplicity '*' Avoid internal errors on cyclic view definitions Strengthen checks on reserved names","title":"Version 1.14.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1134","text":"Feature extend projection with elements extend entity with aspect, i.e. not by specifying new elements, but via a definition which has elements. Changes Localized convenience views (introduced in Version 1.12.0 as beta feature) are now available. The convenience views for views and projections are created as a copy of the regular artifact in the localized namespace which selects from the corresponding localized artifacts. Associations within localized convenience views aren't redirected yet; they still point to their original non-localized target. Convenience views for views containing associations in their FROM clause aren't supported yet. For those views an Info message is produced stating that no convenience view could be created for the given view. In contrast to the beta feature it isn't required anymore to expose the localized association or the primary key. The automatic exposure of entities, redirection and exclusion of associations has been moved from forHana and forOdata post-processing into the core compiler: When an association is projected, the compiler checks whether all elements are propagated which are referred to in the on condition of the projected association. Please reexamine warnings for your model. The compiler checks whether a redirection target (directly or indirectly) projects from the original target (and/or uses the original target as structure include). Elements can be renamed in the redirected target and the on condition is rewritten correspondingly (currently not if the projected association is an indirect one, i.e. if we project assoc1.assoc2 , which was an Error in v1.12.0 ) \u2192 this means that those DB artifacts can be deployed. When following an implicitily redirected association, potentially renamed elements are taken into account. Implicit redirections fail less often as the compiler tries to find a \"minimal\" exposure. Auto-exposure via Composition of now works in all circumstances. Other features like \"localized\" work for auto-exposed entity and/or with implicitly redirected association. Redirections for associations which are sub elements do not work . The name of an autoexposed entity now looks like <Service>.<LastNamePart> where <LastNamePart> is the part of the name of the original entity after the final dot. If you get an error because of name clashes, just expose one entity explicitly (or use the option longAutoexposed ). Multiple backlink associations for one forward association make the OData backend report an error. Fixes Forward the key property to the select items of generated HANA CDS views. Remove some issues of the $projection and $self handling in the association to join translation. Add alias for select items that are primary key in HANA CDS. Fix support for union queries in localized convenience views.","title":"Version 1.13.4"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1121","text":"Changes * With option --beta-mode , automatic exposure of entities, redirection and exclusion of associations has been moved from forHana and forOdata post-processing into the core compiler. Fixes * With option --beta-mode in v1.12.0, a just inherited @cds.autoexpose had not been considered. * With option --beta-mode in v1.12.0, projecting indirect associations ( assoc1.assoc2 ) lead to an error.","title":"Version 1.12.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1120","text":"Features * With option --beta-mode , support localized convenience views: Create a view named localized.<EntityName> for an entity with localized elements. This view allows a coalesced access to localized elements and either returns the default or translated content, depending on the locale setting. + A convencience view is only created if both the localized association and some localized elements are exposed in the entity. + When exposing the localized association in an entity, also the complete primary key has to be exposed, otherwise an error is thrown. * Mark calculated and virtual elements as @Core.Computed:true . If @Core.Computed has been set manually, it remains unchanged. Changes With option --beta-mode , automatic exposure of entities, redirection and exclusion of associations has been moved from forHana and forOdata post-processing into the core compiler. Update to v1.12.1 if you experience problems \u2013 an inherited @cds.autoexpose had not been considered. In toSql and toHana errors are raised for duplicate definitions of elements that differ only in spelling, if the the entity is not abstract or annotated with any @cds.persistence set to true and an element is typed to be an array of a type , an implicit managed composition has cardinality to many. Raise a warning if an element is to be localized which is not of type cds.String . Fixes * OData: + On @Aggregation.ApplySupported.PropertyRestrictions apply @sap.sortable':false, '@sap.filterable':false at new ID__ property. + Allow @Core.OperationAvailable: null + Abstract entities and all inbound navigation properties are removed from the metadata document. + Non-properties are not considered as referential constraints. * Correct annotation cds.autoexposed .","title":"Version 1.12.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1110","text":"Features * Support localized elements: + Add sibling entity <entityName>_texts to store the localized content. + Add two associations texts and localized to the original entity. + Add view localized.<entityName> to retrieve either the translated or original content. * Annotate elements that are virtual or annotated with @odata.on.insert or @odata.on.update with @Core.Computed . * Support OData @Common.ValueList by either + annotating an element for which a value help entity shall be used with @Common.ValueList.viaAssociation . The value is the association to the value list entity. + annotating an entity with @cds.odata.valuelist . All associations targeting to this entity are then annotated with @Common.ValueList.viaAssociation . + annotating an element statically with @Common.ValueList.entity . The annotation value is a static entity name and cannot be dynamically adapted during autoexposure. * Add annotation @cds.odata.bindingparameter: {name: String, collection: Boolean } which allows overriding the binding parameter name and cardinality of a bound action in OData V4. Default is: name='in' , collection=false . * Allow a colon in FROM and TYPE OF references. * Support using and publishing a mixin association in the same view when activating for HANA CDS. Changes * Produce all CSN output in version 1.0 by default. * Virtual elements cannot be used in expressions. * Command toRename creates a stored procedure instead of individual statements. * Don't autoexpose composition target which is annotated with @cds.autoexpose: false . Fixes * OData: + Rename OData annotation vocabulary Auth to Authorization . + Correct exposure of entities with parameters: - Set attribute EntityType of element edm:EntitySet to the correct type - Set attribute EntitySet of element edm:End in edm:AssociationSet to the correct set. + EnumMember in element edm:Annotation has only one delimiting slash * Rewrite ON condition of a mixin backlink association for an inferred and redirected forward association.","title":"Version 1.11.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1100","text":"Features * Annotate entities with @cds.autoexposed that are autoexposed in a service. * Always autoexpose composition targets without annotating them with @cds.autoexpose . * For associations in a service with targets which are not in a service: + automatically exclude them if the associaiton is inferred (via select * or include), + signal an error if the association is explicitly defined in the service. * Support the OData annotation vocabulary Authorization . Changes * Generate null as \u2026 for virtual view elements. * Update OData annotation vocabulary Core . * Change the tranlation of annotation @readonly at an element from @Core.Immutable to @Core.Computed when processing for OData. Fixes * Avoid unnecessary aliases for paths that terminate on an association in the FROM clause. * Fix an issue with table alias handling in Association to Join translation. * Translate type Cds.DateTime to SQL type TIMESTAMP for Sqlite. * Fix an internal error when parsing view V as select distinct from E * Raise an error that an empty service cannot be used to generate an OData metadata document * Correctly set the OData principal in a referential constraint for compositions with free defined ON conditions.","title":"Version 1.10.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-190","text":"Changes * Always use quotes around identifiers for toSql and toHana with quoted or hdbcds names. * Never use quotes around identifiers for toSql and toHana with plain names. Issue a warning if an identifier may conflict with a language keyword. * Generate .hdbtable , .hdbview etc. files if option toSql.src is hdi (default sql generates .sql files). Features * Allow select clauses with standard SQL syntax (i.e. also accept select ... from ... in addition to the CDS-specific form select from ... { ... } ). * Support count(*) etc. * Support function calls with names arguments. * Support aspect definitions. Fixes * Omit unused vocabularies in OData-generated EDMX files. * For toOdata , handle nested anonymous types correctly (also with arrays, e.g. in action/function parameters) * Handle mixins correctly when transforming associations to joins.","title":"Version 1.9.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-181","text":"Changes * With --new-redirect-impl , associations and compositions in services are implicitely redirected to a (unique) projection of the original target if the projection is \"simple and similar enough\" and defined in the service. This is now always done, not only by the toOdata backend; association targets explicitly provided in the service are not implicitly redirected. * With option --new-csn (or --beta-mode ) alone, we do not properly rewrite the on condition or keys anymore. Use option --assoc-on-rewrite and --new-redirect-impl to do so. Fixes * With --new-redirect-impl , the navigation along implicitly redirected associations now properly considers that elements could have been renamed in the new association target. * With --new-redirect-impl , the code completion candidates are the elements of the new association target calculated by the implicit redirection. * With --new-redirect-impl and --assoc-on-rewrite , the on condition or keys are rewritten with implicit redirections. * With toSwagger , enum constants without values are now correctly rendered. * With toSql in sqlite dialect, a warning is now issued if an identifier collides with a known SQL keyword. * For OData, annotations with null values are now ignored (this can also be used to \"delete\" an annotation in an extension). * In OData, structured types that are anonymous or not exposed in a service are now automatically exposed (unless used as an entity element - in that case they are still flattened). * For OData v2, the namespace for service annotations is now correctly set. * For toHana with plain names, all type properties (including length ...) are now propagated correctly when derived types are used explicitly in view columns. * CSN version 0.2.0 is now accepted by the compiler.","title":"Version 1.8.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-180","text":"Features * Support the OData annotation vocabularies PersonalData and Aggregation . The vocabulary for PersonalData contains a number of annotations that are flagged as \"experimental\". Their usage will result in a warning. * New option for specifying the locale in SQLite dialect. As part of the toSql command is now available the options '-l, --locale <locale>' for specifying value for the \"$user.locale\" variable. Changes * Entity definitions with elements of type array and structure type definitions with association elements will now lead to an error message when generating edmx for OData v2. These constructs are not allowed in OData v2, but there was no corresponding check in the cds compiler yet.","title":"Version 1.8.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-171","text":"Fixes * Restore version function which was deleted by accident","title":"Version 1.7.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-170","text":"Features * Allow entities to have parameters. They can be referred to inside the query with :Param . Entites with parameters are not allowed in toSql for dialect \"sqlite\". When generating for HANA, parameters cannot be used in combination with associations: an entity with parameters cannot have associations, and an association must not point to an entity with parameters. * The parameters and return value of actions and functions can now have structured types. * In the annotation translation for OData, falsy values of the special variable $value (that is used to provide nested annotations for scalar values) are correctly handled. * When (new-style) csn is used as input, the compiler ignores unknown attributes. * Implicit redirection and auto-exposure are now applied recursively, i.e. the associations of an auto-exposed entity are considered for implicit redirection and auto-exposure, if necessary. Changes * With --new-csn , consider redirected to on projected associations and adapt the on condition and the keys specification accordingly. There are also Info messages if an element referred to in the on condition or keys specification has not been projected to the new association target. The severity of these messages will be increased if implicit redirections will have been performed by the core compiler. * toHana and toSql now reject entities that only contain unmanaged associations. Such entites would lead to a deployment error later. * SQL name mapping modes quoted and hdbcds are only allowed when generating for HANA. * In the csn, the csn language version is now stored in the top level attribute $version . The version information via version.csn is deprecated and will be removed in a future release. The information about the creator of the csn has been moved inside the new top level attribute meta . Fixes * Provide code completion for references in complex select item expressions not (yet) having an alias (complex = not consisting of just a reference). * With --new-csn , avoid internal error while rewriting the on condition from an element of a source entity which refers to a mixin definition with an on condition containing a reference like $projection.<elem> . * OData, edmx generation: correctly escape the characters < , > , & , and \" . * When an entity is auto-exposed, it's annotations are transferred to the generated projection.","title":"Version 1.7.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-160","text":"Features * Provide code completion for using declarations. * Support the OData annotation vocabulary \"Validation\". * For compositions in EDM, add <OnDelete Action=\"Cascade\"/> to the navigation property where required. Changes * With --new-csn , complain more often about projected associations whose on condition could not be rewritten correctly. * Make associations: 'joins' the default for toSql (because the default for dialect is already sqlite , which requires joins). * Adapt the command line interface to use commands instead of the --to... generation options (e.g. cdsc toHana --src --names plain instead of cdsc --toHana src,plain ). Please see the Command Line Migration guide for details. * Add a generated by cds-compiler version x.y.z comment to all generated SQL and hdbcds sources. * Replace the CSN validator (formerly ajv ) with a new own implementation. Fixes * With --new-csn , do not change references to magic variables like $user.id while rewriting the on conditition of a projected association. * Apply OData specific checks (e.g. that all elements of an entity must have a type) applied only to objects that are exposed in a service. * When generating SQL for SQLite, replace the the special variables $now , $user.id and $user.locale by CURRENT_TIMESTAMP , '$user.id' , and 'EN' , respectively. * Issue a warning for conflicting cardinality declarations (e.g. association[1] to many ... ). * Handle filters with cardinality correctly when translating associations to joins. * Avoid crash when checking structured action parameters. * Handle $self as the first of multiple path steps correctly in toOdata . * In toHana , render the combination of enums and type of correctly. * In mixins generated by toHana , handle special variables starting with $ correctly.","title":"Version 1.6.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-150","text":"Features * The DDL statements in the output of toSql are now sorted according to kind (views after tables), so that they can be deployed sequentially to HANA (view dependencies not yet considered). * (Still work in progress): The output of toSql now also contains kind-specific dictionaries for hdbtable , hdbview etc., which should be directly deployable to HDI. Changes * Element definitions in multiple entity/structure extensions are now sorted according to the layer hierarchy \u2013 elements from highest layers come last. Report such multiple extensions only if they are potentially problematic. * The values for the names option of toSql , toHana and toOdata have been renamed: flat (default) is now plain , deep is now quoted . The old values are still accepted (with a warning) but will be removed in a subsequent release . Fixes * OData, annotation processing for v2: In a view where translation of analytical annotations is switched on, the annotations @Common.Text , @Common.Label , and @Measures.ISOCurrency/@Measures.Unit are now translated into the corresponding v2-style annotations sap:label , sap:text , and sap:unit , respectively, even if the value is a path or has a nested annotation. * OData V2, generation of EDMX: The Parameters of a FunctionImport now always have an attribute Nullable=\"true\" if not specified as not null in CDS. * Produce better parentheses for nested set operations ( union , intersect , ...) in views for SQL output. * Correctly strip off the enum property of types for HANA CDS, even when derived types are involved.","title":"Version 1.5.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-140","text":"Features * OData, annotation processing: Provide a shortcut for the nesting of the TextArrangement annotation: In order to annotate a @Common.Text annotation, just put an annotation @Common.TextArrangement next to it. * Parameters can now be referred to with :param , :1 or ? in the parse API functions. Changes * More checks for the correct usage of $self and associations as values in expressions. * Backlink-Associations: When transforming an ON-condition on $self = foo.bar , check that the association bar really points to the entity enclosing association foo . * Allow and transform multiple $self -comparisons in one association ON-condition (but a true backlink association still requires exactly one such comparison). * Warn if a \"to many\" association or composition does not have an ON-condition (likely not intended because the resulting managed association will at most match a single item) Fixes * Add missing as for flattened structured elements. * Allow using cds; to make the namespace cds explicitly known, which is useful if that had been shadowed by a namespace declaration ending with cds . * OData: don't generate empty <Annotations ...> elements any more. * Draft for OData v2: in the DraftRoot and DraftNode annotations, the path to the draft annotations now contains EntityContainer . * Improved checks for parameters of actions and functions. Inappropriate warnings like \"The type of input parameter ... must be from the current service\" and \"The action ... can only return an array of entities\" don't appear any more. * Correctly generate foreign key fields for associations in structured types. * For toHana() and toSql() , enclose the artificial condition resulting from $self -comparisons in parentheses. * Warn properly when draft-enabled artifacts are not exposed in a service. * Do not render a full entity name for paths like $self.foo to SQL (just skip $self ).","title":"Version 1.4.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-130","text":"Features * The using declaration can now appear top-level also after artifact definitions. * Support for $user.locale and $user.id with HANA generation SESSION_CONTEXT(\u2026) . * For entities annotated with @odata.draft.enabled , the generated DraftAdministrativeData association for ODATA is now annotated with @odata.contained: true (avoiding the generation of an <Attribute> for its foreign key in ODATA V4). Changes * Having just $user in CDL is now rendered as {ref:['$user','id'], as:'$user'} in new-style CSN. * Using SQL's parameter-less functions not having parentheses (like current_date ) is now rendered as {func:'current_date'} in new-style CSN. * betaMode is currently required for entities with parameters. * In old-style CSN, the on condition as source text has been removed. * Explicit redirection of an association to a target that is completely unrelated to the original target is now an error, not just a warning. * The API function toI18n() and the corresponding command line option --to-i18n have been removed. * Annotation assignments after sub structure definitions, enum definitions, and parameters are now considered an error instead of just a warning. * For bound actions and functions, the name of the corresponding function import in OData v2 edmx is now prefixed with the name of the entity. Fixes * For ODATA V2, create correct <Principal> and <Dependent> for backlink associations having @odata.navigable:false . * Avoid the Expecting artifact to be part of a service error that occurred when generating multiple entities with @odata.draft.enabled to SQL. * Generate correct (fully qualified) action names into the @Common.DraftRoot and @Common.DraftNode annotations. * When generating the DRAFT.DraftAdministrativeData entity for SQL, provide proper lengths for all NVARCHAR fields.","title":"Version 1.3.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-120","text":"Features * Provide semantic code completion for the excluding clause. * Add support for \"deep drafts\", i.e. follow compositions from entities annotated with @odata.draft.enabled (\"draft roots\") and draft-enable them as \"draft nodes\". Changes * Finalize the propagation of the key property. Provide Info messages if it is not obvious why it has not been propagated. * Finalize the propagation of the keys property and items property. * Check for illegal use of $self and associations in expressions (may only occur as values in an expression as part of the ON-condition in a backlink association). Fixes * Produce warnings instead of errors in the translation of OData annotations. * For ODATA, in case of managed associations to draft-enabled entities, do not add an extra foreign key for the ODATA-generated key field IsActiveEntity . * For HANA, in the generated draft shadow entities, redirect all associations (not just compositions) so that they point to the draft shadow entities. * For ODATA V2, produce an <EntitySet> for DraftAdministrativeData , too. Ignore the @cds.odata.NoEntitySet annotation. * For ODATA V4, do not generate <Nullable> for <NavigationProperty> s that are collections.","title":"Version 1.2.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-113","text":"Features * A ; is now always optional before } and more often optional after a } . Changes * In toOdata() for v2, in the edmx the names of bound actions and functions now are prefixed with the corresponding entity's name in order to disambiguate actions and functions with the same name at two or more entities. The corresponding implementation code in the CDS runtime needs to be adapted. * Check redirected to target. Fixes * Make the compiler more robust wrt/ parse errors and redefinitions. * Correctly propagate properties inside returns and items . * Some corrections to EDM ActionImport and FunctionImport in ODATA V2 and V4. * Generate correct joins for mixin associations that are traversed with different filters. * Generate joins not only for views, but also for projections. * For entities annotated with @odata.draft.enabled , make all non-key fields nullable in toOdata() .","title":"Version 1.1.3"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-112","text":"Features * Allow reserved names for annotations/properties in assignments. * Allow final , for much more \"lists\" (e.g. arguments). * It is now possible to omit the select list in a view definition, which is the same as writing select from <name> {*} . * Allow array of as type spec for a parameter definition. * SQL generation for sqlite now supports a mode where associations are resolved to joins. Changes * Improved messages for syntax errors. * where now is a reserved keyword and so cannot be used anymore as name at many places. Fixes * In toOdata() with the hdbcds naming convention, the value of the @cds.persistence.name annotation now uses . rather than _ as separator for the names of flattened structured entity elements. * Numeric values in OData annotations are now correctly mapped to edmx.","title":"Version 1.1.2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-111","text":"Fixes * Ignore unapplied extensions when generating HANA CDS source. * Make sure the combination of collectSources() and compileSources() has the same effect as compile() , especially regarding annotation precedence. * Render annotations of edm:Schema correctly in for ODATA V4.","title":"Version 1.1.1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-110","text":"Features * Support @odata.draft.enabled without the need for option { betaMode: true } ). Fixes * Return result of collectSources() as promise.","title":"Version 1.1.0"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1033","text":"Features * Allow to extend query entites with actions. * Allow select distinct . * With --tnt-flavor only: allow to specify (a restricted version of) service include via syntax. * (Work in progress): New option { dialect: 'hana'|'sqlite' } for toSql() , allowing generation of SQL statements without HANA-specific constructs (e.g. without WITH ASSOCIATION ). * For ODATA V4, handle associations to parameterized entities correctly. * Allow specifying key for projection elements (important in case of partial keys not being propagated, see below). * Annotate entities and elements in the CSN with @cds.persistence.name , the name generated for the persistence layer according to the naming convention chosen ( flat , deep , hdbcds ). * (Work in progress, only available with option { betaMode: true } ): Support @odata.draft.enabled with toHana() , toOdata() and toSql() . Only draft roots so far, no compositions. Fixes * Put table alias for from into CSN even without having it explicitly provided in CDL if necessary (the table has been referred via a using with alias). * Do not assume a specific min cardinality if none was provided. * For SQL, provide table aliases when required because of flat naming. * Handle @readonly annotation correctly when applied to entities. * Various fixes to the handling of @odata.contained . Changes in the property propagation, see internalDoc/Propagation.md: * Propagate properties along primary sources in includes, especially actions/functions. * The propagation of key is more restrictive now, most notably: only if all keys are selected (selecting sub elements of a structured key is not enough), only if there is no navigation along a to-many association in a select item. * The propagation of notNull has been corrected. * The propagation of virtual has been corrected. * The propagation of an array type has been corrected. Other changes * For ODATA, provide min cardinality 1 for non-null associations. * Remove obsolete option --check-model . Instead, always perform all checks previously hidden behind that option, possibly resulting in more warnings (but not more errors). * Actions and functions are no longer restricted to entities within services.","title":"Version 1.0.33"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1032","text":"Features * The toHana() , toSql() and toRename() backends now also support a naming convention that is backward compatible to HANA CDS, with option { names: 'hdbcds' } . * New API function collectSources() to conserve a set of compiled sources with its hierarchy relations. * Avoid unnecessary quoting of names generated by toHana() , toSql() and toRename() . * Implement handling of @cds.persistence.table . * Support \"term casts\" in paths of ODATA annotations. * Support the @odata.contained annotation. Changes that only have an effect if the --new-csn option is set * With --disable-propagate , produce CSN in gensrc flavor: + omit inferred elements and keys, + omit propagated properties (like annotation assignments), + supply annotation assignments on inferred and propagated members with an extra annotate statement in the model's extensions property if necessary. * Without --disable-propagate , produce CSN in client flavor: + provide inferred elements and keys, + provide propagated properties (like annotation assignments), + supply annotation assignments directly with the inferred member. * The $inferred property has been removed. * Rename foreignKeys to keys for the keys to target elements of associations. * Rename filter to where in ref s and omit the surrounding {xpr:\u2026} of the condition. * Do not render query columns if no columns have been provided (only implicit * ). * Render technical configuration correctly. * Render select distinct correctly. * Let also those backends that produce CSN as a by-product (e.g. toHana() , toOdata() , ...) produce new-style CSN if the --new-csn option is set. Other changes * The property propagation has been changed, except with --tnt-flavor . See internalDoc/Propagation.md, it is still work in progress. * Remove the special handling of namespaces ending with :: * Sort the output of toHana() and toCdl (also within contexts and services). * When @cds.autoexpose is set for entities that are already exposed, use the existing exposure for implicit redirection. Fixes * An annotate statement on an enum symbol now has the expected effect. * Annotation @cds.autoexposure is renamed to @cds.autoexpose (like it is used in documentation) * EDM Nullable and Cardinality now handled correctly for ODATA V2. * Correctly check that elements must have a type for ODATA. * Handle structured annotation assignments and # -variants correctly with toCdl() . * For toHana , generate correct aliases for foreign key fields in views if the corresponding association has an alias. * Do not propagate @cds.persistence.table and @cds.persistence.exists . * Render artifact paths in from correctly with toSql() . * In EDM, do not render OpenType and Abstract if they have default values. * For EDM annotations, correctly set Target according to vocabulary's AppliesTo . * In EDM, only set Nullable=false if not null was explicitly specified (i.e. not just for all keys). * In EDM, handle entities with parameters correctly regarding the entity type that is generated for the parameters.","title":"Version 1.0.32"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1031","text":"Features * Support multiple imported names in using declaration: using { foo.bar, this as that } from './othermodule'; * Add new command line option --to-rename , generates SQL DDL statements renaming existing HANA tables for migration (work in progress, subject to change). * For ODATA, allow backlink associations on unmanaged associations. Changes * New error for extending views (query entities) with new elements. * Allow annotations of unknown artifacts - slightly change the name resolution in CDL for references in top-level extend and annotate statements. * Make the client tool display info messages by default. * Make keywords new and aspect to be non-reserved. With this change, the set of reserved keywords of CDL is a real subset of the reserved keywords of SQL. * Remove command line options and API functions deprecated with v1.0.24. * In ODATA V2, reuse the edm::Association of the original association for backlink associations. Fixes * Miscellaneous fixes for CSN with option --new-csn . * Avoid internal error by not running extra checks after compilation with error. * Propagate defaults and @odata.Type annotations from keys to generated foreign key fields of associations. * Do not render annotations of subqueries to HANA CDS. * Suppress $projection in ON-conditions for ODATA. * When looking for candidates for implicit redirection, follow FROM sources of views/projections and : -includes of entities transitively, not just for one level. (Please note that this fix may uncover errors in existing models where implicit redirection now fails because of multiple candidates. Use explicit redirection to resolve this to one of the candidates, as suggested in the error message). * For ODATA and HANA CDS, recognize and transform backlink associations also if the condition is in (redundant) parentheses. * For HANA CDS, replace enum literals in defaults by their values. * Reject paths in defaults.","title":"Version 1.0.31"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1030","text":"Features * Complex queries (with joins, sub-selects etc.) are now supported. Changes * Both toHana() and toSql() now use flat names by default (specify options { names: 'deep' } to get the old behavior). The CSN version currently starts with 0.1 for flat names, with 0.0 for deep . This is likely to be adapted again later. * Using Annotate on unknown artifacts or members now only leads to an info message, not an error anymore. The CSN with option --new-csn then has an extensions property containing the effective assignments. * Downward compatibility for @cds.odata.navigable was finally removed (see 1.0.11, use @odata.navigable instead). Fixes * Render table aliases correctly for HANA CDS when an entity is used in from that is aliased by a using declaration.","title":"Version 1.0.30"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1029","text":"Features * Support the generation of multiple services with --to-swagger . * Support SELECT DISTINCT . Changes * Improve smart wildcard handling: simple projections with just redirections now have the original element order of the source. * Restrict limit and offset value to number (and null ). * There is a warning for key elements outside entities or views, as an inner key specification would be ignored for implicit foreign keys and propagation. * Change propagation of the key property: see internalDoc/Propagation.md. Most notably, in a view/projection the key property is no longer propagated along association navigation. Fixes * Entities that contain only virtual elements or are empty (recursively) are now rejected for HANA CDS, unless they are abstract (was only partly checked before). * Multiply nested structs in views or projections are now correctly rendered to HANA CDS (avoiding a completely unrelated error message complaining about extensions).","title":"Version 1.0.29"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1028","text":"Features * The mapping of cds to edm types can be overridden by the annotations @odata.Type and @odata.MaxLength . Currently only Edm.String can be used as target type. This is intended for exceptional cases, where the standard type mapping is not wanted (e.g. if UUID should be mapped to Edm.String rather than Edm.Guid ). Fixes * Issue an error, if an association element that is defined in a mixin of the same view is explicitly redirected. Up to now this modelling error was not recognized and led to the generation of incorrect HANA CDS models. * We now also allow query entities and their elements to use as type, relaxing a check introduces with v1.0.26. It needs to be seen whether we allow entites as type only for actions.","title":"Version 1.0.28"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1027","text":"Changes * The implemented in clause of entity definitions has been removed and will now cause a syntax error (this clause is obsolete since version 1.0.21, see corresponding changelog entry). Replace it by one of these annotations: + use @cds.persistence.exists to indicate that an object should not be created in the database because the database object already exists. + use @cds.persistence.skip to indicate that an object should not be created in the database because it is implemented in the service layer.","title":"Version 1.0.27"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1026","text":"Features * For annotation assignments outside array values, allow paths and variants, not just identifiers as keys in structure values. Changes * In flat mode, the toHana channel will reject quoted identifiers in definitions. * Smart * : just issue a warning if a select item \"overwrites\" an element coming from the wildcard. Might even be downgraded to an Info message in the future. * Artifact references are checked for plausibility: only allow entities as association and composition target and for the select from clause (allow to navigate along associations there, too), only allow (non-query) structures for structure includes, only allow types (and entities) and their elements as types. * Implicit redirection of associations is now also performed for HANA CDS (as it was already for ODATA). Fixes * IDE support: improve syntactic code completion, and messages for parse errors. * OData: correctly escape special xml characters in generated edmx.","title":"Version 1.0.26"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1025","text":"Changes * Better command line error reporting for cdsc . Fixes * Render anonymous structured types correctly to HANA CDS (no : ). * Handle structured elements with aliases in views and projections correctly. * Flatten structured view elements for ODATA (like for HANA CDS).","title":"Version 1.0.25"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1024","text":"Features * The toHana() channel now also supports the option flag toHana.names:'flat' . This option affects how the names of database objects and their columns are built. This option will become the default in one of the next versions . The old behavior can then be enforced with option flag toHana.names:'deep' . With option flag flat , ... + all names are converted to uppercase + in object names, _ is used as separator instead of . Changes * The new command line tool cdsc is going to replace the old cdsv , which is deprecated and will be removed soon . Please see the Command Line Migration guide for details. * New API \"backend\" functions (i.e. those that generate output from a CSN model) are going to replace the existing ones. The old API functions toHanaCdl , forHana , toOdataOutput , exportAnnotations , exportAnnosUi5Style and toSqlDdl , are deprecated and will be removed soon . Please see the API Migration guide for details. * ODATA JSON output can no longer be generated for V2 (there is no valid V2 JSON format). * When generating the CSDL JSON for OData v4, enum values now have an additional attribute $EnumMember@odata.type . This addition reflects an amendment of the specification of CSDL JSON. Fixes * Do not try to find table aliases for references consisting of a single identifier, i.e., a column named x in the select list is also found if the table alias or the table itself has been named x , too. * Fix unjustified message about a undefined reference in mixin definitions when a reference starting with $projection accesses a nested element or an element which has been added to the query via * . * Check that ON-conditions of unmanaged associations do not traverse other unmanaged associations. * When generating EDM, ignore aliased elements in ON conditions of redirected associations. * Guarantee a deterministic artifact processing order even if async calls are involved. * When generating edmx for OData v2, referential constraints for entities with multi-part keys are now correctly rendered.","title":"Version 1.0.24"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1023","text":"Changes * When generating for Swagger, handle TNT-specific features more gracefully.","title":"Version 1.0.23"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1022","text":"Fixes * IDE support: improve syntactic code completion, and messages for parse errors. * Fix behavior of @cds.persistence.exists for HANA CDS (generate correct using , avoid empty contexts). * Strip key from structured type elements when generating for HANA CDS.","title":"Version 1.0.22"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1021","text":"Changes * The CSN element property notNull is not inherited anymore if the select / projection items whose path refering the source element navigates along associations or compositions. * Annotation assignments which are placed after the name of context or service definitions must now use the @(...) syntax variant if a value is supplied, the same restriction already applies for all other definitions. This new syntax restriction can be disabled with option tntFlavor , and re-enabled with its new sub option skipSloppyAnnoAssignments . * The syntax implemented in is deprecated. It is replaced by two new annotations: + use @cds.persistence.exists to indicate that an object should not be created in the database because the database object already exists. + use @cds.persistence.skip to indicate that an object should not be created in the database because it is implemented in the service layer. * The shortcut for the value list annotation has been simplified, you now can just type @Common.ValueList.entity:'SomeValueList' Fixes * IDE support: improve semantic code completion. * Self-associations are now handled correctly in the ODATA generation.","title":"Version 1.0.21"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1020","text":"Features * For Swagger, one parameter of an action or function can now be selected to become the request body, by annotating it with @Swagger.parameter: 'requestBody' . * The shortcut for value help annotation @Common.ValueList:{ type:#fixed, entity:'SomeValueList' } is now generally available. * For associations in ODATA that have targets outside the service, projection-like views are now also considered as implicit redirection targets (not just projections). Fixes * Type properties like length are now omitted when generating an ODATA property Edm.Stream . * Nested annotations for ODATA are now handled correctly. * The transformation of backlink associations for HANA CDS is now more robust against artifact processing order.","title":"Version 1.0.20"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1019","text":"Changes * Allow aliases in projections for HANA CDS (although not 100% watertight in all cases). Features * Entities annotated with @cds.autoexposure are now automatically exposed in a service (by means of a full projection) when they are used as association targets within that service. Fixes * The $user variable is now correctly expanded to SESSION_CONTEXT('XS_APPLICATIONUSER') , with only one underscore. * The --check-model option is now more robust against the order of artifacts in the model. * Enum types are now always reduced to their base type for HANA CDS. * Options given to the compiler or one of the post-processing functions are now always handed down together with the model. * The query clauses LIMIT and OFFSET are now really enabled (were accidentally still left in beta).","title":"Version 1.0.19"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1018","text":"Changes * Compiler now complains if an entity exposed for ODATA has an element without a type. * View and projection elements in CSN now always have a value property (possibly with a path). Features * For ODATA, now also the annotations from the Analytics vocabulary are translated. Fixes * Workaround for a HANA CDS issue: When providing LargeString or LargeBinary as explicit type for a view element, HANA CDS runs into an error during the deployment of the generated HANA CDS (fix pending). This error can be prevented by annotating the corresponding elements in CDX with @cds.workaround.noExplicitTypeForHANA . * not null at a managed association is no longer added to the corresponding unmanaged association in HANA CDS, but only to the foreign keys. * When a redirected association is used as a view element, the select item for the corresponding MIXIN is now correctly rendered for HANA CDS and CDL (accidentally had an explicit association type). * MIXINs that are explicitly added to views are now correctly generated for HANA CDS (were accidentally duplicated). * Do not complain about @Core.MediaType for key-less entities.","title":"Version 1.0.18"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1017","text":"Changes * Correct license in package.json * toSwagger takes in mind only artifacts from services Fixes * Handle type cds.UUID correctly when generating SQL. * Handle associations in GROUP BY and ORDER BY correctly when generating HANA CDS. * When generating MIXINs for associations in HANA CDS views, use an alias to avoid conflicts with association usage in the SELECT. * Wrap bound action and function definitions in an array when generating EDMX.","title":"Version 1.0.17"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1016","text":"Changes * Allow artifacts to be defined in namespace cds.foundation . Features * Support the remaining query clauses group by , having , order by (with optional asc / desc and optional nulls first / nulls last ), and limit (with optional offset ). * Support the magic variables $now and $user . Fixes * Complain about artifact extensions inside context/service extensions. * For ODATA, add a $Partner attribute to edm:NavigationProperty when appropriate for bi-directional asociations. There is a new document which explains some error messages (more messages will be added in the future).","title":"Version 1.0.16"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1015","text":"Changes * More checks for correct ODATA input (element names, keys, ...). Features * Allow redirected to in select items of views. * Support the @Core.MediaType annotation for ODATA. Fixes * Correct bug in the calculation of the _finalType , which could lead to an internal error within the odata backend. * Properly resolve filter conditions in the from clause of select , as we do in value expressions/conditions. * Translate associations and filters in FROM correctly to HANA CDS. * Avoid error with undefined when checking annotations with structs in arrays. * Provide correct defaults for $Nullable in ODATA V4.","title":"Version 1.0.15"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1014","text":"Changes * Preserve the key properties of elements selected in a view (like we do in projections). * Improve the CSN representation for views. Represent the where and on condition of select s like other conditions. * Project name in github is now cdx/cds-compiler . Features * Support select * in views. * First version of transformation into OpenAPI json with --to-swagger option, more about it here Fixes * Resolve the on condition for associations defined in the mixin clause of a select . * Produce correct using directives with --to-hana for artifacts with implemented in . * Handle mixins and expression elements in views correctly with --to-hana . * Improve annotation assigment checks with --check-model . * Check that type declarations for ODATA do not contain anonymous struct types.","title":"Version 1.0.14"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1013","text":"Changes * Rename project from @sap/cdsv to @sap/cds-compiler . Note that you will likely need to adapt your package.json because of that. * Check that no sub- select s are used in expression and conditions (currently: path filters and on -conditions of unmanaged associations); in views, they are only allowed with option --beta-mode . Features * Support the mixin clause in select s (to add unmanaged associations to a view ). * Support extending enum types (and elements where the enum type has been defined in-place), and annotating existing enum symbols. Fixes * Recognize function calls without parentheses (like current_data ) in all expressions and conditions (not just in select items and the where condition). * Make layer computation respect all using from -dependencies. * Make the compiler more robust regarding incomplete/unexpected sources. * During annotation propagation in the ODATA preprocessing, handle overwriting of annotations correctly. * Fix foreign key checks with --toHana . * The key generated for analytical views now has the name ID__ .","title":"Version 1.0.13"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1012","text":"Changes * The --odata-and-hana-output no longer contains the plain compiled CSN but the result of the ODATA-specific preprocessing step. Dito for the API function cdsv.toOdataOutput . Features * For analytical views (those annotated with @Aggregation.ApplySupported.PropertyRestrictions ), transform keys appropriately. Fixes * Views are now handled like projections by --toHana (regarding struct flattening and transformation of association-typed elements into mixins).","title":"Version 1.0.12"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1011","text":"Changes * Check that user code does not define artifacts in namespace cds . * It is an error to have two assignment for the same annotation on the same artifact/member in the same file/layer (see Features below), even if one is via extend and the other via annotate (both still overwrite assignments provided with a definition). Features * Allow arbitrary expressions and comparison operators in ON-condition of unmanaged associations (note: in EDMX, SQL functions that are called without parentheses like CURRENT_DATE are not yet supported) * Annotation assignments are now layer -aware: an annotation assignment in file A overwrites a annotation assignment in file B if file A directly or indirectly depends (via using\u2026from ) on file B , but not the other way round. * New syntax variant using from '<module>' (without an artifact name) to just add <module> to the model (and introduce a dependency between the two files). Fixes * Reintroduced attribute nullable for function import parameters in edmx generation for OData V2 * Better handling of paths for --to-hana in views and projections by using aliases. * SQL functions without parentheses (like CURRENT_DATE etc.) now correctly rendered with --to-hana . * TNT only: Handle @odata.navigable like @cds.odata.navigable","title":"Version 1.0.11"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-1010","text":"Changes * When using the command line tool to generate edmx files, the file names have changed: + the file name now contains the exact service name (dots are preserved and no longer replaced by underscore) + suffix default has been removed * Removed obsolete command line options --old-cdl and --new-cdl Features * Backlink associations now also work for unmanaged associations * Support for WHERE condition in views Fixes * Views are now rendered as EntitySet/EntityType in edmx * Abstract entites do not appear as EntitySet/EntityType in the generated edmx * --to-hana now correctly handles type casts in view definitions * In the generated edmx for OData V2, inside a ReferentialConstraint , the elements Dependent and Principal now have the correct order * Remove attribute nullable for function import parameters in edmx generation for OData V2","title":"Version 1.0.10"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-109","text":"Changes * With --to-hana the $self identifier is replaced by the absolute name of the current artifact, when it is part of a path. * TNT only: Remove obsolete skip options, add new skip options for remaining special cases. * Check that non-abstract entities must have a key for ODATA. Features * (experimental) Introduce shortcut for the value help annotation: @Common.ValueList:{ type:#fixed, entity:'DeliveryStatus' } Fixes * Also consider annotations of bound actions in the edmx generation. * Detect illegal cycles with managed associations. * Remove key property from a managed association which is transformed into an unmanaged one. * Do not swallow key in select items of views. * Handle backlink associations correctly in projections and structs. * For HANA and ODATA, correctly flatten paths starting within structs. * With --export-annotations , also export view annotations. * For nullable keys, let corresponding association foreign keys be nullable, too. * Handle implicit redirections within structs correctly * Render included (inherited) types and projections with implemented in correctly with --cdl-output","title":"Version 1.0.9"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-108","text":"Changes * The namespace declaration now constructs a . -connected namespace, use (final) :: to construct a :: -connected namespace. The nameprefix declaration is considered obsolete (and leads to a warning). * Non-context/service artifacts cannot be named like a namespace. * New implementation of --to-hana , --cdl-output and --odata-and-hana-output produces one hdbcds file per top-level artifact (instead of trying to emulate the input source structure). Old implementation can still be used by specifying --old-cdl (will be removed in next version ). Features * Allow path when defining new artifacts. You can refer to a namespace in a using declaration . * Support simple single-source views, which can have expressions in select items * With option --beta-mode , support multi-source views without union and join - work in progress. * Support more expressions: Path filters, case , is null , not , parentheses, unary - , quantifiers ( any , all , ...), between , like , SQL functions. * Allow CDL files without definitions or extensions. * Initial support for semantic code completion. * Annotation assignments can be written at more places (consistently). * Support structured elements in entities (flattened for ODATA and HANA CDS). * Support backlink associations for --to-hana and --odata-and-hana-output` Fixes * All redefinitions in a source now lead to an error message. * Always do --to-hana checks when necessary. * With the new implementation, --to-hana , --cdl-output and --odata-and-hana-output now handle namespaces, using aliases, associations in projections, enums in entities, default values, strings without length, structured types, managed associations and quoted identifiers correctly. * Keys can now have the attribute null (unless generating for HANA, which does not support that) * Correctly determine multiplicity for backlink associations.","title":"Version 1.0.8"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-107","text":"Features * Support for analytical annotations in ODATA V2 * Deprecated Common.FilterExpressionRestrictions in favor of Capabilities.FilterRestrictions.FilterExpressionRestrictions * --to-hana : Transform managed associations to unmanaged associations (with foreign key fields generated with _ and appropriate ON-conditions). Please note that this results in different field names on generated HANA tables . Fixes * Handle annotations @Analytics.Measures and @Semantics.* annotations correctly * Check that services and contexts are not illegally nested","title":"Version 1.0.7"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-106","text":"Features * Support for the from clause of the using declaration, see the README file . Fixes * EDMX generation for annotations: if an annotation value is an expression that is not a CDS path, dots are no longer replaced by slashes * --to-hana : Handle the target of associations inside views with mixins correctly, when redirected to is used * Handle enums and structured types correctly in ODATA transformation * TNT only: Apply implicit redirection also to CSN output of ODATA translation * TNT only: Fix options skipGeneratedFKsWithout_ and skipAssociationSetsWithTo","title":"Version 1.0.6"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-105","text":"Fixes * Added new dependency on npm module \"resolver\" to npm-shrinkwrap.json","title":"Version 1.0.5"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-104","text":"Features * Support for function SESSION_CONTEXT in the on ON-condition of unmanaged associations * The keyword annotate can be used to annotate actions and functions * Annotation translation mechanism works for annotations at actions/functions and their parameters * Error messages that refer to csn files as input have position information","title":"Version 1.0.4"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-103","text":"Features * Automatic redirection of associations: When a service contains a projection on an entity with an association with a target that is not part of the service, the association is now automatically redirected to a corresponding entity/projection in the service, if this new target can be determined uniquely (via following projections or includes) * --to-hana : now correctly handles elements of type Composition , they are translated to Association * Support for annotation @odata.etag for enabling optimistic concurrency handling in the (v2) OData provider * Support for managed associations as foreign keys of managed associations Fixes * Generated foreign key elements are now correctly marked as key if their association is a key element Other * Removed the message \"compiled successfully\" * A service can now be extended by extend service instead of extend context (the latter still works, but might lead to a compiler warning in the future )","title":"Version 1.0.3"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-103-rc3","text":"Fixes * Disable EDMX schema aliases again (apparently, not all consumers can properly digest them) * TNT-specific @extends : Multiple services exposing the same inherited context with different redirections","title":"Version 1.0.3-RC3"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-103-rc2","text":"Features * Support for virtual elements * More semantic checks for actions, functions and managed associations * Generation of CSDL JSON (work in progress) Fixes * CDS annotations with \"inline CSDL JSON\" now also support $LabeledElement * Version number now consistent with suffix like -RC2 in all places * EDMX schema aliases now use last part of service name (no dots allowed)","title":"Version 1.0.3-RC2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-103-rc1","text":"Features * Command line parameter --new-odata' is deprecated and has no effect any more (it is ignored). Providing this parameter __will lead to an error in future versions__, so please don't use it anymore * New command line parameter --odata-preprocessing : For internal testing only (displays intermediate CSN). * CSN now contains a version attribute (no strict semantic versioning yet, though) * Allow \"inline CSDL JSON\" attributes to be transported through CSN to EDM annotations (still limited to a few use cases) * Allow managed associations with --to-hana (work in progress) * More semantic checks for actions and functions * Support for multiple services in one model. This results in changes to the return value of cdsv.toOdataOutput resp. toTntSpecificOutput . EDMX results (metadata and annotations) are now provided per-service in a dictionary services`. For backward compatibility, the old return value attributes are additionally provided if there is only one service. This will be abandoned in future versions . * Support for entities with parameters in EDMX Fixes * Fiori annotation translation for OData v2: Correctly set xmlns attribute for EntitySet annotations * EDMX generation for actions/functions: Correctly set attribute EntitySet in FunctionImport or ActionImport if the return type is entity or array of entity * TNT-specific: Ignore annotation \"CoreModel\" in the translation to EDMX * Various fixes for ReferentialConstraints in EDMX","title":"Version 1.0.3-RC1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-102","text":"Features * implemented in <id> : Allow wider range of identifier; using calcview as identifier is deprecated and will lead to an error in one of the next versions , please change to another identifier * Allow literals in ON-condition of unmanaged associations * Name resolution in association definition Fixes * Alerts are now sent to stderr * Correct rendering of type Time in EDMX v2","title":"Version 1.0.2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-101-ms1","text":"Features * New implementation of name resolution (according to spec * Support for bound and unbound actions and functions * More semantic checks * Support for implemented in (HANA) * EDMX generation now also for ODATA V4 Fixes * skip options of TNT-flavor now working correctly (TNT only) * Fixed bug affecting elements called items (TNT only) * Correctly handle TypeDefinition in annotations EDMX","title":"Version 1.0.1-MS1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms9","text":"Features * Support for bound functions * EDMX annotations: Support pseudo-nested annotations, multiple enum values * New option --export-annos-ui5-style for localized annotations Fixes * Various fixes for annotation assignment checks * HANA CDS output now with source files like original (fixes issues with using ) * Fixed multiplicity for EDMX V2 * EDMX output: Reject ON-conditions that cannot be expressed in EDMX, reject structured elements, allow service-less input * EDMX annotation generation: More checks, better error messages * Compiler: Better handling of errors on top of errors","title":"Version 1.0.0-MS9"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms8","text":"Features * First primitive type checks with '--check-model' Fixes * TNT-specific: It is in fact @com.sap.gtt.core.CoreModel.Indexable that should not be propagated","title":"Version 1.0.0-MS8"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms7","text":"Fixes * Render view target paths in HANA CDS output like in original source * Various fixes for EDMX generation (XML namespace headers, EntitySet , EntityType , multiplicity, ...) * Structured elements in projections not yet supported for --to-hana Features * TNT-specific: Do not propagate @CoreModel.Indexable * New primitive datatype UUID * New option --check-model (work in progress, starting with annotations) * Option --odata-and-hana-output now also produces combined V4 EDMX file","title":"Version 1.0.0-MS7"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms6","text":"Fixes * Really do not use plural form of entity names anywhere in ODATA * Properly complain about (most) incomplete/unsupported features","title":"Version 1.0.0-MS6"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms5","text":"Fixes * Use all using declarations for HANA CDS * Do not use plural form of entity names for EntitySet in ODATA","title":"Version 1.0.0-MS5"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms4","text":"Features * Allow multiple ReferentialConstraint nodes for ODATA ( --new-odata only) * Support abstract , BaseType , TypeDefinition for ODATA ( --new-odata only) * Digest association ON -conditions properly * Support default values for entity elements * Allow projections with actions * Support implemented in for entities * Produce combined EDMX file, too (containing both metadata and annotations) * Support redirected to for associations in projections * Allow CSN files as compiler input Fixes * Preserve original order for elements and actions in EDMX * Handle association cardinality properly for HANA CDS output * New implementation of EDMX annotation processor * Handle HANA-specific primitive types correctly ( LocalDate , UTCDateTime , ...)","title":"Version 1.0.0-MS4"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms3","text":"Delivery * Now available as scoped module @sap/cdsv Features * New command line option --odata-and-hana-output <dir> to produce EDMX, HANA CDS and CSN output * New command line option --new-odata to select the new ODATA backend implementation * New command line option --odatav4 to produce EDMX metadata with ODADA V4","title":"Version 1.0.0-MS3"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms2","text":"Features: * Allow property files as compiler input (for i18n) * Support managed associations with explicit foreign keys (for ODATA) Fixes: * Improved automatic re-targeting of associations based on exposure * Correct EDMX annotations for Communication.Contact * Complete EDMX primitive type support * Handle one/many cardinality correctly in HANA CDS output * Provide complete type properties for projection elements * Add indexNo also for action parameters * Handle self -associations correctly in EDMX","title":"Version 1.0.0-MS2"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-100-ms1","text":"Features: * Allow multiple includes for entities Miscellaneous: * Improvements for delivery * Cleanup of TNT-specific and not-yet-really-supported features","title":"Version 1.0.0-MS1"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-005-make-cdsv-usable-for-early-adopters-like-tnt","text":"Make TNT usage case work: * Produce special output for TNT: annotations.xml , metadata.xml and csn.json . * Add full TNT model, and smaller TNT examples as tests \u2192 produce same output as produced by prototype. * Adopt CSN format to a format expected by TNT (with option --tnt-flavor ) Extended functionality: * Support property files for internationalization (export and import). * Support generation of CDL (CDS language source) from CSN, with or without transformations to make it HANA-CDS compatible. * Started support to compile CSN files together with CDL files. General compiler things: * Introduce options for (temporary) language variants: --tnt-flavor , --hana-flavor . * Support extend and annotate , and includes. * Support projections. * Support actions with their parameters. * Support annotation variants and all syntax variants for annotation assignments. Support propagation of annotation assignments. * Support all type expressions with potential errors. * Parse DCL constructs (no further processing yet). Miscellaneous: * Provide Promise -less API. * Start with some (internal) documentation. * Much more tests. * Remove RND-inspired grammar. * Miscellaneous fixes and improvements.","title":"Version 0.0.5: Make cdsv usable for early adopters like TNT"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-004-adapt-antlr4-error-strategy-use-all-hana-cds-tests","text":"Adapt ANTLR4 error strategy and related things: * Allow unreserved keywords as identifier without listing them in error messages if an identifier is expected (but do list those which are to be matched as keywords!). * Match even reserved keywords as identifier (with message in the future?) if there is no alternative. * Avoid excessive use of ANTLR's adaptive prediction, as it would slow down the parser (done in grammar, there is a test which ensure that it stays that way). * Proper xmake configuration to generate lexer and parser. * PEG.js-based parser is discontinued. Use all HANA-CDS standalone tests: * Cover the complete HANA-CDS language. The main grammar use wildcards just for the SERIES and TECHNICAL CONFIGURATION section of entity definitions. (There is currently a second, much slower, grammar without wildcards, which is a one-to-one transformation of the RND grammar for HANA-CDS.) * Tests show completeness of parsing (except the wildcard use, see above), CSN-output equivalence (on specified parts) for 80% of the test cases.","title":"Version 0.0.4: Adapt ANTLR4 error strategy, use all HANA-CDS tests"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-003-antlr4-based-parser-and-lexer","text":"PEG.js-based parser still used by default, because it does not need Java to build. Currently, we have a small ANTLR grammar in \"final style\", and a full ANTLR grammar in \"HANA-CDS style\".","title":"Version 0.0.3: ANTLR4-based Parser and Lexer"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-002-define-and-resolve-augmented-csn","text":"Functionality: Multi-file support with namespace / nameprefix and using declarations Context, entity, type, annotation, and element definitions Types: builtin (also with parameters), derived, structure types Unchecked annotation assignments (with absolute name calculation according to spec) All values: null, bool, number, string and other quoted literals ( x , date , time , timestamp ), enum symbols, structure (top-level are flattened for annotation assignments) and arrays \"Define\": merge source ASTs, set name.absolute and _parent links, \"Resolve\" for main artifacts: set type.absolute and _artifact links Dependency cycle detection with exact error positioning Compact JSON: for \"official\" CSN and tests Environment: Integration with xmake Checked accoding to our eslint rules Full tests: invocation, negative, positive","title":"Version 0.0.2: Define and Resolve \u2013 Augmented CSN"},{"location":"apis/cds-compiler/doc/doc/CHANGELOG_ARCHIVE/#version-001-package-setup-initial-grammar","text":"Done: * Promise orchestration for asynchronous file processing, * avoid checking-in the generated parser, * proper whitespace handling in the grammar, * source location in AST, location includes filename * easy-to-use standard AST creation Our Promise orchestration must support the intended error policy: * We do not mix error categories, e.g., we do not output syntax/semantic errors in CDS files if the command invocation itself is wrong. * Inside one error category, we (intend to) list as many errors as possible, e.g. when two given files do not exist and another one is provided repeatedly, we report all these 3 errors at once. We do not include the generated parser : * As we have no npm publish phase at the moment, we list the parser generator pegjs in package.json \u2192 dependencies and run the parser generation in package.json \u2192 scripts/postinstall . * If the product is published, we list the parser generator pegjs in package.json \u2192 devDependencies and run the parser generation in package.json \u2192 scripts/prepublish . Parsers generated by PEG.js are without tokenizer \u2013 this looks cool at first, but leads to some problems: Still open: Error reporting is less then ideal \u2013 if the intended top-level context definition start with contxt , you just see one char after but : Expected \"context\", \u2026 but \"c\" found. See the grammar for a potential future hack to cover at least the most common occurrences. We always need to think about correct whitespace handling. See the initial comment in the grammar for details and common patterns. ( Solved ). In rules ending with optional whitespaces, we need to adjust the end location \u2013 it should not include the final whitespaces! See the initial comment in the grammar for details. ( Solved ). As an alternative , we could look at Antlr3.JavaScript, Antlr4.JavaScript, or RND.JavaScript.","title":"Version 0.0.1: Package Setup &amp; Initial Grammar"},{"location":"apis/cds-compiler/doc/doc/CommandLineMigration/","text":"Command Line Migration \u00b6 Status Oct 2019: this document is still basically valid. The future version of this document (renamed to CommandLine.md ) will basically explain the recommended CLI options, the migration will only be a minor aspect and explained in a later section. With revision 1.5.1, the cdsc command line interface has been adapted to use commands with options. Usage is now cdsc <command> [options] <files...> instead of cdsc [options] <file...> . The generation options ( --toHana , --toSql , ...) have been replaced by commands ( toHana , toSql , ...). This allows for better per-command options, which can now be optional, can use more single-letter abbreviations, and now match those from the options object in the API. Some examples: Old command line New command line cdsc --new-csn --toHana csn,plain foo.cds cdsc --new-csn toHana --csn --names plain foo.cds cdsc -R --H csn,plain foo.cds cdsc -R H -c -n plain foo.cds cdsc --toOdata xml,v2,separate foo.cds cdsc toOdata --xml --version v2 --separate foo.cds cdsc --toSql src foo.cds cdsc toSql foo.cds cdsc foo.cds cdsc foo.cds List of commands (as of v1.5.1): Commands H , toHana [ options ] < files ... > Generate HANA CDS source files O , toOdata [ options ] < files ... > Generate ODATA metadata and annotations C , toCdl < files ... > Generate CDS source files S , toSwagger [ options ] < files ... > Generate Swagger ( OpenAPI ) JSON Q , toSql [ options ] < files ... > Generate SQL DDL statements toCsn [ options ] < files ... > ( default ) Generate original model as CSN toTntSpecificOutput < files ... > ( internal ) Generate TNT - specific post - processed CSN toRename [ options ] < files ... > ( internal ) Generate SQL DDL rename statements Please see cdsc --help for the list of commands and general options, or cdsc <command> --help for help regarding a specific command. Some helpful hints \u00b6 Please note the following general concepts regarding the new command line: - General options can be placed anywhere, command specific options must appear after the command. - In the unlikely case that a file name starts with - , please use -- to indicate the end of options. - The src argument of toHana , toCdl , toSql is now optional (and it would now be --src ). - If no command is specified, the default is toCsn --flavor client (as before). - When no --out option is provided or if - is specified as output directory , all output will go to <stdout> instead of being written to files (like before). - The --raw-output option also affects all commands where a CSN file is generated. Instead of ...csn.json , a ...csn_raw.txt will be produced (like before).","title":"Command Line Migration"},{"location":"apis/cds-compiler/doc/doc/CommandLineMigration/#command-line-migration","text":"Status Oct 2019: this document is still basically valid. The future version of this document (renamed to CommandLine.md ) will basically explain the recommended CLI options, the migration will only be a minor aspect and explained in a later section. With revision 1.5.1, the cdsc command line interface has been adapted to use commands with options. Usage is now cdsc <command> [options] <files...> instead of cdsc [options] <file...> . The generation options ( --toHana , --toSql , ...) have been replaced by commands ( toHana , toSql , ...). This allows for better per-command options, which can now be optional, can use more single-letter abbreviations, and now match those from the options object in the API. Some examples: Old command line New command line cdsc --new-csn --toHana csn,plain foo.cds cdsc --new-csn toHana --csn --names plain foo.cds cdsc -R --H csn,plain foo.cds cdsc -R H -c -n plain foo.cds cdsc --toOdata xml,v2,separate foo.cds cdsc toOdata --xml --version v2 --separate foo.cds cdsc --toSql src foo.cds cdsc toSql foo.cds cdsc foo.cds cdsc foo.cds List of commands (as of v1.5.1): Commands H , toHana [ options ] < files ... > Generate HANA CDS source files O , toOdata [ options ] < files ... > Generate ODATA metadata and annotations C , toCdl < files ... > Generate CDS source files S , toSwagger [ options ] < files ... > Generate Swagger ( OpenAPI ) JSON Q , toSql [ options ] < files ... > Generate SQL DDL statements toCsn [ options ] < files ... > ( default ) Generate original model as CSN toTntSpecificOutput < files ... > ( internal ) Generate TNT - specific post - processed CSN toRename [ options ] < files ... > ( internal ) Generate SQL DDL rename statements Please see cdsc --help for the list of commands and general options, or cdsc <command> --help for help regarding a specific command.","title":"Command Line Migration"},{"location":"apis/cds-compiler/doc/doc/CommandLineMigration/#some-helpful-hints","text":"Please note the following general concepts regarding the new command line: - General options can be placed anywhere, command specific options must appear after the command. - In the unlikely case that a file name starts with - , please use -- to indicate the end of options. - The src argument of toHana , toCdl , toSql is now optional (and it would now be --src ). - If no command is specified, the default is toCsn --flavor client (as before). - When no --out option is provided or if - is specified as output directory , all output will go to <stdout> instead of being written to files (like before). - The --raw-output option also affects all commands where a CSN file is generated. Instead of ...csn.json , a ...csn_raw.txt will be produced (like before).","title":"Some helpful hints"},{"location":"apis/cds-compiler/doc/doc/ErrorMessages/","text":"Error Messages Explained \u00b6 Status Oct 2019: up-to-date This document tries to explain some of the less-obvious error messages. Common Compiler Messages (Independent From Backend) \u00b6 Duplicate definitions \u00b6 In most cases, you really have just used the same name twice when defining an artifact. This section is about a situation where you are pretty sure that you have not done that. node_modules/Base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/dep/node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" Here, the CDS Compiler considers \u2026/Base/index.cds to be different to \u2026/base/index.cds , and also considers the two \u2026/model/index.cds files to be different files. Why is that the case? Consider the following \"top-level\" file using from 'Base'; // upper-case 'B'! using from 'model'; using from 'dep'; File node_modules/dep/index.cds` looks like: using from 'base'; // lower-case 'b'! using from 'model'; node_modules/Base/index.cds is the same file as node_modules/base/index.cds on case-insensitive file systems (Windows, Mac): type T: Integer; We have node_modules/model/index.cds and a copy of it in node_modules/dep/node_modules/model/index.cds : entity E { i: Integer; } The technical explanation is that the CDS Compiler considers two file names pointing to the same file if their fs.realpath is equal. That means that we properly recognize symlinks (Linux, Mac), but we do not recognize two files to be equal if: the same file is referred to with different name casing, which does not work on case-sensitive file systems (Linux) anyway (yes, we might issue a better message when node v9.2 is widely adopted), a file is copied within the NPM package (or when hardlinks are used). The CDL code/package can be corrected as follows: Use consistent casing when referring to file and modules in using from (if in doubt, please check the error output provided by the CDS compiler client tool). Clean up a dirty NPM installation . Then, the file node_modules/dep/node_modules/model/index.cds should disappear (or be a symlink to node_modules/model/index.cds ). Nested extensions \u00b6 If you use nested extensions, you might get messages like: nested-extensions.cds:3:20-26: Error: No `EXTEND artifact` within CONTEXT extensions nested-extensions.cds:4:20-28: Error: No `ANNOTATE artifact` within SERVICE extensions nested-extensions.cds:5:14-22: Error: Elements only exist in entities, types or typed constructs nested-extensions.cds:6:12-36: Error: Elements only exist in entities, types or typed constructs Artifacts (entities, types, \u2026) should not be extended within other extensions \u2013 just elements (and other members) are to be extended within an artifact extension. The above messages are reported for the following CDL code: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend context C { extend C.E { e: Integer; } } extend service S { annotate S.E @Anno; } annotate C { E @Anno; } extend S { extend E { e: Integer; } } The reason for these messages is \u2013 if we would allow it: If we follow the normal name resolution rules , people would have to refer to the entity the same way as outside extend context / extend service . Most people would probably expect being able to write just E instead C.E / S.E in line 3 and 4, but this not only require special rules, but leads to other surprises \u2013 see below. Using { \u2026 } inside a plain annotate or extend statement is supposed to annotate/extend elements (or enums), not containing artifacts. The CDL code can be corrected as follows: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend C.E { e: Integer; } annotate S.E @Anno; annotate C.E @Anno; extend S.E { e: Integer; } Now consider that you could use the following to extend the entity C.E : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E } extend context C { entity F { a: association to E; } // target: E, not C.E (normal name resolution) } What about combining the two extend context : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E entity F { a: association to E; } // target: E or C.E ? } In summary, allowing artifact extensions inside extend context / extend service would provide little benefit, but would add complexity and confusion. Redirection issues \u00b6 The target OrigTarget of an existing association can only be redirected to another target NewTarget if the NewTarget is a direct or indirect projection of OrigTarget (complex views are questionable and lead to a Warning), or an entity definition which directly or indirectly includes OrigTarget . entity Base { key i : Integer ; } entity Proj as projection on Base ; entity NewTarget as projection on Intermediate ; entity Intermediate as projection on Base ; entity Assocs { base : association to Base ; proj : association to Proj ; } entity Redirect as projection on Assocs { base : redirected to NewTarget , // works proj : redirected to NewTarget // ERROR : does not originate from Proj } For the above CDS code, you get the following error message: redirect-to-unrelated.cds:16:25-34: Error: The redirected target does not originate from \"Proj\" (in entity:\"Redirect\"/element:\"proj\")","title":"Error Messages Explained"},{"location":"apis/cds-compiler/doc/doc/ErrorMessages/#error-messages-explained","text":"Status Oct 2019: up-to-date This document tries to explain some of the less-obvious error messages.","title":"Error Messages Explained"},{"location":"apis/cds-compiler/doc/doc/ErrorMessages/#common-compiler-messages-independent-from-backend","text":"","title":"Common Compiler Messages (Independent From Backend)"},{"location":"apis/cds-compiler/doc/doc/ErrorMessages/#duplicate-definitions","text":"In most cases, you really have just used the same name twice when defining an artifact. This section is about a situation where you are pretty sure that you have not done that. node_modules/Base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/base/index.cds:1:6-7: Error: Duplicate definition of artifact \"T\" node_modules/dep/node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" node_modules/model/index.cds:1:8-9: Error: Duplicate definition of artifact \"E\" Here, the CDS Compiler considers \u2026/Base/index.cds to be different to \u2026/base/index.cds , and also considers the two \u2026/model/index.cds files to be different files. Why is that the case? Consider the following \"top-level\" file using from 'Base'; // upper-case 'B'! using from 'model'; using from 'dep'; File node_modules/dep/index.cds` looks like: using from 'base'; // lower-case 'b'! using from 'model'; node_modules/Base/index.cds is the same file as node_modules/base/index.cds on case-insensitive file systems (Windows, Mac): type T: Integer; We have node_modules/model/index.cds and a copy of it in node_modules/dep/node_modules/model/index.cds : entity E { i: Integer; } The technical explanation is that the CDS Compiler considers two file names pointing to the same file if their fs.realpath is equal. That means that we properly recognize symlinks (Linux, Mac), but we do not recognize two files to be equal if: the same file is referred to with different name casing, which does not work on case-sensitive file systems (Linux) anyway (yes, we might issue a better message when node v9.2 is widely adopted), a file is copied within the NPM package (or when hardlinks are used). The CDL code/package can be corrected as follows: Use consistent casing when referring to file and modules in using from (if in doubt, please check the error output provided by the CDS compiler client tool). Clean up a dirty NPM installation . Then, the file node_modules/dep/node_modules/model/index.cds should disappear (or be a symlink to node_modules/model/index.cds ).","title":"Duplicate definitions"},{"location":"apis/cds-compiler/doc/doc/ErrorMessages/#nested-extensions","text":"If you use nested extensions, you might get messages like: nested-extensions.cds:3:20-26: Error: No `EXTEND artifact` within CONTEXT extensions nested-extensions.cds:4:20-28: Error: No `ANNOTATE artifact` within SERVICE extensions nested-extensions.cds:5:14-22: Error: Elements only exist in entities, types or typed constructs nested-extensions.cds:6:12-36: Error: Elements only exist in entities, types or typed constructs Artifacts (entities, types, \u2026) should not be extended within other extensions \u2013 just elements (and other members) are to be extended within an artifact extension. The above messages are reported for the following CDL code: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend context C { extend C.E { e: Integer; } } extend service S { annotate S.E @Anno; } annotate C { E @Anno; } extend S { extend E { e: Integer; } } The reason for these messages is \u2013 if we would allow it: If we follow the normal name resolution rules , people would have to refer to the entity the same way as outside extend context / extend service . Most people would probably expect being able to write just E instead C.E / S.E in line 3 and 4, but this not only require special rules, but leads to other surprises \u2013 see below. Using { \u2026 } inside a plain annotate or extend statement is supposed to annotate/extend elements (or enums), not containing artifacts. The CDL code can be corrected as follows: context C { entity E { d: Integer; } } service S { entity E { d: Integer; } } extend C.E { e: Integer; } annotate S.E @Anno; annotate C.E @Anno; extend S.E { e: Integer; } Now consider that you could use the following to extend the entity C.E : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E } extend context C { entity F { a: association to E; } // target: E, not C.E (normal name resolution) } What about combining the two extend context : context C { entity E { key d: Integer; } } entity E { key x: Integer; } extend context C { extend E { e: Integer; } // i.e. extend C.E entity F { a: association to E; } // target: E or C.E ? } In summary, allowing artifact extensions inside extend context / extend service would provide little benefit, but would add complexity and confusion.","title":"Nested extensions"},{"location":"apis/cds-compiler/doc/doc/ErrorMessages/#redirection-issues","text":"The target OrigTarget of an existing association can only be redirected to another target NewTarget if the NewTarget is a direct or indirect projection of OrigTarget (complex views are questionable and lead to a Warning), or an entity definition which directly or indirectly includes OrigTarget . entity Base { key i : Integer ; } entity Proj as projection on Base ; entity NewTarget as projection on Intermediate ; entity Intermediate as projection on Base ; entity Assocs { base : association to Base ; proj : association to Proj ; } entity Redirect as projection on Assocs { base : redirected to NewTarget , // works proj : redirected to NewTarget // ERROR : does not originate from Proj } For the above CDS code, you get the following error message: redirect-to-unrelated.cds:16:25-34: Error: The redirected target does not originate from \"Proj\" (in entity:\"Redirect\"/element:\"proj\")","title":"Redirection issues"},{"location":"apis/cds-compiler/doc/doc/FioriAnnotations/","text":"Translation of Fiori annotations \u00b6 Status Oct 2019: too vague, old links, to be moved to internalDoc if we want to keep it. Fiori annotations are translated in a generic way. Essentially, write down in CDS precisely what you want to get in edmx. A more detailed description will follow soon, for the time being we hope the following example will give the idea: These CDS annotations @( UI.Chart : { ChartType: #Bullet, Measures: [ Revenue ], MeasureAttributes: [ { Measure: Revenue, Role: #Axis1, DataPoint: '@UI.DataPoint#BulletChartDataPoint' } ] }, UI.DataPoint#BulletChartDataPoint: { Title: 'Product', Value: Revenue, TargetValue: TargetRevenue, ForecastValue: ForecastRevenue, MinimumValue: MinValue, MaximumValue: MaxValue, CriticalityCalculation: { ImprovementDirection: #Target, ToleranceRangeLowValue: ToleranceRangeLow, ToleranceRangeHighValue: ToleranceRangeHigh, DeviationRangeLowValue: DeviationRangeLow, DeviationRangeHighValue: DeviationRangeHigh } } ) Something ...; are translated into the following edmx: <Annotations Target= \"Something\" > <Annotation Term= \"UI.Chart\" > <Record> <PropertyValue EnumMember= \"UI.ChartType/Bullet\" Property= \"ChartType\" /> <PropertyValue Property= \"Measures\" > <Collection> <PropertyPath> Revenue </PropertyPath> </Collection> </PropertyValue> <PropertyValue Property= \"MeasureAttributes\" > <Collection> <Record Type= \"UI.ChartMeasureAttributeType\" > <PropertyValue Property= \"Measure\" PropertyPath= \"Revenue\" /> <PropertyValue Property= \"Role\" EnumMember= \"UI.ChartMeasureRoleType/Axis1\" /> <PropertyValue Property= \"DataPoint\" AnnotationPath= \"@UI.DataPoint#BulletChartDataPoint\" /> </Record> </Collection> </PropertyValue> </Record> </Annotation> <Annotation Term= \"UI.DataPoint\" Qualifier= \"BulletChartDataPoint\" > <Record> <PropertyValue String= \"Product\" Property= \"Title\" /> <PropertyValue Path= \"Revenue\" Property= \"Value\" /> <PropertyValue Path= \"TargetRevenue\" Property= \"TargetValue\" /> <PropertyValue Path= \"ForecastRevenue\" Property= \"ForecastValue\" /> <PropertyValue Path= \"MinValue\" Property= \"MinimumValue\" /> <PropertyValue Path= \"MaxValue\" Property= \"MaximumValue\" /> <PropertyValue Property= \"CriticalityCalculation\" > <Record> <PropertyValue Property= \"ImprovementDirection\" EnumMember= \"UI.ImprovementDirectionType/Target\" /> <PropertyValue Path= \"ToleranceRangeLow\" Property= \"ToleranceRangeLowValue\" /> <PropertyValue Path= \"ToleranceRangeHigh\" Property= \"ToleranceRangeHighValue\" /> <PropertyValue Path= \"DeviationRangeLow\" Property= \"DeviationRangeLowValue\" /> <PropertyValue Path= \"DeviationRangeHigh\" Property= \"DeviationRangeHighValue\" /> </Record> </PropertyValue> </Record> </Annotation> </Annotations> All suppoted Fiori annotations are defined in the following vocabularies: * Core * Measures * Capabilities * Aggregation * Common * Communication * UI","title":"Translation of Fiori annotations"},{"location":"apis/cds-compiler/doc/doc/FioriAnnotations/#translation-of-fiori-annotations","text":"Status Oct 2019: too vague, old links, to be moved to internalDoc if we want to keep it. Fiori annotations are translated in a generic way. Essentially, write down in CDS precisely what you want to get in edmx. A more detailed description will follow soon, for the time being we hope the following example will give the idea: These CDS annotations @( UI.Chart : { ChartType: #Bullet, Measures: [ Revenue ], MeasureAttributes: [ { Measure: Revenue, Role: #Axis1, DataPoint: '@UI.DataPoint#BulletChartDataPoint' } ] }, UI.DataPoint#BulletChartDataPoint: { Title: 'Product', Value: Revenue, TargetValue: TargetRevenue, ForecastValue: ForecastRevenue, MinimumValue: MinValue, MaximumValue: MaxValue, CriticalityCalculation: { ImprovementDirection: #Target, ToleranceRangeLowValue: ToleranceRangeLow, ToleranceRangeHighValue: ToleranceRangeHigh, DeviationRangeLowValue: DeviationRangeLow, DeviationRangeHighValue: DeviationRangeHigh } } ) Something ...; are translated into the following edmx: <Annotations Target= \"Something\" > <Annotation Term= \"UI.Chart\" > <Record> <PropertyValue EnumMember= \"UI.ChartType/Bullet\" Property= \"ChartType\" /> <PropertyValue Property= \"Measures\" > <Collection> <PropertyPath> Revenue </PropertyPath> </Collection> </PropertyValue> <PropertyValue Property= \"MeasureAttributes\" > <Collection> <Record Type= \"UI.ChartMeasureAttributeType\" > <PropertyValue Property= \"Measure\" PropertyPath= \"Revenue\" /> <PropertyValue Property= \"Role\" EnumMember= \"UI.ChartMeasureRoleType/Axis1\" /> <PropertyValue Property= \"DataPoint\" AnnotationPath= \"@UI.DataPoint#BulletChartDataPoint\" /> </Record> </Collection> </PropertyValue> </Record> </Annotation> <Annotation Term= \"UI.DataPoint\" Qualifier= \"BulletChartDataPoint\" > <Record> <PropertyValue String= \"Product\" Property= \"Title\" /> <PropertyValue Path= \"Revenue\" Property= \"Value\" /> <PropertyValue Path= \"TargetRevenue\" Property= \"TargetValue\" /> <PropertyValue Path= \"ForecastRevenue\" Property= \"ForecastValue\" /> <PropertyValue Path= \"MinValue\" Property= \"MinimumValue\" /> <PropertyValue Path= \"MaxValue\" Property= \"MaximumValue\" /> <PropertyValue Property= \"CriticalityCalculation\" > <Record> <PropertyValue Property= \"ImprovementDirection\" EnumMember= \"UI.ImprovementDirectionType/Target\" /> <PropertyValue Path= \"ToleranceRangeLow\" Property= \"ToleranceRangeLowValue\" /> <PropertyValue Path= \"ToleranceRangeHigh\" Property= \"ToleranceRangeHighValue\" /> <PropertyValue Path= \"DeviationRangeLow\" Property= \"DeviationRangeLowValue\" /> <PropertyValue Path= \"DeviationRangeHigh\" Property= \"DeviationRangeHighValue\" /> </Record> </PropertyValue> </Record> </Annotation> </Annotations> All suppoted Fiori annotations are defined in the following vocabularies: * Core * Measures * Capabilities * Aggregation * Common * Communication * UI","title":"Translation of Fiori annotations"},{"location":"apis/cds-compiler/doc/doc/NameResolution/","text":"Name Resolution in CDS \u00b6 Status Oct 2019: TODOs must be filled, say more about name resolution in CSN. Name resolution refers to the resolution of names (identifiers) within expressions of the source to the intended artifact or member in the model. As CDL is related to SQL, its name resolution strategy must be natural to SQL programmers. This forbids us to use the simple lexical scoping name resolution for all language constructs. This document presents the exact semantics of the resolution in CDS especially how it is influenced by the language constructs where the reference is embedded in. In explanations, we have CDL as the main focus, but name resolution in CSN is covered as well. The overall goal is that the name resolution is low on surprises throughout the complete life-cycle of any CDS model, and robust concerning any model extensions. Remark: this is the intended behavior, the code must still be adapted at some places. The impatient reader might want to jump to the summary , others might want to skip the introduction . Table of Contents \u00b6 Introduction \u2013 Background: SQL \u2013 Background: modern programming languages Design Principles Name Resolution - the Basics \u2013 Common rules \u2013 Resolving paths \u2013 Navigation environment References to main artifacts Values and references to elements \u2013 References in queries \u2013 References to sibling elements \u2013 Other element references Paths as Annotation Values Differences to HANA-CDS Summary Introduction \u00b6 If you look at typical examples given in introductionary documents about CDS, you might wonder why there is a lengthy document about the name resolution. So, let us start with such an example: nameprefix sap . core ; context types { type Price { amount : Amount ; currency : CurrencySymbol ; } type Amount : Decimal ( 5 , 3 ); } type CurrencySymbol : String ( 3 ); entity ProductsInternal { productId : Integer ; retailPrice : types . Price ; salesPrice = retailPrice ; // we give no reduction } view Products as select from ProductsInternal { productId, salesPrice } Let us first go a step backwards: in CDS, all entities and other main artifacts (short: artifacts) have a unique name , which we call absolute name . Why don't we just use that name, like we do in SQL and in CSN? As we want to support a hierarchical naming convention, it should be easy to define and to refer to artifacts sharing a common name prefix. In the example above, we have 3 types with the absolute names sap.core.types.Price , sap.core.types.Amount and sap.core.CurrencySymbol . For convenience , we do not use these lengthy names in CDL, but shorter names without the common prefix. These are then \"translated\" by the name resolution into the absolute names. This also allows us to easily change the common name prefix in the development phase. In which area of the code do we assume which common name prefix? In the example above, we refer to these 3 types by types.Price , just Amount , and CurrencySymbol . The first observation is: name resolution (and the new name introduced by an artifact definition) depends on the block structure . In the view, we also refer to elements of (another) artifact. There is no special language construct for such references \u2013 it is a simple identifier (or path) like the references to the types and the source entity of the view. The second observation is: name resolution in CDL depends on the argument position , i.e. the place of the reference relative to the statement (e.g. in the from or where clause of a select statement). This is not only valid in SQL and related languages like CDL, but also in languages like C (for labels after goto ). Let us now look at the name resolution and why it is not as obvious as it might seem to be\u2026 What happens if an inner block introduces the same name as an outer block? Do we have name shadowing (we cannot access the artifact defined in the outer block by its simple name)? Consider that we have defined a type CurrencySymbol inside the block of the context types \u2026 Is the same true for nested element definitions? How do we refer to elements and subelements inside the definition of a subelement? Does a simple name refer to a subelement of the same parent element, or an element of the corresponding main artifact? How do we access artifacts which are defined in another file? That is an easy one: the using declarations introduce a file-local alias name to an absolute name for accessing artifacts in other files or in the current file (useful to refer to shadowed definitions). Can something bad happen if extensions come into play? Yes, extensions must be used with care. Extensions might break existing models \u2013 if two extensions decide to add an element with the same name to the same entity, there is nothing we can do about it. But we make sure that something real bad cannot happen: an extension cannot silently change the semantics of a model \u2013 the name resolution is defined in such a way that a valid reference does not silently (without errors or warnings) point to another artifact when the extension is applied to the model. Background: SQL \u00b6 In this section, we look at the heritage from SQL. Given is the following SQL query: SELECT a , a . b as e FROM a as x , tab as a The identifier a refers to different objects: at the \"select item\" position in line 1, a refers to a column in one of the tables, at the \"select item\" position in line 2, a refers to the table alias introduced in line 4, at the \"table reference\" position in line 3, a refers to the table a , and in line 4, we define a table alias with name a ( a is no reference here). Our task is to generalize the semantics to make it applicable for CDS features not found in SQL: sub structures, associations, extensions, \u2026 find argument positions which are \"similar\" to argument positions with given name resolution semantics \u2013 we then apply the same semantics to the \"new\" argument positions As an example for the latter, let us consider an SQL view which is a projection on a given table and additionally exposes one of its column under an extra name: entity B { a: Integer; } view E as select from B { *, a as e }; In CDS, we can define a table which uses the same layout as a given table and additionally exposes one of its elements under an extra name: entity B { a: Integer; } entity E : B { e = a; } As the situation is very similar, the name resolution strategy for the referred column/element should be the same (the syntax is unfortunately not the same due to the SQL syntax of select items). In SQL, we have silent semantic changes, but only with subqueries \u2013 see the first example in Section \"Design Principles\" . To avoid this situation in CDx/Language, we are a bit incompatible in this case. Background: modern programming languages \u00b6 Modern programming languages (try to) use just one name resolution strategy: lexical scoping. Assuming that the \"free-floating\" column a was defined in table a , the SELECT query from the beginning of previous section would look like the following in JavaScript: select ( [ a , tab ], ( x , a ) => ({ a : x . a , e : a . b }) ) Apart from the syntax and expression structure, the difference to SQL is that there are no \"free-floating\" references : the column a in (the line of) table a must be prefixed by the corresponding table alias x (parameter name of the anonymous function in JavaScript). This is not only a good thing for itself (the original SQL query would be considered incorrect if a column a is added later to table tab ) it also enables lexical scoping, as the table alias names are defined in the query expression itself. Any \"convenience\" declaration which \"extends\" lexical scoping is usually soon to be declared as obsolete, because its little convenience benefit is not worth the additional issues . As an example, see the fate of the with statement in JavaScript. If sold with the label \"OO\", the convenience is often considered to be more important. Given is the following Java program: class T { int C = 0 ; } class B { // class T { int C = 1; } } class J extends B { int go () { return ( new T ()). C ; } public static void main ( String [] args ) { System . out . println (( new J ()). go ()); } } Uncomment the definition of B.T \u2192 the output changes from 0 to 1 (silent semantic change). Now consider that class B is usually defined somewhere else \u2192 same kind of convenience, same kind of issues. Design Principles \u00b6 The name resolution rules in the following sections are based on the following design principles: Applications/customers can safely add new artifacts without silently changing the semantics of other applications. A valid SQL SELECT should be a valid CDL SELECT with the same semantics (modulo changes in the concrete syntax), as CDL uses CQL \u2013 an \"official\" extension of SQL SELECT. Applications/customers can safely add new artifacts without inducing other applications to compile with an error. The name resolution does not depend on package definitions and its dependencies. The chosen name resolution strategy for an argument position should not come at a surprise. Convenience: there must be a more convenient solution than always using absolute names. Please note that these principles are ordered. There are many cases where one principle cannot be fulfilled in order to fulfill a higher prioritized design principles. The first design principle is therefore always fulfilled. This can be seen in the following examples. For (1), CDL compiles the following source with an error: entity A { a: String(20); j: Integer; x: Integer; } entity B { b: String(20); j: Integer; } view V as select from A { a, x } where // x is valid here j = (select from B { j + x }); // invalid: use A.x instead of x (ok: j) It contradicts (2), because SQL would compile the subquery. But there would be a silent semantic change when column x is added to table B . For (2), CDL needs to support unqualified element (column) names in the SELECT clause even if a JOIN is used - we might issue a warning for this case, though. entity A { a: String(20); j: Integer; x: Integer; } // from Partner A entity B { b: String(20); j: Integer; } // from Partner B view V as select from A join B {a, b, x} ON A.j = B.j; // valid customer view It contradicts (3), as the unchanged customer view compiles with an error when partner B adds an element x to their table B . Principle (3) is also contradicted for specific features like (multiple) entity includes. Principle (4) is not part of the name resolution rules in HANA-CDS. As we never allow to break Principle (1), we have the following guideline: It is fine if definitions in the own source shadow other definitions (in the own source or others), because the programmer is aware (and in control) of all these definitions. It is evil if definitions made in other sources shadow other definitions (in the own source or others). Name Resolution - the Basics \u00b6 We start with some terminology: An environment is a dictionary binding/mapping (local) names to language constructs (e.g. entities or elements). A navigation environment of a construct is the dictionary for definitions within that construct or a type/entity referred by that construct. For contexts (and services), these are the sub artifacts defined within that context. For types, entities, elements, these are the elements (or enum symbols) defined within that object or the object's (direct or indirect) type; for association types, these are the elements of the target entity. (The actions and parameters of an object cannot be accessed this way.) context C { type X: Integer; }; // context \"C\" supplies env{ X: type(\"C.X\") } type S { E: Integer; } extend S with { F: Integer; }; // type \"S\" supplies env{ E: elem(\"S\",\"E\"), F: \u2026 } type T: S; // type \"T\" supplies the same env as type \"S\" Common rules \u00b6 Name resolution is case sensitive . In general, a model can contain artifacts and members whose name differ in case only; there might be a linter check which informs model writers if they make use of this \"feature\". While being case sensitive might be against the original intention of SQL, it actually conforms to the SQL Specification after abstraction from the lexical syntax, see e.g. SQL-92, \u00a75.2.10 and 5.2.12\u202614 for the semantics of quoted and non-quoted identifiers. In CDL, we just do not transform non-quoted identifiers to all-upper names. Also, CSN-processors are cumbersome to write if they have to deal with (partial/feigned) case-insensitivity. In a future version of this project, we or others might provide a \"use at your own risk\" backend which produce SQL DDL statements without quoted identifiers In CDL, an identifier may be used before its definitions, there is no need of forward declarations . Thus, the sequence of definitions inside a block does not matter for the scope rules: using T as OuterT; // introduced to have a name for the shadowed \"T\" type T: String(20); context C { type D: T; // -> C.T -> cds.Integer type T: Integer; type O: OuterT; // -> T -> String(20) } // type C.O: T; // alternative: define \"C.O\" outside the block of \"C\" There are two reasons to do so: When using associations, (mutually) recursive usage is quote common, and forward references are cumbersome. (We can always access shadowed artifacts.) Real-world models will very likely reside in multiple files/resources \u2013 there is no natural order in which the definitions are to be processed. Resolving paths \u00b6 The algorithm for resolution of paths (consisting of dot-connected names) is as follows: First, we try to find the language construct O for the first name in the path; this language construct is called the path base . We resolve the next name in the path by inspecting the navigation environment of O . The found language artifact is our next O . We repeat Step 2 until the complete path is resolved. Even the algorithm for finding the path base follows the same pattern: We have a list of search environments, which we inspect in order. The first hit is the path base. It is an error if the name (the first name of the path) cannot be found in any environment of the list. All but the last environment are constructed from definitions in the current source following the lexical block structure of the source, or a small, fixed number of predefined names (e.g. $projection .) We will call such an environment a lexical search environment . Only the last environment contains bindings defined externally , at least potentially. It can be the environment for predefined artifacts (like cds.Integer ), or the navigation environment of the \"current artifact/member of interest\" (like the elements of the projection source). So the guideline at the end of the previous section essentially becomes lexical scoping first, search in one externally provided environment last . The basic difference between the name resolution strategies is the relevance of the lexical and the last environments, and how they are build. Navigation environment \u00b6 The navigation environment might depend on on the argument position. If an object is typed with an array, the environment supplied by that object is usually considered to be empty. For type of references and the to-be-extended element referenced in an inner extend, it is the environment supplied by the array item type: @ A . e : 1 // warning : cannot find `e` for annotation assignments annotation A : array of { e : Integer ; } ; annotate A with { annotate e with @ lineElement ; } annotation B : type of : A . e ; // valid = Integer For the to-be-extended element referenced in an inner extend, we consider the environment supplied by an association to be empty: type A: association to E; entity E { i: Integer; } annotate A with { @targetElem i; // error: do not follow associations } type S { e: Integer; } type T : S; annotate T with { @derivedElem e; // ok: follow derived type } References to main artifacts \u00b6 When we have an argument position where we expect a main artifact, the list of lexical search environments depends on the blocks containing the current statement, and the last, non-lexical search environment is independent from the block structure or a current object of interest. A reference to a main artifact can be a reference to a projection or view source (table reference after SELECT \u2026 FROM in SQL), association target , type (but not the reference after type of , see below) annotation for an annotation assignment, to-be-extended main artifact of an outer extend structure include , type parameter (should be a constant, not yet). The construction of the list of lexical search environments starts at the innermost block containing the current statement, and then continues to the next outer block: As opposed to HANA-CDS, we skip blocks containing just element definitions (or generally definitions of members like actions). For blocks of context and service definitions, we add the definition inside that block (all definitions in the environment supplied by the context or service can contain more definitions). For the top-level block of the current source, we add the top-level definitions and the bindings for the using declarations. The last, non-lexical search environment is the environment for built-in artifacts. Currently, it contains String for cds.String , similarly LargeString , Integer , Integer64 , Binary , LargeBinary , Decimal , DecimalFloat , Double , Date , Time , Timestamp , DateTime , and Boolean . More artifacts are defined with the options --hana-flavor . When searching for an annotation (after the initial @ ), the last search environment are the model definitions. We conclude this section with a little weird example \u2013 nobody would write models like that, but it demonstrates the exact semantics. nameprefix test; using cds.Boolean as Integer; type Time { @Date // @Date: true, not @cds.Date: true Date: Date; // typeOf(test.Time,Date) = cds.Date, no error C: C.Date; // typeOf(test.Time,C) = test.C.Date, no error } @C.Anno // @test.C.Anno: true define context C { type Date: Time; // test.C.Date -> test.C.Time, not test.Time type Time: Integer; // test.C.Time -> alias Integer -> cds.Boolean type CC: C.Integer; // test.C.CC -> test.C.Integer } @Integer // @cds.Boolean: true (warning: is no annotation) type C.Integer: Time; // test.C.Integer -> test.Time, not test.C.Time In this example, we have the following two lexical search environments: The search environment containing definitions directly inside the block after define context C : Date , Time and CC , but not Integer (but which is in the environment supplied by test.C ). Used as first search environment when resolving main artifact references in the block after define context C , the next search environment is the environment containing top-level definitions. The search environment containing the top-level definitions and using declarations of the source: Integer , Time and C . Used as first search environment when resolving main artifact references outside the block after define context C , the next search environment is the non-lexical environment containing built-in artifacts. There is no lexical search environment for the element definitions supplied by test.Time . We allow paths for names in top-level definitions. All but the last name in the paths are (on-the-fly) contexts, which do not introduce blocks for the lexical scoping: entity N.mid.E { key i: Integer; to1: association to E; // invalid to2: association to mid.E; // invalid to3: association to N.mid.E; // valid } context C { context mid { entity E { key i: Integer; to1: association to E; // valid to2: association to mid.E; // valid to3: association to C.mid.E; // valid } } } Values and references to elements \u00b6 When we have an argument position where we expect a value or a reference to an element, We usually have just one lexical search environment which is sometimes only inpected if the path consists of at least two identifiers. This basically introduces an escape mechanism . The last, non-lexical environments is usually the environment either supplied from an artifact referred by the current statement or supplied by the object containing the current definition. It is often allowed to switch to the \"main artifact name resolution\" by prefixing the path with a : , used usually to refer to constants. The semantics is best explained separately for the diffent groups of argument positions. References in queries \u00b6 We start with the most complicated group, because it is known from SQL: references in SELECT item positions \u2013 similar: WHERE , ON , TODO : GROUP BY , ORDER BY (or special?), \u2026 TODO : do the same for as projection on ? TODO : names in mixins The list of search environments is created as follows: The (first) lexical search environment is build from the explicit and implicit alias names for the sources (table references after from ); we also bind $projection to the resulting view/projection elements of the current SELECT if not already used as a table alias. If the current SELECT is a sub-SELECT, we have additional lexical search environments containing alias names for the corresponding outer SELECTs; their $projection bindings are shadowed. For compatibility with ABAP CDS, we have another environment with one entry: we bind $parameters to the parameters of the current view \u2013 the SQL way is to use :param1 instead of $parameters.param1 , see below. The last, non-lexical environment is the environent containing the elements from all source entities of the current SELECT; if an element with the same name is contained in more than one source, this search environment binds the name to an \"ambiguity\" entry (i.e. a reference to it leads to an error) There are no additional non-lexical search environments for the elements of outer SELECTs. The lexical search environments are only inspected if the path consists of at least two identifiers. The above mentioned : -escape mechanism leads to the following name resolution: The first lexical search environment is the the environment containing all parameter names of the current view. The following search environments are the usual ones from the \"main artifact name resolution\"; constant values can be accessed this way ( TODO : probably not now). References to sibling elements \u00b6 The next group is for references in member definitions to other elements of the same main artifact. Such a reference can be a reference to a: calculated field , references in the default value (HANA SQL does not allow this) references in the ON condition of an unmanaged association * reference after type of \u2013 can also be a references to an element of another main artifact The list of search environments is created as follows: There is one lexical search environment, it has one entry: we bind $self to the main artifact, or to be exact: to the current instance of that artifact, e.g. the current line of an entity. This environment is also inspecteded if the path consists of just $self \u2013 useful for on conditions of unmanaged associations. The second and last, the non-lexical search environment is the environment supplied by the object (main artifact or element) where the current member is defined in. The above mentioned : -escape mechanism leads to the \"main artifact name resolution\"; it can be used to access constants, or \u2013for references after type of \u2013 elements of other artifacts. The reason for the $self references is visible in an example with subelements: type T { a: Integer; b = a; // b = a c = $self.a; // c = a } entity E { a: Integer; x: T; // x.b = x.a, x.c = x.a y { a: Integer; b = a; // y.b = y.a c = $self.a; // y.c = a }; } entity S { $self: Integer; // we might complain about such an element name x = $self.$self; // x = $self (the element) } Other element references \u00b6 A foreign key in the definition of a managed association, is just searched in the environment supplied by the target entity. No lexical search environment is inspected first. In an inner extend , we just search in the navigation environment of the current language construct. No lexical search environment is inspected first. These are actually not necessary references to elements, but also sub artifacts (e.g. extend in extend context ), actions (in the actions clause of extend entity ), or parameters (in the parameters clause of extend action ). TODO : more use cases, like references inside filter conditions of paths. Paths as annotation values \u00b6 We can also use paths as annotation assignment values. If there is no annotation definition (there might be a warning for this) then the path cannot be resolved at all. The same is true if the annotation type does not allow path values (then there might be a warning for this) or just a cds.UnspecifiedRef . If there is a annotation definition which allows to use paths by specifying the type cds.ArtifactRef (or a variant of it), then the path resolution works as described in Section \"References to Main Artifacts\" . If there is a annotation definition which allows to use paths by specifying the type cds.ElementRef then the path resolution works as described in Section \"References sibling elements\" . If that annotation is assigned to a main artifact then same main artifact mean the main artifact itself. Differences to HANA-CDS \u00b6 The most visible differences in the name resolution semantics of CDx/Language compared to HANA CDS are: Using constant values requires to prefix the path (referring to the constant) with a : . There is a new semantic for paths (without initial : ) used in annotation assignments. In the definitions of sub elements, accessing elements supplied by the corresponding main artifact requires to prefix the path with $self. . Accessing sibling elements works the same as in HANA CDS. It is no problem to define elements which have the same (local) name as the referenced type. In views with more than one source entity, selecting an element e from one source without the use of a table alias (which is not recommended anyway!) suddenly does not compile anymore if another source entity is extended by a new element e . In HANA-CDS, the name resolution works quite uniformly for all argument positions, with most clauses of SELECT being the main exception. It is also compatible to the \"pre-extension\" name resolution semantics of HANA-CDS. This is nice! Why do we specify a different name resolution semantics for CDx/Language? The reason is: we do not want to have the \"extended\" lexical scoping semantics of HANA CDS concerning elements, which heavily relies on the package hierchy. To avoid silent semantic changes with extensions, the HANA-CDS compiler enforces the following properties: Every source belongs to a package; packages can depend on other packages, no cycles are allowed. No language construct can be extended in the same package where it is defined in, no language construct can be extended twice in the same package Artifacts can only be extended by top-level extend statements, elements can only be extended by inner extends (the second is true for CDx/Language, too). These are properties which do not hold for consumers of the CDx Compiler. Additionally, while direct changes in base packages can always lead to semantic changes, the following example shows that this unwanted effect is more likely in HANA-CDS: // BaseApp.cds --- entity E { a: String(20); b { // a: Integer; // CHANGE: introduce sub element x: Integer; }; } // MyExtension.cds --- extend E with { extend b with { z = a; // in CDx/Language: $self.a } } In HANA-CDS, both files compile before and after the change in BaseApp.cds : the element b.z of E refers to element a of E , but after the change to b.a of E , because that element is visible in the base package and all its extensions (we would not see the problem if b.a would have been introduced by an extension in another package). In CDx/Language, the files only compile after the change in BaseApp.cds : (with the same semantics as in HANA-CDS). To make it work before the change, element b.z of E can refer to element a of E by writing this references as $self.a \u2013 with this path, b.z still refers to a of E after the change in BaseApp.cds . Summary \u00b6 To avoid silent semantic changes with extensions or new CDL versions, we follow the following principle: After we have tried to find a local name in an environment containing artifacts or elements which are potentially defined somewhere else (e.g. via an extension), we do not inspect any other environment. In CDx/Language, we basically have two search strategies. But let us start with Strategy 0: Resolving a name in the tail of a path . For a path a.b , we only inspect one environment when resolving b : the environment supplied by a . For example, if a is a structured element, we try to find b in all sub elements of a \u2013 it does not matter whether the sub element b has been directly defined with the definition of element a , or whether is has been defined externally: via an extension or as an element of the referenced type. Resolving the first name of a path when looking for artifacts . We apply lexical scoping when we refer to types, entities and similar artifacts. When looking for an artifact A , we search in the blocks of surrounding context , service and top-level definitions, starting at the innermost block and ending at the top-level block of the source. To make it clear: we do not search in blocks of type, entity or other definitions, just blocks of contexts (and similar constructs). We only consider definitions within these blocks, not all sub artifacts of the contexts, which might have been introduced by context extensions, or by using a path in the definition, e.g. type MyContext.A: \u2026 . If the search is not successful so far, we finally inpect an environment containing artifacts which are normally not defined in our own source: For the @A of an annotation assignment , we look for A in the definitions property of the model. For all other references, we look for A in the built-in environment, where we define things like cds.Integer . This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ArtifactRef (or variants, future). Resolving the first name of a path when looking for values or elements . We search for elements supplied by the current \"language construct of interest\", which depends on the argument position. The most relevant ones are: The element or artifact where the current (sub) artifact is defined in, i.e. we access sibling elements. The source of the current projection or view. Depending on the argument position, there is an escape mechanism \u2013 which is tried first \u2013 to access also other elements. The most relevant ones are: If the paths starts with the identifier $self , we look for the next name of the path in the environment supplied by the corresponding main artifact of the current element. This is useful for element references inside sub elements to access siblings of ancestors. If a path in most clauses of a view starts with a , and a is an explicit or implicit table alias (which we always see in our source), we look for the next identifier of the path in the environment supplied by the corresponding entity. If the path is prefixed by a : , we actually switch to the other search strategy: looking for artifacts like types. This is useful to access constant values (or for type of ). This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ElementRef (future).","title":"Name Resolution in CDS"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#name-resolution-in-cds","text":"Status Oct 2019: TODOs must be filled, say more about name resolution in CSN. Name resolution refers to the resolution of names (identifiers) within expressions of the source to the intended artifact or member in the model. As CDL is related to SQL, its name resolution strategy must be natural to SQL programmers. This forbids us to use the simple lexical scoping name resolution for all language constructs. This document presents the exact semantics of the resolution in CDS especially how it is influenced by the language constructs where the reference is embedded in. In explanations, we have CDL as the main focus, but name resolution in CSN is covered as well. The overall goal is that the name resolution is low on surprises throughout the complete life-cycle of any CDS model, and robust concerning any model extensions. Remark: this is the intended behavior, the code must still be adapted at some places. The impatient reader might want to jump to the summary , others might want to skip the introduction .","title":"Name Resolution in CDS"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#table-of-contents","text":"Introduction \u2013 Background: SQL \u2013 Background: modern programming languages Design Principles Name Resolution - the Basics \u2013 Common rules \u2013 Resolving paths \u2013 Navigation environment References to main artifacts Values and references to elements \u2013 References in queries \u2013 References to sibling elements \u2013 Other element references Paths as Annotation Values Differences to HANA-CDS Summary","title":"Table of Contents"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#introduction","text":"If you look at typical examples given in introductionary documents about CDS, you might wonder why there is a lengthy document about the name resolution. So, let us start with such an example: nameprefix sap . core ; context types { type Price { amount : Amount ; currency : CurrencySymbol ; } type Amount : Decimal ( 5 , 3 ); } type CurrencySymbol : String ( 3 ); entity ProductsInternal { productId : Integer ; retailPrice : types . Price ; salesPrice = retailPrice ; // we give no reduction } view Products as select from ProductsInternal { productId, salesPrice } Let us first go a step backwards: in CDS, all entities and other main artifacts (short: artifacts) have a unique name , which we call absolute name . Why don't we just use that name, like we do in SQL and in CSN? As we want to support a hierarchical naming convention, it should be easy to define and to refer to artifacts sharing a common name prefix. In the example above, we have 3 types with the absolute names sap.core.types.Price , sap.core.types.Amount and sap.core.CurrencySymbol . For convenience , we do not use these lengthy names in CDL, but shorter names without the common prefix. These are then \"translated\" by the name resolution into the absolute names. This also allows us to easily change the common name prefix in the development phase. In which area of the code do we assume which common name prefix? In the example above, we refer to these 3 types by types.Price , just Amount , and CurrencySymbol . The first observation is: name resolution (and the new name introduced by an artifact definition) depends on the block structure . In the view, we also refer to elements of (another) artifact. There is no special language construct for such references \u2013 it is a simple identifier (or path) like the references to the types and the source entity of the view. The second observation is: name resolution in CDL depends on the argument position , i.e. the place of the reference relative to the statement (e.g. in the from or where clause of a select statement). This is not only valid in SQL and related languages like CDL, but also in languages like C (for labels after goto ). Let us now look at the name resolution and why it is not as obvious as it might seem to be\u2026 What happens if an inner block introduces the same name as an outer block? Do we have name shadowing (we cannot access the artifact defined in the outer block by its simple name)? Consider that we have defined a type CurrencySymbol inside the block of the context types \u2026 Is the same true for nested element definitions? How do we refer to elements and subelements inside the definition of a subelement? Does a simple name refer to a subelement of the same parent element, or an element of the corresponding main artifact? How do we access artifacts which are defined in another file? That is an easy one: the using declarations introduce a file-local alias name to an absolute name for accessing artifacts in other files or in the current file (useful to refer to shadowed definitions). Can something bad happen if extensions come into play? Yes, extensions must be used with care. Extensions might break existing models \u2013 if two extensions decide to add an element with the same name to the same entity, there is nothing we can do about it. But we make sure that something real bad cannot happen: an extension cannot silently change the semantics of a model \u2013 the name resolution is defined in such a way that a valid reference does not silently (without errors or warnings) point to another artifact when the extension is applied to the model.","title":"Introduction"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#background-sql","text":"In this section, we look at the heritage from SQL. Given is the following SQL query: SELECT a , a . b as e FROM a as x , tab as a The identifier a refers to different objects: at the \"select item\" position in line 1, a refers to a column in one of the tables, at the \"select item\" position in line 2, a refers to the table alias introduced in line 4, at the \"table reference\" position in line 3, a refers to the table a , and in line 4, we define a table alias with name a ( a is no reference here). Our task is to generalize the semantics to make it applicable for CDS features not found in SQL: sub structures, associations, extensions, \u2026 find argument positions which are \"similar\" to argument positions with given name resolution semantics \u2013 we then apply the same semantics to the \"new\" argument positions As an example for the latter, let us consider an SQL view which is a projection on a given table and additionally exposes one of its column under an extra name: entity B { a: Integer; } view E as select from B { *, a as e }; In CDS, we can define a table which uses the same layout as a given table and additionally exposes one of its elements under an extra name: entity B { a: Integer; } entity E : B { e = a; } As the situation is very similar, the name resolution strategy for the referred column/element should be the same (the syntax is unfortunately not the same due to the SQL syntax of select items). In SQL, we have silent semantic changes, but only with subqueries \u2013 see the first example in Section \"Design Principles\" . To avoid this situation in CDx/Language, we are a bit incompatible in this case.","title":"Background: SQL"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#background-modern-programming-languages","text":"Modern programming languages (try to) use just one name resolution strategy: lexical scoping. Assuming that the \"free-floating\" column a was defined in table a , the SELECT query from the beginning of previous section would look like the following in JavaScript: select ( [ a , tab ], ( x , a ) => ({ a : x . a , e : a . b }) ) Apart from the syntax and expression structure, the difference to SQL is that there are no \"free-floating\" references : the column a in (the line of) table a must be prefixed by the corresponding table alias x (parameter name of the anonymous function in JavaScript). This is not only a good thing for itself (the original SQL query would be considered incorrect if a column a is added later to table tab ) it also enables lexical scoping, as the table alias names are defined in the query expression itself. Any \"convenience\" declaration which \"extends\" lexical scoping is usually soon to be declared as obsolete, because its little convenience benefit is not worth the additional issues . As an example, see the fate of the with statement in JavaScript. If sold with the label \"OO\", the convenience is often considered to be more important. Given is the following Java program: class T { int C = 0 ; } class B { // class T { int C = 1; } } class J extends B { int go () { return ( new T ()). C ; } public static void main ( String [] args ) { System . out . println (( new J ()). go ()); } } Uncomment the definition of B.T \u2192 the output changes from 0 to 1 (silent semantic change). Now consider that class B is usually defined somewhere else \u2192 same kind of convenience, same kind of issues.","title":"Background: modern programming languages"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#design-principles","text":"The name resolution rules in the following sections are based on the following design principles: Applications/customers can safely add new artifacts without silently changing the semantics of other applications. A valid SQL SELECT should be a valid CDL SELECT with the same semantics (modulo changes in the concrete syntax), as CDL uses CQL \u2013 an \"official\" extension of SQL SELECT. Applications/customers can safely add new artifacts without inducing other applications to compile with an error. The name resolution does not depend on package definitions and its dependencies. The chosen name resolution strategy for an argument position should not come at a surprise. Convenience: there must be a more convenient solution than always using absolute names. Please note that these principles are ordered. There are many cases where one principle cannot be fulfilled in order to fulfill a higher prioritized design principles. The first design principle is therefore always fulfilled. This can be seen in the following examples. For (1), CDL compiles the following source with an error: entity A { a: String(20); j: Integer; x: Integer; } entity B { b: String(20); j: Integer; } view V as select from A { a, x } where // x is valid here j = (select from B { j + x }); // invalid: use A.x instead of x (ok: j) It contradicts (2), because SQL would compile the subquery. But there would be a silent semantic change when column x is added to table B . For (2), CDL needs to support unqualified element (column) names in the SELECT clause even if a JOIN is used - we might issue a warning for this case, though. entity A { a: String(20); j: Integer; x: Integer; } // from Partner A entity B { b: String(20); j: Integer; } // from Partner B view V as select from A join B {a, b, x} ON A.j = B.j; // valid customer view It contradicts (3), as the unchanged customer view compiles with an error when partner B adds an element x to their table B . Principle (3) is also contradicted for specific features like (multiple) entity includes. Principle (4) is not part of the name resolution rules in HANA-CDS. As we never allow to break Principle (1), we have the following guideline: It is fine if definitions in the own source shadow other definitions (in the own source or others), because the programmer is aware (and in control) of all these definitions. It is evil if definitions made in other sources shadow other definitions (in the own source or others).","title":"Design Principles"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#name-resolution-the-basics","text":"We start with some terminology: An environment is a dictionary binding/mapping (local) names to language constructs (e.g. entities or elements). A navigation environment of a construct is the dictionary for definitions within that construct or a type/entity referred by that construct. For contexts (and services), these are the sub artifacts defined within that context. For types, entities, elements, these are the elements (or enum symbols) defined within that object or the object's (direct or indirect) type; for association types, these are the elements of the target entity. (The actions and parameters of an object cannot be accessed this way.) context C { type X: Integer; }; // context \"C\" supplies env{ X: type(\"C.X\") } type S { E: Integer; } extend S with { F: Integer; }; // type \"S\" supplies env{ E: elem(\"S\",\"E\"), F: \u2026 } type T: S; // type \"T\" supplies the same env as type \"S\"","title":"Name Resolution - the Basics"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#common-rules","text":"Name resolution is case sensitive . In general, a model can contain artifacts and members whose name differ in case only; there might be a linter check which informs model writers if they make use of this \"feature\". While being case sensitive might be against the original intention of SQL, it actually conforms to the SQL Specification after abstraction from the lexical syntax, see e.g. SQL-92, \u00a75.2.10 and 5.2.12\u202614 for the semantics of quoted and non-quoted identifiers. In CDL, we just do not transform non-quoted identifiers to all-upper names. Also, CSN-processors are cumbersome to write if they have to deal with (partial/feigned) case-insensitivity. In a future version of this project, we or others might provide a \"use at your own risk\" backend which produce SQL DDL statements without quoted identifiers In CDL, an identifier may be used before its definitions, there is no need of forward declarations . Thus, the sequence of definitions inside a block does not matter for the scope rules: using T as OuterT; // introduced to have a name for the shadowed \"T\" type T: String(20); context C { type D: T; // -> C.T -> cds.Integer type T: Integer; type O: OuterT; // -> T -> String(20) } // type C.O: T; // alternative: define \"C.O\" outside the block of \"C\" There are two reasons to do so: When using associations, (mutually) recursive usage is quote common, and forward references are cumbersome. (We can always access shadowed artifacts.) Real-world models will very likely reside in multiple files/resources \u2013 there is no natural order in which the definitions are to be processed.","title":"Common rules"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#resolving-paths","text":"The algorithm for resolution of paths (consisting of dot-connected names) is as follows: First, we try to find the language construct O for the first name in the path; this language construct is called the path base . We resolve the next name in the path by inspecting the navigation environment of O . The found language artifact is our next O . We repeat Step 2 until the complete path is resolved. Even the algorithm for finding the path base follows the same pattern: We have a list of search environments, which we inspect in order. The first hit is the path base. It is an error if the name (the first name of the path) cannot be found in any environment of the list. All but the last environment are constructed from definitions in the current source following the lexical block structure of the source, or a small, fixed number of predefined names (e.g. $projection .) We will call such an environment a lexical search environment . Only the last environment contains bindings defined externally , at least potentially. It can be the environment for predefined artifacts (like cds.Integer ), or the navigation environment of the \"current artifact/member of interest\" (like the elements of the projection source). So the guideline at the end of the previous section essentially becomes lexical scoping first, search in one externally provided environment last . The basic difference between the name resolution strategies is the relevance of the lexical and the last environments, and how they are build.","title":"Resolving paths"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#navigation-environment","text":"The navigation environment might depend on on the argument position. If an object is typed with an array, the environment supplied by that object is usually considered to be empty. For type of references and the to-be-extended element referenced in an inner extend, it is the environment supplied by the array item type: @ A . e : 1 // warning : cannot find `e` for annotation assignments annotation A : array of { e : Integer ; } ; annotate A with { annotate e with @ lineElement ; } annotation B : type of : A . e ; // valid = Integer For the to-be-extended element referenced in an inner extend, we consider the environment supplied by an association to be empty: type A: association to E; entity E { i: Integer; } annotate A with { @targetElem i; // error: do not follow associations } type S { e: Integer; } type T : S; annotate T with { @derivedElem e; // ok: follow derived type }","title":"Navigation environment"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#references-to-main-artifacts","text":"When we have an argument position where we expect a main artifact, the list of lexical search environments depends on the blocks containing the current statement, and the last, non-lexical search environment is independent from the block structure or a current object of interest. A reference to a main artifact can be a reference to a projection or view source (table reference after SELECT \u2026 FROM in SQL), association target , type (but not the reference after type of , see below) annotation for an annotation assignment, to-be-extended main artifact of an outer extend structure include , type parameter (should be a constant, not yet). The construction of the list of lexical search environments starts at the innermost block containing the current statement, and then continues to the next outer block: As opposed to HANA-CDS, we skip blocks containing just element definitions (or generally definitions of members like actions). For blocks of context and service definitions, we add the definition inside that block (all definitions in the environment supplied by the context or service can contain more definitions). For the top-level block of the current source, we add the top-level definitions and the bindings for the using declarations. The last, non-lexical search environment is the environment for built-in artifacts. Currently, it contains String for cds.String , similarly LargeString , Integer , Integer64 , Binary , LargeBinary , Decimal , DecimalFloat , Double , Date , Time , Timestamp , DateTime , and Boolean . More artifacts are defined with the options --hana-flavor . When searching for an annotation (after the initial @ ), the last search environment are the model definitions. We conclude this section with a little weird example \u2013 nobody would write models like that, but it demonstrates the exact semantics. nameprefix test; using cds.Boolean as Integer; type Time { @Date // @Date: true, not @cds.Date: true Date: Date; // typeOf(test.Time,Date) = cds.Date, no error C: C.Date; // typeOf(test.Time,C) = test.C.Date, no error } @C.Anno // @test.C.Anno: true define context C { type Date: Time; // test.C.Date -> test.C.Time, not test.Time type Time: Integer; // test.C.Time -> alias Integer -> cds.Boolean type CC: C.Integer; // test.C.CC -> test.C.Integer } @Integer // @cds.Boolean: true (warning: is no annotation) type C.Integer: Time; // test.C.Integer -> test.Time, not test.C.Time In this example, we have the following two lexical search environments: The search environment containing definitions directly inside the block after define context C : Date , Time and CC , but not Integer (but which is in the environment supplied by test.C ). Used as first search environment when resolving main artifact references in the block after define context C , the next search environment is the environment containing top-level definitions. The search environment containing the top-level definitions and using declarations of the source: Integer , Time and C . Used as first search environment when resolving main artifact references outside the block after define context C , the next search environment is the non-lexical environment containing built-in artifacts. There is no lexical search environment for the element definitions supplied by test.Time . We allow paths for names in top-level definitions. All but the last name in the paths are (on-the-fly) contexts, which do not introduce blocks for the lexical scoping: entity N.mid.E { key i: Integer; to1: association to E; // invalid to2: association to mid.E; // invalid to3: association to N.mid.E; // valid } context C { context mid { entity E { key i: Integer; to1: association to E; // valid to2: association to mid.E; // valid to3: association to C.mid.E; // valid } } }","title":"References to main artifacts"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#values-and-references-to-elements","text":"When we have an argument position where we expect a value or a reference to an element, We usually have just one lexical search environment which is sometimes only inpected if the path consists of at least two identifiers. This basically introduces an escape mechanism . The last, non-lexical environments is usually the environment either supplied from an artifact referred by the current statement or supplied by the object containing the current definition. It is often allowed to switch to the \"main artifact name resolution\" by prefixing the path with a : , used usually to refer to constants. The semantics is best explained separately for the diffent groups of argument positions.","title":"Values and references to elements"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#references-in-queries","text":"We start with the most complicated group, because it is known from SQL: references in SELECT item positions \u2013 similar: WHERE , ON , TODO : GROUP BY , ORDER BY (or special?), \u2026 TODO : do the same for as projection on ? TODO : names in mixins The list of search environments is created as follows: The (first) lexical search environment is build from the explicit and implicit alias names for the sources (table references after from ); we also bind $projection to the resulting view/projection elements of the current SELECT if not already used as a table alias. If the current SELECT is a sub-SELECT, we have additional lexical search environments containing alias names for the corresponding outer SELECTs; their $projection bindings are shadowed. For compatibility with ABAP CDS, we have another environment with one entry: we bind $parameters to the parameters of the current view \u2013 the SQL way is to use :param1 instead of $parameters.param1 , see below. The last, non-lexical environment is the environent containing the elements from all source entities of the current SELECT; if an element with the same name is contained in more than one source, this search environment binds the name to an \"ambiguity\" entry (i.e. a reference to it leads to an error) There are no additional non-lexical search environments for the elements of outer SELECTs. The lexical search environments are only inspected if the path consists of at least two identifiers. The above mentioned : -escape mechanism leads to the following name resolution: The first lexical search environment is the the environment containing all parameter names of the current view. The following search environments are the usual ones from the \"main artifact name resolution\"; constant values can be accessed this way ( TODO : probably not now).","title":"References in queries"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#references-to-sibling-elements","text":"The next group is for references in member definitions to other elements of the same main artifact. Such a reference can be a reference to a: calculated field , references in the default value (HANA SQL does not allow this) references in the ON condition of an unmanaged association * reference after type of \u2013 can also be a references to an element of another main artifact The list of search environments is created as follows: There is one lexical search environment, it has one entry: we bind $self to the main artifact, or to be exact: to the current instance of that artifact, e.g. the current line of an entity. This environment is also inspecteded if the path consists of just $self \u2013 useful for on conditions of unmanaged associations. The second and last, the non-lexical search environment is the environment supplied by the object (main artifact or element) where the current member is defined in. The above mentioned : -escape mechanism leads to the \"main artifact name resolution\"; it can be used to access constants, or \u2013for references after type of \u2013 elements of other artifacts. The reason for the $self references is visible in an example with subelements: type T { a: Integer; b = a; // b = a c = $self.a; // c = a } entity E { a: Integer; x: T; // x.b = x.a, x.c = x.a y { a: Integer; b = a; // y.b = y.a c = $self.a; // y.c = a }; } entity S { $self: Integer; // we might complain about such an element name x = $self.$self; // x = $self (the element) }","title":"References to sibling elements"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#other-element-references","text":"A foreign key in the definition of a managed association, is just searched in the environment supplied by the target entity. No lexical search environment is inspected first. In an inner extend , we just search in the navigation environment of the current language construct. No lexical search environment is inspected first. These are actually not necessary references to elements, but also sub artifacts (e.g. extend in extend context ), actions (in the actions clause of extend entity ), or parameters (in the parameters clause of extend action ). TODO : more use cases, like references inside filter conditions of paths.","title":"Other element references"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#paths-as-annotation-values","text":"We can also use paths as annotation assignment values. If there is no annotation definition (there might be a warning for this) then the path cannot be resolved at all. The same is true if the annotation type does not allow path values (then there might be a warning for this) or just a cds.UnspecifiedRef . If there is a annotation definition which allows to use paths by specifying the type cds.ArtifactRef (or a variant of it), then the path resolution works as described in Section \"References to Main Artifacts\" . If there is a annotation definition which allows to use paths by specifying the type cds.ElementRef then the path resolution works as described in Section \"References sibling elements\" . If that annotation is assigned to a main artifact then same main artifact mean the main artifact itself.","title":"Paths as annotation values"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#differences-to-hana-cds","text":"The most visible differences in the name resolution semantics of CDx/Language compared to HANA CDS are: Using constant values requires to prefix the path (referring to the constant) with a : . There is a new semantic for paths (without initial : ) used in annotation assignments. In the definitions of sub elements, accessing elements supplied by the corresponding main artifact requires to prefix the path with $self. . Accessing sibling elements works the same as in HANA CDS. It is no problem to define elements which have the same (local) name as the referenced type. In views with more than one source entity, selecting an element e from one source without the use of a table alias (which is not recommended anyway!) suddenly does not compile anymore if another source entity is extended by a new element e . In HANA-CDS, the name resolution works quite uniformly for all argument positions, with most clauses of SELECT being the main exception. It is also compatible to the \"pre-extension\" name resolution semantics of HANA-CDS. This is nice! Why do we specify a different name resolution semantics for CDx/Language? The reason is: we do not want to have the \"extended\" lexical scoping semantics of HANA CDS concerning elements, which heavily relies on the package hierchy. To avoid silent semantic changes with extensions, the HANA-CDS compiler enforces the following properties: Every source belongs to a package; packages can depend on other packages, no cycles are allowed. No language construct can be extended in the same package where it is defined in, no language construct can be extended twice in the same package Artifacts can only be extended by top-level extend statements, elements can only be extended by inner extends (the second is true for CDx/Language, too). These are properties which do not hold for consumers of the CDx Compiler. Additionally, while direct changes in base packages can always lead to semantic changes, the following example shows that this unwanted effect is more likely in HANA-CDS: // BaseApp.cds --- entity E { a: String(20); b { // a: Integer; // CHANGE: introduce sub element x: Integer; }; } // MyExtension.cds --- extend E with { extend b with { z = a; // in CDx/Language: $self.a } } In HANA-CDS, both files compile before and after the change in BaseApp.cds : the element b.z of E refers to element a of E , but after the change to b.a of E , because that element is visible in the base package and all its extensions (we would not see the problem if b.a would have been introduced by an extension in another package). In CDx/Language, the files only compile after the change in BaseApp.cds : (with the same semantics as in HANA-CDS). To make it work before the change, element b.z of E can refer to element a of E by writing this references as $self.a \u2013 with this path, b.z still refers to a of E after the change in BaseApp.cds .","title":"Differences to HANA-CDS"},{"location":"apis/cds-compiler/doc/doc/NameResolution/#summary","text":"To avoid silent semantic changes with extensions or new CDL versions, we follow the following principle: After we have tried to find a local name in an environment containing artifacts or elements which are potentially defined somewhere else (e.g. via an extension), we do not inspect any other environment. In CDx/Language, we basically have two search strategies. But let us start with Strategy 0: Resolving a name in the tail of a path . For a path a.b , we only inspect one environment when resolving b : the environment supplied by a . For example, if a is a structured element, we try to find b in all sub elements of a \u2013 it does not matter whether the sub element b has been directly defined with the definition of element a , or whether is has been defined externally: via an extension or as an element of the referenced type. Resolving the first name of a path when looking for artifacts . We apply lexical scoping when we refer to types, entities and similar artifacts. When looking for an artifact A , we search in the blocks of surrounding context , service and top-level definitions, starting at the innermost block and ending at the top-level block of the source. To make it clear: we do not search in blocks of type, entity or other definitions, just blocks of contexts (and similar constructs). We only consider definitions within these blocks, not all sub artifacts of the contexts, which might have been introduced by context extensions, or by using a path in the definition, e.g. type MyContext.A: \u2026 . If the search is not successful so far, we finally inpect an environment containing artifacts which are normally not defined in our own source: For the @A of an annotation assignment , we look for A in the definitions property of the model. For all other references, we look for A in the built-in environment, where we define things like cds.Integer . This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ArtifactRef (or variants, future). Resolving the first name of a path when looking for values or elements . We search for elements supplied by the current \"language construct of interest\", which depends on the argument position. The most relevant ones are: The element or artifact where the current (sub) artifact is defined in, i.e. we access sibling elements. The source of the current projection or view. Depending on the argument position, there is an escape mechanism \u2013 which is tried first \u2013 to access also other elements. The most relevant ones are: If the paths starts with the identifier $self , we look for the next name of the path in the environment supplied by the corresponding main artifact of the current element. This is useful for element references inside sub elements to access siblings of ancestors. If a path in most clauses of a view starts with a , and a is an explicit or implicit table alias (which we always see in our source), we look for the next identifier of the path in the environment supplied by the corresponding entity. If the path is prefixed by a : , we actually switch to the other search strategy: looking for artifacts like types. This is useful to access constant values (or for type of ). This search is also used for path references in annotation assignments when the corresponding definition allows the type cds.ElementRef (future).","title":"Summary"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/","text":"ODATA Transformation \u00b6 Status Oct 2019: outdated, uses old-style CSN, to be reworked completely -> move to internalDoc/. For users, OData is a backend, they do not care too much that it works via a CSN transformation. Prior to the generation of EDMX (Entity Data Model XML) files from a CDS model, the following transformations are applied to the model. Most (but not all) of them become visible both in Augmented CSN and in Plain CSN: Generated foreign key fields for managed associations \u00b6 Managed associations do not have ON-conditions. Instead, they implicitly compare fields (usually the key fields) of the association's target entity with foreign key fields automatically generated into the entity containing the association. Creating the generated fields \u00b6 The ODATA transformation adds the generated foreign key fields to the model. The names of the generated foreign key fields are a concatenation of the association element name, an underscore, and the key name or its alias. Each generated foreign key field gets the name of the corresponding association as an annotation @odata.foreignKey4 . FIXME : Do we want to keep that? For example, for the three association elements a1 , a2 and a3 in the following snippet: service S { entity FromEntity { a1 : association to ToEntity ; // Use target ' s keys a2 : association to ToEntity { x } ; // Explicitly specified key a3 : association to ToEntity { x as z } ; // Key with alias } entity ToEntity { key x : Integer ; key y : Integer ; } } the ODATA transformation would generate foreign key fields in the resulting CSN as follows (shown here in CDS source form): entity FromEntity { a1 : association to ToEntity; a2 : association to ToEntity {x}; @odata.foreignKey4: 'a1' a1_x : Integer; // Generated foreign key @odata.foreignKey4: 'a1' a1_y : Integer; // Generated foreign key @odata.foreignKey4: 'a2' a2_x : Integer; // Generated foreign key @odata.foreignKey4: 'a3' a3_z : Integer; // Generated foreign key } It is an error if the generated fields conflict with existing fields. Annotation propagation \u00b6 The ODATA transformation propagates all annotations from the association to all its generated foreign key fields. FIXME : Do we want to keep that? Connecting the associations with the generated fields \u00b6 The CSN for the managed association elements contains a foreignKeys property, which is a dictionary of foreign key names (taken from the target key names, or from explicitly specified keys resp. their aliases) to the foreign key properties. The ODATA transformation adds a generatedFieldName property to each foreign key, containing the name of the generated foreign key field. Together with the @odata.foreignKey4 annotation described above, this provides a bi-directional link between the association and its generated field. For the example shown above, the CSN for the three association elements a1 , a2 and a3 would look as follows: \"a1\": { \"indexNo\": 1, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"indexNo\": 1, \"path\": \"x\", \"generatedFieldName\": \"a1_x\" }, \"y\": { \"indexNo\": 2, \"path\": \"y\", \"generatedFieldName\": \"a1_y\" } } }, \"a2\": { \"indexNo\": 2, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a2_x\" } } }, \"a3\": { \"indexNo\": 3, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"z\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a3_z\" } } }, (Augmented CSN only): Adding _service to exposed artifacts \u00b6 For each artifact that is exposed by a service (including the service itself), the ODATA transformation adds a non-enumerable property _service to the artifact in the Augmented CSN model, containing a link to the corresponding service artifact. This is convenient for EDMX processors that want to process only exposed artifacts or only artifacts belonging to a specific service. Implicit redirection for non-exposed association targets \u00b6 For each exposed artifact that contains associations, it is checked that the association target is also exposed by the same service. If this is not the case, the ODATA transformation tries to find an \"exposed representative\" of the target, i.e. an exposed projection or view on the target, or an exposed entity that includes the target. If such a representative is found and unique, the association is implicitly redirected to the exposed representative. Note that only projections and projection-like views (i.e. those that have a single from source without union , join or nested queries) are considered as implicit redirection targets. Example: // All these entities are used as association targets below // Simple target entity E1 { key id : Integer ; } // Base target included by E2a entity E2 { key id : Integer ; } entity E2a : E2 { s : String ( 10 ); } // Base target included by S . E3a entity E3 { key id : Integer ; } // Exposure in service service S { entity P1 as projection on E1 ; // Exposes simple target E1 entity P2a as projection on E2a ; // Exposes E2a but also its included E2 entity E3a : E3 { } ; // Exposes included E3 entity Redirected { toE1 : association to E1 ; // Implicitly redirected to P1 ( projection exposes E1 ) toE2 : association to E2 ; // Implicitly redirected to P2a ( projection exposes something that includes E2 ) toE3 : association to E3 ; // Implicitly redirected to E3a ( entity includes E3 ) } } Exposure checking \u00b6 Currently, it is assumed that services must be self-contained, i.e. that all associations within a service must point to targets also exposed by this service. This is checked by the ODATA transformation. FIXME: The same restriction will probably apply when structured types are allowed as element types within exposed entities. Unraveling derived scalar types \u00b6 The ODATA transformation unravels derived scalar types, i.e. primitive types for which the user has provided a custom name (possibly multiple times in a chain) are replaced by the original primitive type. Annotations are propagated upwards in the chain from the primitive type to the most derived type. For example, the following CDS source @IsName : true type Name : String ( 20 ); @IsCustomer : true type CustomerName : Name ; service S { entity E { name : CustomerName ; } } essentially behaves as if the user had written service S { entity E { @IsCustomer: true @IsName: true name : String(20); } } (Tentative): Checking ON-conditions \u00b6 Currently, the ODATA transformation checks for various restrictions regarding ON-conditions of unmanaged associations: only = and AND operators may be used operands may only be paths or values (not expressions) exactly one of the operands must traverse the association The intention behind this restriction is to produce a meaningful value for the ReferentialConstraint of the resulting NavigationProperty . FIXME : Do we want to keep that? (Tentative): Renaming annotations \u00b6 Currently, the ODATA transformation renames various \"shorthand\" annotations to their more elaborate \"long form\". Original name New name @label @Common.Label @label @Common.Label @title @Common.Label @ValueList.entity @Common.ValueList.entity @ValueList.type @Common.ValueList.type @Capabilities.Deletable @Capabilities.DeleteRestrictions.Deletable @Capabilities.Insertable @Capabilities.InsertRestrictions.Insertable @Capabilities.Updatable @Capabilities.UpdateRestrictions.Updatable @readonly @Core.Immutable @important @UI.Importance For the annotation @important (which is renamed to @UI.Importance ), the values true / false are also replaced by the enum constants #High / #Low . FIXME : Do we want to keep that?","title":"ODATA Transformation"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#odata-transformation","text":"Status Oct 2019: outdated, uses old-style CSN, to be reworked completely -> move to internalDoc/. For users, OData is a backend, they do not care too much that it works via a CSN transformation. Prior to the generation of EDMX (Entity Data Model XML) files from a CDS model, the following transformations are applied to the model. Most (but not all) of them become visible both in Augmented CSN and in Plain CSN:","title":"ODATA Transformation"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#generated-foreign-key-fields-for-managed-associations","text":"Managed associations do not have ON-conditions. Instead, they implicitly compare fields (usually the key fields) of the association's target entity with foreign key fields automatically generated into the entity containing the association.","title":"Generated foreign key fields for managed associations"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#creating-the-generated-fields","text":"The ODATA transformation adds the generated foreign key fields to the model. The names of the generated foreign key fields are a concatenation of the association element name, an underscore, and the key name or its alias. Each generated foreign key field gets the name of the corresponding association as an annotation @odata.foreignKey4 . FIXME : Do we want to keep that? For example, for the three association elements a1 , a2 and a3 in the following snippet: service S { entity FromEntity { a1 : association to ToEntity ; // Use target ' s keys a2 : association to ToEntity { x } ; // Explicitly specified key a3 : association to ToEntity { x as z } ; // Key with alias } entity ToEntity { key x : Integer ; key y : Integer ; } } the ODATA transformation would generate foreign key fields in the resulting CSN as follows (shown here in CDS source form): entity FromEntity { a1 : association to ToEntity; a2 : association to ToEntity {x}; @odata.foreignKey4: 'a1' a1_x : Integer; // Generated foreign key @odata.foreignKey4: 'a1' a1_y : Integer; // Generated foreign key @odata.foreignKey4: 'a2' a2_x : Integer; // Generated foreign key @odata.foreignKey4: 'a3' a3_z : Integer; // Generated foreign key } It is an error if the generated fields conflict with existing fields.","title":"Creating the generated fields"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#annotation-propagation","text":"The ODATA transformation propagates all annotations from the association to all its generated foreign key fields. FIXME : Do we want to keep that?","title":"Annotation propagation"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#connecting-the-associations-with-the-generated-fields","text":"The CSN for the managed association elements contains a foreignKeys property, which is a dictionary of foreign key names (taken from the target key names, or from explicitly specified keys resp. their aliases) to the foreign key properties. The ODATA transformation adds a generatedFieldName property to each foreign key, containing the name of the generated foreign key field. Together with the @odata.foreignKey4 annotation described above, this provides a bi-directional link between the association and its generated field. For the example shown above, the CSN for the three association elements a1 , a2 and a3 would look as follows: \"a1\": { \"indexNo\": 1, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"indexNo\": 1, \"path\": \"x\", \"generatedFieldName\": \"a1_x\" }, \"y\": { \"indexNo\": 2, \"path\": \"y\", \"generatedFieldName\": \"a1_y\" } } }, \"a2\": { \"indexNo\": 2, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"x\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a2_x\" } } }, \"a3\": { \"indexNo\": 3, \"target\": \"S.ToEntity\", \"type\": \"cds.Association\", \"foreignKeys\": { \"z\": { \"path\": \"x\", \"indexNo\": 1, \"generatedFieldName\": \"a3_z\" } } },","title":"Connecting the associations with the generated fields"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#augmented-csn-only-adding-_service-to-exposed-artifacts","text":"For each artifact that is exposed by a service (including the service itself), the ODATA transformation adds a non-enumerable property _service to the artifact in the Augmented CSN model, containing a link to the corresponding service artifact. This is convenient for EDMX processors that want to process only exposed artifacts or only artifacts belonging to a specific service.","title":"(Augmented CSN only): Adding _service to exposed artifacts"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#implicit-redirection-for-non-exposed-association-targets","text":"For each exposed artifact that contains associations, it is checked that the association target is also exposed by the same service. If this is not the case, the ODATA transformation tries to find an \"exposed representative\" of the target, i.e. an exposed projection or view on the target, or an exposed entity that includes the target. If such a representative is found and unique, the association is implicitly redirected to the exposed representative. Note that only projections and projection-like views (i.e. those that have a single from source without union , join or nested queries) are considered as implicit redirection targets. Example: // All these entities are used as association targets below // Simple target entity E1 { key id : Integer ; } // Base target included by E2a entity E2 { key id : Integer ; } entity E2a : E2 { s : String ( 10 ); } // Base target included by S . E3a entity E3 { key id : Integer ; } // Exposure in service service S { entity P1 as projection on E1 ; // Exposes simple target E1 entity P2a as projection on E2a ; // Exposes E2a but also its included E2 entity E3a : E3 { } ; // Exposes included E3 entity Redirected { toE1 : association to E1 ; // Implicitly redirected to P1 ( projection exposes E1 ) toE2 : association to E2 ; // Implicitly redirected to P2a ( projection exposes something that includes E2 ) toE3 : association to E3 ; // Implicitly redirected to E3a ( entity includes E3 ) } }","title":"Implicit redirection for non-exposed association targets"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#exposure-checking","text":"Currently, it is assumed that services must be self-contained, i.e. that all associations within a service must point to targets also exposed by this service. This is checked by the ODATA transformation. FIXME: The same restriction will probably apply when structured types are allowed as element types within exposed entities.","title":"Exposure checking"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#unraveling-derived-scalar-types","text":"The ODATA transformation unravels derived scalar types, i.e. primitive types for which the user has provided a custom name (possibly multiple times in a chain) are replaced by the original primitive type. Annotations are propagated upwards in the chain from the primitive type to the most derived type. For example, the following CDS source @IsName : true type Name : String ( 20 ); @IsCustomer : true type CustomerName : Name ; service S { entity E { name : CustomerName ; } } essentially behaves as if the user had written service S { entity E { @IsCustomer: true @IsName: true name : String(20); } }","title":"Unraveling derived scalar types"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#tentative-checking-on-conditions","text":"Currently, the ODATA transformation checks for various restrictions regarding ON-conditions of unmanaged associations: only = and AND operators may be used operands may only be paths or values (not expressions) exactly one of the operands must traverse the association The intention behind this restriction is to produce a meaningful value for the ReferentialConstraint of the resulting NavigationProperty . FIXME : Do we want to keep that?","title":"(Tentative): Checking ON-conditions"},{"location":"apis/cds-compiler/doc/doc/ODataTransformation/#tentative-renaming-annotations","text":"Currently, the ODATA transformation renames various \"shorthand\" annotations to their more elaborate \"long form\". Original name New name @label @Common.Label @label @Common.Label @title @Common.Label @ValueList.entity @Common.ValueList.entity @ValueList.type @Common.ValueList.type @Capabilities.Deletable @Capabilities.DeleteRestrictions.Deletable @Capabilities.Insertable @Capabilities.InsertRestrictions.Insertable @Capabilities.Updatable @Capabilities.UpdateRestrictions.Updatable @readonly @Core.Immutable @important @UI.Importance For the annotation @important (which is renamed to @UI.Importance ), the values true / false are also replaced by the enum constants #High / #Low . FIXME : Do we want to keep that?","title":"(Tentative): Renaming annotations"},{"location":"apis/cds-compiler/doc/doc/toSwagger/","text":"To Swagger transformation \u00b6 Status Oct 2019: outdated. As long as the toSwagger backend only works with --beta-mode , this doc should be in internalDoc/. Some JSON code snippets might be a bit too long. \"The OpenAPI Specification, originally known as the Swagger Specification, is a specification for machine-readable interface files for describing, producing, consuming, and visualizing RESTful Web services.\" - Wikipedia In 2015 the Swagger specification was renamed to the OpenAPI specification. The compiler's functionality provides an output as per the OpenAPI 3.0.0 specification, regardless of being called 'to Swagger'. Transform a CDS model to a swagger json file \u00b6 Executing the compiler with the --to-swagger option or in short -S gives the opportunity based on your CDS model an OpenAPI json file(s) to be produced. In addition to the option, a mandatory flag(s) needs to be added. The flags can be a comma-separated combination of \"json\" and \"csn\". The json flag generate output for each service in the model, the csn flag the preprocessed model with to swagger specifics. Basic information \u00b6 Multiple services generation is supported as for each service in the input CDS model a separate swagger document is created. Every OpenAPI 3.0.0 document should have an \"openapi\" property, which specifies the version of the specification followed, in our case the \"3.0.0\" value is assigned. Also, the document receives a property \"info\" with \"title\" and value is the name of the corresponding service for the swagger document. Paths \u00b6 The \"paths\" property of the OpenAPI document describes the available paths and operations for the API in question. The unbound actions and functions play a role as a feeder for the information in the paths property of the swagger model. As the paths property is a mandatory one, if no content for generation is found in the model, then an empty object will be generated. HTTP method \u00b6 The corresponding definitions of paths in CDS model are the (un)bound actions and functions. Such an action or a function must be annotated with the specified annotation so the generator takes it in mind. The annotation declares the desired HTTP method and the response code. Three different syntaxes are available: @Swagger.GET : 200 - a GET operation with response code 200 is generated @Swagger.POST - a POST operation with the default response code is generated @Swagger.DELETE : [202, 204, 200] - a DELETE operation with responses for every of 202, 204 and 200 codes or the three variants can be combined in: @Swagger : { GET : 200, POST, DELETE : [202, 204, 200] } To define a range of response codes, you may use the following range definitions: 1XX , 2XX , 3XX , 4XX , and 5XX . By the OpenAPI specification GET , PUT , POST , DELETE , OPTIONS , HEAD , PATCH and TRACE are the supported http verbs. Still not supported in the CDS compiler are only OPTIONS and TRACE . If the user decides not to specify a response code(using the @Swagger. method ), then an operation with default code will be generated. The default code for a PATCH operation is 204 , for the rest of the operations is 200 . Path to an individual endpoint \u00b6 If a relative path to an individual endpoint is not specified by the user, then the default one is assigned. This default path is composed from the service name, the entity name(if the action/function is bound) and the name of the action. An example for bound action will be: /com.test.MyService.MyEntyty/myAction and for unbound: /com.test.MyService/myFunction . For the case when the user wants an operation to serves under a specific path, that can be arranged with the @Swagger.path annotation. The custom path can include parameters e.g. @Swagger.path : '/MyPath/bookByName/{bookName}' . In this case the user has to take care the names of the parameters to correspond to the name of parameters specified in the action/function declaration. Operations parameters \u00b6 The OpenAPI specification states that a parameter can have location ( the property 'in' of a parameter object ) with one of the following values: - query - header - path - cookie With the @Swagger.parameter annotation applied to a parameter this location can be specified. If not specified - query is taken as value. If a value path is given for the @Swagger.parameter annotation, this means that automatically the name of the parameter is prepended to the path name. This is valid only if a @Swagger.path annotation is not used. The parameter location resolving is illustrated with the following example: Given is the CDS model ... actions { @Swagger.GET action bookById(@Swagger.parameter: 'path' bookId : Integer) returns Book; @Swagger.GET action bookByName(@Swagger.parameter: 'cookie' bookName: String) returns Book; @Swagger.GET action booksByAuthor(authorName: String) returns array of Book; }; ... the result will look like: ... \"paths\" : { \"/Bookstore/Book/bookById/{bookId}\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookId\" , \"in\" : \"path\" , \"description\" : \"\" , \"required\" : true , \"schema\" : { \"type\" : \"integer\" , \"format\" : \"int32\" } } ] } }, \"/Bookstore/Book/bookByName\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookName\" , \"in\" : \"cookie\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } }, \"/Bookstore/Book/booksByAuthor\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"authorName\" , \"in\" : \"query\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } } } ... Request body \u00b6 For the @Swagger.parameter annotation can be given one more value - requestBody . This value can be used in a POST , PUT or PATCH requests. It indicates that for the specified parameter a requestBody property will be generated for the path object. Only one parameter can be annotated with this value - the first found will be taken in mind. The annotated parameter will not be included in the parameters property. Arrayed responses \u00b6 As seen in the example above, if an action/function has a return type ... returns array of <entity_name> , then for the OpenAPI document the schema for this specific response is of type array with items of type the pointed entity and a header, which is a link to the next page of responses, or: \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/<entity_name>\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } } , Schemas \u00b6 One of the major components in an OpenAPI interface file is the components' schemas. The corresponding artifacts to schemas in the OpenAPI file from a CDS model are the definitions. Executing the following model: service Petstore { entity Pet { id : Integer64 not null; name : String not null; tag : String(10); }; }; will result in: ... \"components\" : { \"schemas\" : { \"Petstore.Pet\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"tag\" : { \"maxLength\" : 10 , \"type\" : \"string\" } } } ... In short, all the artifacts enclosed in a service definition of a CDS model are transformed into a top-level definitions into the schemas part of an OpenAPI json file, except for the services/contexts, unbound actions and functions, namespaces. A service declaration in a CDS model should be self-containing, which means that is declarations outside of the service are used, an error will be thrown. The only case that is an exception here is when an element is of a type which is user-defined and the user-defined type is builtin and outside of the service, then the type of the element is expanded to the builtin type. When we have an association the target should be from the current service or exposed in the current service via projection. Every top-level artifact is represented like a Schema Object as described in the OpenAPI specification The associations are treated regarding their cardinality respectively: - to-one leads to a single object response with schema as the target - to-many is represented as an array with items of a type the corresponding target Association redirection in projections \u00b6 This redirection is expressed in switching the target of an association, which is part of a projection to the corresponding projection(on the target of the association in the underlying context) from the current service. For example the following model: service Bookstore { entity Book as projection on BookstoreContext . Book ; entity Author as projection on BookstoreContext . Author ; @Swagger . GET action books () returns array of Book ; } ; context BookstoreContext { entity Book { id : Integer64 not null ; name : String not null ; author : association to Author ; } ; entity Author { key id : Integer ; firstName : String ; lastName : String ; } ; } ; will result in: { \"openapi\" : \"3.0.0\" , \"info\" : { \"version\" : \"\" , \"title\" : \"Bookstore\" }, \"paths\" : { \"/Bookstore/books\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } } } } }, \"components\" : { \"schemas\" : { \"Bookstore.Book\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"author\" : { \"$ref\" : \"#/components/schemas/Bookstore.Author\" } } }, \"Bookstore.Author\" : { \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"firstName\" : { \"type\" : \"string\" }, \"lastName\" : { \"type\" : \"string\" } } }, \"Error\" : { \"required\" : [ \"code\" , \"message\" ], \"properties\" : { \"code\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"message\" : { \"type\" : \"string\" } } } } } } The same redirection is performed for user-defined types, as the type declaration should be also exposed to the service in question. CDS Views \u00b6 From a view declared in the CDS model is generated a schema similar to the one coming from an entity, as the logic from the view is not applicable for describe in the API spec. Enums \u00b6 Declared in the CDS model enums are generated as the values are taken in mind. ... entity MyEntity { elem : String enum { foo = 'bar'; }; }; ... The output: ... \"components\" : { \"schemas\" : { \"MyEntity\" : { \"properties\" : { \"elem\" : { \"enum\" : [ \"bar\" ], \"type\" : \"string\" } } }, ...","title":"To Swagger transformation"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#to-swagger-transformation","text":"Status Oct 2019: outdated. As long as the toSwagger backend only works with --beta-mode , this doc should be in internalDoc/. Some JSON code snippets might be a bit too long. \"The OpenAPI Specification, originally known as the Swagger Specification, is a specification for machine-readable interface files for describing, producing, consuming, and visualizing RESTful Web services.\" - Wikipedia In 2015 the Swagger specification was renamed to the OpenAPI specification. The compiler's functionality provides an output as per the OpenAPI 3.0.0 specification, regardless of being called 'to Swagger'.","title":"To Swagger transformation"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#transform-a-cds-model-to-a-swagger-json-file","text":"Executing the compiler with the --to-swagger option or in short -S gives the opportunity based on your CDS model an OpenAPI json file(s) to be produced. In addition to the option, a mandatory flag(s) needs to be added. The flags can be a comma-separated combination of \"json\" and \"csn\". The json flag generate output for each service in the model, the csn flag the preprocessed model with to swagger specifics.","title":"Transform a CDS model to a swagger json file"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#basic-information","text":"Multiple services generation is supported as for each service in the input CDS model a separate swagger document is created. Every OpenAPI 3.0.0 document should have an \"openapi\" property, which specifies the version of the specification followed, in our case the \"3.0.0\" value is assigned. Also, the document receives a property \"info\" with \"title\" and value is the name of the corresponding service for the swagger document.","title":"Basic information"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#paths","text":"The \"paths\" property of the OpenAPI document describes the available paths and operations for the API in question. The unbound actions and functions play a role as a feeder for the information in the paths property of the swagger model. As the paths property is a mandatory one, if no content for generation is found in the model, then an empty object will be generated.","title":"Paths"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#http-method","text":"The corresponding definitions of paths in CDS model are the (un)bound actions and functions. Such an action or a function must be annotated with the specified annotation so the generator takes it in mind. The annotation declares the desired HTTP method and the response code. Three different syntaxes are available: @Swagger.GET : 200 - a GET operation with response code 200 is generated @Swagger.POST - a POST operation with the default response code is generated @Swagger.DELETE : [202, 204, 200] - a DELETE operation with responses for every of 202, 204 and 200 codes or the three variants can be combined in: @Swagger : { GET : 200, POST, DELETE : [202, 204, 200] } To define a range of response codes, you may use the following range definitions: 1XX , 2XX , 3XX , 4XX , and 5XX . By the OpenAPI specification GET , PUT , POST , DELETE , OPTIONS , HEAD , PATCH and TRACE are the supported http verbs. Still not supported in the CDS compiler are only OPTIONS and TRACE . If the user decides not to specify a response code(using the @Swagger. method ), then an operation with default code will be generated. The default code for a PATCH operation is 204 , for the rest of the operations is 200 .","title":"HTTP method"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#path-to-an-individual-endpoint","text":"If a relative path to an individual endpoint is not specified by the user, then the default one is assigned. This default path is composed from the service name, the entity name(if the action/function is bound) and the name of the action. An example for bound action will be: /com.test.MyService.MyEntyty/myAction and for unbound: /com.test.MyService/myFunction . For the case when the user wants an operation to serves under a specific path, that can be arranged with the @Swagger.path annotation. The custom path can include parameters e.g. @Swagger.path : '/MyPath/bookByName/{bookName}' . In this case the user has to take care the names of the parameters to correspond to the name of parameters specified in the action/function declaration.","title":"Path to an individual endpoint"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#operations-parameters","text":"The OpenAPI specification states that a parameter can have location ( the property 'in' of a parameter object ) with one of the following values: - query - header - path - cookie With the @Swagger.parameter annotation applied to a parameter this location can be specified. If not specified - query is taken as value. If a value path is given for the @Swagger.parameter annotation, this means that automatically the name of the parameter is prepended to the path name. This is valid only if a @Swagger.path annotation is not used. The parameter location resolving is illustrated with the following example: Given is the CDS model ... actions { @Swagger.GET action bookById(@Swagger.parameter: 'path' bookId : Integer) returns Book; @Swagger.GET action bookByName(@Swagger.parameter: 'cookie' bookName: String) returns Book; @Swagger.GET action booksByAuthor(authorName: String) returns array of Book; }; ... the result will look like: ... \"paths\" : { \"/Bookstore/Book/bookById/{bookId}\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookId\" , \"in\" : \"path\" , \"description\" : \"\" , \"required\" : true , \"schema\" : { \"type\" : \"integer\" , \"format\" : \"int32\" } } ] } }, \"/Bookstore/Book/bookByName\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"bookName\" , \"in\" : \"cookie\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } }, \"/Bookstore/Book/booksByAuthor\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } }, \"parameters\" : [ { \"name\" : \"authorName\" , \"in\" : \"query\" , \"description\" : \"\" , \"required\" : false , \"schema\" : { \"type\" : \"string\" } } ] } } } ...","title":"Operations parameters"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#request-body","text":"For the @Swagger.parameter annotation can be given one more value - requestBody . This value can be used in a POST , PUT or PATCH requests. It indicates that for the specified parameter a requestBody property will be generated for the path object. Only one parameter can be annotated with this value - the first found will be taken in mind. The annotated parameter will not be included in the parameters property.","title":"Request body"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#arrayed-responses","text":"As seen in the example above, if an action/function has a return type ... returns array of <entity_name> , then for the OpenAPI document the schema for this specific response is of type array with items of type the pointed entity and a header, which is a link to the next page of responses, or: \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/<entity_name>\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } } ,","title":"Arrayed responses"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#schemas","text":"One of the major components in an OpenAPI interface file is the components' schemas. The corresponding artifacts to schemas in the OpenAPI file from a CDS model are the definitions. Executing the following model: service Petstore { entity Pet { id : Integer64 not null; name : String not null; tag : String(10); }; }; will result in: ... \"components\" : { \"schemas\" : { \"Petstore.Pet\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"tag\" : { \"maxLength\" : 10 , \"type\" : \"string\" } } } ... In short, all the artifacts enclosed in a service definition of a CDS model are transformed into a top-level definitions into the schemas part of an OpenAPI json file, except for the services/contexts, unbound actions and functions, namespaces. A service declaration in a CDS model should be self-containing, which means that is declarations outside of the service are used, an error will be thrown. The only case that is an exception here is when an element is of a type which is user-defined and the user-defined type is builtin and outside of the service, then the type of the element is expanded to the builtin type. When we have an association the target should be from the current service or exposed in the current service via projection. Every top-level artifact is represented like a Schema Object as described in the OpenAPI specification The associations are treated regarding their cardinality respectively: - to-one leads to a single object response with schema as the target - to-many is represented as an array with items of a type the corresponding target","title":"Schemas"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#association-redirection-in-projections","text":"This redirection is expressed in switching the target of an association, which is part of a projection to the corresponding projection(on the target of the association in the underlying context) from the current service. For example the following model: service Bookstore { entity Book as projection on BookstoreContext . Book ; entity Author as projection on BookstoreContext . Author ; @Swagger . GET action books () returns array of Book ; } ; context BookstoreContext { entity Book { id : Integer64 not null ; name : String not null ; author : association to Author ; } ; entity Author { key id : Integer ; firstName : String ; lastName : String ; } ; } ; will result in: { \"openapi\" : \"3.0.0\" , \"info\" : { \"version\" : \"\" , \"title\" : \"Bookstore\" }, \"paths\" : { \"/Bookstore/books\" : { \"get\" : { \"summary\" : \"\" , \"operationId\" : \"\" , \"tags\" : [], \"responses\" : { \"200\" : { \"description\" : \"Expected response to a valid request\" , \"content\" : { \"application/json\" : { \"schema\" : { \"type\" : \"array\" , \"items\" : { \"$ref\" : \"#/components/schemas/Bookstore.Book\" } } } }, \"headers\" : { \"x-next\" : { \"description\" : \"A link to the next page of responses\" , \"schema\" : { \"type\" : \"string\" } } } }, \"default\" : { \"description\" : \"unexpected error\" , \"content\" : { \"application/json\" : { \"schema\" : { \"$ref\" : \"#/components/schemas/Error\" } } } } } } } }, \"components\" : { \"schemas\" : { \"Bookstore.Book\" : { \"required\" : [ \"id\" , \"name\" ], \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int64\" }, \"name\" : { \"type\" : \"string\" }, \"author\" : { \"$ref\" : \"#/components/schemas/Bookstore.Author\" } } }, \"Bookstore.Author\" : { \"properties\" : { \"id\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"firstName\" : { \"type\" : \"string\" }, \"lastName\" : { \"type\" : \"string\" } } }, \"Error\" : { \"required\" : [ \"code\" , \"message\" ], \"properties\" : { \"code\" : { \"type\" : \"integer\" , \"format\" : \"int32\" }, \"message\" : { \"type\" : \"string\" } } } } } } The same redirection is performed for user-defined types, as the type declaration should be also exposed to the service in question.","title":"Association redirection in projections"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#cds-views","text":"From a view declared in the CDS model is generated a schema similar to the one coming from an entity, as the logic from the view is not applicable for describe in the API spec.","title":"CDS Views"},{"location":"apis/cds-compiler/doc/doc/toSwagger/#enums","text":"Declared in the CDS model enums are generated as the values are taken in mind. ... entity MyEntity { elem : String enum { foo = 'bar'; }; }; ... The output: ... \"components\" : { \"schemas\" : { \"MyEntity\" : { \"properties\" : { \"elem\" : { \"enum\" : [ \"bar\" ], \"type\" : \"string\" } } }, ...","title":"Enums"},{"location":"apis/cds-dk/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.8.5 - 2020-06-05 \u00b6 Changed \u00b6 cds init uses latest Maven Java archetype version 1.6.0 for creating Java projects. Version 1.8.4 - 2020-05-30 \u00b6 Changed \u00b6 cds init uses latest Maven Java archetype version 1.5.2 for creating Java projects. Fixes \u00b6 An issue in @sap/edm-converters with missing entity sets Version 1.8.2 - 2020-05-08 \u00b6 Fixes \u00b6 An issue in @sap/edm-converters with missing entity sets Version 1.8.0 - 2020-04-27 \u00b6 Added \u00b6 cds watch now also accepts package names as arguments, e.g. cds w @capire/bookshop . cds add mta now supports cds configuration requires.db.kind:\"sql\" which allows seamless production deployments using HANA db while keepping sqlite for local development scenario. Changed \u00b6 Parameter verbose in cds init and cds add is now deprecated. Use environment variable DEBUG=true to obtain detailed output. cds init uses latest Java archetype version 1.4.0 for creating Java projects. Fixed \u00b6 Fixing terminology in cds init and cds add console output. cds init is logging cds env output only in debug mode. Using cds build command in generated mta.yaml file. Fixing Hana dependency during cds init --add hana for project type java . Fixing bug in cds init when cds-dk is not installed globally. Fixing bug in cds init when calling log methods. Fixing cds.env object by attaching prototype chain. Version 1.7.0 - 2020-03-24 \u00b6 Added \u00b6 cds init --add java supports --java:mvn to add additional parameter. Improvements when logging console output during cds init . Link to Maven archetype documentation shown in cds help init . Changed \u00b6 cds add mta now activates the production profile when creating the mta.yaml , which is consistent with what the MTA build does. This way, configuration like \"[production]: {\"kind\": \"hana\"} gets activated automatically. Version 1.6.3 - 2020-03-05 \u00b6 Changed \u00b6 Fixed \u00b6 Proper npm-shrinkwrap.json cds init is a bit more relaxed when checking for existing project content Version 1.6.0 - 2020-02-25 \u00b6 Added \u00b6 cds init --add java now also works with --hana Changed \u00b6 cds add mta now creates resources for SAP HANA with an explicit service type hana . If deploying to trial landscapes, this needs to be changed manually to hanatrial . Fixed \u00b6 cds add mta now creates valid configuration for uaa and auditlog resources. Version 1.5.0 - 2020-02-10 \u00b6 Changed \u00b6 cds init only supports new syntax. See cds init help for more info. cds init now supports adding template hana to Java projects. Fixed \u00b6 cds add mta fixes an issue in created mta.yaml for nodejs projects if used in xmake environment. cds add mta fixes an build order issue in created mta.yaml for java projects. Now service module is built before db module. cds init does not create package.json in db folder. Added \u00b6 cds init adds private: true and license: \"UNLICENSED\" to newly generated projects. cds init adds a default .hdiconfig file when using template hana . cds init supports Java package name via --java:package parameter. cds init generates dependency entry for @sap/hana-client when using template hana . cds init uses latest Java archetype version 1.3.0 for creating Java projects. cds init now creates a .cdsrc.json file. Version 1.4.0 - 2019-12-12 \u00b6 Added \u00b6 Abort installation with a hint if @sap/cds is installed globally. New project generation using cds init . See cds help init for details. cds init --add java now creates Java projects with Spring Boot support. cds watch now also watches .properties files Fixed \u00b6 Find locally installed modules like passport , so that cds watch and cds run behave symmetrically. Version 1.3.0 - 2019-11-19 \u00b6 Fixed \u00b6 cds import no longer fails due to Windows paths. Also see \u00b6 Changes of @sap/cds 3.20.0 Changes of @sap/cds-sidecar-client 1.1.2 Version 1.2.0 - 2019-10-31 \u00b6 Added \u00b6 Experimental support for cds init Version 1.1.3 - 2019-10-28 \u00b6 Fixed \u00b6 cds watch now uses the same lookup paths for models as cds run Also see \u00b6 Changes of @sap/cds 3.18.3 Version 1.1.0 - 2019-10-08 \u00b6 Added \u00b6 Added dependencies to express and sqlite3 to ease development Changed \u00b6 Improved cds watch Also see \u00b6 Changes of @sap/cds 3.18.0 Changes of @sap/edm-converters 1.0.19 Changes of @sap/generator-cds 2.8.3 Changes of @sap/cds-sidecar-client 1.1.1 Version 1.0.6 - 2019-09-25 \u00b6 Changed \u00b6 Updated version of @sap/cds to 3.17.8 Version 1.0.5 - 2019-09-24 \u00b6 Changed \u00b6 Updated version of @sap/cds to 3.17.7 Version 1.0.4 - 2019-09-23 \u00b6 Changed \u00b6 Updated version of @sap/cds to 3.17.6 Version 1.0.3 - 2019-09-21 \u00b6 Changed \u00b6 Updated version of @sap/cds to 3.17.5 Version 1.0.2 - 2019-09-19 \u00b6 Changed \u00b6 Updated version of @sap/cds to 3.17.4 Version 1.0.1 - 2019-09-18 \u00b6 Changed \u00b6 Updated version of @sap/cds to 3.17.2 Version 1.0.0 - 2019-09-10 \u00b6 Added \u00b6 Initial implementation cds watch cds import","title":"Change Log"},{"location":"apis/cds-dk/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/cds-dk/CHANGELOG/#version-185-2020-06-05","text":"","title":"Version 1.8.5 - 2020-06-05"},{"location":"apis/cds-dk/CHANGELOG/#changed","text":"cds init uses latest Maven Java archetype version 1.6.0 for creating Java projects.","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-184-2020-05-30","text":"","title":"Version 1.8.4 - 2020-05-30"},{"location":"apis/cds-dk/CHANGELOG/#changed_1","text":"cds init uses latest Maven Java archetype version 1.5.2 for creating Java projects.","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#fixes","text":"An issue in @sap/edm-converters with missing entity sets","title":"Fixes"},{"location":"apis/cds-dk/CHANGELOG/#version-182-2020-05-08","text":"","title":"Version 1.8.2 - 2020-05-08"},{"location":"apis/cds-dk/CHANGELOG/#fixes_1","text":"An issue in @sap/edm-converters with missing entity sets","title":"Fixes"},{"location":"apis/cds-dk/CHANGELOG/#version-180-2020-04-27","text":"","title":"Version 1.8.0 - 2020-04-27"},{"location":"apis/cds-dk/CHANGELOG/#added","text":"cds watch now also accepts package names as arguments, e.g. cds w @capire/bookshop . cds add mta now supports cds configuration requires.db.kind:\"sql\" which allows seamless production deployments using HANA db while keepping sqlite for local development scenario.","title":"Added"},{"location":"apis/cds-dk/CHANGELOG/#changed_2","text":"Parameter verbose in cds init and cds add is now deprecated. Use environment variable DEBUG=true to obtain detailed output. cds init uses latest Java archetype version 1.4.0 for creating Java projects.","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#fixed","text":"Fixing terminology in cds init and cds add console output. cds init is logging cds env output only in debug mode. Using cds build command in generated mta.yaml file. Fixing Hana dependency during cds init --add hana for project type java . Fixing bug in cds init when cds-dk is not installed globally. Fixing bug in cds init when calling log methods. Fixing cds.env object by attaching prototype chain.","title":"Fixed"},{"location":"apis/cds-dk/CHANGELOG/#version-170-2020-03-24","text":"","title":"Version 1.7.0 - 2020-03-24"},{"location":"apis/cds-dk/CHANGELOG/#added_1","text":"cds init --add java supports --java:mvn to add additional parameter. Improvements when logging console output during cds init . Link to Maven archetype documentation shown in cds help init .","title":"Added"},{"location":"apis/cds-dk/CHANGELOG/#changed_3","text":"cds add mta now activates the production profile when creating the mta.yaml , which is consistent with what the MTA build does. This way, configuration like \"[production]: {\"kind\": \"hana\"} gets activated automatically.","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-163-2020-03-05","text":"","title":"Version 1.6.3 - 2020-03-05"},{"location":"apis/cds-dk/CHANGELOG/#changed_4","text":"","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#fixed_1","text":"Proper npm-shrinkwrap.json cds init is a bit more relaxed when checking for existing project content","title":"Fixed"},{"location":"apis/cds-dk/CHANGELOG/#version-160-2020-02-25","text":"","title":"Version 1.6.0 - 2020-02-25"},{"location":"apis/cds-dk/CHANGELOG/#added_2","text":"cds init --add java now also works with --hana","title":"Added"},{"location":"apis/cds-dk/CHANGELOG/#changed_5","text":"cds add mta now creates resources for SAP HANA with an explicit service type hana . If deploying to trial landscapes, this needs to be changed manually to hanatrial .","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#fixed_2","text":"cds add mta now creates valid configuration for uaa and auditlog resources.","title":"Fixed"},{"location":"apis/cds-dk/CHANGELOG/#version-150-2020-02-10","text":"","title":"Version 1.5.0 - 2020-02-10"},{"location":"apis/cds-dk/CHANGELOG/#changed_6","text":"cds init only supports new syntax. See cds init help for more info. cds init now supports adding template hana to Java projects.","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#fixed_3","text":"cds add mta fixes an issue in created mta.yaml for nodejs projects if used in xmake environment. cds add mta fixes an build order issue in created mta.yaml for java projects. Now service module is built before db module. cds init does not create package.json in db folder.","title":"Fixed"},{"location":"apis/cds-dk/CHANGELOG/#added_3","text":"cds init adds private: true and license: \"UNLICENSED\" to newly generated projects. cds init adds a default .hdiconfig file when using template hana . cds init supports Java package name via --java:package parameter. cds init generates dependency entry for @sap/hana-client when using template hana . cds init uses latest Java archetype version 1.3.0 for creating Java projects. cds init now creates a .cdsrc.json file.","title":"Added"},{"location":"apis/cds-dk/CHANGELOG/#version-140-2019-12-12","text":"","title":"Version 1.4.0 - 2019-12-12"},{"location":"apis/cds-dk/CHANGELOG/#added_4","text":"Abort installation with a hint if @sap/cds is installed globally. New project generation using cds init . See cds help init for details. cds init --add java now creates Java projects with Spring Boot support. cds watch now also watches .properties files","title":"Added"},{"location":"apis/cds-dk/CHANGELOG/#fixed_4","text":"Find locally installed modules like passport , so that cds watch and cds run behave symmetrically.","title":"Fixed"},{"location":"apis/cds-dk/CHANGELOG/#version-130-2019-11-19","text":"","title":"Version 1.3.0 - 2019-11-19"},{"location":"apis/cds-dk/CHANGELOG/#fixed_5","text":"cds import no longer fails due to Windows paths.","title":"Fixed"},{"location":"apis/cds-dk/CHANGELOG/#also-see","text":"Changes of @sap/cds 3.20.0 Changes of @sap/cds-sidecar-client 1.1.2","title":"Also see"},{"location":"apis/cds-dk/CHANGELOG/#version-120-2019-10-31","text":"","title":"Version 1.2.0 - 2019-10-31"},{"location":"apis/cds-dk/CHANGELOG/#added_5","text":"Experimental support for cds init","title":"Added"},{"location":"apis/cds-dk/CHANGELOG/#version-113-2019-10-28","text":"","title":"Version 1.1.3 - 2019-10-28"},{"location":"apis/cds-dk/CHANGELOG/#fixed_6","text":"cds watch now uses the same lookup paths for models as cds run","title":"Fixed"},{"location":"apis/cds-dk/CHANGELOG/#also-see_1","text":"Changes of @sap/cds 3.18.3","title":"Also see"},{"location":"apis/cds-dk/CHANGELOG/#version-110-2019-10-08","text":"","title":"Version 1.1.0 - 2019-10-08"},{"location":"apis/cds-dk/CHANGELOG/#added_6","text":"Added dependencies to express and sqlite3 to ease development","title":"Added"},{"location":"apis/cds-dk/CHANGELOG/#changed_7","text":"Improved cds watch","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#also-see_2","text":"Changes of @sap/cds 3.18.0 Changes of @sap/edm-converters 1.0.19 Changes of @sap/generator-cds 2.8.3 Changes of @sap/cds-sidecar-client 1.1.1","title":"Also see"},{"location":"apis/cds-dk/CHANGELOG/#version-106-2019-09-25","text":"","title":"Version 1.0.6 - 2019-09-25"},{"location":"apis/cds-dk/CHANGELOG/#changed_8","text":"Updated version of @sap/cds to 3.17.8","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-105-2019-09-24","text":"","title":"Version 1.0.5 - 2019-09-24"},{"location":"apis/cds-dk/CHANGELOG/#changed_9","text":"Updated version of @sap/cds to 3.17.7","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-104-2019-09-23","text":"","title":"Version 1.0.4 - 2019-09-23"},{"location":"apis/cds-dk/CHANGELOG/#changed_10","text":"Updated version of @sap/cds to 3.17.6","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-103-2019-09-21","text":"","title":"Version 1.0.3 - 2019-09-21"},{"location":"apis/cds-dk/CHANGELOG/#changed_11","text":"Updated version of @sap/cds to 3.17.5","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-102-2019-09-19","text":"","title":"Version 1.0.2 - 2019-09-19"},{"location":"apis/cds-dk/CHANGELOG/#changed_12","text":"Updated version of @sap/cds to 3.17.4","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-101-2019-09-18","text":"","title":"Version 1.0.1 - 2019-09-18"},{"location":"apis/cds-dk/CHANGELOG/#changed_13","text":"Updated version of @sap/cds to 3.17.2","title":"Changed"},{"location":"apis/cds-dk/CHANGELOG/#version-100-2019-09-10","text":"","title":"Version 1.0.0 - 2019-09-10"},{"location":"apis/cds-dk/CHANGELOG/#added_7","text":"Initial implementation cds watch cds import","title":"Added"},{"location":"apis/cds-dk/readme/","text":"@sap/cds-dk \u00b6 The command line client and development toolkit for the SAP Cloud Application Programming Model (CAP) . See the usage docs for more. License \u00b6 This package is provided under the terms of the SAP Developer License Agreement .","title":"@sap/cds-dk"},{"location":"apis/cds-dk/readme/#sapcds-dk","text":"The command line client and development toolkit for the SAP Cloud Application Programming Model (CAP) . See the usage docs for more.","title":"@sap/cds-dk"},{"location":"apis/cds-dk/readme/#license","text":"This package is provided under the terms of the SAP Developer License Agreement .","title":"License"},{"location":"apis/cds-foss/","text":"cds-foss \u00b6 This package contains the foss modules for cds related modules. Disclaimer \u00b6 This package is only to be used as dependency by SAP, not by consumer apps","title":"cds-foss"},{"location":"apis/cds-foss/#cds-foss","text":"This package contains the foss modules for cds related modules.","title":"cds-foss"},{"location":"apis/cds-foss/#disclaimer","text":"This package is only to be used as dependency by SAP, not by consumer apps","title":"Disclaimer"},{"location":"apis/cds-foss/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.2.0 - tbd \u00b6 Added \u00b6 Changed \u00b6 Fixed \u00b6 Removed \u00b6 Version 1.1.0 - 2019-10-29 \u00b6 Added \u00b6 Changelog Version 1.0.0 - 2019-10-29 \u00b6 Added \u00b6 Initial version of cds-foss package","title":"Changelog"},{"location":"apis/cds-foss/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-foss/CHANGELOG/#version-120-tbd","text":"","title":"Version 1.2.0 - tbd"},{"location":"apis/cds-foss/CHANGELOG/#added","text":"","title":"Added"},{"location":"apis/cds-foss/CHANGELOG/#changed","text":"","title":"Changed"},{"location":"apis/cds-foss/CHANGELOG/#fixed","text":"","title":"Fixed"},{"location":"apis/cds-foss/CHANGELOG/#removed","text":"","title":"Removed"},{"location":"apis/cds-foss/CHANGELOG/#version-110-2019-10-29","text":"","title":"Version 1.1.0 - 2019-10-29"},{"location":"apis/cds-foss/CHANGELOG/#added_1","text":"Changelog","title":"Added"},{"location":"apis/cds-foss/CHANGELOG/#version-100-2019-10-29","text":"","title":"Version 1.0.0 - 2019-10-29"},{"location":"apis/cds-foss/CHANGELOG/#added_2","text":"Initial version of cds-foss package","title":"Added"},{"location":"apis/cds-hana/","text":"cds-hana \u00b6 Driver package for access to hana database, including setting up the client, configuring all the necessary options to initiate the connection and handling database specifics so that they can be processed on our end. Overview ## \u00b6 TBD Prerequisites ## \u00b6 @sap/cds-sql Installation ## \u00b6 npm install Usage/Configuration ## \u00b6 TBD Reference \u00b6 TBD","title":"cds-hana #"},{"location":"apis/cds-hana/#cds-hana","text":"Driver package for access to hana database, including setting up the client, configuring all the necessary options to initiate the connection and handling database specifics so that they can be processed on our end.","title":"cds-hana"},{"location":"apis/cds-hana/#overview","text":"TBD","title":"Overview ##"},{"location":"apis/cds-hana/#prerequisites","text":"@sap/cds-sql","title":"Prerequisites ##"},{"location":"apis/cds-hana/#installation","text":"npm install","title":"Installation ##"},{"location":"apis/cds-hana/#usageconfiguration","text":"TBD","title":"Usage/Configuration ##"},{"location":"apis/cds-hana/#reference","text":"TBD","title":"Reference"},{"location":"apis/cds-hana/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.25.1 - 2020-03-20 \u00b6 Removed \u00b6 Timeout for update and delete statements (if needed: increase libuv's threadpool size via environment variable UV_THREADPOOL_SIZE ) Version 1.25.0 - 2020-03-19 \u00b6 Added \u00b6 Single timestamp per transaction default timeout 20s for acquiring client from pool Version 1.24.0 - 2020-02-26 \u00b6 Added \u00b6 Streaming from draft Timeout for update and delete statements to handle locked records (@sap/hana-client only, default: 1s) Version 1.23.0 - 2020-02-19 \u00b6 Changed \u00b6 Use like instead of contains fuzzy search for $search queries Version 1.22.0 - 2020-02-05 \u00b6 Added \u00b6 Implement statement drop Changed \u00b6 SESSION_CONTEXT('APPLICATIONUSER') instead of SESSION_CONTEXT('XS_APPLICATIONUSER') @sap/hana-client is preferred over hdb Version 1.21.0 - 2019-12-10 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.21.0 Version 1.20.1 - 2019-11-29 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.20.1 Version 1.20.0 - 2019-11-19 \u00b6 Added \u00b6 Method to set session context Version 1.19.1 - 2019-10-30 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.19.1 Version 1.19.0 - 2019-10-29 \u00b6 Removed \u00b6 npm-shrinkwrap.json Version 1.18.1 - 2019-10-16 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.18.1 Version 1.18.0 - 2019-10-02 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.18.0 Version 1.17.1 - 2019-09-18 \u00b6 Fixed \u00b6 Issue in streaming while using hana-client Version 1.17.0 - 2019-09-09 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.17.0 Version 1.16.0 - 2019-08-21 \u00b6 Changed \u00b6 Signature of the Client's constructor Version 1.15.0 - 2019-07-23 \u00b6 Fixed \u00b6 @sap/hana-client streaming extension is used only if necessary Streaming supports null values Version 1.14.0 - 2019-07-09 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.13.0 Version 1.13.0 - 2019-06-24 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.13.0 Version 1.12.0 - 2019-05-24 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.12.0 Version 1.11.1 - 2019-05-16 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.11.1 Version 1.11.0 - 2019-05-15 \u00b6 Changed \u00b6 Improved performance by reducing calls to process.nextTick() Version 1.10.0 - 2019-05-03 \u00b6 Added \u00b6 Service related functions Version 1.9.0 - 2019-04-16 \u00b6 Added \u00b6 client.stream() for streaming large binaries Changed \u00b6 Make hdb default driver Version 1.8.0 - 2019-03-29 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.8.0 Version 1.7.1 - 2019-03-19 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.7.0 Version 1.7.0 - 2019-03-19 \u00b6 Removed \u00b6 Hana specific SQL generation for SELECT statements in case of 'contains' Version 1.6.0 - 2019-02-25 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.6.0 Version 1.5.1 - 2019-02-12 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.5.1 Version 1.5.0 - 2019-02-06 \u00b6 Changed \u00b6 Minimum node version 8.9.0 Improve expand performance Version 1.4.0 - 2019-01-22 \u00b6 Added \u00b6 validate_certificate and hostname_in_certificate to override certificate validation in local development mode .execute supports placeholders in CQN Version 1.3.0 - 2019-01-11 \u00b6 Changed \u00b6 Use latest version of @sap/cds-sql Version 1.2.0 - 2018-12-21 \u00b6 Added \u00b6 Set default values in case of CREATE, UPSERT and adding a child in deep documents Version 1.1.0 - 2018-12-12 \u00b6 Added \u00b6 Support Deep Document CQNs Version 1.0.3 - 2018-11-27 \u00b6 Changed \u00b6 Throw db error instead of wrapping it in Sql Error Use options.credentials instead of options directly Fixed \u00b6 Post processing of Binary, Boolean and Integer64 Version 0.10.0 - 2018-10-17 \u00b6 Refactoring and changes due to updated dependencies Version 0.9.0 - 2018-10-04 \u00b6 Fixed \u00b6 limit and order when expanding a to many association Version 0.8.0 - 2018-09-17 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 0.10.0 Version 0.7.1 - 2018-09-05 \u00b6 Changed \u00b6 Improved npm-shrinkwrap Version 0.7.0 - 2018-08-28 \u00b6 Added \u00b6 Fallback in case certificate is used instead of ca at connect options Changed \u00b6 API documentation updated Version 0.6.1 - 2018-08-09 \u00b6 Changed \u00b6 Require submodules on demand Version 0.6.0 - 2018-08-07 \u00b6 Added \u00b6 Full SQL including eventual parameters to stack trace error message Support for abstract placeholders #now and #user Support for unary and binary expressions in contains Changed \u00b6 Increased default option of max. db connection clients to 100 Fixed \u00b6 SQL error hides internal error messages and provides details in log Version 0.5.1 - 2018-07-02 \u00b6 Fixed \u00b6 Escaping of special characters in case of 'contains' Version 0.5.0 - 2018-06-25 \u00b6 Added \u00b6 Hana specific SQL generation for DROP statements Hana specific SQL generation for SELECT statements in case of 'contains' Added SQL Error to hide the internal information from other errors support execution of blocks of statements support plain mode of SQL name mapping Fixed \u00b6 CDS injection Version 0.4.0 - 2018-05-02 \u00b6 Changed \u00b6 connect options aligned to spec support for latest CQN spec changes Version 0.3.0 - 2018-04-16 \u00b6 Added \u00b6 support CREATE statements Version 0.2.0 - 2018-03-16 \u00b6 Added \u00b6 usage of npm-shrinkwrap Changed \u00b6 improved performance for expand in case of one-to-many relations","title":"Changelog"},{"location":"apis/cds-hana/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-hana/CHANGELOG/#version-1251-2020-03-20","text":"","title":"Version 1.25.1 - 2020-03-20"},{"location":"apis/cds-hana/CHANGELOG/#removed","text":"Timeout for update and delete statements (if needed: increase libuv's threadpool size via environment variable UV_THREADPOOL_SIZE )","title":"Removed"},{"location":"apis/cds-hana/CHANGELOG/#version-1250-2020-03-19","text":"","title":"Version 1.25.0 - 2020-03-19"},{"location":"apis/cds-hana/CHANGELOG/#added","text":"Single timestamp per transaction default timeout 20s for acquiring client from pool","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-1240-2020-02-26","text":"","title":"Version 1.24.0 - 2020-02-26"},{"location":"apis/cds-hana/CHANGELOG/#added_1","text":"Streaming from draft Timeout for update and delete statements to handle locked records (@sap/hana-client only, default: 1s)","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-1230-2020-02-19","text":"","title":"Version 1.23.0 - 2020-02-19"},{"location":"apis/cds-hana/CHANGELOG/#changed","text":"Use like instead of contains fuzzy search for $search queries","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1220-2020-02-05","text":"","title":"Version 1.22.0 - 2020-02-05"},{"location":"apis/cds-hana/CHANGELOG/#added_2","text":"Implement statement drop","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#changed_1","text":"SESSION_CONTEXT('APPLICATIONUSER') instead of SESSION_CONTEXT('XS_APPLICATIONUSER') @sap/hana-client is preferred over hdb","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1210-2019-12-10","text":"","title":"Version 1.21.0 - 2019-12-10"},{"location":"apis/cds-hana/CHANGELOG/#changed_2","text":"Updated version of @sap/cds-sql to 1.21.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1201-2019-11-29","text":"","title":"Version 1.20.1 - 2019-11-29"},{"location":"apis/cds-hana/CHANGELOG/#changed_3","text":"Updated version of @sap/cds-sql to 1.20.1","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1200-2019-11-19","text":"","title":"Version 1.20.0 - 2019-11-19"},{"location":"apis/cds-hana/CHANGELOG/#added_3","text":"Method to set session context","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-1191-2019-10-30","text":"","title":"Version 1.19.1 - 2019-10-30"},{"location":"apis/cds-hana/CHANGELOG/#changed_4","text":"Updated version of @sap/cds-sql to 1.19.1","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1190-2019-10-29","text":"","title":"Version 1.19.0 - 2019-10-29"},{"location":"apis/cds-hana/CHANGELOG/#removed_1","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-hana/CHANGELOG/#version-1181-2019-10-16","text":"","title":"Version 1.18.1 - 2019-10-16"},{"location":"apis/cds-hana/CHANGELOG/#changed_5","text":"Updated version of @sap/cds-sql to 1.18.1","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1180-2019-10-02","text":"","title":"Version 1.18.0 - 2019-10-02"},{"location":"apis/cds-hana/CHANGELOG/#changed_6","text":"Updated version of @sap/cds-sql to 1.18.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1171-2019-09-18","text":"","title":"Version 1.17.1 - 2019-09-18"},{"location":"apis/cds-hana/CHANGELOG/#fixed","text":"Issue in streaming while using hana-client","title":"Fixed"},{"location":"apis/cds-hana/CHANGELOG/#version-1170-2019-09-09","text":"","title":"Version 1.17.0 - 2019-09-09"},{"location":"apis/cds-hana/CHANGELOG/#changed_7","text":"Updated version of @sap/cds-sql to 1.17.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1160-2019-08-21","text":"","title":"Version 1.16.0 - 2019-08-21"},{"location":"apis/cds-hana/CHANGELOG/#changed_8","text":"Signature of the Client's constructor","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1150-2019-07-23","text":"","title":"Version 1.15.0 - 2019-07-23"},{"location":"apis/cds-hana/CHANGELOG/#fixed_1","text":"@sap/hana-client streaming extension is used only if necessary Streaming supports null values","title":"Fixed"},{"location":"apis/cds-hana/CHANGELOG/#version-1140-2019-07-09","text":"","title":"Version 1.14.0 - 2019-07-09"},{"location":"apis/cds-hana/CHANGELOG/#changed_9","text":"Updated version of @sap/cds-sql to 1.13.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1130-2019-06-24","text":"","title":"Version 1.13.0 - 2019-06-24"},{"location":"apis/cds-hana/CHANGELOG/#changed_10","text":"Updated version of @sap/cds-sql to 1.13.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1120-2019-05-24","text":"","title":"Version 1.12.0 - 2019-05-24"},{"location":"apis/cds-hana/CHANGELOG/#changed_11","text":"Updated version of @sap/cds-sql to 1.12.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1111-2019-05-16","text":"","title":"Version 1.11.1 - 2019-05-16"},{"location":"apis/cds-hana/CHANGELOG/#changed_12","text":"Updated version of @sap/cds-sql to 1.11.1","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1110-2019-05-15","text":"","title":"Version 1.11.0 - 2019-05-15"},{"location":"apis/cds-hana/CHANGELOG/#changed_13","text":"Improved performance by reducing calls to process.nextTick()","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-1100-2019-05-03","text":"","title":"Version 1.10.0 - 2019-05-03"},{"location":"apis/cds-hana/CHANGELOG/#added_4","text":"Service related functions","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-190-2019-04-16","text":"","title":"Version 1.9.0 - 2019-04-16"},{"location":"apis/cds-hana/CHANGELOG/#added_5","text":"client.stream() for streaming large binaries","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#changed_14","text":"Make hdb default driver","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-180-2019-03-29","text":"","title":"Version 1.8.0 - 2019-03-29"},{"location":"apis/cds-hana/CHANGELOG/#changed_15","text":"Updated version of @sap/cds-sql to 1.8.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-171-2019-03-19","text":"","title":"Version 1.7.1 - 2019-03-19"},{"location":"apis/cds-hana/CHANGELOG/#changed_16","text":"Updated version of @sap/cds-sql to 1.7.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-170-2019-03-19","text":"","title":"Version 1.7.0 - 2019-03-19"},{"location":"apis/cds-hana/CHANGELOG/#removed_2","text":"Hana specific SQL generation for SELECT statements in case of 'contains'","title":"Removed"},{"location":"apis/cds-hana/CHANGELOG/#version-160-2019-02-25","text":"","title":"Version 1.6.0 - 2019-02-25"},{"location":"apis/cds-hana/CHANGELOG/#changed_17","text":"Updated version of @sap/cds-sql to 1.6.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-151-2019-02-12","text":"","title":"Version 1.5.1 - 2019-02-12"},{"location":"apis/cds-hana/CHANGELOG/#changed_18","text":"Updated version of @sap/cds-sql to 1.5.1","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-150-2019-02-06","text":"","title":"Version 1.5.0 - 2019-02-06"},{"location":"apis/cds-hana/CHANGELOG/#changed_19","text":"Minimum node version 8.9.0 Improve expand performance","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-140-2019-01-22","text":"","title":"Version 1.4.0 - 2019-01-22"},{"location":"apis/cds-hana/CHANGELOG/#added_6","text":"validate_certificate and hostname_in_certificate to override certificate validation in local development mode .execute supports placeholders in CQN","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-130-2019-01-11","text":"","title":"Version 1.3.0 - 2019-01-11"},{"location":"apis/cds-hana/CHANGELOG/#changed_20","text":"Use latest version of @sap/cds-sql","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-120-2018-12-21","text":"","title":"Version 1.2.0 - 2018-12-21"},{"location":"apis/cds-hana/CHANGELOG/#added_7","text":"Set default values in case of CREATE, UPSERT and adding a child in deep documents","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-110-2018-12-12","text":"","title":"Version 1.1.0 - 2018-12-12"},{"location":"apis/cds-hana/CHANGELOG/#added_8","text":"Support Deep Document CQNs","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-103-2018-11-27","text":"","title":"Version 1.0.3 - 2018-11-27"},{"location":"apis/cds-hana/CHANGELOG/#changed_21","text":"Throw db error instead of wrapping it in Sql Error Use options.credentials instead of options directly","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#fixed_2","text":"Post processing of Binary, Boolean and Integer64","title":"Fixed"},{"location":"apis/cds-hana/CHANGELOG/#version-0100-2018-10-17","text":"Refactoring and changes due to updated dependencies","title":"Version 0.10.0 - 2018-10-17"},{"location":"apis/cds-hana/CHANGELOG/#version-090-2018-10-04","text":"","title":"Version 0.9.0 - 2018-10-04"},{"location":"apis/cds-hana/CHANGELOG/#fixed_3","text":"limit and order when expanding a to many association","title":"Fixed"},{"location":"apis/cds-hana/CHANGELOG/#version-080-2018-09-17","text":"","title":"Version 0.8.0 - 2018-09-17"},{"location":"apis/cds-hana/CHANGELOG/#changed_22","text":"Updated version of @sap/cds-sql to 0.10.0","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-071-2018-09-05","text":"","title":"Version 0.7.1 - 2018-09-05"},{"location":"apis/cds-hana/CHANGELOG/#changed_23","text":"Improved npm-shrinkwrap","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-070-2018-08-28","text":"","title":"Version 0.7.0 - 2018-08-28"},{"location":"apis/cds-hana/CHANGELOG/#added_9","text":"Fallback in case certificate is used instead of ca at connect options","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#changed_24","text":"API documentation updated","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-061-2018-08-09","text":"","title":"Version 0.6.1 - 2018-08-09"},{"location":"apis/cds-hana/CHANGELOG/#changed_25","text":"Require submodules on demand","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-060-2018-08-07","text":"","title":"Version 0.6.0 - 2018-08-07"},{"location":"apis/cds-hana/CHANGELOG/#added_10","text":"Full SQL including eventual parameters to stack trace error message Support for abstract placeholders #now and #user Support for unary and binary expressions in contains","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#changed_26","text":"Increased default option of max. db connection clients to 100","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#fixed_4","text":"SQL error hides internal error messages and provides details in log","title":"Fixed"},{"location":"apis/cds-hana/CHANGELOG/#version-051-2018-07-02","text":"","title":"Version 0.5.1 - 2018-07-02"},{"location":"apis/cds-hana/CHANGELOG/#fixed_5","text":"Escaping of special characters in case of 'contains'","title":"Fixed"},{"location":"apis/cds-hana/CHANGELOG/#version-050-2018-06-25","text":"","title":"Version 0.5.0 - 2018-06-25"},{"location":"apis/cds-hana/CHANGELOG/#added_11","text":"Hana specific SQL generation for DROP statements Hana specific SQL generation for SELECT statements in case of 'contains' Added SQL Error to hide the internal information from other errors support execution of blocks of statements support plain mode of SQL name mapping","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#fixed_6","text":"CDS injection","title":"Fixed"},{"location":"apis/cds-hana/CHANGELOG/#version-040-2018-05-02","text":"","title":"Version 0.4.0 - 2018-05-02"},{"location":"apis/cds-hana/CHANGELOG/#changed_27","text":"connect options aligned to spec support for latest CQN spec changes","title":"Changed"},{"location":"apis/cds-hana/CHANGELOG/#version-030-2018-04-16","text":"","title":"Version 0.3.0 - 2018-04-16"},{"location":"apis/cds-hana/CHANGELOG/#added_12","text":"support CREATE statements","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#version-020-2018-03-16","text":"","title":"Version 0.2.0 - 2018-03-16"},{"location":"apis/cds-hana/CHANGELOG/#added_13","text":"usage of npm-shrinkwrap","title":"Added"},{"location":"apis/cds-hana/CHANGELOG/#changed_28","text":"improved performance for expand in case of one-to-many relations","title":"Changed"},{"location":"apis/cds-messaging/","text":"cds-messaging \u00b6","title":"cds-messaging"},{"location":"apis/cds-messaging/#cds-messaging","text":"","title":"cds-messaging"},{"location":"apis/cds-messaging/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.8.2 - 2020-03-19 \u00b6 Added \u00b6 It is now possible to set the queue configuration with the queueConfig property in the credentials section https://help.sap.com/doc/75c9efd00fc14183abc4c613490c53f4/Cloud/en-US/rest-management-messaging.html#_queuep Removed \u00b6 Bound events are not supported anymore Version 1.7.0 - 2020-02-19 \u00b6 Changed \u00b6 Updated version number for public release Version 1.6.0 - 2020-02-05 \u00b6 Added \u00b6 Support for prefix credentials options to prefix topics Changed \u00b6 You can no longer set the namespace outside of the credentials block Fixed \u00b6 Fixed bug where non-trimmed data causes problems in file-based messaging Version 1.5.0 - 2019-12-10 \u00b6 Fixed \u00b6 Receiving chunks can be an array with more than one item Version 1.4.0 - 2019-11-19 \u00b6 Removed \u00b6 The namespace property of a services does not need to be set anymore Version 1.3.0 - 2019-10-29 \u00b6 Removed \u00b6 npm-shrinkwrap.json Version 1.2.1 - 2019-10-16 \u00b6 Added \u00b6 headers parameter for .emit Version 1.2.0 - 2019-10-02 \u00b6 Changed \u00b6 Minor improvements Version 1.1.1 - 2019-09-18 \u00b6 Added \u00b6 File-based-messaging: If you set the file to true or \"default\", the default file name is chosen Changed \u00b6 File-based-messaging: Default file location ist set to /cds-message-box File-based-messaging: File configuration is moved to credentials block For external (cloud-event-based) services, the data property is now in message.data (before it was message.data.data) Version 1.1.0 - 2019-09-09 \u00b6 Added \u00b6 Queue name can be specified by setting the queue property You can now use srv.on('my/custom/topic', ()={...}) to register on topics and srv.emit('my/custom/topic, {...}) to emit messages with topics (If your topic contains only one segment, you must write topic:myCustomTopic ) Changed \u00b6 The hashes in generated topic or queue names now only consist of 4 characters Default file name of 'file-based-messaging' is /message_box Fixed \u00b6 Special characters in topic and queue names are now omitted Non-JSON payloads are now ignored OAuthToken request occacionally fails Removed \u00b6 srv.on.topic and srv.emit.to.topic Version 1.0.1 - 2019-08-26 \u00b6 Changed \u00b6 Package '@sap/xb-msg-amqp-v100' is only dev dependency Version 1.0.0 - 2019-08-21 \u00b6 Added \u00b6 Initial implementation","title":"Changelog"},{"location":"apis/cds-messaging/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-messaging/CHANGELOG/#version-182-2020-03-19","text":"","title":"Version 1.8.2 - 2020-03-19"},{"location":"apis/cds-messaging/CHANGELOG/#added","text":"It is now possible to set the queue configuration with the queueConfig property in the credentials section https://help.sap.com/doc/75c9efd00fc14183abc4c613490c53f4/Cloud/en-US/rest-management-messaging.html#_queuep","title":"Added"},{"location":"apis/cds-messaging/CHANGELOG/#removed","text":"Bound events are not supported anymore","title":"Removed"},{"location":"apis/cds-messaging/CHANGELOG/#version-170-2020-02-19","text":"","title":"Version 1.7.0 - 2020-02-19"},{"location":"apis/cds-messaging/CHANGELOG/#changed","text":"Updated version number for public release","title":"Changed"},{"location":"apis/cds-messaging/CHANGELOG/#version-160-2020-02-05","text":"","title":"Version 1.6.0 - 2020-02-05"},{"location":"apis/cds-messaging/CHANGELOG/#added_1","text":"Support for prefix credentials options to prefix topics","title":"Added"},{"location":"apis/cds-messaging/CHANGELOG/#changed_1","text":"You can no longer set the namespace outside of the credentials block","title":"Changed"},{"location":"apis/cds-messaging/CHANGELOG/#fixed","text":"Fixed bug where non-trimmed data causes problems in file-based messaging","title":"Fixed"},{"location":"apis/cds-messaging/CHANGELOG/#version-150-2019-12-10","text":"","title":"Version 1.5.0 - 2019-12-10"},{"location":"apis/cds-messaging/CHANGELOG/#fixed_1","text":"Receiving chunks can be an array with more than one item","title":"Fixed"},{"location":"apis/cds-messaging/CHANGELOG/#version-140-2019-11-19","text":"","title":"Version 1.4.0 - 2019-11-19"},{"location":"apis/cds-messaging/CHANGELOG/#removed_1","text":"The namespace property of a services does not need to be set anymore","title":"Removed"},{"location":"apis/cds-messaging/CHANGELOG/#version-130-2019-10-29","text":"","title":"Version 1.3.0 - 2019-10-29"},{"location":"apis/cds-messaging/CHANGELOG/#removed_2","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-messaging/CHANGELOG/#version-121-2019-10-16","text":"","title":"Version 1.2.1 - 2019-10-16"},{"location":"apis/cds-messaging/CHANGELOG/#added_2","text":"headers parameter for .emit","title":"Added"},{"location":"apis/cds-messaging/CHANGELOG/#version-120-2019-10-02","text":"","title":"Version 1.2.0 - 2019-10-02"},{"location":"apis/cds-messaging/CHANGELOG/#changed_2","text":"Minor improvements","title":"Changed"},{"location":"apis/cds-messaging/CHANGELOG/#version-111-2019-09-18","text":"","title":"Version 1.1.1 - 2019-09-18"},{"location":"apis/cds-messaging/CHANGELOG/#added_3","text":"File-based-messaging: If you set the file to true or \"default\", the default file name is chosen","title":"Added"},{"location":"apis/cds-messaging/CHANGELOG/#changed_3","text":"File-based-messaging: Default file location ist set to /cds-message-box File-based-messaging: File configuration is moved to credentials block For external (cloud-event-based) services, the data property is now in message.data (before it was message.data.data)","title":"Changed"},{"location":"apis/cds-messaging/CHANGELOG/#version-110-2019-09-09","text":"","title":"Version 1.1.0 - 2019-09-09"},{"location":"apis/cds-messaging/CHANGELOG/#added_4","text":"Queue name can be specified by setting the queue property You can now use srv.on('my/custom/topic', ()={...}) to register on topics and srv.emit('my/custom/topic, {...}) to emit messages with topics (If your topic contains only one segment, you must write topic:myCustomTopic )","title":"Added"},{"location":"apis/cds-messaging/CHANGELOG/#changed_4","text":"The hashes in generated topic or queue names now only consist of 4 characters Default file name of 'file-based-messaging' is /message_box","title":"Changed"},{"location":"apis/cds-messaging/CHANGELOG/#fixed_2","text":"Special characters in topic and queue names are now omitted Non-JSON payloads are now ignored OAuthToken request occacionally fails","title":"Fixed"},{"location":"apis/cds-messaging/CHANGELOG/#removed_3","text":"srv.on.topic and srv.emit.to.topic","title":"Removed"},{"location":"apis/cds-messaging/CHANGELOG/#version-101-2019-08-26","text":"","title":"Version 1.0.1 - 2019-08-26"},{"location":"apis/cds-messaging/CHANGELOG/#changed_5","text":"Package '@sap/xb-msg-amqp-v100' is only dev dependency","title":"Changed"},{"location":"apis/cds-messaging/CHANGELOG/#version-100-2019-08-21","text":"","title":"Version 1.0.0 - 2019-08-21"},{"location":"apis/cds-messaging/CHANGELOG/#added_5","text":"Initial implementation","title":"Added"},{"location":"apis/cds-mtx/","text":"cds-mtx \u00b6 https://cap.cloud.sap/ \u00b6 https://cap.cloud.sap/docs/guides/extensibility \u00b6","title":"cds-mtx"},{"location":"apis/cds-mtx/#cds-mtx","text":"","title":"cds-mtx"},{"location":"apis/cds-mtx/#httpscapcloudsap","text":"","title":"https://cap.cloud.sap/"},{"location":"apis/cds-mtx/#httpscapcloudsapdocsguidesextensibility","text":"","title":"https://cap.cloud.sap/docs/guides/extensibility"},{"location":"apis/cds-mtx/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . [1.0.13] \u00b6 Added \u00b6 Logs are now collected by default when running asynchronous APIs can be disabled with environment variable MTX_COLLECT_LOGS=true logs can be limited by MTX_LOG_COLLECTION_LIMIT=<limit> extensibility API that accepts csn notation cds.mtx.activate(tenantId, csn) Fixed \u00b6 handling of errornous undeploy.json files: error message now points to the root problem handling of build errors: API now returns build and compile errors properly [1.0.12] \u00b6 Added \u00b6 reenabled the support of different domains (BETA) Support for asynchronous extension activation to handle long-running jobs [1.0.11] \u00b6 Added \u00b6 Support of asynchronous onboarding as specified by the saas-registry [1.0.10] \u00b6 Fixed \u00b6 Compatibility with snapi compiler mode (env variable CDS_FEATURES_SNAPI=y) WARNING: in this mode, it is currently not checked if annotations of the basemodel are overwritten in the extension Tenant upgrade with undeploy=true is now working properly [1.0.9] \u00b6 Fixed \u00b6 Compatibility with older versions of @sap/cds [1.0.8] \u00b6 Added \u00b6 possibility to store build / deployment logs in job log for asynchronous tenant update must currently be activated by environment variables ( MTX_COLLECT_LOGS=true and MTX_LOG_COLLECTION_LIMIT=<limit> ) whitelist for entities and services that are allowed to be extended \"mtx\": { \"element-prefix\": \"Z_\", \"namespace-blacklist\": [\"com.sap.\", \"sap.\"], \"entity-whitelist\": [\"my.bookshop.Books\"], \"service-whitelist\": [\"CatalogService\"] } Fixed \u00b6 Enable compatibility with SAP HANA cloud edition (no hdbcds support) Deployment error with very old tenants (conflict with custom_tenant_objects.hdbtable) [1.0.7] \u00b6 Added \u00b6 allows to enable auto-undeploy in base model update request Fixed \u00b6 datatype error in synchronous base model update api [1.0.6] \u00b6 [1.0.5] \u00b6 Added \u00b6 accept database_id in onboarding request [1.0.4] \u00b6 Added \u00b6 enhanced namespace check for extensions metadata API now supports ETags Changed \u00b6 Fixed \u00b6 Datatype of custom content tables now LargeString Bad request when sending non-json content Removed \u00b6 [1.0.3] \u00b6 Bug fixes [1.0.2] \u00b6 Bug fixes [1.0.1] \u00b6 Ignore namespace rules for customer extension entities Enable hdbtabledata generation [1.0.0] - 26.07.2019 \u00b6 Initial release version.","title":"Change Log"},{"location":"apis/cds-mtx/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/cds-mtx/CHANGELOG/#1013","text":"","title":"[1.0.13]"},{"location":"apis/cds-mtx/CHANGELOG/#added","text":"Logs are now collected by default when running asynchronous APIs can be disabled with environment variable MTX_COLLECT_LOGS=true logs can be limited by MTX_LOG_COLLECTION_LIMIT=<limit> extensibility API that accepts csn notation cds.mtx.activate(tenantId, csn)","title":"Added"},{"location":"apis/cds-mtx/CHANGELOG/#fixed","text":"handling of errornous undeploy.json files: error message now points to the root problem handling of build errors: API now returns build and compile errors properly","title":"Fixed"},{"location":"apis/cds-mtx/CHANGELOG/#1012","text":"","title":"[1.0.12]"},{"location":"apis/cds-mtx/CHANGELOG/#added_1","text":"reenabled the support of different domains (BETA) Support for asynchronous extension activation to handle long-running jobs","title":"Added"},{"location":"apis/cds-mtx/CHANGELOG/#1011","text":"","title":"[1.0.11]"},{"location":"apis/cds-mtx/CHANGELOG/#added_2","text":"Support of asynchronous onboarding as specified by the saas-registry","title":"Added"},{"location":"apis/cds-mtx/CHANGELOG/#1010","text":"","title":"[1.0.10]"},{"location":"apis/cds-mtx/CHANGELOG/#fixed_1","text":"Compatibility with snapi compiler mode (env variable CDS_FEATURES_SNAPI=y) WARNING: in this mode, it is currently not checked if annotations of the basemodel are overwritten in the extension Tenant upgrade with undeploy=true is now working properly","title":"Fixed"},{"location":"apis/cds-mtx/CHANGELOG/#109","text":"","title":"[1.0.9]"},{"location":"apis/cds-mtx/CHANGELOG/#fixed_2","text":"Compatibility with older versions of @sap/cds","title":"Fixed"},{"location":"apis/cds-mtx/CHANGELOG/#108","text":"","title":"[1.0.8]"},{"location":"apis/cds-mtx/CHANGELOG/#added_3","text":"possibility to store build / deployment logs in job log for asynchronous tenant update must currently be activated by environment variables ( MTX_COLLECT_LOGS=true and MTX_LOG_COLLECTION_LIMIT=<limit> ) whitelist for entities and services that are allowed to be extended \"mtx\": { \"element-prefix\": \"Z_\", \"namespace-blacklist\": [\"com.sap.\", \"sap.\"], \"entity-whitelist\": [\"my.bookshop.Books\"], \"service-whitelist\": [\"CatalogService\"] }","title":"Added"},{"location":"apis/cds-mtx/CHANGELOG/#fixed_3","text":"Enable compatibility with SAP HANA cloud edition (no hdbcds support) Deployment error with very old tenants (conflict with custom_tenant_objects.hdbtable)","title":"Fixed"},{"location":"apis/cds-mtx/CHANGELOG/#107","text":"","title":"[1.0.7]"},{"location":"apis/cds-mtx/CHANGELOG/#added_4","text":"allows to enable auto-undeploy in base model update request","title":"Added"},{"location":"apis/cds-mtx/CHANGELOG/#fixed_4","text":"datatype error in synchronous base model update api","title":"Fixed"},{"location":"apis/cds-mtx/CHANGELOG/#106","text":"","title":"[1.0.6]"},{"location":"apis/cds-mtx/CHANGELOG/#105","text":"","title":"[1.0.5]"},{"location":"apis/cds-mtx/CHANGELOG/#added_5","text":"accept database_id in onboarding request","title":"Added"},{"location":"apis/cds-mtx/CHANGELOG/#104","text":"","title":"[1.0.4]"},{"location":"apis/cds-mtx/CHANGELOG/#added_6","text":"enhanced namespace check for extensions metadata API now supports ETags","title":"Added"},{"location":"apis/cds-mtx/CHANGELOG/#changed","text":"","title":"Changed"},{"location":"apis/cds-mtx/CHANGELOG/#fixed_5","text":"Datatype of custom content tables now LargeString Bad request when sending non-json content","title":"Fixed"},{"location":"apis/cds-mtx/CHANGELOG/#removed","text":"","title":"Removed"},{"location":"apis/cds-mtx/CHANGELOG/#103","text":"Bug fixes","title":"[1.0.3]"},{"location":"apis/cds-mtx/CHANGELOG/#102","text":"Bug fixes","title":"[1.0.2]"},{"location":"apis/cds-mtx/CHANGELOG/#101","text":"Ignore namespace rules for customer extension entities Enable hdbtabledata generation","title":"[1.0.1]"},{"location":"apis/cds-mtx/CHANGELOG/#100-26072019","text":"Initial release version.","title":"[1.0.0] - 26.07.2019"},{"location":"apis/cds-odata-v2-adapter-proxy/","text":"cds-odata-v2-adapter-proxy \u00b6 OData v2 Adapter Proxy for CDS OData v4 Services Build Status \u00b6 Getting Started \u00b6 Install: npm install @sap/cds-odata-v2-adapter-proxy Unit Tests: npm test Test Server: npm start Service: http://localhost:4004/v2/main Metadata: http://localhost:4004/v2/main/$metadata Data: http://localhost:4004/v2/main/Header?$expand=Items Usage \u00b6 CDS combined backend (Node.js) - integrated \u00b6 In your existing @sap/cds project: Run npm install @sap/cds-odata-v2-adapter-proxy -s Create new file server.js in the service folder srv of your project: ./srv/server.js \"use strict\" ; const cds = require ( \"@sap/cds\" ); const proxy = require ( \"@sap/cds-odata-v2-adapter-proxy\" ); cds . on ( \"bootstrap\" , app => app . use ( proxy ())); module . exports = cds . server ; Run cds run from the project root to start the server: OData v2 service will be available at http://localhost:4004/v2/ OData v4 service will be available at http://localhost:4004/ Note that @sap/cds and express are peer dependency and needs to be available as module as well. CDS combined backend (Node.js) - custom \u00b6 In your existing @sap/cds project: Run npm install @sap/cds-odata-v2-adapter-proxy -s Create new file index.js in the service folder srv of your project: ./srv/index.js \"use strict\"; const express = require(\"express\"); const cds = require(\"@sap/cds\"); const proxy = require(\"@sap/cds-odata-v2-adapter-proxy\"); const host = \"0.0.0.0\"; const port = process.env.PORT || 4004; (async () => { const app = express(); // serve odata v4 await cds .connect(\"db\") // ensure database is connected! .serve(\"all\") .in(app); // serve odata v2 process.env.XS_APP_LOG_LEVEL = \"warning\"; app.use(proxy({ path: \"v2\", port: port })); // start server const server = app.listen(port, host, () => console.info(`app is listing at ${ host } : ${ port } `)); server.on(\"error\", error => console.error(error.stack)); })(); Run node srv/index from the project root to start the server: OData v2 service will be available at http://localhost:4004/v2/ OData v4 service will be available at http://localhost:4004/ Note that @sap/cds and express are peer dependency and needs to be available as module as well. CDS standalone backend (e.g. Java) \u00b6 In a new Node.js express project: Run npm install @sap/cds -s Run npm install @sap/cds-odata-v2-adapter-proxy -s Place CDS models in db and srv model folders Create new file index.js in the service folder srv of the project: ./srv/index.js \"use strict\"; const express = require(\"express\"); const http = require(\"http\"); const proxy = require(\"@sap/cds-odata-v2-adapter-proxy\"); const host = \"0.0.0.0\"; const port = process.env.PORT || 4004; (async () => { const app = express(); // serve odata v2 process.env.XS_APP_LOG_LEVEL = \"warning\"; app.use(proxy({ path: \"v2\", target: \"http://localhost:8080\", services: { \" <odata -v4-service-path > \": \" <qualified.ServiceName> \" } })); // start server const server = app.listen(port, host, () => console.info(`app is listing at ${ host } : ${ port } `)); server.on(\"error\", error => console.error(error.stack)); })(); Make sure, that your CDS models are also available in the project. Those reside either in db and srv folders, or a compiled (untransformed) srv.json is provided. This can be generated by using the following command: cds srv -s all -o . If not detected automatically, the model path can be set with option model (especially if srv.json option is used). Make sure, that all i18n property files reside next to the srv.json in a i18n or _i18n folder, to be detected by localization. Run node srv/index from the project root to start the server: OData v2 service will be available at http://localhost:4004/v2/ OData v4 service shall be available at http://localhost:8080/ A deployed version of OData v2 proxy shall have option target set to the deployed OData v4 backend URL. This can be retrieved from the CF environment using node-xsenv module, e.g. from the destinations environment variable. Note that @sap/cds and express are peer dependency and needs to be available as module as well. Cloud Foundry Deployment \u00b6 When deploying the CDS OData v2 Adapter Proxy to CF, make sure that it has access to the whole CDS model. Especially, it is the case, that normally the Node.js server is only based on folder srv and folder db is then missing on CF. To come around this situation, trigger a cds build , that generates a csn.json at location gen/srv/srv/csn.json . If your CF deployment of the Node.js backend (incl. CDS OData v2 Adapter Proxy) is then based on folder gen/srv , the CDS models can be found during runtime on Cloud Foundry. Documentation \u00b6 Instantiates an CDS OData v2 Adapter Proxy Express Router for a CDS based OData v4 Server options: CDS OData v2 Adapter Proxy options [options.base]: Base path, under which the service is reachable. Default is ''. [options.path]: Path, under which the proxy is reachable. Default is 'v2'. [options.model]: CDS service model (path(s) or CSN). Default is 'all'. [options.port]: Target port, which points to OData v4 backend port. Default is '4004'. [options.target]: Target, which points to OData v4 backend host/port. Default is 'http://localhost:4004'. [options.services]: Service mapping, from url path name to service name. If omitted local CDS defaults apply. [options.standalone]: Indication, that OData v2 Adapter proxy is a standalone process. Default is 'false'. [options.mtxEndpoint]: Endpoint to retrieve MTX metadata for standalone proxy. Default is '/mtx/v1' [options.ieee754Compatible]: Edm.Decimal and Edm.Int64 are serialized IEEE754 compatible. Default is 'true'. [options.pathRewrite]: Custom path rewrite rules. Default uses 'path' option as rule: { \"^/v2\": \"\" } [options.disableNetworkLog]: Disable networking logging. Default is 'true'. Logging is controlled with XSA environment variable XS_APP_LOG_LEVEL . Details can be found at xs2/node-logging . Features \u00b6 GET, POST, PUT/PATCH, DELETE Batch support Actions, Functions Analytical Annotations Deep Expands/Selects JSON format Deep Structures Data Type Mapping (incl. Date Time) IEEE754Compatible Messages/Error Handling Location Header $inlinecount / $count / \\$value Entity with Parameters Stream Support (Octet and Url), Content Disposition Multitenancy, Extensibility (proxy in same process only) Content-ID Draft Support Search Support Localization Tracing Logging Correlation ETag Support (Concurrency Control) OData v2/v4 Delta \u00b6 http://docs.oasis-open.org/odata/new-in-odata/v4.0/cn01/new-in-odata-v4.0-cn01.html Open: $links -> $ref KEY(...) -> \\$root years, months, days, minutes, seconds Function Parameters as Query Options","title":"cds-odata-v2-adapter-proxy"},{"location":"apis/cds-odata-v2-adapter-proxy/#cds-odata-v2-adapter-proxy","text":"OData v2 Adapter Proxy for CDS OData v4 Services","title":"cds-odata-v2-adapter-proxy"},{"location":"apis/cds-odata-v2-adapter-proxy/#build-status","text":"","title":"Build Status"},{"location":"apis/cds-odata-v2-adapter-proxy/#getting-started","text":"Install: npm install @sap/cds-odata-v2-adapter-proxy Unit Tests: npm test Test Server: npm start Service: http://localhost:4004/v2/main Metadata: http://localhost:4004/v2/main/$metadata Data: http://localhost:4004/v2/main/Header?$expand=Items","title":"Getting Started"},{"location":"apis/cds-odata-v2-adapter-proxy/#usage","text":"","title":"Usage"},{"location":"apis/cds-odata-v2-adapter-proxy/#cds-combined-backend-nodejs-integrated","text":"In your existing @sap/cds project: Run npm install @sap/cds-odata-v2-adapter-proxy -s Create new file server.js in the service folder srv of your project: ./srv/server.js \"use strict\" ; const cds = require ( \"@sap/cds\" ); const proxy = require ( \"@sap/cds-odata-v2-adapter-proxy\" ); cds . on ( \"bootstrap\" , app => app . use ( proxy ())); module . exports = cds . server ; Run cds run from the project root to start the server: OData v2 service will be available at http://localhost:4004/v2/ OData v4 service will be available at http://localhost:4004/ Note that @sap/cds and express are peer dependency and needs to be available as module as well.","title":"CDS combined backend (Node.js) - integrated"},{"location":"apis/cds-odata-v2-adapter-proxy/#cds-combined-backend-nodejs-custom","text":"In your existing @sap/cds project: Run npm install @sap/cds-odata-v2-adapter-proxy -s Create new file index.js in the service folder srv of your project: ./srv/index.js \"use strict\"; const express = require(\"express\"); const cds = require(\"@sap/cds\"); const proxy = require(\"@sap/cds-odata-v2-adapter-proxy\"); const host = \"0.0.0.0\"; const port = process.env.PORT || 4004; (async () => { const app = express(); // serve odata v4 await cds .connect(\"db\") // ensure database is connected! .serve(\"all\") .in(app); // serve odata v2 process.env.XS_APP_LOG_LEVEL = \"warning\"; app.use(proxy({ path: \"v2\", port: port })); // start server const server = app.listen(port, host, () => console.info(`app is listing at ${ host } : ${ port } `)); server.on(\"error\", error => console.error(error.stack)); })(); Run node srv/index from the project root to start the server: OData v2 service will be available at http://localhost:4004/v2/ OData v4 service will be available at http://localhost:4004/ Note that @sap/cds and express are peer dependency and needs to be available as module as well.","title":"CDS combined backend (Node.js) - custom"},{"location":"apis/cds-odata-v2-adapter-proxy/#cds-standalone-backend-eg-java","text":"In a new Node.js express project: Run npm install @sap/cds -s Run npm install @sap/cds-odata-v2-adapter-proxy -s Place CDS models in db and srv model folders Create new file index.js in the service folder srv of the project: ./srv/index.js \"use strict\"; const express = require(\"express\"); const http = require(\"http\"); const proxy = require(\"@sap/cds-odata-v2-adapter-proxy\"); const host = \"0.0.0.0\"; const port = process.env.PORT || 4004; (async () => { const app = express(); // serve odata v2 process.env.XS_APP_LOG_LEVEL = \"warning\"; app.use(proxy({ path: \"v2\", target: \"http://localhost:8080\", services: { \" <odata -v4-service-path > \": \" <qualified.ServiceName> \" } })); // start server const server = app.listen(port, host, () => console.info(`app is listing at ${ host } : ${ port } `)); server.on(\"error\", error => console.error(error.stack)); })(); Make sure, that your CDS models are also available in the project. Those reside either in db and srv folders, or a compiled (untransformed) srv.json is provided. This can be generated by using the following command: cds srv -s all -o . If not detected automatically, the model path can be set with option model (especially if srv.json option is used). Make sure, that all i18n property files reside next to the srv.json in a i18n or _i18n folder, to be detected by localization. Run node srv/index from the project root to start the server: OData v2 service will be available at http://localhost:4004/v2/ OData v4 service shall be available at http://localhost:8080/ A deployed version of OData v2 proxy shall have option target set to the deployed OData v4 backend URL. This can be retrieved from the CF environment using node-xsenv module, e.g. from the destinations environment variable. Note that @sap/cds and express are peer dependency and needs to be available as module as well.","title":"CDS standalone backend (e.g. Java)"},{"location":"apis/cds-odata-v2-adapter-proxy/#cloud-foundry-deployment","text":"When deploying the CDS OData v2 Adapter Proxy to CF, make sure that it has access to the whole CDS model. Especially, it is the case, that normally the Node.js server is only based on folder srv and folder db is then missing on CF. To come around this situation, trigger a cds build , that generates a csn.json at location gen/srv/srv/csn.json . If your CF deployment of the Node.js backend (incl. CDS OData v2 Adapter Proxy) is then based on folder gen/srv , the CDS models can be found during runtime on Cloud Foundry.","title":"Cloud Foundry Deployment"},{"location":"apis/cds-odata-v2-adapter-proxy/#documentation","text":"Instantiates an CDS OData v2 Adapter Proxy Express Router for a CDS based OData v4 Server options: CDS OData v2 Adapter Proxy options [options.base]: Base path, under which the service is reachable. Default is ''. [options.path]: Path, under which the proxy is reachable. Default is 'v2'. [options.model]: CDS service model (path(s) or CSN). Default is 'all'. [options.port]: Target port, which points to OData v4 backend port. Default is '4004'. [options.target]: Target, which points to OData v4 backend host/port. Default is 'http://localhost:4004'. [options.services]: Service mapping, from url path name to service name. If omitted local CDS defaults apply. [options.standalone]: Indication, that OData v2 Adapter proxy is a standalone process. Default is 'false'. [options.mtxEndpoint]: Endpoint to retrieve MTX metadata for standalone proxy. Default is '/mtx/v1' [options.ieee754Compatible]: Edm.Decimal and Edm.Int64 are serialized IEEE754 compatible. Default is 'true'. [options.pathRewrite]: Custom path rewrite rules. Default uses 'path' option as rule: { \"^/v2\": \"\" } [options.disableNetworkLog]: Disable networking logging. Default is 'true'. Logging is controlled with XSA environment variable XS_APP_LOG_LEVEL . Details can be found at xs2/node-logging .","title":"Documentation"},{"location":"apis/cds-odata-v2-adapter-proxy/#features","text":"GET, POST, PUT/PATCH, DELETE Batch support Actions, Functions Analytical Annotations Deep Expands/Selects JSON format Deep Structures Data Type Mapping (incl. Date Time) IEEE754Compatible Messages/Error Handling Location Header $inlinecount / $count / \\$value Entity with Parameters Stream Support (Octet and Url), Content Disposition Multitenancy, Extensibility (proxy in same process only) Content-ID Draft Support Search Support Localization Tracing Logging Correlation ETag Support (Concurrency Control)","title":"Features"},{"location":"apis/cds-odata-v2-adapter-proxy/#odata-v2v4-delta","text":"http://docs.oasis-open.org/odata/new-in-odata/v4.0/cn01/new-in-odata-v4.0-cn01.html Open: $links -> $ref KEY(...) -> \\$root years, months, days, minutes, seconds Function Parameters as Query Options","title":"OData v2/v4 Delta"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . Version 1.4.33 - 2020-05-29 \u00b6 Fixed \u00b6 Service Document in XML format (default) Update dependencies Disable network log per default Version 1.4.32 - 2020-05-27 \u00b6 Fixed \u00b6 Update dependencies Update README on localization Toggle switch for network logging Allow HANA SYSUUID as UUID Version 1.4.31 - 2020-05-25 \u00b6 Fixed \u00b6 Align model resolving Fix data types conversion for numbers Fix data types recognition in functions Support response compression Prevent unnecessary data serialization for tracing Performance optimization for entity key/uri calculation General performance optimizations Update dependencies Version 1.4.30 - 2020-05-01 \u00b6 Fixed \u00b6 Make function call with request body more robust Fallback severity for detail messages to error Keep request body for action call Update README on CF deployment Version 1.4.29 - 2020-04-28 \u00b6 Fixed \u00b6 Fix analytics default value for all OData types Fix long running data type conversion for filter elements Version 1.4.28 - 2020-04-27 \u00b6 Fixed \u00b6 Fix \\$filter in analytics query Fix count for empty analytics result Fix result projection for analytics query Fix analytics \"null\" result values Only add root error, if no details messages Version 1.4.27 - 2020-04-21 \u00b6 Fixed \u00b6 Add root error as first detail message Error code including \"transition\", marks transition message Version 1.4.26 - 2020-04-20 \u00b6 Fixed \u00b6 Fix \\$filter for navigation elements Fix OData annotations conversion for Java backends Add request authorization parsing for logging Version 1.4.25 - 2020-04-08 \u00b6 Fixed \u00b6 Add additional messages as details Version 1.4.24 - 2020-04-07 \u00b6 Fixed \u00b6 Fix for metadata transfer-encoding chunked Filter '@' attributes Version 1.4.23 - 2020-04-01 \u00b6 Fixed \u00b6 Fix type conversion for \"le\" operator Version 1.4.22 - 2020-03-27 \u00b6 Fixed \u00b6 Fix entity uri path behind app router Update dependencies Version 1.4.21 - 2020-03-02 \u00b6 Fixed \u00b6 Improve \\$metadata logging Fix \\$metadata call headers Version 1.4.20 - 2020-02-27 \u00b6 Fixed \u00b6 Fix CDS backwards compatibility Version 1.4.19 - 2020-02-25 \u00b6 Fixed \u00b6 Fix ETag Support (Concurrency Control) Support streaming from URL media Adding custom path rewrite Custom server.js support Fix for rendering aggregation of integers Fix time duration parsing Misc fixes and improvements General housekeeping Moving from axios to node-fetch Version 1.4.18 - 2020-02-03 \u00b6 Fixed \u00b6 Improve \\$value handling for streaming Fix stream filename retrieval Optimize edmx localization Improve logging and tracing handling Fix for external services (e.g. Java backend) support Re-add \"services\" configuration for external service mapping Fix for search phrase Version 1.4.17 - 2020-01-20 \u00b6 Fixed \u00b6 Support for virtual hosts (e.g. Cloud Connector) Fix decode URI for path name Fix IEEE754 compatibility for single requests Add IEEE754 compatibility option switch Version 1.4.16 - 2020-01-14 \u00b6 Fixed \u00b6 Enforce IEEE754 compatibility Pin Axios library Version 1.4.15 - 2019-12-20 \u00b6 Fixed \u00b6 Fix authentication prompt for \\$metadata Improve trace handling Version 1.4.14 - 2019-12-19 \u00b6 Fixed \u00b6 Protect \\$metadata call Fix \\$filter parentheses nesting Fix \"all\" model loading from app, srv Improve \\$filter handling, incl. data type and negative tests Version 1.4.13 - 2019-12-12 \u00b6 Fixed \u00b6 Remove \"services\" configuration, as it is obsolete Fix nested functions in \\$filter Version 1.4.12 - 2019-12-06 \u00b6 Fixed \u00b6 Fix service and CSN model detection Version 1.4.9 - 2019-12-05 \u00b6 Fixed \u00b6 Allow CSN JSON object as model option Raise error, if service not found based on path Fix service paths with hyphen Fix cds.Date, cds.Time data type mappings Version 1.4.8 - 2019-11-14 \u00b6 Fixed \u00b6 Increased body size limit Fix engine config, to allow Node >= 8 Map cds.DateTime and cds.Timestamp to Edm.DateTimeOffset Version 1.4.6 - 2019-11-07 \u00b6 Fixed \u00b6 Update on README documentation Minor fixes Version 1.4.5 - 2019-10-25 \u00b6 Fixed \u00b6 __count is now of type String Aggregation values are converted according to dynamic type Search support Fix for converting warning messages Version 1.4.4 - 2019-10-07 \u00b6 Fixed \u00b6 Filter data type conversions Version 1.4.3 - 2019-10-01 \u00b6 Fixed \u00b6 Check CDS multitenancy/extensibility (mtx) Allow options that are falsy for Javascript Version 1.4.2 - 2019-09-24 \u00b6 Fixed \u00b6 Looser declaration or peer dependency to be compatible with snapshots Version 1.4.1 - 2019-09-11 \u00b6 Fixed \u00b6 Fixed compatibility to CDS 3.17.0 Propagate x-request-id, x-correlationid Version 1.4.0 - 2019-09-09 \u00b6 Fixed \u00b6 Raise error message for not supported aggregation function (e.g. #FORMULA) Fixed entity key calculation for key associations Fixed DateTime representation in entity key structure Version 1.3.0 - 2019-08-30 \u00b6 Fixed \u00b6 Passing through responses in XML (just for errors) Data-type mapping on aggregation values works for non-strings Version 1.2.0 - 2019-08-08 \u00b6 Added \u00b6 External Release Version 1.0.0 - 2019-05-21 \u00b6 Added \u00b6 Internal Release","title":"Changelog"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1433-2020-05-29","text":"","title":"Version 1.4.33 - 2020-05-29"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed","text":"Service Document in XML format (default) Update dependencies Disable network log per default","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1432-2020-05-27","text":"","title":"Version 1.4.32 - 2020-05-27"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_1","text":"Update dependencies Update README on localization Toggle switch for network logging Allow HANA SYSUUID as UUID","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1431-2020-05-25","text":"","title":"Version 1.4.31 - 2020-05-25"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_2","text":"Align model resolving Fix data types conversion for numbers Fix data types recognition in functions Support response compression Prevent unnecessary data serialization for tracing Performance optimization for entity key/uri calculation General performance optimizations Update dependencies","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1430-2020-05-01","text":"","title":"Version 1.4.30 - 2020-05-01"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_3","text":"Make function call with request body more robust Fallback severity for detail messages to error Keep request body for action call Update README on CF deployment","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1429-2020-04-28","text":"","title":"Version 1.4.29 - 2020-04-28"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_4","text":"Fix analytics default value for all OData types Fix long running data type conversion for filter elements","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1428-2020-04-27","text":"","title":"Version 1.4.28 - 2020-04-27"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_5","text":"Fix \\$filter in analytics query Fix count for empty analytics result Fix result projection for analytics query Fix analytics \"null\" result values Only add root error, if no details messages","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1427-2020-04-21","text":"","title":"Version 1.4.27 - 2020-04-21"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_6","text":"Add root error as first detail message Error code including \"transition\", marks transition message","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1426-2020-04-20","text":"","title":"Version 1.4.26 - 2020-04-20"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_7","text":"Fix \\$filter for navigation elements Fix OData annotations conversion for Java backends Add request authorization parsing for logging","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1425-2020-04-08","text":"","title":"Version 1.4.25 - 2020-04-08"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_8","text":"Add additional messages as details","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1424-2020-04-07","text":"","title":"Version 1.4.24 - 2020-04-07"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_9","text":"Fix for metadata transfer-encoding chunked Filter '@' attributes","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1423-2020-04-01","text":"","title":"Version 1.4.23 - 2020-04-01"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_10","text":"Fix type conversion for \"le\" operator","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1422-2020-03-27","text":"","title":"Version 1.4.22 - 2020-03-27"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_11","text":"Fix entity uri path behind app router Update dependencies","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1421-2020-03-02","text":"","title":"Version 1.4.21 - 2020-03-02"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_12","text":"Improve \\$metadata logging Fix \\$metadata call headers","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1420-2020-02-27","text":"","title":"Version 1.4.20 - 2020-02-27"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_13","text":"Fix CDS backwards compatibility","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1419-2020-02-25","text":"","title":"Version 1.4.19 - 2020-02-25"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_14","text":"Fix ETag Support (Concurrency Control) Support streaming from URL media Adding custom path rewrite Custom server.js support Fix for rendering aggregation of integers Fix time duration parsing Misc fixes and improvements General housekeeping Moving from axios to node-fetch","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1418-2020-02-03","text":"","title":"Version 1.4.18 - 2020-02-03"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_15","text":"Improve \\$value handling for streaming Fix stream filename retrieval Optimize edmx localization Improve logging and tracing handling Fix for external services (e.g. Java backend) support Re-add \"services\" configuration for external service mapping Fix for search phrase","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1417-2020-01-20","text":"","title":"Version 1.4.17 - 2020-01-20"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_16","text":"Support for virtual hosts (e.g. Cloud Connector) Fix decode URI for path name Fix IEEE754 compatibility for single requests Add IEEE754 compatibility option switch","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1416-2020-01-14","text":"","title":"Version 1.4.16 - 2020-01-14"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_17","text":"Enforce IEEE754 compatibility Pin Axios library","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1415-2019-12-20","text":"","title":"Version 1.4.15 - 2019-12-20"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_18","text":"Fix authentication prompt for \\$metadata Improve trace handling","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1414-2019-12-19","text":"","title":"Version 1.4.14 - 2019-12-19"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_19","text":"Protect \\$metadata call Fix \\$filter parentheses nesting Fix \"all\" model loading from app, srv Improve \\$filter handling, incl. data type and negative tests","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1413-2019-12-12","text":"","title":"Version 1.4.13 - 2019-12-12"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_20","text":"Remove \"services\" configuration, as it is obsolete Fix nested functions in \\$filter","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-1412-2019-12-06","text":"","title":"Version 1.4.12 - 2019-12-06"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_21","text":"Fix service and CSN model detection","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-149-2019-12-05","text":"","title":"Version 1.4.9 - 2019-12-05"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_22","text":"Allow CSN JSON object as model option Raise error, if service not found based on path Fix service paths with hyphen Fix cds.Date, cds.Time data type mappings","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-148-2019-11-14","text":"","title":"Version 1.4.8 - 2019-11-14"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_23","text":"Increased body size limit Fix engine config, to allow Node >= 8 Map cds.DateTime and cds.Timestamp to Edm.DateTimeOffset","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-146-2019-11-07","text":"","title":"Version 1.4.6 - 2019-11-07"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_24","text":"Update on README documentation Minor fixes","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-145-2019-10-25","text":"","title":"Version 1.4.5 - 2019-10-25"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_25","text":"__count is now of type String Aggregation values are converted according to dynamic type Search support Fix for converting warning messages","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-144-2019-10-07","text":"","title":"Version 1.4.4 - 2019-10-07"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_26","text":"Filter data type conversions","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-143-2019-10-01","text":"","title":"Version 1.4.3 - 2019-10-01"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_27","text":"Check CDS multitenancy/extensibility (mtx) Allow options that are falsy for Javascript","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-142-2019-09-24","text":"","title":"Version 1.4.2 - 2019-09-24"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_28","text":"Looser declaration or peer dependency to be compatible with snapshots","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-141-2019-09-11","text":"","title":"Version 1.4.1 - 2019-09-11"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_29","text":"Fixed compatibility to CDS 3.17.0 Propagate x-request-id, x-correlationid","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-140-2019-09-09","text":"","title":"Version 1.4.0 - 2019-09-09"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_30","text":"Raise error message for not supported aggregation function (e.g. #FORMULA) Fixed entity key calculation for key associations Fixed DateTime representation in entity key structure","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-130-2019-08-30","text":"","title":"Version 1.3.0 - 2019-08-30"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#fixed_31","text":"Passing through responses in XML (just for errors) Data-type mapping on aggregation values works for non-strings","title":"Fixed"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-120-2019-08-08","text":"","title":"Version 1.2.0 - 2019-08-08"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#added","text":"External Release","title":"Added"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#version-100-2019-05-21","text":"","title":"Version 1.0.0 - 2019-05-21"},{"location":"apis/cds-odata-v2-adapter-proxy/CHANGELOG/#added_1","text":"Internal Release","title":"Added"},{"location":"apis/cds-ql/","text":"CDS QL \u00b6 This package deals with creating a pool of connection clients, connecting to a driver (read: db) and using these connection clients from the pool to insert, delete, select and update values or rows from a specific table. Performing these insert, delete, select and update operations also includes executing embedded queries and plain statements. Overview \u00b6 TBD Installation \u00b6 npm install Usage/Configuration \u00b6 Examples \u00b6 Following is an example of how to set up a connection pool by specifying the maximum and minimum number of connections and a connection by specifying host, port, user and password. These connect options can be client specific. For example SAP Hana might include certificate and schema, while others like SQLite have neither. cds.connect({ kind: 'hana', pool: { min: 1, max: 100 }, credentials: { host: 'hana.tld', port: 39015, user: 'TECHNICAL_USER', password: 'VerySecure' } }) Following is an example of a basic SELECT statement: SELECT.from('Authors') Following is an example of a basic INSERT statement: INSERT.into('Authors') .rows([ 1, 'Wuthering Heights' ]) Following is an example of a basic UPDATE statement: UPDATE('Authors') .set({NAME : 'Jon Doe' , STOCK : 123}) Following is an example of a basic DELETE statement: DELETE.from('Authors')","title":"CDS QL"},{"location":"apis/cds-ql/#cds-ql","text":"This package deals with creating a pool of connection clients, connecting to a driver (read: db) and using these connection clients from the pool to insert, delete, select and update values or rows from a specific table. Performing these insert, delete, select and update operations also includes executing embedded queries and plain statements.","title":"CDS QL"},{"location":"apis/cds-ql/#overview","text":"TBD","title":"Overview"},{"location":"apis/cds-ql/#installation","text":"npm install","title":"Installation"},{"location":"apis/cds-ql/#usageconfiguration","text":"","title":"Usage/Configuration"},{"location":"apis/cds-ql/#examples","text":"Following is an example of how to set up a connection pool by specifying the maximum and minimum number of connections and a connection by specifying host, port, user and password. These connect options can be client specific. For example SAP Hana might include certificate and schema, while others like SQLite have neither. cds.connect({ kind: 'hana', pool: { min: 1, max: 100 }, credentials: { host: 'hana.tld', port: 39015, user: 'TECHNICAL_USER', password: 'VerySecure' } }) Following is an example of a basic SELECT statement: SELECT.from('Authors') Following is an example of a basic INSERT statement: INSERT.into('Authors') .rows([ 1, 'Wuthering Heights' ]) Following is an example of a basic UPDATE statement: UPDATE('Authors') .set({NAME : 'Jon Doe' , STOCK : 123}) Following is an example of a basic DELETE statement: DELETE.from('Authors')","title":"Examples"},{"location":"apis/cds-ql/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.21.0 - 2019-11-19 \u00b6 Added \u00b6 Acquire now sets session contexts valid-from and valid-to Fixed \u00b6 Single ticked entry in function now resolves to val instead of ref Version 1.20.1 - 2019-10-30 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.19.1 Updated version of @sap/cds-sqlite to 1.19.1 Updated version of @sap/cds-hana to 1.19.1 Version 1.20.0 - 2019-10-29 \u00b6 Changed \u00b6 Improved UPDATE error messages Removed \u00b6 npm-shrinkwrap.json Version 1.19.2 - 2019-10-16 \u00b6 Changed \u00b6 .run handles arrays in a Promise.all fashion Version 1.19.1 - 2019-10-08 \u00b6 Fixed \u00b6 Default mainkind in case of compound service (messaging and rest) Version 1.19.0 - 2019-10-02 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.18.0 Updated version of @sap/cds-sqlite to 1.18.0 Updated version of @sap/cds-hana to 1.18.0 Version 1.18.2 - 2019-09-18 \u00b6 Changed \u00b6 Improved error messages Fixed \u00b6 Disconnect in multi tenancy scenario Version 1.18.1 - 2019-09-10 \u00b6 Fixed \u00b6 Model loading Version 1.18.0 - 2019-09-09 \u00b6 Changed \u00b6 Improved error messages for statements No more model loading, model needs to be passed now Fixed \u00b6 Nested functions as strings in statements Options in connect combined with env variables Removed \u00b6 Workaround for onCond that used custom object notation Version 1.17.0 - 2019-08-21 \u00b6 Added \u00b6 options.kind can also be an object Service related functions create , insert , read , update and delete to transaction Http related functions get , post , put , patch and delete to transaction Changed \u00b6 .transaction(...).run can be used with an array of queries Fixed \u00b6 Update with binary property Version 1.16.0 - 2019-07-23 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.15.0 Updated version of @sap/cds-sqlite to 1.15.0 Updated version of @sap/cds-hana to 1.15.0 Version 1.15.0 - 2019-07-09 \u00b6 Added \u00b6 Enhanced statements to be compatible to specification Support for views with parameters Removed \u00b6 generateUUID function and uuid dependency usage of xsenv for authorization (is provided by cds.env) Version 1.14.0 - 2019-06-24 \u00b6 Fixed \u00b6 Bug with nested types in update Improved logging of SQLs when DEBUG=true is provided Version 1.13.0 - 2019-06-07 \u00b6 Changed \u00b6 updated generic-pool to 3.7.1 Version 1.12.0 - 2019-05-24 \u00b6 Removed \u00b6 Removed superficial cache for services Version 1.11.1 - 2019-05-16 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.11.1 Updated version of @sap/cds-sqlite to 1.11.1 Updated version of @sap/cds-hana to 1.11.1 Version 1.11.0 - 2015-05-15 \u00b6 Changed \u00b6 Improved performance by reducing calls to process.nextTick() Version 1.10.2 - 2019-05-08 \u00b6 Fixed \u00b6 service.deploy Version 1.10.1 - 2019-05-07 \u00b6 Changed \u00b6 More resilience towards setting the model manually in service Version 1.10.0 - 2019-05-03 \u00b6 Added \u00b6 Functions create , insert , read , update and delete added to service Streaming support via service.stream() Changed \u00b6 instanceof replaced with typeof in some cases Version 1.9.0 - 2019-04-16 \u00b6 Changed \u00b6 Select.one now adds property one instead of limit to CQN Transactions can be created (i.e. are not promisified) although initial model loading is not yet finished Version 1.8.0 - 2019-03-29 \u00b6 Added \u00b6 Support for transactions on multiple data sources Service.stream() provided for cds.stream() Changed \u00b6 Entities can be accessed via short name (if only one service in model) Version 1.7.1 - 2019-03-19 \u00b6 Changed \u00b6 Updated version of @sap/cds-hana to 1.7.1 Version 1.7.0 - 2019-03-19 \u00b6 Added \u00b6 Added more transaction functions ( tx.foreach , tx.commit , tx.rollback ) Changed \u00b6 Prevent app crash if tenant cannot connect Service hands over model to clients Version 1.6.0 - 2019-02-25 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.6.0 Updated version of @sap/cds-sqlite to 1.6.0 Updated version of @sap/cds-hana to 1.6.0 Version 1.5.1 - 2019-02-12 \u00b6 Added \u00b6 Support for sql functions lower, upper, trim, length in $filter and $orderby Support .and for where conditions Fixed \u00b6 Use .entities from reflected models Version 1.5.0 - 2019-02-06 \u00b6 Changed \u00b6 Minimum node version 8.9.0 Version 1.4.0 - 2019-01-22 \u00b6 Changed \u00b6 Use latest version of @sap/cds-sql Version 1.3.0 - 2019-01-11 \u00b6 Changed \u00b6 Use latest version of uuid and @sap/cds-sql Version 1.2.0 - 2018-12-21 \u00b6 Added \u00b6 Allow Arrays in UPDATE.set() Version 1.1.0 - 2018-12-12 \u00b6 Added \u00b6 Support for full join in SELECT Support for inline Version 1.0.0 - 2018-11-27 \u00b6 Added \u00b6 tenantId can be specified at disconnect model property can specified at connect entities and model of connection can be accessed Changed \u00b6 Connect option driver is renamed to kind Connect options regarding connecting moved to 'credentials' property instead of one flat object Fixed \u00b6 Read drafts with $filter/$search Version 0.12.0 - 2018-10-17 \u00b6 Added \u00b6 .where supports object notation with arrays of and/or Changed \u00b6 Refactoring and changes due to updated dependencies Version 0.11.0 - 2018-10-04 \u00b6 Added \u00b6 Support of string values bei fluid usage in .where Fixed \u00b6 Promise rejection in Service.run Version 0.10.0 - 2018-09-17 \u00b6 Added \u00b6 Auto lookup of db service if no configuration given at connect but is available at environmental VCAP_SERVICES Support of an array as argument in .where Version 0.9.1 - 2018-09-05 \u00b6 Changed \u00b6 Improved npm-shrinkwrap Version 0.9.0 - 2018-08-28 \u00b6 Added \u00b6 Added support for .columns() in SELECT where/or/having support fluid API based on the first argument init.js at reuse model can be used by deploy and may export an async function Changed \u00b6 any object filter combination of @sap/xsenv can be used to search the db service Version 0.8.1 - 2018-08-09 \u00b6 Changed \u00b6 Require submodules on demand Version 0.8.0 - 2018-08-07 \u00b6 Added \u00b6 Pool and Pool resources are evicted by default .from, .where and .having support partial CQN Inline support at CQN of where and columns in Select Functions .values and .entries at INSERT Support of .run().then.run() shortcut Debug is printed in case environmental variable DEBUG=true is set SELECT( , ).from( ) SELECT.from( ).where({ : CQN}) Support for unary and binary expressions in contains Support for expand with string/array notation in SELECT.columns (e. g. SELECT.from('Books', ['author', ['name']])) Support for excluding in service projection Changed \u00b6 .where and .having can be used multiple times instead of .where.and or .having.and .or can be used directly: Instead of calling where.or you can call or.or Fixed \u00b6 Issue with service renaming attributes Issue with 'exists' in object mode Removed \u00b6 .and for .where/.having Version 0.7.0 - 2018-07-11 \u00b6 Fixed \u00b6 Race condition at running block statements in transactional mode Brackets are only added to where or having if needed Removed \u00b6 Statement blocks cannot be run with \"sequential\" pragma anymore (use \"serialized\" instead) Version 0.6.0 - 2018-07-02 \u00b6 Added \u00b6 Multi tenancy support Version 0.5.0 - 2018-06-25 \u00b6 Added \u00b6 support .deploy to automatically set up database artifacts support of SQL functions lower and contains in .where support for navigation over entities with multiple keys SELECT allows partial CQNs as columns .run can execute blocks of statements Changed \u00b6 support for latest CQN spec changes renamed .hasPool to .hasSession Fixed \u00b6 CQL navigation on entity CDS injection .where with nested ORs and ANDs if provided as object input parameter Version 0.4.1 - 2018-05-03 \u00b6 Fixed \u00b6 Issue with postinstall script in package.json Version 0.4.0 - 2018-05-02 \u00b6 Added \u00b6 support DROP statements connection pool validates resources before provisioning support .foreach cds used via injection support fluid usage of .where and .having in DML statements Changed \u00b6 connect options aligned to spec support for latest CQN spec changes refactored .connect to return undefined instead of Promise refactored .acquire to wait for .connect before providing a client Version 0.3.0 - 2018-04-16 \u00b6 Added \u00b6 allow CQN as parameter in SELECT.from support CREATE statements Version 0.2.0 - 2018-03-16 \u00b6 Added \u00b6 support for SELECT.one usage of npm-shrinkwrap Changed \u00b6 made generateUUID synchronous","title":"Changelog"},{"location":"apis/cds-ql/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-ql/CHANGELOG/#version-1210-2019-11-19","text":"","title":"Version 1.21.0 - 2019-11-19"},{"location":"apis/cds-ql/CHANGELOG/#added","text":"Acquire now sets session contexts valid-from and valid-to","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#fixed","text":"Single ticked entry in function now resolves to val instead of ref","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-1201-2019-10-30","text":"","title":"Version 1.20.1 - 2019-10-30"},{"location":"apis/cds-ql/CHANGELOG/#changed","text":"Updated version of @sap/cds-sql to 1.19.1 Updated version of @sap/cds-sqlite to 1.19.1 Updated version of @sap/cds-hana to 1.19.1","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1200-2019-10-29","text":"","title":"Version 1.20.0 - 2019-10-29"},{"location":"apis/cds-ql/CHANGELOG/#changed_1","text":"Improved UPDATE error messages","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#removed","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-ql/CHANGELOG/#version-1192-2019-10-16","text":"","title":"Version 1.19.2 - 2019-10-16"},{"location":"apis/cds-ql/CHANGELOG/#changed_2","text":".run handles arrays in a Promise.all fashion","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1191-2019-10-08","text":"","title":"Version 1.19.1 - 2019-10-08"},{"location":"apis/cds-ql/CHANGELOG/#fixed_1","text":"Default mainkind in case of compound service (messaging and rest)","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-1190-2019-10-02","text":"","title":"Version 1.19.0 - 2019-10-02"},{"location":"apis/cds-ql/CHANGELOG/#changed_3","text":"Updated version of @sap/cds-sql to 1.18.0 Updated version of @sap/cds-sqlite to 1.18.0 Updated version of @sap/cds-hana to 1.18.0","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1182-2019-09-18","text":"","title":"Version 1.18.2 - 2019-09-18"},{"location":"apis/cds-ql/CHANGELOG/#changed_4","text":"Improved error messages","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#fixed_2","text":"Disconnect in multi tenancy scenario","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-1181-2019-09-10","text":"","title":"Version 1.18.1 - 2019-09-10"},{"location":"apis/cds-ql/CHANGELOG/#fixed_3","text":"Model loading","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-1180-2019-09-09","text":"","title":"Version 1.18.0 - 2019-09-09"},{"location":"apis/cds-ql/CHANGELOG/#changed_5","text":"Improved error messages for statements No more model loading, model needs to be passed now","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#fixed_4","text":"Nested functions as strings in statements Options in connect combined with env variables","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#removed_1","text":"Workaround for onCond that used custom object notation","title":"Removed"},{"location":"apis/cds-ql/CHANGELOG/#version-1170-2019-08-21","text":"","title":"Version 1.17.0 - 2019-08-21"},{"location":"apis/cds-ql/CHANGELOG/#added_1","text":"options.kind can also be an object Service related functions create , insert , read , update and delete to transaction Http related functions get , post , put , patch and delete to transaction","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_6","text":".transaction(...).run can be used with an array of queries","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#fixed_5","text":"Update with binary property","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-1160-2019-07-23","text":"","title":"Version 1.16.0 - 2019-07-23"},{"location":"apis/cds-ql/CHANGELOG/#changed_7","text":"Updated version of @sap/cds-sql to 1.15.0 Updated version of @sap/cds-sqlite to 1.15.0 Updated version of @sap/cds-hana to 1.15.0","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1150-2019-07-09","text":"","title":"Version 1.15.0 - 2019-07-09"},{"location":"apis/cds-ql/CHANGELOG/#added_2","text":"Enhanced statements to be compatible to specification Support for views with parameters","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#removed_2","text":"generateUUID function and uuid dependency usage of xsenv for authorization (is provided by cds.env)","title":"Removed"},{"location":"apis/cds-ql/CHANGELOG/#version-1140-2019-06-24","text":"","title":"Version 1.14.0 - 2019-06-24"},{"location":"apis/cds-ql/CHANGELOG/#fixed_6","text":"Bug with nested types in update Improved logging of SQLs when DEBUG=true is provided","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-1130-2019-06-07","text":"","title":"Version 1.13.0 - 2019-06-07"},{"location":"apis/cds-ql/CHANGELOG/#changed_8","text":"updated generic-pool to 3.7.1","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1120-2019-05-24","text":"","title":"Version 1.12.0 - 2019-05-24"},{"location":"apis/cds-ql/CHANGELOG/#removed_3","text":"Removed superficial cache for services","title":"Removed"},{"location":"apis/cds-ql/CHANGELOG/#version-1111-2019-05-16","text":"","title":"Version 1.11.1 - 2019-05-16"},{"location":"apis/cds-ql/CHANGELOG/#changed_9","text":"Updated version of @sap/cds-sql to 1.11.1 Updated version of @sap/cds-sqlite to 1.11.1 Updated version of @sap/cds-hana to 1.11.1","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1110-2015-05-15","text":"","title":"Version 1.11.0 - 2015-05-15"},{"location":"apis/cds-ql/CHANGELOG/#changed_10","text":"Improved performance by reducing calls to process.nextTick()","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1102-2019-05-08","text":"","title":"Version 1.10.2 - 2019-05-08"},{"location":"apis/cds-ql/CHANGELOG/#fixed_7","text":"service.deploy","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-1101-2019-05-07","text":"","title":"Version 1.10.1 - 2019-05-07"},{"location":"apis/cds-ql/CHANGELOG/#changed_11","text":"More resilience towards setting the model manually in service","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-1100-2019-05-03","text":"","title":"Version 1.10.0 - 2019-05-03"},{"location":"apis/cds-ql/CHANGELOG/#added_3","text":"Functions create , insert , read , update and delete added to service Streaming support via service.stream()","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_12","text":"instanceof replaced with typeof in some cases","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-190-2019-04-16","text":"","title":"Version 1.9.0 - 2019-04-16"},{"location":"apis/cds-ql/CHANGELOG/#changed_13","text":"Select.one now adds property one instead of limit to CQN Transactions can be created (i.e. are not promisified) although initial model loading is not yet finished","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-180-2019-03-29","text":"","title":"Version 1.8.0 - 2019-03-29"},{"location":"apis/cds-ql/CHANGELOG/#added_4","text":"Support for transactions on multiple data sources Service.stream() provided for cds.stream()","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_14","text":"Entities can be accessed via short name (if only one service in model)","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-171-2019-03-19","text":"","title":"Version 1.7.1 - 2019-03-19"},{"location":"apis/cds-ql/CHANGELOG/#changed_15","text":"Updated version of @sap/cds-hana to 1.7.1","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-170-2019-03-19","text":"","title":"Version 1.7.0 - 2019-03-19"},{"location":"apis/cds-ql/CHANGELOG/#added_5","text":"Added more transaction functions ( tx.foreach , tx.commit , tx.rollback )","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_16","text":"Prevent app crash if tenant cannot connect Service hands over model to clients","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-160-2019-02-25","text":"","title":"Version 1.6.0 - 2019-02-25"},{"location":"apis/cds-ql/CHANGELOG/#changed_17","text":"Updated version of @sap/cds-sql to 1.6.0 Updated version of @sap/cds-sqlite to 1.6.0 Updated version of @sap/cds-hana to 1.6.0","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-151-2019-02-12","text":"","title":"Version 1.5.1 - 2019-02-12"},{"location":"apis/cds-ql/CHANGELOG/#added_6","text":"Support for sql functions lower, upper, trim, length in $filter and $orderby Support .and for where conditions","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#fixed_8","text":"Use .entities from reflected models","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-150-2019-02-06","text":"","title":"Version 1.5.0 - 2019-02-06"},{"location":"apis/cds-ql/CHANGELOG/#changed_18","text":"Minimum node version 8.9.0","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-140-2019-01-22","text":"","title":"Version 1.4.0 - 2019-01-22"},{"location":"apis/cds-ql/CHANGELOG/#changed_19","text":"Use latest version of @sap/cds-sql","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-130-2019-01-11","text":"","title":"Version 1.3.0 - 2019-01-11"},{"location":"apis/cds-ql/CHANGELOG/#changed_20","text":"Use latest version of uuid and @sap/cds-sql","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-120-2018-12-21","text":"","title":"Version 1.2.0 - 2018-12-21"},{"location":"apis/cds-ql/CHANGELOG/#added_7","text":"Allow Arrays in UPDATE.set()","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#version-110-2018-12-12","text":"","title":"Version 1.1.0 - 2018-12-12"},{"location":"apis/cds-ql/CHANGELOG/#added_8","text":"Support for full join in SELECT Support for inline","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#version-100-2018-11-27","text":"","title":"Version 1.0.0 - 2018-11-27"},{"location":"apis/cds-ql/CHANGELOG/#added_9","text":"tenantId can be specified at disconnect model property can specified at connect entities and model of connection can be accessed","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_21","text":"Connect option driver is renamed to kind Connect options regarding connecting moved to 'credentials' property instead of one flat object","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#fixed_9","text":"Read drafts with $filter/$search","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-0120-2018-10-17","text":"","title":"Version 0.12.0 - 2018-10-17"},{"location":"apis/cds-ql/CHANGELOG/#added_10","text":".where supports object notation with arrays of and/or","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_22","text":"Refactoring and changes due to updated dependencies","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-0110-2018-10-04","text":"","title":"Version 0.11.0 - 2018-10-04"},{"location":"apis/cds-ql/CHANGELOG/#added_11","text":"Support of string values bei fluid usage in .where","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#fixed_10","text":"Promise rejection in Service.run","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-0100-2018-09-17","text":"","title":"Version 0.10.0 - 2018-09-17"},{"location":"apis/cds-ql/CHANGELOG/#added_12","text":"Auto lookup of db service if no configuration given at connect but is available at environmental VCAP_SERVICES Support of an array as argument in .where","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#version-091-2018-09-05","text":"","title":"Version 0.9.1 - 2018-09-05"},{"location":"apis/cds-ql/CHANGELOG/#changed_23","text":"Improved npm-shrinkwrap","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-090-2018-08-28","text":"","title":"Version 0.9.0 - 2018-08-28"},{"location":"apis/cds-ql/CHANGELOG/#added_13","text":"Added support for .columns() in SELECT where/or/having support fluid API based on the first argument init.js at reuse model can be used by deploy and may export an async function","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_24","text":"any object filter combination of @sap/xsenv can be used to search the db service","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-081-2018-08-09","text":"","title":"Version 0.8.1 - 2018-08-09"},{"location":"apis/cds-ql/CHANGELOG/#changed_25","text":"Require submodules on demand","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-080-2018-08-07","text":"","title":"Version 0.8.0 - 2018-08-07"},{"location":"apis/cds-ql/CHANGELOG/#added_14","text":"Pool and Pool resources are evicted by default .from, .where and .having support partial CQN Inline support at CQN of where and columns in Select Functions .values and .entries at INSERT Support of .run().then.run() shortcut Debug is printed in case environmental variable DEBUG=true is set SELECT( , ).from( ) SELECT.from( ).where({ : CQN}) Support for unary and binary expressions in contains Support for expand with string/array notation in SELECT.columns (e. g. SELECT.from('Books', ['author', ['name']])) Support for excluding in service projection","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_26","text":".where and .having can be used multiple times instead of .where.and or .having.and .or can be used directly: Instead of calling where.or you can call or.or","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#fixed_11","text":"Issue with service renaming attributes Issue with 'exists' in object mode","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#removed_4","text":".and for .where/.having","title":"Removed"},{"location":"apis/cds-ql/CHANGELOG/#version-070-2018-07-11","text":"","title":"Version 0.7.0 - 2018-07-11"},{"location":"apis/cds-ql/CHANGELOG/#fixed_12","text":"Race condition at running block statements in transactional mode Brackets are only added to where or having if needed","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#removed_5","text":"Statement blocks cannot be run with \"sequential\" pragma anymore (use \"serialized\" instead)","title":"Removed"},{"location":"apis/cds-ql/CHANGELOG/#version-060-2018-07-02","text":"","title":"Version 0.6.0 - 2018-07-02"},{"location":"apis/cds-ql/CHANGELOG/#added_15","text":"Multi tenancy support","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#version-050-2018-06-25","text":"","title":"Version 0.5.0 - 2018-06-25"},{"location":"apis/cds-ql/CHANGELOG/#added_16","text":"support .deploy to automatically set up database artifacts support of SQL functions lower and contains in .where support for navigation over entities with multiple keys SELECT allows partial CQNs as columns .run can execute blocks of statements","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_27","text":"support for latest CQN spec changes renamed .hasPool to .hasSession","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#fixed_13","text":"CQL navigation on entity CDS injection .where with nested ORs and ANDs if provided as object input parameter","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-041-2018-05-03","text":"","title":"Version 0.4.1 - 2018-05-03"},{"location":"apis/cds-ql/CHANGELOG/#fixed_14","text":"Issue with postinstall script in package.json","title":"Fixed"},{"location":"apis/cds-ql/CHANGELOG/#version-040-2018-05-02","text":"","title":"Version 0.4.0 - 2018-05-02"},{"location":"apis/cds-ql/CHANGELOG/#added_17","text":"support DROP statements connection pool validates resources before provisioning support .foreach cds used via injection support fluid usage of .where and .having in DML statements","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_28","text":"connect options aligned to spec support for latest CQN spec changes refactored .connect to return undefined instead of Promise refactored .acquire to wait for .connect before providing a client","title":"Changed"},{"location":"apis/cds-ql/CHANGELOG/#version-030-2018-04-16","text":"","title":"Version 0.3.0 - 2018-04-16"},{"location":"apis/cds-ql/CHANGELOG/#added_18","text":"allow CQN as parameter in SELECT.from support CREATE statements","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#version-020-2018-03-16","text":"","title":"Version 0.2.0 - 2018-03-16"},{"location":"apis/cds-ql/CHANGELOG/#added_19","text":"support for SELECT.one usage of npm-shrinkwrap","title":"Added"},{"location":"apis/cds-ql/CHANGELOG/#changed_29","text":"made generateUUID synchronous","title":"Changed"},{"location":"apis/cds-reflect/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project are documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . Version 2.11.0 - 2020-04-27 \u00b6 Added \u00b6 QL parser Version 2.10.2 - 2020-03-19 \u00b6 Removed \u00b6 npm-shrinkwrap.json Version 2.10.1 - 2020-02-20 \u00b6 Changed \u00b6 Updated version number for public release Version 2.9.3 - 2020-02-19 \u00b6 Changed \u00b6 Updated version number for public release Version 2.9.2 - 2020-01-17 \u00b6 Fixed \u00b6 Linked view entities erroneously inherited their base entities' .keys e.g.: const m = cds . linked ( cds . parse ( ` entity Foo { key ID : UUID } entity Bar as select from Foo { ID as Kennung }; ` )) const { Foo , Bar } = m . entities Foo . keys //> { ID: string { key: true, type: 'cds.UUID' } } Bar . keys //> { Kennung: string { key: true, type: 'cds.UUID' } } // The latter before was erronously: Bar . keys //> { ID: string { key: true, type: 'cds.UUID' } } -> WRONG Version 2.9.1 - 2019-12-11 \u00b6 Added \u00b6 Preparations for streamlined compiler APIs Version 2.8.0 - 2019-10-08 \u00b6 Added \u00b6 Entity definitions know their service Version 2.7.1 - 2019-09-09 \u00b6 Added \u00b6 Support for cds.extend(Foo) Version 2.7.0 - 2019-09-09 \u00b6 Added \u00b6 Support for linking typeof refs Version 2.6.0 - 2019-08-21 \u00b6 Added \u00b6 .valueOf to easily construct qualified names Changed \u00b6 Improved stack traces Version 2.5.0 - 2019-05-03 \u00b6 Added \u00b6 cds now is an EventEmitter -- This allows server modules to inform interested listeners about notable events in a loose-coupling fashion. Fixed \u00b6 model.services now really filters cds.infer supports paths with filters Version 2.3.0 \u00b6 Changed \u00b6 The minimum required Node.js version is now set more specifically to 8.9 LTS. Previously, just Node.js 8 was mentioned. Version 2.2.1 - 2019-01-24 \u00b6 Fixed \u00b6 Getter for linked_entity.source Version 2.2.0 \u00b6 Added \u00b6 Getter for linked_entity.source (better use: linked_entity.query._target ) Version 2.0.5 \u00b6 Features \u00b6 Seperated iteration and recursion .foreach is now iteration only, use .forall to visit all definitions recursively. Version 1.8.0 \u00b6 Features \u00b6 Entities and services can be retrieved with namespace scope Version 1.7.0 \u00b6 Changes \u00b6 Clean up of TypeScript APIs Version 1.6.0 \u00b6 Features \u00b6 Getters for entities and services Infer keys for managed associations Support for getting entities and services with namespace, e.g. cds.reflect(m).entities ('my.bookshop') Version 1.5.0 \u00b6 Fixes \u00b6 Fixes for linking associations and foreign keys","title":"Change Log"},{"location":"apis/cds-reflect/CHANGELOG/#change-log","text":"All notable changes to this project are documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Change Log"},{"location":"apis/cds-reflect/CHANGELOG/#version-2110-2020-04-27","text":"","title":"Version 2.11.0 - 2020-04-27"},{"location":"apis/cds-reflect/CHANGELOG/#added","text":"QL parser","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#version-2102-2020-03-19","text":"","title":"Version 2.10.2 - 2020-03-19"},{"location":"apis/cds-reflect/CHANGELOG/#removed","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-reflect/CHANGELOG/#version-2101-2020-02-20","text":"","title":"Version 2.10.1 - 2020-02-20"},{"location":"apis/cds-reflect/CHANGELOG/#changed","text":"Updated version number for public release","title":"Changed"},{"location":"apis/cds-reflect/CHANGELOG/#version-293-2020-02-19","text":"","title":"Version 2.9.3 - 2020-02-19"},{"location":"apis/cds-reflect/CHANGELOG/#changed_1","text":"Updated version number for public release","title":"Changed"},{"location":"apis/cds-reflect/CHANGELOG/#version-292-2020-01-17","text":"","title":"Version 2.9.2 - 2020-01-17"},{"location":"apis/cds-reflect/CHANGELOG/#fixed","text":"Linked view entities erroneously inherited their base entities' .keys e.g.: const m = cds . linked ( cds . parse ( ` entity Foo { key ID : UUID } entity Bar as select from Foo { ID as Kennung }; ` )) const { Foo , Bar } = m . entities Foo . keys //> { ID: string { key: true, type: 'cds.UUID' } } Bar . keys //> { Kennung: string { key: true, type: 'cds.UUID' } } // The latter before was erronously: Bar . keys //> { ID: string { key: true, type: 'cds.UUID' } } -> WRONG","title":"Fixed"},{"location":"apis/cds-reflect/CHANGELOG/#version-291-2019-12-11","text":"","title":"Version 2.9.1 - 2019-12-11"},{"location":"apis/cds-reflect/CHANGELOG/#added_1","text":"Preparations for streamlined compiler APIs","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#version-280-2019-10-08","text":"","title":"Version 2.8.0 - 2019-10-08"},{"location":"apis/cds-reflect/CHANGELOG/#added_2","text":"Entity definitions know their service","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#version-271-2019-09-09","text":"","title":"Version 2.7.1 - 2019-09-09"},{"location":"apis/cds-reflect/CHANGELOG/#added_3","text":"Support for cds.extend(Foo)","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#version-270-2019-09-09","text":"","title":"Version 2.7.0 - 2019-09-09"},{"location":"apis/cds-reflect/CHANGELOG/#added_4","text":"Support for linking typeof refs","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#version-260-2019-08-21","text":"","title":"Version 2.6.0 - 2019-08-21"},{"location":"apis/cds-reflect/CHANGELOG/#added_5","text":".valueOf to easily construct qualified names","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#changed_2","text":"Improved stack traces","title":"Changed"},{"location":"apis/cds-reflect/CHANGELOG/#version-250-2019-05-03","text":"","title":"Version 2.5.0 - 2019-05-03"},{"location":"apis/cds-reflect/CHANGELOG/#added_6","text":"cds now is an EventEmitter -- This allows server modules to inform interested listeners about notable events in a loose-coupling fashion.","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#fixed_1","text":"model.services now really filters cds.infer supports paths with filters","title":"Fixed"},{"location":"apis/cds-reflect/CHANGELOG/#version-230","text":"","title":"Version 2.3.0"},{"location":"apis/cds-reflect/CHANGELOG/#changed_3","text":"The minimum required Node.js version is now set more specifically to 8.9 LTS. Previously, just Node.js 8 was mentioned.","title":"Changed"},{"location":"apis/cds-reflect/CHANGELOG/#version-221-2019-01-24","text":"","title":"Version 2.2.1 - 2019-01-24"},{"location":"apis/cds-reflect/CHANGELOG/#fixed_2","text":"Getter for linked_entity.source","title":"Fixed"},{"location":"apis/cds-reflect/CHANGELOG/#version-220","text":"","title":"Version 2.2.0"},{"location":"apis/cds-reflect/CHANGELOG/#added_7","text":"Getter for linked_entity.source (better use: linked_entity.query._target )","title":"Added"},{"location":"apis/cds-reflect/CHANGELOG/#version-205","text":"","title":"Version 2.0.5"},{"location":"apis/cds-reflect/CHANGELOG/#features","text":"Seperated iteration and recursion .foreach is now iteration only, use .forall to visit all definitions recursively.","title":"Features"},{"location":"apis/cds-reflect/CHANGELOG/#version-180","text":"","title":"Version 1.8.0"},{"location":"apis/cds-reflect/CHANGELOG/#features_1","text":"Entities and services can be retrieved with namespace scope","title":"Features"},{"location":"apis/cds-reflect/CHANGELOG/#version-170","text":"","title":"Version 1.7.0"},{"location":"apis/cds-reflect/CHANGELOG/#changes","text":"Clean up of TypeScript APIs","title":"Changes"},{"location":"apis/cds-reflect/CHANGELOG/#version-160","text":"","title":"Version 1.6.0"},{"location":"apis/cds-reflect/CHANGELOG/#features_2","text":"Getters for entities and services Infer keys for managed associations Support for getting entities and services with namespace, e.g. cds.reflect(m).entities ('my.bookshop')","title":"Features"},{"location":"apis/cds-reflect/CHANGELOG/#version-150","text":"","title":"Version 1.5.0"},{"location":"apis/cds-reflect/CHANGELOG/#fixes","text":"Fixes for linking associations and foreign keys","title":"Fixes"},{"location":"apis/cds-reflect/readme/","text":"cds.reflect \u00b6 Provides core reflection for CDS models in CSN format. Local usage in a project \u00b6 npm i @sap/cds-reflect const cds = require ( '@sap/cds-reflect' ) // then use it as described in the above docs, e.g.... let model = cds . reflect ({ namespace : 'foo.bar' , definitions : { 'foo.bar.Foo' : { kind : 'entity' , elements : { bar : { type : 'cds.Association' , target : 'foo.bar.Bar' } }}, 'foo.bar.Bar' : { kind : 'entity' }, } }) let { Foo , Bar } = m . exports","title":"Readme"},{"location":"apis/cds-reflect/readme/#cdsreflect","text":"Provides core reflection for CDS models in CSN format.","title":"cds.reflect"},{"location":"apis/cds-reflect/readme/#local-usage-in-a-project","text":"npm i @sap/cds-reflect const cds = require ( '@sap/cds-reflect' ) // then use it as described in the above docs, e.g.... let model = cds . reflect ({ namespace : 'foo.bar' , definitions : { 'foo.bar.Foo' : { kind : 'entity' , elements : { bar : { type : 'cds.Association' , target : 'foo.bar.Bar' } }}, 'foo.bar.Bar' : { kind : 'entity' }, } }) let { Foo , Bar } = m . exports","title":"Local usage in a project"},{"location":"apis/cds-rest/","text":"cds-rest \u00b6","title":"cds-rest"},{"location":"apis/cds-rest/#cds-rest","text":"","title":"cds-rest"},{"location":"apis/cds-rest/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.6.2 - 2020-03-19 \u00b6 Changed \u00b6 In case there is no credentials.destination provided the destinations environment variable is not created anymore. The connection to the remote service is handled internally. Removed \u00b6 npm-shrinkwrap.json Version 1.5.0 - 2020-02-19 \u00b6 Changed \u00b6 Updated version number for public release Version 1.4.0 - 2020-02-05 \u00b6 Added \u00b6 Where x in (a,b,...) predicates are translated to series of (x eq a) or (x eq b) in OData $filter options Changed \u00b6 Version of @sap/cloud-sdk-core pinned to 1.15.1 Version of @sap/cloud-sdk-util pinned to 1.15.1 Version 1.3.0 - 2019-10-29 \u00b6 Removed \u00b6 npm-shrinkwrap.json Version 1.2.0 - 2019-10-02 \u00b6 Added \u00b6 If JWT token provided in context, it is forwarded to Cloud SDK Changed \u00b6 Version of @sap/cloud-sdk-core to 1.10.0 Version of @sap/cloud-sdk-util to 1.10.0 Version 1.1.3 - 2019-09-21 \u00b6 Added \u00b6 Dependency to @sap/cloud-sdk-util Version 1.1.2 - 2019-09-19 \u00b6 Fixed \u00b6 npm-shrinkwrap.json containing wrong versions Version 1.1.1 - 2019-09-18 \u00b6 Added \u00b6 Support where , columns and one properties in SELECT Changed \u00b6 Enforce JSON format in OData Clean up OData V2 responses Version 1.1.0 - 2019-09-09 \u00b6 Added \u00b6 Auto-generate destinations env variable if NODE_ENV !== 'production ' Version 1.0.2 - 2019-08-27 \u00b6 Fixed \u00b6 npm-shrinkwrap.json containing wrong versions Version 1.0.1 - 2019-08-26 \u00b6 ### Changed Version of @sap/cloud-sdk-core pinned to 1.8.0 Version 1.0.0 - 2019-08-21 \u00b6 Added \u00b6 Initial implementation","title":"Changelog"},{"location":"apis/cds-rest/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-rest/CHANGELOG/#version-162-2020-03-19","text":"","title":"Version 1.6.2 - 2020-03-19"},{"location":"apis/cds-rest/CHANGELOG/#changed","text":"In case there is no credentials.destination provided the destinations environment variable is not created anymore. The connection to the remote service is handled internally.","title":"Changed"},{"location":"apis/cds-rest/CHANGELOG/#removed","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-rest/CHANGELOG/#version-150-2020-02-19","text":"","title":"Version 1.5.0 - 2020-02-19"},{"location":"apis/cds-rest/CHANGELOG/#changed_1","text":"Updated version number for public release","title":"Changed"},{"location":"apis/cds-rest/CHANGELOG/#version-140-2020-02-05","text":"","title":"Version 1.4.0 - 2020-02-05"},{"location":"apis/cds-rest/CHANGELOG/#added","text":"Where x in (a,b,...) predicates are translated to series of (x eq a) or (x eq b) in OData $filter options","title":"Added"},{"location":"apis/cds-rest/CHANGELOG/#changed_2","text":"Version of @sap/cloud-sdk-core pinned to 1.15.1 Version of @sap/cloud-sdk-util pinned to 1.15.1","title":"Changed"},{"location":"apis/cds-rest/CHANGELOG/#version-130-2019-10-29","text":"","title":"Version 1.3.0 - 2019-10-29"},{"location":"apis/cds-rest/CHANGELOG/#removed_1","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-rest/CHANGELOG/#version-120-2019-10-02","text":"","title":"Version 1.2.0 - 2019-10-02"},{"location":"apis/cds-rest/CHANGELOG/#added_1","text":"If JWT token provided in context, it is forwarded to Cloud SDK","title":"Added"},{"location":"apis/cds-rest/CHANGELOG/#changed_3","text":"Version of @sap/cloud-sdk-core to 1.10.0 Version of @sap/cloud-sdk-util to 1.10.0","title":"Changed"},{"location":"apis/cds-rest/CHANGELOG/#version-113-2019-09-21","text":"","title":"Version 1.1.3 - 2019-09-21"},{"location":"apis/cds-rest/CHANGELOG/#added_2","text":"Dependency to @sap/cloud-sdk-util","title":"Added"},{"location":"apis/cds-rest/CHANGELOG/#version-112-2019-09-19","text":"","title":"Version 1.1.2 - 2019-09-19"},{"location":"apis/cds-rest/CHANGELOG/#fixed","text":"npm-shrinkwrap.json containing wrong versions","title":"Fixed"},{"location":"apis/cds-rest/CHANGELOG/#version-111-2019-09-18","text":"","title":"Version 1.1.1 - 2019-09-18"},{"location":"apis/cds-rest/CHANGELOG/#added_3","text":"Support where , columns and one properties in SELECT","title":"Added"},{"location":"apis/cds-rest/CHANGELOG/#changed_4","text":"Enforce JSON format in OData Clean up OData V2 responses","title":"Changed"},{"location":"apis/cds-rest/CHANGELOG/#version-110-2019-09-09","text":"","title":"Version 1.1.0 - 2019-09-09"},{"location":"apis/cds-rest/CHANGELOG/#added_4","text":"Auto-generate destinations env variable if NODE_ENV !== 'production '","title":"Added"},{"location":"apis/cds-rest/CHANGELOG/#version-102-2019-08-27","text":"","title":"Version 1.0.2 - 2019-08-27"},{"location":"apis/cds-rest/CHANGELOG/#fixed_1","text":"npm-shrinkwrap.json containing wrong versions","title":"Fixed"},{"location":"apis/cds-rest/CHANGELOG/#version-101-2019-08-26","text":"### Changed Version of @sap/cloud-sdk-core pinned to 1.8.0","title":"Version 1.0.1 - 2019-08-26"},{"location":"apis/cds-rest/CHANGELOG/#version-100-2019-08-21","text":"","title":"Version 1.0.0 - 2019-08-21"},{"location":"apis/cds-rest/CHANGELOG/#added_5","text":"Initial implementation","title":"Added"},{"location":"apis/cds-runtime/","text":"CDS Runtime \u00b6 With the CDS Node.js runtime library services can be provided and consumed through synchronous as well as asynchronous APIs. Based on ubiquitous notions of events and queries, it allows implementing services in protocol-agnostic and platform-agnostic ways. The CDS Runtime is part of the SAP Cloud Application Programming Model. Please visit https://cap.cloud.sap/docs/ to learn about provided features, installation and usage. The CDS Runtime module is the successor of @sap/cds-services , @sap/cds-ql , @sap/cds-messaging , @sap/cds-rest , @sap/cds-hana , @sap/cds-sqlite and @sap/cds-sql . Please note that future development and bug fixes will be provided in the CDS Runtime module only.","title":"CDS Runtime #"},{"location":"apis/cds-runtime/#cds-runtime","text":"With the CDS Node.js runtime library services can be provided and consumed through synchronous as well as asynchronous APIs. Based on ubiquitous notions of events and queries, it allows implementing services in protocol-agnostic and platform-agnostic ways. The CDS Runtime is part of the SAP Cloud Application Programming Model. Please visit https://cap.cloud.sap/docs/ to learn about provided features, installation and usage. The CDS Runtime module is the successor of @sap/cds-services , @sap/cds-ql , @sap/cds-messaging , @sap/cds-rest , @sap/cds-hana , @sap/cds-sqlite and @sap/cds-sql . Please note that future development and bug fixes will be provided in the CDS Runtime module only.","title":"CDS Runtime"},{"location":"apis/cds-runtime/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.2.2 - 2020-05-27 \u00b6 Changed \u00b6 Updated version for internal release Version 1.2.1 - 2020-05-20 \u00b6 Added \u00b6 The timeout of the exclusive lock of drafts can now be configured using cds.drafts.cancellationTimeout req.params : iterable with key value pairs for the key predicates of the addressed resource Fixed \u00b6 Custom handler registration in multi tenant scenario alias in associations was not processed correctly in post processing $search is now applied on the query result of $apply as specified in OData V4 spec evictionRunIntervalMillisForPools is now treated properly POST/PATCH requests on Composition of many with backlink association as key Version 1.1.1 - 2020-04-28 \u00b6 Added \u00b6 Support for orderBy in rest client Changed \u00b6 limit in CQN is translated to placeholders in SQL Per default, results are now ordered by keys of the entity Fixed \u00b6 CREATE now returns context.data if not all non-UUID keys are provided and no error is thrown in the database client CANCEL and PATCH drafts now supports multiple fields in where clauses Handler registration for draft events in multi tenancy scenario Localize expanded entities Composition and Association to one with expand in draft case Disable local default pagination via @cds.query.limit.default: 0 Version 1.1.0 - 2020-04-23 \u00b6 Added \u00b6 Support for CREATE operations with delegated key generation @cds.persistence.skip annotated entities return HTTP code 501 in generic handlers Introduced @cds.localized:false on entity level for switching off automatic redirection to localized views Server-side pagination on global, service, and entity level via @cds.query.limit Omitted key predicates of nested composition items are augmented, if possible The exclusive lock of a draft automatically times out after 15 minutes Static where annotations for RUD Associations to one annotated with @assert.integrity: false are ignored on integrity checks Support input validation annotations in ODATA Changed \u00b6 Object notation in .where of statements does not allow functions anymore context.diff() ignores @cds.persistence.skip annotated entities Always try to read from localized view (also by draft enabled entities) In multitenant scenario, the CSN model is now always loaded from @sap/cds-mtx . Previously, it was only loaded if it was extended. Use open source version of @sap-cloud-sdk/core If a column or column alias is used multiple times in a SELECT query, the query is from now on rejected. Example: SELECT.from(Foo).columns(['c1', 'c1']) Fixed \u00b6 Reference integrity checks for foreign entities without stored keys Calculation of HasActiveEntity Update and Delete with where annotations Aliases by navigation with complex where annotation req._.res is express' ServerResponse SQL Error in case of $filter using ne operator in combination with $search Deep update with immutable fields in child entities Draft union scenario in case of DraftAdministrativeData navigation Transaction handling inside $batch requests Multiple aliases in SELECT.columns Use hdb if in direct dependencies of app (and @sap/hana-client is not) Mapping over a result will propagate $count Don't ignore rows with null column values in negated $search queries Changelog History \u00b6 The CDS Runtime module is the successor of @sap/cds-services , @sap/cds-messaging , @sap/cds-rest , @sap/cds-hana , @sap/cds-sqlite and @sap/cds-sql . The changelogs of these components can be found here: * CHANGELOG cds-services * CHANGELOG cds-messaging * CHANGELOG cds-rest * CHANGELOG cds-hana * CHANGELOG cds-sqlite * CHANGELOG cds-sql","title":"Changelog"},{"location":"apis/cds-runtime/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-runtime/CHANGELOG/#version-122-2020-05-27","text":"","title":"Version 1.2.2 - 2020-05-27"},{"location":"apis/cds-runtime/CHANGELOG/#changed","text":"Updated version for internal release","title":"Changed"},{"location":"apis/cds-runtime/CHANGELOG/#version-121-2020-05-20","text":"","title":"Version 1.2.1 - 2020-05-20"},{"location":"apis/cds-runtime/CHANGELOG/#added","text":"The timeout of the exclusive lock of drafts can now be configured using cds.drafts.cancellationTimeout req.params : iterable with key value pairs for the key predicates of the addressed resource","title":"Added"},{"location":"apis/cds-runtime/CHANGELOG/#fixed","text":"Custom handler registration in multi tenant scenario alias in associations was not processed correctly in post processing $search is now applied on the query result of $apply as specified in OData V4 spec evictionRunIntervalMillisForPools is now treated properly POST/PATCH requests on Composition of many with backlink association as key","title":"Fixed"},{"location":"apis/cds-runtime/CHANGELOG/#version-111-2020-04-28","text":"","title":"Version 1.1.1 - 2020-04-28"},{"location":"apis/cds-runtime/CHANGELOG/#added_1","text":"Support for orderBy in rest client","title":"Added"},{"location":"apis/cds-runtime/CHANGELOG/#changed_1","text":"limit in CQN is translated to placeholders in SQL Per default, results are now ordered by keys of the entity","title":"Changed"},{"location":"apis/cds-runtime/CHANGELOG/#fixed_1","text":"CREATE now returns context.data if not all non-UUID keys are provided and no error is thrown in the database client CANCEL and PATCH drafts now supports multiple fields in where clauses Handler registration for draft events in multi tenancy scenario Localize expanded entities Composition and Association to one with expand in draft case Disable local default pagination via @cds.query.limit.default: 0","title":"Fixed"},{"location":"apis/cds-runtime/CHANGELOG/#version-110-2020-04-23","text":"","title":"Version 1.1.0 - 2020-04-23"},{"location":"apis/cds-runtime/CHANGELOG/#added_2","text":"Support for CREATE operations with delegated key generation @cds.persistence.skip annotated entities return HTTP code 501 in generic handlers Introduced @cds.localized:false on entity level for switching off automatic redirection to localized views Server-side pagination on global, service, and entity level via @cds.query.limit Omitted key predicates of nested composition items are augmented, if possible The exclusive lock of a draft automatically times out after 15 minutes Static where annotations for RUD Associations to one annotated with @assert.integrity: false are ignored on integrity checks Support input validation annotations in ODATA","title":"Added"},{"location":"apis/cds-runtime/CHANGELOG/#changed_2","text":"Object notation in .where of statements does not allow functions anymore context.diff() ignores @cds.persistence.skip annotated entities Always try to read from localized view (also by draft enabled entities) In multitenant scenario, the CSN model is now always loaded from @sap/cds-mtx . Previously, it was only loaded if it was extended. Use open source version of @sap-cloud-sdk/core If a column or column alias is used multiple times in a SELECT query, the query is from now on rejected. Example: SELECT.from(Foo).columns(['c1', 'c1'])","title":"Changed"},{"location":"apis/cds-runtime/CHANGELOG/#fixed_2","text":"Reference integrity checks for foreign entities without stored keys Calculation of HasActiveEntity Update and Delete with where annotations Aliases by navigation with complex where annotation req._.res is express' ServerResponse SQL Error in case of $filter using ne operator in combination with $search Deep update with immutable fields in child entities Draft union scenario in case of DraftAdministrativeData navigation Transaction handling inside $batch requests Multiple aliases in SELECT.columns Use hdb if in direct dependencies of app (and @sap/hana-client is not) Mapping over a result will propagate $count Don't ignore rows with null column values in negated $search queries","title":"Fixed"},{"location":"apis/cds-runtime/CHANGELOG/#changelog-history","text":"The CDS Runtime module is the successor of @sap/cds-services , @sap/cds-messaging , @sap/cds-rest , @sap/cds-hana , @sap/cds-sqlite and @sap/cds-sql . The changelogs of these components can be found here: * CHANGELOG cds-services * CHANGELOG cds-messaging * CHANGELOG cds-rest * CHANGELOG cds-hana * CHANGELOG cds-sqlite * CHANGELOG cds-sql","title":"Changelog History"},{"location":"apis/cds-services/","text":"CDS Services \u00b6 This package handles the generation of an OData service using the provided model. It is possible to start N services per server and each service has its own endpoint. This package also offers the possibility to register custom handlers for performing create, read, update and delete operations. Overview \u00b6 TBD Prerequisites \u00b6 Dependencies: * @sap/cds-ql * @sap/odata-server Installation \u00b6 npm install Usage/Configuration \u00b6 Examples \u00b6 Following is an example of the service factory, which will create an OData Service: const serviceInstance = cds.service('cat-service', {}, function() { this.use((req,res,next)=>{/* ... */}) }) serviceInstance.use ((req,res,next)=>{/* ... */}) OData Requests Supported by Generic Handlers \u00b6 Request Description POST /Employees create entity; if UUID key exists, UUID is generated if it is not provided PUT /Employees(4) update entity; Complete or subset of properties, 404 if entity cannot be found DELETE /Employees(4) delete entity; 404 if entity cannot be found GET /Employees read collection GET /Employees/$count get the number of elements in a collection GET /Employees(4) read entity; 404 if entity cannot be found GET /Authors(4)/name read property of entity GET /Citations(source=1,target=3) read entity with multiple key elements GET /Employees?$filter=birthyear eq 1980 filter collection GET /Employees/$count?$filter=birthyear eq 1980 count the number of elements in a collection after applying the filter GET /Employees?$orderby=birthyear desc,name asc order collection GET /Employees?$top=1 read first N records of collection GET /Employees?$top=1&$skip=2 read first N records of collection after skipping M records GET /Employees?$skip=2 read collection after skipping N records GET /Employees?$select=id,birthyear read subset of properties per entity GET /Employees?$count=true read collection and include the number of elements in the result set (can be combined with to-many-associations, $top, $skip, $orderby and $filter. Note that $filter will be reflected in the number of elements) GET /Books(3)/author navigation via managed or unmanaged to-one association GET /Books(3)/orders navigation via managed to-many association (with or w/o $self) GET /Books(3)/orders(6a48328d-55f8-4c0a-8974-433ca4421b26)/book/author/name navigation with multiple path segments GET /Employees?odata-debug=json Show debug output in json format if enabled (configurable parameter 'debug: true' when service is created) GET /Employees?odata-debug=html Show debug output in html format if enabled (configurable parameter 'debug: true' when service is created) Reference \u00b6 TBD","title":"CDS Services #"},{"location":"apis/cds-services/#cds-services","text":"This package handles the generation of an OData service using the provided model. It is possible to start N services per server and each service has its own endpoint. This package also offers the possibility to register custom handlers for performing create, read, update and delete operations.","title":"CDS Services"},{"location":"apis/cds-services/#overview","text":"TBD","title":"Overview"},{"location":"apis/cds-services/#prerequisites","text":"Dependencies: * @sap/cds-ql * @sap/odata-server","title":"Prerequisites"},{"location":"apis/cds-services/#installation","text":"npm install","title":"Installation"},{"location":"apis/cds-services/#usageconfiguration","text":"","title":"Usage/Configuration"},{"location":"apis/cds-services/#examples","text":"Following is an example of the service factory, which will create an OData Service: const serviceInstance = cds.service('cat-service', {}, function() { this.use((req,res,next)=>{/* ... */}) }) serviceInstance.use ((req,res,next)=>{/* ... */})","title":"Examples"},{"location":"apis/cds-services/#odata-requests-supported-by-generic-handlers","text":"Request Description POST /Employees create entity; if UUID key exists, UUID is generated if it is not provided PUT /Employees(4) update entity; Complete or subset of properties, 404 if entity cannot be found DELETE /Employees(4) delete entity; 404 if entity cannot be found GET /Employees read collection GET /Employees/$count get the number of elements in a collection GET /Employees(4) read entity; 404 if entity cannot be found GET /Authors(4)/name read property of entity GET /Citations(source=1,target=3) read entity with multiple key elements GET /Employees?$filter=birthyear eq 1980 filter collection GET /Employees/$count?$filter=birthyear eq 1980 count the number of elements in a collection after applying the filter GET /Employees?$orderby=birthyear desc,name asc order collection GET /Employees?$top=1 read first N records of collection GET /Employees?$top=1&$skip=2 read first N records of collection after skipping M records GET /Employees?$skip=2 read collection after skipping N records GET /Employees?$select=id,birthyear read subset of properties per entity GET /Employees?$count=true read collection and include the number of elements in the result set (can be combined with to-many-associations, $top, $skip, $orderby and $filter. Note that $filter will be reflected in the number of elements) GET /Books(3)/author navigation via managed or unmanaged to-one association GET /Books(3)/orders navigation via managed to-many association (with or w/o $self) GET /Books(3)/orders(6a48328d-55f8-4c0a-8974-433ca4421b26)/book/author/name navigation with multiple path segments GET /Employees?odata-debug=json Show debug output in json format if enabled (configurable parameter 'debug: true' when service is created) GET /Employees?odata-debug=html Show debug output in html format if enabled (configurable parameter 'debug: true' when service is created)","title":"OData Requests Supported by Generic Handlers"},{"location":"apis/cds-services/#reference","text":"TBD","title":"Reference"},{"location":"apis/cds-services/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.27.1 - 2020-03-23 \u00b6 Fixed \u00b6 Alias was added twice to CQN in case of a request including navigations on a draft enabled entity Version 1.27.0 - 2020-03-19 \u00b6 Added \u00b6 Transaction uses one timestamp for all queries Pool acquire timeout is set by default and can be configured in pool options Ordered OData singletons ( ... as select from <entity> order by <property> ) Changed \u00b6 $count=true triggers handlers only once now draftPrepare action can be called on the entity set of child nodes of the draft enabled entity Normalize user.id if an email address Allow functions and properties as 2nd param in contains, startswith, endswith Fixed \u00b6 Entity is now correctly resolved if there are conflicting names Where conditions from security annotations were appended twice when using $count=true req._.req always contains the incoming request - also in $batch requests Error in delete when fields are renamed in views Using view by draft & localized context.diff() returns changes also for PATCH of drafts OData requests using /$count on navigation-to-many Authentication-requirement detected if in multi tenant mode (i.e., multiTenant: true ) Integrity check of atomicity group Where annotation in case of draft and navigations /$count on parameterized views Streaming from draft in case localized and where annotations @mandatory: empty strings (whitespaces only = empty) are not allowed Version 1.25.1 - 2020-02-26 \u00b6 Fixed \u00b6 update of localized text entries replies with 403 if no changes are detected Removed \u00b6 npm-shrinkwrap.json Version 1.25.0 - 2020-02-25 \u00b6 Added \u00b6 Support for OData singletons Streaming from draft Navigations in aggregate expressions Changed \u00b6 use odata-server 1.5.2 Fixed \u00b6 handling of virtual field in column generation callstack exceeded in SELECT Version 1.24.1 - 2020-02-21 \u00b6 Added \u00b6 Support draft for localized texts (to be enabled by @sap/cds and @sap/cds-compiler) Version 1.24.0 - 2020-02-20 \u00b6 Added \u00b6 Support for OData $apply with count distinct Changed \u00b6 use odata-server 1.5.1 Fixed \u00b6 Column generation for SELECT.from() queries without specifying .columns() HasDraftEntity was not properly calculated Virtual properties were not excluded Where secure annotations with localized entities Handling of @cds.on.insert/update annotated properties of draft-enabled entities Keys in root element were not correctly calculated for deep operations @Core.MediaType could not be used in entity annotated with @cds.persistence.skip Removed \u00b6 Annotation @Search.fuzzinessThreshold Version 1.23.0 - 2020-02-05 \u00b6 Added \u00b6 Support non-UUID field as ETags Support draft and ETags Support for complex where in annotations Additional argument target for req.info Changed \u00b6 Direct access to auto-exposed entities in draft case Errors normalized based on OData v4 standard Messages (i.e., header sap-messages ) normalized based on Fiori standard Referential integrity checks are now executed before the commit Result of create and update queries is read from the data source to include computed values (update: root only, i.e., w/o compositons, etc.) Fixed \u00b6 Race condition when there are erros when saving draft Handling of where from @restrict annotation of draft enabled entity Saving a draft will not ignore readonly fields anymore Not having a connection for unauthorized users will not crash the server anymore In mocked authorization, users don't need the ID property Filtering using the NE operator handles null values properly For insertable-only entities default values are correctly handled now Immutable values are now ignored during PATCH or UPDATE requests Batch input via REST SELECT * by customer handlers will work also on Hana in case the columns are lowercase Support \"userAttributes\" by Mocked Authentication, \"xs.user.attributes\" is deprecated and will be removed in the next releases Arbitrary users are allowed if fake user '*'= true exist by Mocked Authentication Version 1.22.0 - 2019-12-11 \u00b6 Added \u00b6 @sap/cds-ql merged into @sap/cds-services Support for subselects and aliasing for remote service definitions Support for @cds.persistence.table . Actions/functions support $select and $expand query params in odata Support cds annotation on insert and update with # (e.g @cds.on.update: #user) Changed \u00b6 Improve error messages for return type validation of custom operations Draft removal is handled in onDraftActivateEvent instead of onDraftActivate Fixed \u00b6 Check whether service requires authentication Independent passport configs per service Version 1.21.2 - 2019-12-03 \u00b6 Fixed \u00b6 Default values for patch Version 1.21.1 - 2019-11-29 \u00b6 Added \u00b6 Authentication strategy debug messages and error messages for erroneous authentication configurations Fixed \u00b6 Transform redirect properties in post processing Version 1.21.0 - 2019-11-19 \u00b6 Added \u00b6 Support for reading temporal data on HANA Support ETag at odata-v4 Fixed \u00b6 Key generation in deep update Reading DraftAdministrativeData of an active entry without existing draft Version 1.20.1 - 2019-10-30 \u00b6 Changed \u00b6 Updated version of @sap/cds-ql to 1.20.1 Version 1.20.0 - 2019-10-29 \u00b6 Added \u00b6 req.method property which contains the HTTP method Return type validation for custom operations in rest Support for redirected media properties using @Core.IsURL Fixed \u00b6 Requests to $metadata Removed \u00b6 npm-shrinkwrap.json req._.isPatch Version 1.19.1 - 2019-10-16 \u00b6 Changed \u00b6 Improved error messages Fixed \u00b6 Empty user attributes in where conditions Queries in custom handler executed twice Version 1.19.0 - 2019-10-02 \u00b6 Added \u00b6 Check of source for navigation-to-one in not Draft case log function in default logger Changed \u00b6 Improved error messages Use @sap/odata-server@1.3.8 Fixed \u00b6 Draft service having column names from draft admin table POST and PUT on views with renaming and excluding Draft with custom oncond in backlink Batch with multitenancy Version 1.18.2 - 2019-09-19 \u00b6 Changed \u00b6 Use @sap/odata-server@1.3.7 Version 1.18.1 - 2019-09-18 \u00b6 Added \u00b6 Support of authorization restrictions with simple static where clauses (e.g. $user.level = 3 ) for actions/functions Fixed \u00b6 Draft activation by multiple views Binary processing in rest adapter Version 1.18.0 - 2019-09-09 \u00b6 Added \u00b6 Support for @assert.enum annotation Support for media content-type provided as property Support for binary encoding in rest Changed \u00b6 Use @sap/odata-server@1.3.5 Fixed \u00b6 READ with @cds.api.ignore annotation Navigation on Entities with multiple keys did not work correctly UPDATE and UPSERT requests with @cds.on.update and @cds.on.insert annotations Logging of missing permissions if no authentication strategy is detected Version 1.17.0 - 2019-08-21 \u00b6 Added \u00b6 Error handling for streaming Limited support for CREATE requests via navigations Method .transaction to local client Changed \u00b6 CREATE with WHERE restriction is supported only with static checks, otherwise rejected Extended error logs from custom handlers next() returns the result of the subsequent handler Use @sap/cds-messaging for sending/receiving events between services Fixed \u00b6 Expand entity with where restriction when clause references a user attribute with multiple values Navigations in get requests using cds.String as key type Deletion of active entries during draft activation Checking security annotations in service and in entities UUID generation for deep inserts/updates Combination of localized data and $count=true in OData requests req.query in case of bound actions and reached via navigation Version 1.16.0 - 2019-07-23 \u00b6 Added \u00b6 Batch Update in REST Adapter using an Array as request body Content-Type for streaming using annotation DELETE requests on an entity property sets the property to null Integrity check for DELETE requests Changed \u00b6 Behaviour of mock authentication according to documentation cds.env is used by authentication if passport not provided in options Fixed \u00b6 Draft actions for localized entities Write localized data via deep update/insert Version 1.15.0 - 2019-07-09 \u00b6 Added \u00b6 Support for views with parameters Support for filter transformation in $apply Support for /$value on primitive properties Changed \u00b6 Rest adapter accepts non-modelled data fields in the request payload and exposes them in req.data ; the fields are ignored in the generic handlers Replaced @sap/cds-ql dependency with uuid Fixed \u00b6 Custom handlers by extended tenants Generic handler lookup if multiple services in one .cds file $expand with instance-based authorization result parameter in AfterHandler has correct format (not always an array) CREATE : the created entity UPDATE : the updated entity DELETE : undefined for actions and functions it is the defined return type @cds.on.insert and @cds.on.update could not be used at the same time @cds.on.insert and @cds.on.update in deep insert / update Version 1.14.0 - 2019-06-24 \u00b6 Added \u00b6 Alternative mock strategy config Support for value ranges annotations for REST adapter Multiple authentication strategies Changed \u00b6 Handling of deep insert / update for associations Use @sap/odata-server@1.3.4 Fixed \u00b6 Bound actions for draft-enabled entities Combination of $apply with other query parameters Removed \u00b6 Caching of metadata as odata already does it Version 1.13.0 - 2019-06-07 \u00b6 Added \u00b6 Method diff to calculate the actual changes in a CUD request or while saving a draft Support authorization annotations for actions and functions Support for default sort order using @cds.default.order or @odata.default.order Support for writing binary stream through odata Version 1.12.0 - 2019-05-24 \u00b6 Added \u00b6 Support for localized in generic handlers (no compositions / associations) Handler registration by path for autoexposed and redirected entities Support for Rest parametric functions and actions Changed \u00b6 Renamed Service.with to Service.impl Fixed \u00b6 falsy values as default value req.info in case of draft actions Scopes are checked before custom before handlers Version 1.11.1 - 2019-05-16 \u00b6 Changed \u00b6 service.options is now a public property (previously private as service._options ) Version 1.11.0 - 2019-05-15 \u00b6 Added \u00b6 read-only field annotations validation Deactivate ResourceJsonSerializer in production Validation for content type in rest adapter Support for OData request path expressions \u00e0 la Authors/1 Changed \u00b6 Use @sap/odata-server@1.3.3 Version 1.10.2 - 2019-05-08 \u00b6 Added \u00b6 Support for @Capabilities annotations Changed \u00b6 Improved performance by reducing calls to process.nextTick() Fixed \u00b6 Unbound actions and functions in REST Version 1.10.1 - 2019-05-07 \u00b6 Added \u00b6 error handling in case mtx errors Changed \u00b6 Handler registration using .with (as done in reuse scenarios) Fixed \u00b6 Using $select=association in odata-v4 adapter Version 1.10.0 - 2019-05-03 \u00b6 Added \u00b6 Support for reading streams in odata v4 Support for batch create in REST adapter Support for combination of scopes and instance based authorization checks Fiori Draft event SAVE as alias for CREATE and UPDATE Changed \u00b6 Improved performance Version 1.9.0 - 2019-04-16 \u00b6 Added \u00b6 'mock' strategy accepts any user credentials if none configured Support for pseudo role 'system-user' Additional cases at security annotations sap-statistics=true as query or header parameter will yield performance statistics $top and $skip at rest adapter Changed \u00b6 Handlers for failed events must only have the error object as an argument Handlers for succeeded and done events must have no argument at all used new function notation in generated CQN Reduction of round trips to data source by not using transactional blocks at reading requests Fixed \u00b6 Deep operations in REST adapter Draft edit in case one composition has no entries Version 1.8.1 - 2019-04-03 \u00b6 Fixed \u00b6 Events are populated through req.event Version 1.8.0 - 2019-03-29 \u00b6 Added \u00b6 after handlers using each or row also work with keyword async Changed \u00b6 Generic onCommit or onRollback handlers end the transaction of potentially multiple db sessions in the request context Merged client adapter into service Fixed \u00b6 Errors not of type Error are not recognized req.target in case of a READ request of the DraftAministrativeData entity Version 1.7.2 - 2019-03-25 \u00b6 Added \u00b6 Element/Field annotated with @mandatory or @FieldControl.Mandatory is treated as not null Added 'mock' strategy for passport Complex cases at security annotations When registering custom handlers for transactional draft events the target property of the req parameter now points to the draft Version 1.7.1 - 2019-03-20 \u00b6 Fixed \u00b6 Passport is registered correctly in case of cds.serve('all') User is now set before it is needed Version 1.7.0 - 2019-03-19 \u00b6 Added \u00b6 req.event contains the type or name of the incoming request Support for specifying a target in req.error and req.reject req.info to collect info messages in odata-v4. Eventually, they result in the sap-messages header. Annotation @Search.fuzzinessThreshold to configure Fuzzy Search Support for Extensibility Event handlers for events succeeded , failed and done can be registered at the service event context Support for OData Arithmetic Functions , Date and Time Functions , String Functions Changed \u00b6 before handlers are executed in parallel req.error returns a generic error with all collected errors in .details passport method is extracted to the package interface Fixed \u00b6 No SQL error in case key is generated by DB like done with sequences Version 1.6.0 - 2019-02-25 \u00b6 Added \u00b6 Support for Lambda operators Fixed \u00b6 CUD operation with association as key of entity Version 1.5.2 - 2019-02-13 \u00b6 Added \u00b6 Support for sql functions lower, upper, trim, length in $filter and $orderby Changed \u00b6 Sync functions at before and after handler are not wrapped in promise anymore req.reject does not throw anymore @sap/audit-logging only used in case the service is provided via VCAP_SERVICES Unknown query parameters are not longer rejected at REST adapter Fixed \u00b6 OData version for $metadata Multiple atomicity groups should not share same transaction block Brackets in $filter now work correctly Version 1.5.1 - 2019-02-12 \u00b6 Changed \u00b6 @sap/audit-logging only used in case the service is provided via VCAP_SERVICES Fixed \u00b6 No integrity checks when running without db connection Version 1.5.0 - 2019-02-07 \u00b6 Added \u00b6 Set foreign keys for POST via navigation-to-many and modeled with $self Support content id placeholders in odata v4 batch requests Support complex cases at security annotations Changed \u00b6 Referential integrity checks do not run for associations with specified on conditions Rest adapter now ignores query parameters Minimum node version 8.9.0 .data and .query can be overwritten Fixed \u00b6 Insert with excluded properties having default values Delete active documents in a draft-enabled service without a draft Path segment /$count respects $filter Version 1.4.0 - 2019-01-22 \u00b6 Added \u00b6 When registering service handlers, entities can be given as a list Support requests to /SiblingEntity in draft Annotation @cds.integrity.skip to disable reference integrity checks (experimental!) Changed \u00b6 Replaced @sap/odata-v4 by @sap/odata-server Version 1.3.0 - 2019-01-11 \u00b6 Added \u00b6 Authorization filtering and user attributes as lists Referential integrity checks Fixed \u00b6 No fallback for user identifier in case the user object is empty Reading draft administrative data Version 1.2.0 - 2018-12-21 \u00b6 Added \u00b6 Set default values in case of CREATE, UPSERT and adding a child in deep documents Changed \u00b6 context.draftMetadata contains draft metadata context.isDraftChange indicates only changes in drafts Error messages to be more consistent Fixed \u00b6 On handler registration for custom handlers in draft Draft children can be deleted without navigations Reading all draft-enabled documents takes into account only own drafts Removed \u00b6 Version 1.1.0 - 2018-12-12 \u00b6 Added \u00b6 Deep Document Calls (deep insert, deep update and cascade delete) context.draft contains draftUUID in case of Create, Update or Delete filter and orderby with navigation Changed \u00b6 improved error messages Activating a draft now triggers the 'UPDATE' or 'CREATE' event Fixed \u00b6 Create Draft uses default values draftActivate uses correct keys for update $count in draft context now calculates correct result db view with select Support for navigation over draft with count .code property of Errors in Custom handlers will not be overwritten Version 1.0.0 - 2018-11-27 \u00b6 Added \u00b6 Support for now function in $filter Support for authorization annotations CREATE, UPDATE, DELETE Conversion of cds.DateTime/Timestamp using UTC Entity definition at service as select view Changed \u00b6 Update entry makes insert if the entry doesn't exist Log messages are used directly instead of being wrapped Bound functions now have a query value Function next is implicitly executed in synchronous on-handlers Improved error handling Handler registration allows following variations: Array of events: e.g. ['READ', 'UPDATE'] '*' wildcard for any entity event next() throws error if called twice in same handler Custom implementation must be provided via .with Renamed service.definition to service.model Renamed service.service to service.name updated odata-v4 version to 1.8.0 Location header for draft actions is now relative Fixed \u00b6 POST on existing entity throws 'Bad Request' $search and $filter in combination with some read draft cases POST with navigation does not create a new key Access restriction on service level UPDATE sql statement generated wrong for entity with multiple keys Access to user's locale draftEdit action on entities without children CREATE with not nullable elements Version 0.12.0 - 2018-10-17 \u00b6 Added \u00b6 Custom handlers can be registered and executed for bound functions and function imports Added BeforeCreate and BeforeCreateDraft handlers to generate needed UUIDs Changed \u00b6 Removed translator in the insert based on where by instanced based authorization Removed internal event rejections Not found error message generalized for reading through navigation Refactoring and changes due to updated dependencies Version 0.11.0 - 2018-10-04 \u00b6 Added \u00b6 Generic support for Create, Update, Delete on draft-enabled entities Generic support for draftEdit, draftPrepare, draftActivate actions Logger is available in handlers via context.log Changed \u00b6 Log warning if database connection is missing Fixed \u00b6 Service requests now return promises instead of thenables Version 0.10.1 - 2018-09-18 \u00b6 Added \u00b6 Generic support for Read on draft-enabled entities Fixed \u00b6 $user annotation works without authorization Version 0.10.0 - 2018-09-17 \u00b6 Added \u00b6 Delete Draft Audit Logging of GDPR related events Auto lookup of to be used CF/XSA services from environmental VCAP_SERVICES OData to context.query for nested $filter, $orderby, $op and $skip at $expand Custom types on top of associations Changed \u00b6 Default for maxPageSize increased to 1000 from 100 Fixed \u00b6 Values for annotated columns (user/now) are included in the response Version 0.9.2 - 2018-09-05 \u00b6 Changed \u00b6 Improved npm-shrinkwrap Version 0.9.1 - 2018-09-03 \u00b6 Added \u00b6 Create draft Removed \u00b6 implicit dependency to @sap/cds-sql Version 0.9.0 - 2018-08-28 \u00b6 Added \u00b6 API to support the implementation of authorization restrictions Local service client Support for to-one-navigation in $filter Support for annotation @Search.defaultSearchElement to restrict searchable columns in $search Support for sap-language query parameter Support authorization annotations Hooks to add custom logic before and after rollback event Audit Logging of security events Fixed \u00b6 Pagination in case of $expand $select with managed associations as key Version 0.8.1 - 2018-08-09 \u00b6 Added \u00b6 Authentication using passport (including user/attr proxy) Changed \u00b6 Require submodules on demand Version 0.8.0 - 2018-08-07 \u00b6 Added \u00b6 OData Service: $search supports Unary and Binary Expressions without brackets Registration of global handler using star symbol like \"this.on('*', () => {})\" Registration of express middleware using this.use() Improved FeautureNotSupported error message context.reject supported for before, on and after handlers Changed \u00b6 Updated version of @sap/odata-v4 to ^1.6.0 Fixed \u00b6 Localization in case language is changed Issue with not working $count when filtering active in custom hook Version 0.7.0 - 2018-07-11 \u00b6 Added \u00b6 Localization support for $metadata Support for Compositions Fixed \u00b6 $search also considers foreign keys of managed associations, structured elements and complex types Version 0.6.0 - 2018-07-02 \u00b6 Added \u00b6 Multi tenancy support Fixed \u00b6 Columns are only added once to CQN in case of $expand in combination with $select Version 0.5.0 - 2018-06-25 \u00b6 Added \u00b6 Hooks An any handler can be registered and will be executed for any but COMMIT events Custom handlers can be registered for before COMMIT and after COMMIT events \"_\" property added to cds handler argument, which can contain adapter specific data like a request object OData Service $filter supports (not) contains, startsWith, endsWith $filter supports combinations with and/or $select within $expand $apply supported with limited scope $search supported with limited scope Changed \u00b6 Hooks Undocumented OData specific properties removed from \"cds\" handler argument cds.target contains the unreflected entity instead of the reflected entity cds.error will collect errors and throw at the end of each block of .before, .on or .after handlers Second call to next() at a on handler will be ignored and not break the sequence Fixed \u00b6 Support navigation over entities with multiple keys Removed \u00b6 In case of a SerializationError the details are only logged and not provided in the response anymore Version 0.4.1 - 2018-05-03 \u00b6 Changed \u00b6 Updated version of @sap/cds-ql to 0.4.1 Version 0.4.0 - 2018-05-02 \u00b6 Added \u00b6 service factory cds used via injection Hooks Support annotations @insertonly and @readonly Support reject registration for CSN entities Support reject registration with multiple entity parameters Changed \u00b6 default logger uses matching methods from console object instead of console.log packages are loaded on demand at Services.js and OData.js instead of required in any case adapted error message in case of 501 Version 0.3.0 - 2018-04-16 \u00b6 Added \u00b6 service factory service.entities is set OData Service Support for $expand=* Support for $select=* Hooks CSN entities can be used instead of strings to register a handler .on can be registered with CQN instead of function as handler .on supports registering N handlers .on handlers can use a second argument next() .on can be finished by returning a value .after with convenience wrappers for each|row argument .after can now work asynchronously Changed \u00b6 server side paging is enabled by default and set to 100, to disable it set maxPageSize to false. refactored service factory removed option to compile CSN on the fly, only CSN accepted as input format option to set the URL path is removed Multi service CSN can be used refactored Service class OData service instantiation is now split in constructor, createODataService and getMiddleWare OData Service Renamed parameters in handler context object (target replaces entity and getEntity) More expressive error messages Crash Node.js instance on unhandled error Fixed \u00b6 limit property is only added to CQN if necessary .reply() is able to handle null values Version 0.2.0 - 2018-03-16 \u00b6 Added \u00b6 option to enable debug mode for odata-v4 default logger with option to register custom logger support for server side paging support for cds.serve, which is a Fluent API-style method to read service definitions from the given model(s) and construct services usage of npm-shrinkwrap Fixed \u00b6 $filter in combination with to many association","title":"Changelog"},{"location":"apis/cds-services/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-services/CHANGELOG/#version-1271-2020-03-23","text":"","title":"Version 1.27.1 - 2020-03-23"},{"location":"apis/cds-services/CHANGELOG/#fixed","text":"Alias was added twice to CQN in case of a request including navigations on a draft enabled entity","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1270-2020-03-19","text":"","title":"Version 1.27.0 - 2020-03-19"},{"location":"apis/cds-services/CHANGELOG/#added","text":"Transaction uses one timestamp for all queries Pool acquire timeout is set by default and can be configured in pool options Ordered OData singletons ( ... as select from <entity> order by <property> )","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed","text":"$count=true triggers handlers only once now draftPrepare action can be called on the entity set of child nodes of the draft enabled entity Normalize user.id if an email address Allow functions and properties as 2nd param in contains, startswith, endswith","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_1","text":"Entity is now correctly resolved if there are conflicting names Where conditions from security annotations were appended twice when using $count=true req._.req always contains the incoming request - also in $batch requests Error in delete when fields are renamed in views Using view by draft & localized context.diff() returns changes also for PATCH of drafts OData requests using /$count on navigation-to-many Authentication-requirement detected if in multi tenant mode (i.e., multiTenant: true ) Integrity check of atomicity group Where annotation in case of draft and navigations /$count on parameterized views Streaming from draft in case localized and where annotations @mandatory: empty strings (whitespaces only = empty) are not allowed","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1251-2020-02-26","text":"","title":"Version 1.25.1 - 2020-02-26"},{"location":"apis/cds-services/CHANGELOG/#fixed_2","text":"update of localized text entries replies with 403 if no changes are detected","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#removed","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-services/CHANGELOG/#version-1250-2020-02-25","text":"","title":"Version 1.25.0 - 2020-02-25"},{"location":"apis/cds-services/CHANGELOG/#added_1","text":"Support for OData singletons Streaming from draft Navigations in aggregate expressions","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_1","text":"use odata-server 1.5.2","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_3","text":"handling of virtual field in column generation callstack exceeded in SELECT","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1241-2020-02-21","text":"","title":"Version 1.24.1 - 2020-02-21"},{"location":"apis/cds-services/CHANGELOG/#added_2","text":"Support draft for localized texts (to be enabled by @sap/cds and @sap/cds-compiler)","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#version-1240-2020-02-20","text":"","title":"Version 1.24.0 - 2020-02-20"},{"location":"apis/cds-services/CHANGELOG/#added_3","text":"Support for OData $apply with count distinct","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_2","text":"use odata-server 1.5.1","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_4","text":"Column generation for SELECT.from() queries without specifying .columns() HasDraftEntity was not properly calculated Virtual properties were not excluded Where secure annotations with localized entities Handling of @cds.on.insert/update annotated properties of draft-enabled entities Keys in root element were not correctly calculated for deep operations @Core.MediaType could not be used in entity annotated with @cds.persistence.skip","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#removed_1","text":"Annotation @Search.fuzzinessThreshold","title":"Removed"},{"location":"apis/cds-services/CHANGELOG/#version-1230-2020-02-05","text":"","title":"Version 1.23.0 - 2020-02-05"},{"location":"apis/cds-services/CHANGELOG/#added_4","text":"Support non-UUID field as ETags Support draft and ETags Support for complex where in annotations Additional argument target for req.info","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_3","text":"Direct access to auto-exposed entities in draft case Errors normalized based on OData v4 standard Messages (i.e., header sap-messages ) normalized based on Fiori standard Referential integrity checks are now executed before the commit Result of create and update queries is read from the data source to include computed values (update: root only, i.e., w/o compositons, etc.)","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_5","text":"Race condition when there are erros when saving draft Handling of where from @restrict annotation of draft enabled entity Saving a draft will not ignore readonly fields anymore Not having a connection for unauthorized users will not crash the server anymore In mocked authorization, users don't need the ID property Filtering using the NE operator handles null values properly For insertable-only entities default values are correctly handled now Immutable values are now ignored during PATCH or UPDATE requests Batch input via REST SELECT * by customer handlers will work also on Hana in case the columns are lowercase Support \"userAttributes\" by Mocked Authentication, \"xs.user.attributes\" is deprecated and will be removed in the next releases Arbitrary users are allowed if fake user '*'= true exist by Mocked Authentication","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1220-2019-12-11","text":"","title":"Version 1.22.0 - 2019-12-11"},{"location":"apis/cds-services/CHANGELOG/#added_5","text":"@sap/cds-ql merged into @sap/cds-services Support for subselects and aliasing for remote service definitions Support for @cds.persistence.table . Actions/functions support $select and $expand query params in odata Support cds annotation on insert and update with # (e.g @cds.on.update: #user)","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_4","text":"Improve error messages for return type validation of custom operations Draft removal is handled in onDraftActivateEvent instead of onDraftActivate","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_6","text":"Check whether service requires authentication Independent passport configs per service","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1212-2019-12-03","text":"","title":"Version 1.21.2 - 2019-12-03"},{"location":"apis/cds-services/CHANGELOG/#fixed_7","text":"Default values for patch","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1211-2019-11-29","text":"","title":"Version 1.21.1 - 2019-11-29"},{"location":"apis/cds-services/CHANGELOG/#added_6","text":"Authentication strategy debug messages and error messages for erroneous authentication configurations","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_8","text":"Transform redirect properties in post processing","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1210-2019-11-19","text":"","title":"Version 1.21.0 - 2019-11-19"},{"location":"apis/cds-services/CHANGELOG/#added_7","text":"Support for reading temporal data on HANA Support ETag at odata-v4","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_9","text":"Key generation in deep update Reading DraftAdministrativeData of an active entry without existing draft","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1201-2019-10-30","text":"","title":"Version 1.20.1 - 2019-10-30"},{"location":"apis/cds-services/CHANGELOG/#changed_5","text":"Updated version of @sap/cds-ql to 1.20.1","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-1200-2019-10-29","text":"","title":"Version 1.20.0 - 2019-10-29"},{"location":"apis/cds-services/CHANGELOG/#added_8","text":"req.method property which contains the HTTP method Return type validation for custom operations in rest Support for redirected media properties using @Core.IsURL","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_10","text":"Requests to $metadata","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#removed_2","text":"npm-shrinkwrap.json req._.isPatch","title":"Removed"},{"location":"apis/cds-services/CHANGELOG/#version-1191-2019-10-16","text":"","title":"Version 1.19.1 - 2019-10-16"},{"location":"apis/cds-services/CHANGELOG/#changed_6","text":"Improved error messages","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_11","text":"Empty user attributes in where conditions Queries in custom handler executed twice","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1190-2019-10-02","text":"","title":"Version 1.19.0 - 2019-10-02"},{"location":"apis/cds-services/CHANGELOG/#added_9","text":"Check of source for navigation-to-one in not Draft case log function in default logger","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_7","text":"Improved error messages Use @sap/odata-server@1.3.8","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_12","text":"Draft service having column names from draft admin table POST and PUT on views with renaming and excluding Draft with custom oncond in backlink Batch with multitenancy","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1182-2019-09-19","text":"","title":"Version 1.18.2 - 2019-09-19"},{"location":"apis/cds-services/CHANGELOG/#changed_8","text":"Use @sap/odata-server@1.3.7","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-1181-2019-09-18","text":"","title":"Version 1.18.1 - 2019-09-18"},{"location":"apis/cds-services/CHANGELOG/#added_10","text":"Support of authorization restrictions with simple static where clauses (e.g. $user.level = 3 ) for actions/functions","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_13","text":"Draft activation by multiple views Binary processing in rest adapter","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1180-2019-09-09","text":"","title":"Version 1.18.0 - 2019-09-09"},{"location":"apis/cds-services/CHANGELOG/#added_11","text":"Support for @assert.enum annotation Support for media content-type provided as property Support for binary encoding in rest","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_9","text":"Use @sap/odata-server@1.3.5","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_14","text":"READ with @cds.api.ignore annotation Navigation on Entities with multiple keys did not work correctly UPDATE and UPSERT requests with @cds.on.update and @cds.on.insert annotations Logging of missing permissions if no authentication strategy is detected","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1170-2019-08-21","text":"","title":"Version 1.17.0 - 2019-08-21"},{"location":"apis/cds-services/CHANGELOG/#added_12","text":"Error handling for streaming Limited support for CREATE requests via navigations Method .transaction to local client","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_10","text":"CREATE with WHERE restriction is supported only with static checks, otherwise rejected Extended error logs from custom handlers next() returns the result of the subsequent handler Use @sap/cds-messaging for sending/receiving events between services","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_15","text":"Expand entity with where restriction when clause references a user attribute with multiple values Navigations in get requests using cds.String as key type Deletion of active entries during draft activation Checking security annotations in service and in entities UUID generation for deep inserts/updates Combination of localized data and $count=true in OData requests req.query in case of bound actions and reached via navigation","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1160-2019-07-23","text":"","title":"Version 1.16.0 - 2019-07-23"},{"location":"apis/cds-services/CHANGELOG/#added_13","text":"Batch Update in REST Adapter using an Array as request body Content-Type for streaming using annotation DELETE requests on an entity property sets the property to null Integrity check for DELETE requests","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_11","text":"Behaviour of mock authentication according to documentation cds.env is used by authentication if passport not provided in options","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_16","text":"Draft actions for localized entities Write localized data via deep update/insert","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1150-2019-07-09","text":"","title":"Version 1.15.0 - 2019-07-09"},{"location":"apis/cds-services/CHANGELOG/#added_14","text":"Support for views with parameters Support for filter transformation in $apply Support for /$value on primitive properties","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_12","text":"Rest adapter accepts non-modelled data fields in the request payload and exposes them in req.data ; the fields are ignored in the generic handlers Replaced @sap/cds-ql dependency with uuid","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_17","text":"Custom handlers by extended tenants Generic handler lookup if multiple services in one .cds file $expand with instance-based authorization result parameter in AfterHandler has correct format (not always an array) CREATE : the created entity UPDATE : the updated entity DELETE : undefined for actions and functions it is the defined return type @cds.on.insert and @cds.on.update could not be used at the same time @cds.on.insert and @cds.on.update in deep insert / update","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1140-2019-06-24","text":"","title":"Version 1.14.0 - 2019-06-24"},{"location":"apis/cds-services/CHANGELOG/#added_15","text":"Alternative mock strategy config Support for value ranges annotations for REST adapter Multiple authentication strategies","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_13","text":"Handling of deep insert / update for associations Use @sap/odata-server@1.3.4","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_18","text":"Bound actions for draft-enabled entities Combination of $apply with other query parameters","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#removed_3","text":"Caching of metadata as odata already does it","title":"Removed"},{"location":"apis/cds-services/CHANGELOG/#version-1130-2019-06-07","text":"","title":"Version 1.13.0 - 2019-06-07"},{"location":"apis/cds-services/CHANGELOG/#added_16","text":"Method diff to calculate the actual changes in a CUD request or while saving a draft Support authorization annotations for actions and functions Support for default sort order using @cds.default.order or @odata.default.order Support for writing binary stream through odata","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#version-1120-2019-05-24","text":"","title":"Version 1.12.0 - 2019-05-24"},{"location":"apis/cds-services/CHANGELOG/#added_17","text":"Support for localized in generic handlers (no compositions / associations) Handler registration by path for autoexposed and redirected entities Support for Rest parametric functions and actions","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_14","text":"Renamed Service.with to Service.impl","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_19","text":"falsy values as default value req.info in case of draft actions Scopes are checked before custom before handlers","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1111-2019-05-16","text":"","title":"Version 1.11.1 - 2019-05-16"},{"location":"apis/cds-services/CHANGELOG/#changed_15","text":"service.options is now a public property (previously private as service._options )","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-1110-2019-05-15","text":"","title":"Version 1.11.0 - 2019-05-15"},{"location":"apis/cds-services/CHANGELOG/#added_18","text":"read-only field annotations validation Deactivate ResourceJsonSerializer in production Validation for content type in rest adapter Support for OData request path expressions \u00e0 la Authors/1","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_16","text":"Use @sap/odata-server@1.3.3","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-1102-2019-05-08","text":"","title":"Version 1.10.2 - 2019-05-08"},{"location":"apis/cds-services/CHANGELOG/#added_19","text":"Support for @Capabilities annotations","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_17","text":"Improved performance by reducing calls to process.nextTick()","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_20","text":"Unbound actions and functions in REST","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1101-2019-05-07","text":"","title":"Version 1.10.1 - 2019-05-07"},{"location":"apis/cds-services/CHANGELOG/#added_20","text":"error handling in case mtx errors","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_18","text":"Handler registration using .with (as done in reuse scenarios)","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_21","text":"Using $select=association in odata-v4 adapter","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-1100-2019-05-03","text":"","title":"Version 1.10.0 - 2019-05-03"},{"location":"apis/cds-services/CHANGELOG/#added_21","text":"Support for reading streams in odata v4 Support for batch create in REST adapter Support for combination of scopes and instance based authorization checks Fiori Draft event SAVE as alias for CREATE and UPDATE","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_19","text":"Improved performance","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-190-2019-04-16","text":"","title":"Version 1.9.0 - 2019-04-16"},{"location":"apis/cds-services/CHANGELOG/#added_22","text":"'mock' strategy accepts any user credentials if none configured Support for pseudo role 'system-user' Additional cases at security annotations sap-statistics=true as query or header parameter will yield performance statistics $top and $skip at rest adapter","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_20","text":"Handlers for failed events must only have the error object as an argument Handlers for succeeded and done events must have no argument at all used new function notation in generated CQN Reduction of round trips to data source by not using transactional blocks at reading requests","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_22","text":"Deep operations in REST adapter Draft edit in case one composition has no entries","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-181-2019-04-03","text":"","title":"Version 1.8.1 - 2019-04-03"},{"location":"apis/cds-services/CHANGELOG/#fixed_23","text":"Events are populated through req.event","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-180-2019-03-29","text":"","title":"Version 1.8.0 - 2019-03-29"},{"location":"apis/cds-services/CHANGELOG/#added_23","text":"after handlers using each or row also work with keyword async","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_21","text":"Generic onCommit or onRollback handlers end the transaction of potentially multiple db sessions in the request context Merged client adapter into service","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_24","text":"Errors not of type Error are not recognized req.target in case of a READ request of the DraftAministrativeData entity","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-172-2019-03-25","text":"","title":"Version 1.7.2 - 2019-03-25"},{"location":"apis/cds-services/CHANGELOG/#added_24","text":"Element/Field annotated with @mandatory or @FieldControl.Mandatory is treated as not null Added 'mock' strategy for passport Complex cases at security annotations When registering custom handlers for transactional draft events the target property of the req parameter now points to the draft","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#version-171-2019-03-20","text":"","title":"Version 1.7.1 - 2019-03-20"},{"location":"apis/cds-services/CHANGELOG/#fixed_25","text":"Passport is registered correctly in case of cds.serve('all') User is now set before it is needed","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-170-2019-03-19","text":"","title":"Version 1.7.0 - 2019-03-19"},{"location":"apis/cds-services/CHANGELOG/#added_25","text":"req.event contains the type or name of the incoming request Support for specifying a target in req.error and req.reject req.info to collect info messages in odata-v4. Eventually, they result in the sap-messages header. Annotation @Search.fuzzinessThreshold to configure Fuzzy Search Support for Extensibility Event handlers for events succeeded , failed and done can be registered at the service event context Support for OData Arithmetic Functions , Date and Time Functions , String Functions","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_22","text":"before handlers are executed in parallel req.error returns a generic error with all collected errors in .details passport method is extracted to the package interface","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_26","text":"No SQL error in case key is generated by DB like done with sequences","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-160-2019-02-25","text":"","title":"Version 1.6.0 - 2019-02-25"},{"location":"apis/cds-services/CHANGELOG/#added_26","text":"Support for Lambda operators","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_27","text":"CUD operation with association as key of entity","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-152-2019-02-13","text":"","title":"Version 1.5.2 - 2019-02-13"},{"location":"apis/cds-services/CHANGELOG/#added_27","text":"Support for sql functions lower, upper, trim, length in $filter and $orderby","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_23","text":"Sync functions at before and after handler are not wrapped in promise anymore req.reject does not throw anymore @sap/audit-logging only used in case the service is provided via VCAP_SERVICES Unknown query parameters are not longer rejected at REST adapter","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_28","text":"OData version for $metadata Multiple atomicity groups should not share same transaction block Brackets in $filter now work correctly","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-151-2019-02-12","text":"","title":"Version 1.5.1 - 2019-02-12"},{"location":"apis/cds-services/CHANGELOG/#changed_24","text":"@sap/audit-logging only used in case the service is provided via VCAP_SERVICES","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_29","text":"No integrity checks when running without db connection","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-150-2019-02-07","text":"","title":"Version 1.5.0 - 2019-02-07"},{"location":"apis/cds-services/CHANGELOG/#added_28","text":"Set foreign keys for POST via navigation-to-many and modeled with $self Support content id placeholders in odata v4 batch requests Support complex cases at security annotations","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_25","text":"Referential integrity checks do not run for associations with specified on conditions Rest adapter now ignores query parameters Minimum node version 8.9.0 .data and .query can be overwritten","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_30","text":"Insert with excluded properties having default values Delete active documents in a draft-enabled service without a draft Path segment /$count respects $filter","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-140-2019-01-22","text":"","title":"Version 1.4.0 - 2019-01-22"},{"location":"apis/cds-services/CHANGELOG/#added_29","text":"When registering service handlers, entities can be given as a list Support requests to /SiblingEntity in draft Annotation @cds.integrity.skip to disable reference integrity checks (experimental!)","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_26","text":"Replaced @sap/odata-v4 by @sap/odata-server","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-130-2019-01-11","text":"","title":"Version 1.3.0 - 2019-01-11"},{"location":"apis/cds-services/CHANGELOG/#added_30","text":"Authorization filtering and user attributes as lists Referential integrity checks","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_31","text":"No fallback for user identifier in case the user object is empty Reading draft administrative data","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-120-2018-12-21","text":"","title":"Version 1.2.0 - 2018-12-21"},{"location":"apis/cds-services/CHANGELOG/#added_31","text":"Set default values in case of CREATE, UPSERT and adding a child in deep documents","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_27","text":"context.draftMetadata contains draft metadata context.isDraftChange indicates only changes in drafts Error messages to be more consistent","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_32","text":"On handler registration for custom handlers in draft Draft children can be deleted without navigations Reading all draft-enabled documents takes into account only own drafts","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#removed_4","text":"","title":"Removed"},{"location":"apis/cds-services/CHANGELOG/#version-110-2018-12-12","text":"","title":"Version 1.1.0 - 2018-12-12"},{"location":"apis/cds-services/CHANGELOG/#added_32","text":"Deep Document Calls (deep insert, deep update and cascade delete) context.draft contains draftUUID in case of Create, Update or Delete filter and orderby with navigation","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_28","text":"improved error messages Activating a draft now triggers the 'UPDATE' or 'CREATE' event","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_33","text":"Create Draft uses default values draftActivate uses correct keys for update $count in draft context now calculates correct result db view with select Support for navigation over draft with count .code property of Errors in Custom handlers will not be overwritten","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-100-2018-11-27","text":"","title":"Version 1.0.0 - 2018-11-27"},{"location":"apis/cds-services/CHANGELOG/#added_33","text":"Support for now function in $filter Support for authorization annotations CREATE, UPDATE, DELETE Conversion of cds.DateTime/Timestamp using UTC Entity definition at service as select view","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_29","text":"Update entry makes insert if the entry doesn't exist Log messages are used directly instead of being wrapped Bound functions now have a query value Function next is implicitly executed in synchronous on-handlers Improved error handling Handler registration allows following variations: Array of events: e.g. ['READ', 'UPDATE'] '*' wildcard for any entity event next() throws error if called twice in same handler Custom implementation must be provided via .with Renamed service.definition to service.model Renamed service.service to service.name updated odata-v4 version to 1.8.0 Location header for draft actions is now relative","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_34","text":"POST on existing entity throws 'Bad Request' $search and $filter in combination with some read draft cases POST with navigation does not create a new key Access restriction on service level UPDATE sql statement generated wrong for entity with multiple keys Access to user's locale draftEdit action on entities without children CREATE with not nullable elements","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-0120-2018-10-17","text":"","title":"Version 0.12.0 - 2018-10-17"},{"location":"apis/cds-services/CHANGELOG/#added_34","text":"Custom handlers can be registered and executed for bound functions and function imports Added BeforeCreate and BeforeCreateDraft handlers to generate needed UUIDs","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_30","text":"Removed translator in the insert based on where by instanced based authorization Removed internal event rejections Not found error message generalized for reading through navigation Refactoring and changes due to updated dependencies","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-0110-2018-10-04","text":"","title":"Version 0.11.0 - 2018-10-04"},{"location":"apis/cds-services/CHANGELOG/#added_35","text":"Generic support for Create, Update, Delete on draft-enabled entities Generic support for draftEdit, draftPrepare, draftActivate actions Logger is available in handlers via context.log","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_31","text":"Log warning if database connection is missing","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_35","text":"Service requests now return promises instead of thenables","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-0101-2018-09-18","text":"","title":"Version 0.10.1 - 2018-09-18"},{"location":"apis/cds-services/CHANGELOG/#added_36","text":"Generic support for Read on draft-enabled entities","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_36","text":"$user annotation works without authorization","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-0100-2018-09-17","text":"","title":"Version 0.10.0 - 2018-09-17"},{"location":"apis/cds-services/CHANGELOG/#added_37","text":"Delete Draft Audit Logging of GDPR related events Auto lookup of to be used CF/XSA services from environmental VCAP_SERVICES OData to context.query for nested $filter, $orderby, $op and $skip at $expand Custom types on top of associations","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_32","text":"Default for maxPageSize increased to 1000 from 100","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_37","text":"Values for annotated columns (user/now) are included in the response","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-092-2018-09-05","text":"","title":"Version 0.9.2 - 2018-09-05"},{"location":"apis/cds-services/CHANGELOG/#changed_33","text":"Improved npm-shrinkwrap","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-091-2018-09-03","text":"","title":"Version 0.9.1 - 2018-09-03"},{"location":"apis/cds-services/CHANGELOG/#added_38","text":"Create draft","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#removed_5","text":"implicit dependency to @sap/cds-sql","title":"Removed"},{"location":"apis/cds-services/CHANGELOG/#version-090-2018-08-28","text":"","title":"Version 0.9.0 - 2018-08-28"},{"location":"apis/cds-services/CHANGELOG/#added_39","text":"API to support the implementation of authorization restrictions Local service client Support for to-one-navigation in $filter Support for annotation @Search.defaultSearchElement to restrict searchable columns in $search Support for sap-language query parameter Support authorization annotations Hooks to add custom logic before and after rollback event Audit Logging of security events","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_38","text":"Pagination in case of $expand $select with managed associations as key","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-081-2018-08-09","text":"","title":"Version 0.8.1 - 2018-08-09"},{"location":"apis/cds-services/CHANGELOG/#added_40","text":"Authentication using passport (including user/attr proxy)","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_34","text":"Require submodules on demand","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-080-2018-08-07","text":"","title":"Version 0.8.0 - 2018-08-07"},{"location":"apis/cds-services/CHANGELOG/#added_41","text":"OData Service: $search supports Unary and Binary Expressions without brackets Registration of global handler using star symbol like \"this.on('*', () => {})\" Registration of express middleware using this.use() Improved FeautureNotSupported error message context.reject supported for before, on and after handlers","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_35","text":"Updated version of @sap/odata-v4 to ^1.6.0","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_39","text":"Localization in case language is changed Issue with not working $count when filtering active in custom hook","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-070-2018-07-11","text":"","title":"Version 0.7.0 - 2018-07-11"},{"location":"apis/cds-services/CHANGELOG/#added_42","text":"Localization support for $metadata Support for Compositions","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_40","text":"$search also considers foreign keys of managed associations, structured elements and complex types","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-060-2018-07-02","text":"","title":"Version 0.6.0 - 2018-07-02"},{"location":"apis/cds-services/CHANGELOG/#added_43","text":"Multi tenancy support","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_41","text":"Columns are only added once to CQN in case of $expand in combination with $select","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-050-2018-06-25","text":"","title":"Version 0.5.0 - 2018-06-25"},{"location":"apis/cds-services/CHANGELOG/#added_44","text":"Hooks An any handler can be registered and will be executed for any but COMMIT events Custom handlers can be registered for before COMMIT and after COMMIT events \"_\" property added to cds handler argument, which can contain adapter specific data like a request object OData Service $filter supports (not) contains, startsWith, endsWith $filter supports combinations with and/or $select within $expand $apply supported with limited scope $search supported with limited scope","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_36","text":"Hooks Undocumented OData specific properties removed from \"cds\" handler argument cds.target contains the unreflected entity instead of the reflected entity cds.error will collect errors and throw at the end of each block of .before, .on or .after handlers Second call to next() at a on handler will be ignored and not break the sequence","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_42","text":"Support navigation over entities with multiple keys","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#removed_6","text":"In case of a SerializationError the details are only logged and not provided in the response anymore","title":"Removed"},{"location":"apis/cds-services/CHANGELOG/#version-041-2018-05-03","text":"","title":"Version 0.4.1 - 2018-05-03"},{"location":"apis/cds-services/CHANGELOG/#changed_37","text":"Updated version of @sap/cds-ql to 0.4.1","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-040-2018-05-02","text":"","title":"Version 0.4.0 - 2018-05-02"},{"location":"apis/cds-services/CHANGELOG/#added_45","text":"service factory cds used via injection Hooks Support annotations @insertonly and @readonly Support reject registration for CSN entities Support reject registration with multiple entity parameters","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_38","text":"default logger uses matching methods from console object instead of console.log packages are loaded on demand at Services.js and OData.js instead of required in any case adapted error message in case of 501","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#version-030-2018-04-16","text":"","title":"Version 0.3.0 - 2018-04-16"},{"location":"apis/cds-services/CHANGELOG/#added_46","text":"service factory service.entities is set OData Service Support for $expand=* Support for $select=* Hooks CSN entities can be used instead of strings to register a handler .on can be registered with CQN instead of function as handler .on supports registering N handlers .on handlers can use a second argument next() .on can be finished by returning a value .after with convenience wrappers for each|row argument .after can now work asynchronously","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#changed_39","text":"server side paging is enabled by default and set to 100, to disable it set maxPageSize to false. refactored service factory removed option to compile CSN on the fly, only CSN accepted as input format option to set the URL path is removed Multi service CSN can be used refactored Service class OData service instantiation is now split in constructor, createODataService and getMiddleWare OData Service Renamed parameters in handler context object (target replaces entity and getEntity) More expressive error messages Crash Node.js instance on unhandled error","title":"Changed"},{"location":"apis/cds-services/CHANGELOG/#fixed_43","text":"limit property is only added to CQN if necessary .reply() is able to handle null values","title":"Fixed"},{"location":"apis/cds-services/CHANGELOG/#version-020-2018-03-16","text":"","title":"Version 0.2.0 - 2018-03-16"},{"location":"apis/cds-services/CHANGELOG/#added_47","text":"option to enable debug mode for odata-v4 default logger with option to register custom logger support for server side paging support for cds.serve, which is a Fluent API-style method to read service definitions from the given model(s) and construct services usage of npm-shrinkwrap","title":"Added"},{"location":"apis/cds-services/CHANGELOG/#fixed_44","text":"$filter in combination with to many association","title":"Fixed"},{"location":"apis/cds-sql/","text":"CDX SQL \u00b6 This package offers a factory method to build a SQL string from a CQN object and a BaseClient which performs default post processing to be used by the inheriting clients. Overview ## \u00b6 TBD Prerequisites ## \u00b6 Dependencies: N/A Installation ## \u00b6 npm install Usage/Configuration ## \u00b6 Examples \u00b6 TBD Reference \u00b6 TBD","title":"CDX SQL"},{"location":"apis/cds-sql/#cdx-sql","text":"This package offers a factory method to build a SQL string from a CQN object and a BaseClient which performs default post processing to be used by the inheriting clients.","title":"CDX SQL"},{"location":"apis/cds-sql/#overview","text":"TBD","title":"Overview ##"},{"location":"apis/cds-sql/#prerequisites","text":"Dependencies: N/A","title":"Prerequisites ##"},{"location":"apis/cds-sql/#installation","text":"npm install","title":"Installation ##"},{"location":"apis/cds-sql/#usageconfiguration","text":"","title":"Usage/Configuration ##"},{"location":"apis/cds-sql/#examples","text":"TBD","title":"Examples"},{"location":"apis/cds-sql/#reference","text":"TBD","title":"Reference"},{"location":"apis/cds-sql/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.24.0 - 2020-03-19 \u00b6 Added \u00b6 Support for different columns combinations in INSERT.entries Support for $count in SELECT CQN Support String objects in the annotation expressions .setTransactionTimestamp in BaseClient check for @cds.persistence.skip for deep operations Changed \u00b6 Use || for concat (works for HANA and sqlite) Fixed \u00b6 Using view by draft & localized Quote alias in orderBy to work on HANA Expand from not draft enabled entity to draft enabled entity where and orderBy clauses containing navigations in combination with expand are correctly translated to SQL Version 1.23.2 - 2020-02-25 \u00b6 Fixed \u00b6 Missing alias for orderBy caused column ambiguously defined error Version 1.23.1 - 2020-02-21 \u00b6 Added \u00b6 Support for set and data in UPDATE CQN Support draft for localized texts Support for with and data in UPDATE CQN Version 1.23.0 - 2020-02-19 \u00b6 Changed \u00b6 Convert all search queries using contains to like Fixed \u00b6 Searching for _ or % in $search Version 1.22.0 - 2020-02-05 \u00b6 Changed \u00b6 Managed fields are not removed anymore if they dont belong to operation (e.g. modifiedAt in INSERT, createdAt in UPDATE) null is a valid value for a managed field (e. g. if null is provided for @cds.on.insert , null will be inserted to DB) Fixed \u00b6 Expand with composition to one for draft enabled entity Version 1.21.0 - 2019-12-10 \u00b6 Fixed \u00b6 post-processing for columns with function calls Version 1.20.1 - 2019-11-29 \u00b6 Error message when ambiguous naming of alias and entity property occurs in SELECT query Changed \u00b6 Minor improvements Version 1.20.0 - 2019-11-19 \u00b6 Fixed \u00b6 Managed fields were not generated when values are null Read of active entity with navigation and orderBy with draft specific column (e.g HasActiveEntity ) Version 1.19.1 - 2019-10-30 \u00b6 Fixed \u00b6 Expand adding foreign keys twice Version 1.19.0 - 2019-10-29 \u00b6 Changed \u00b6 Improved deep update Removed \u00b6 npm-shrinkwrap.json Version 1.18.1 - 2019-10-16 \u00b6 Fixed \u00b6 Problems with deep update of a composition of one Unhandled promise rejections by expand Version 1.18.0 - 2019-10-02 \u00b6 Fixed \u00b6 Problems with backlinks with custom on condition Version 1.17.1 - 2019-09-18 \u00b6 Changed \u00b6 Improved error messages Improves SQL Builder for .where clauses Version 1.17.0 - 2019-09-09 \u00b6 Fixed \u00b6 Expand-to-one in draft context Expand with multiple orderby elements using window function UUID generation for INSERT statements Version 1.16.0 - 2019-08-21 \u00b6 Fixed \u00b6 Missing sub-select columns in case of UNIONs (e.g. when expanding on the DraftAdminTable) UUID generation in custom built deep inserts/updates Version 1.15.0 - 2019-07-23 \u00b6 Added \u00b6 getDraftCompositionTree to get draft specific composition tree Fixed \u00b6 Deep Operations with custom on-Condition without backlink Version 1.14.0 - 2019-07-09 \u00b6 Fixed \u00b6 Combination of expand with instance-based authorization Version 1.13.0 - 2019-06-24 \u00b6 Added \u00b6 Struct Mapper checks subselect for matching columns Version 1.12.0 - 2019-05-24 \u00b6 Changed \u00b6 Deep insert/update for to-many associations is not allowed Fixed \u00b6 Property mapper now works for fully-specified columns in SELECT statements Version 1.11.1 - 2019-05-16 \u00b6 Fixed \u00b6 Cases with multiple brackets during onCond generation Version 1.11.0 - 2019-05-15 \u00b6 Fixed \u00b6 Annotate elements with both @cds.on.insert and @cds.on.update Version 1.10.0 - 2019-05-03 \u00b6 Added \u00b6 Support for composition to-one using $self Service functions update , read , insert , delete and create Fixed \u00b6 Expand with compound keys and orderby where order column is not requested Deeply nested expands Version 1.9.0 - 2019-04-16 \u00b6 Fixed \u00b6 Cascading Delete CQN generation in case of transitive model Version 1.8.0 - 2019-03-29 \u00b6 Changed \u00b6 Minor improvements alphabetical aliases instead of md5 in case of expand Version 1.7.0 - 2019-03-19 \u00b6 Added \u00b6 Support for 'list' in function arguments Support for from: { ref: [] } in DeleteBuilder Support for Compositions with custom on condition (no and/or) Fixed \u00b6 Expanding of on active draft documents lists without $filter Expand of entities with compound key might return duplicate results Version 1.6.0 - 2019-02-25 \u00b6 Added \u00b6 Support for 'func' as defined in cqn spec Support for 'list' in expressions Support for deep insert with recursive entities Changed \u00b6 Fixed \u00b6 Recursion in composition tree Added brackets in oncond Fixed is null / is not null in oncond Falsy values at expanded elements Fixed expand with selected column 'IsActiveEntity' Version 1.5.1 - 2019-02-12 \u00b6 Added \u00b6 Support for sql functions lower, upper, trim, length in $filter and $orderby Version 1.5.0 - 2019-02-06 \u00b6 Added \u00b6 Support for INSERT into ... SELECT ... Changed \u00b6 Minimum node version 8.9.0 Improve expand performance Version 1.4.0 - 2019-01-22 \u00b6 Added \u00b6 Construct SQLs from CQN which includes placeholder Support draft scenario 'Locked by another user' Version 1.3.0 - 2019-01-11 \u00b6 Added \u00b6 Support for compound keys Changed \u00b6 Improve inline detection Version 1.2.0 - 2018-12-21 \u00b6 Added \u00b6 Set default values in case of CREATE, UPSERT and adding a child in deep documents Reversed cascade delete Version 1.1.0 - 2018-12-12 \u00b6 Added \u00b6 Support Deep Document CQNs Support for inline Post processing with CQN that uses select * Fixed \u00b6 Expand in combination with left outer joins Version 1.0.3 - 2018-11-27 \u00b6 Changed \u00b6 Throw root cause instead of CqnParseError Throw root cause instead of SqlError Fixed \u00b6 Binary generated wrong SQL Complex CQN with draft and expand for Hana Expand modifies copy instead of original CQN Expand with missing columns Expand in combination with limit Post processing of DateTime and Boolean Version 0.12.0 - 2018-10-17 \u00b6 Refactoring and changes due to updated dependencies Version 0.11.0 - 2018-10-04 \u00b6 Added \u00b6 Expanding of drafts entries at list pages Expanding of drafts entries at object pages Version 0.10.0 - 2018-09-17 \u00b6 Added \u00b6 Support of now/user annotations in structured type Support of expand in combination with contains at where Support of LIMIT/OFFSET, ORDER BY and WHERE at expanded items Custom types on top of associations Support columns: ['*'] at CQN Version 0.9.2 - 2018-09-05 \u00b6 Added \u00b6 SQL generation for SELECT statements that include UNION Changed \u00b6 Improved npm-shrinkwrap Fixed \u00b6 Postprocessing breaks without CSN Version 0.9.1 - 2018-08-28 \u00b6 (Preparation for Release) Version 0.9.0 - 2018-08-28 \u00b6 Changed \u00b6 .getColumns includes annotations .deploy of BaseClient uses CDS-Compiler to do database setup Fixed \u00b6 SQL generation in case of CREATE statements using structured elements containing managed associations Postprocessing of expand to many in plain mode Version 0.8.1 - 2018-08-09 \u00b6 Changed \u00b6 Require submodules on demand Version 0.8.0 - 2018-08-07 \u00b6 Added \u00b6 Support for exists in combination with expand Support column annotations '@cds.on.insert', '@cds.on.update', '@odata.on.insert' and '@odata.on.update' Post processing of complex and structured types Support for unary and binary expressions in contains Support for CQN partials at .where Changed \u00b6 Renamed SELECT.elements to SELECT.columns SQL Error provides info about the executed query and values in logs Fixed \u00b6 Deep expands with more than 10 levels Expand to composition and further to one association Structured types at expand could lead to ambiguity Version 0.7.0 - 2018-07-11 \u00b6 Added \u00b6 CREATE supports type cds.Composition Expand supports type cds.Composition Support for structured elements Version 0.6.0 - 2018-07-02 \u00b6 Added \u00b6 Fixed \u00b6 SQL generation in case of combination of navigation and expand in SELECT statements Version 0.5.0 - 2018-06-25 \u00b6 Added \u00b6 custom builders can now be provided via options in SQL Builder support create with views added SQL Error to hide the internal information from other errors support structured elements support for complex types in Create Builder BaseClient has method .deploy to easily create database artifacts from csn model support for SQL function contains by converting it using like support execution of blocks of statements Changed \u00b6 quotation in SQL generation is now configurable (default is plain) support for latest CQN spec changes Fixed \u00b6 column generation for managed associations CREATE statement with managed association as key resolve $self for expand 1:1 associations can be null Version 0.4.0 - 2018-05-02 \u00b6 Added \u00b6 BaseClient has methods .run & .foreach & .isValid Changed \u00b6 support for latest CQN spec changes Version 0.3.0 - 2018-04-16 \u00b6 Added \u00b6 support CREATE statements Fixed \u00b6 auto-generated columns in expand=* requests Version 0.2.0 - 2018-03-16 \u00b6 Added \u00b6 usage of npm-shrinkwrap Changed \u00b6 improved performance for expand in case of one-to-many relations Fixed \u00b6 ambiguous column name when having multiple expands on same entity","title":"Changelog"},{"location":"apis/cds-sql/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-sql/CHANGELOG/#version-1240-2020-03-19","text":"","title":"Version 1.24.0 - 2020-03-19"},{"location":"apis/cds-sql/CHANGELOG/#added","text":"Support for different columns combinations in INSERT.entries Support for $count in SELECT CQN Support String objects in the annotation expressions .setTransactionTimestamp in BaseClient check for @cds.persistence.skip for deep operations","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed","text":"Use || for concat (works for HANA and sqlite)","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed","text":"Using view by draft & localized Quote alias in orderBy to work on HANA Expand from not draft enabled entity to draft enabled entity where and orderBy clauses containing navigations in combination with expand are correctly translated to SQL","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1232-2020-02-25","text":"","title":"Version 1.23.2 - 2020-02-25"},{"location":"apis/cds-sql/CHANGELOG/#fixed_1","text":"Missing alias for orderBy caused column ambiguously defined error","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1231-2020-02-21","text":"","title":"Version 1.23.1 - 2020-02-21"},{"location":"apis/cds-sql/CHANGELOG/#added_1","text":"Support for set and data in UPDATE CQN Support draft for localized texts Support for with and data in UPDATE CQN","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-1230-2020-02-19","text":"","title":"Version 1.23.0 - 2020-02-19"},{"location":"apis/cds-sql/CHANGELOG/#changed_1","text":"Convert all search queries using contains to like","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_2","text":"Searching for _ or % in $search","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1220-2020-02-05","text":"","title":"Version 1.22.0 - 2020-02-05"},{"location":"apis/cds-sql/CHANGELOG/#changed_2","text":"Managed fields are not removed anymore if they dont belong to operation (e.g. modifiedAt in INSERT, createdAt in UPDATE) null is a valid value for a managed field (e. g. if null is provided for @cds.on.insert , null will be inserted to DB)","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_3","text":"Expand with composition to one for draft enabled entity","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1210-2019-12-10","text":"","title":"Version 1.21.0 - 2019-12-10"},{"location":"apis/cds-sql/CHANGELOG/#fixed_4","text":"post-processing for columns with function calls","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1201-2019-11-29","text":"Error message when ambiguous naming of alias and entity property occurs in SELECT query","title":"Version 1.20.1 - 2019-11-29"},{"location":"apis/cds-sql/CHANGELOG/#changed_3","text":"Minor improvements","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#version-1200-2019-11-19","text":"","title":"Version 1.20.0 - 2019-11-19"},{"location":"apis/cds-sql/CHANGELOG/#fixed_5","text":"Managed fields were not generated when values are null Read of active entity with navigation and orderBy with draft specific column (e.g HasActiveEntity )","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1191-2019-10-30","text":"","title":"Version 1.19.1 - 2019-10-30"},{"location":"apis/cds-sql/CHANGELOG/#fixed_6","text":"Expand adding foreign keys twice","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1190-2019-10-29","text":"","title":"Version 1.19.0 - 2019-10-29"},{"location":"apis/cds-sql/CHANGELOG/#changed_4","text":"Improved deep update","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#removed","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-sql/CHANGELOG/#version-1181-2019-10-16","text":"","title":"Version 1.18.1 - 2019-10-16"},{"location":"apis/cds-sql/CHANGELOG/#fixed_7","text":"Problems with deep update of a composition of one Unhandled promise rejections by expand","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1180-2019-10-02","text":"","title":"Version 1.18.0 - 2019-10-02"},{"location":"apis/cds-sql/CHANGELOG/#fixed_8","text":"Problems with backlinks with custom on condition","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1171-2019-09-18","text":"","title":"Version 1.17.1 - 2019-09-18"},{"location":"apis/cds-sql/CHANGELOG/#changed_5","text":"Improved error messages Improves SQL Builder for .where clauses","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#version-1170-2019-09-09","text":"","title":"Version 1.17.0 - 2019-09-09"},{"location":"apis/cds-sql/CHANGELOG/#fixed_9","text":"Expand-to-one in draft context Expand with multiple orderby elements using window function UUID generation for INSERT statements","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1160-2019-08-21","text":"","title":"Version 1.16.0 - 2019-08-21"},{"location":"apis/cds-sql/CHANGELOG/#fixed_10","text":"Missing sub-select columns in case of UNIONs (e.g. when expanding on the DraftAdminTable) UUID generation in custom built deep inserts/updates","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1150-2019-07-23","text":"","title":"Version 1.15.0 - 2019-07-23"},{"location":"apis/cds-sql/CHANGELOG/#added_2","text":"getDraftCompositionTree to get draft specific composition tree","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#fixed_11","text":"Deep Operations with custom on-Condition without backlink","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1140-2019-07-09","text":"","title":"Version 1.14.0 - 2019-07-09"},{"location":"apis/cds-sql/CHANGELOG/#fixed_12","text":"Combination of expand with instance-based authorization","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1130-2019-06-24","text":"","title":"Version 1.13.0 - 2019-06-24"},{"location":"apis/cds-sql/CHANGELOG/#added_3","text":"Struct Mapper checks subselect for matching columns","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-1120-2019-05-24","text":"","title":"Version 1.12.0 - 2019-05-24"},{"location":"apis/cds-sql/CHANGELOG/#changed_6","text":"Deep insert/update for to-many associations is not allowed","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_13","text":"Property mapper now works for fully-specified columns in SELECT statements","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1111-2019-05-16","text":"","title":"Version 1.11.1 - 2019-05-16"},{"location":"apis/cds-sql/CHANGELOG/#fixed_14","text":"Cases with multiple brackets during onCond generation","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1110-2019-05-15","text":"","title":"Version 1.11.0 - 2019-05-15"},{"location":"apis/cds-sql/CHANGELOG/#fixed_15","text":"Annotate elements with both @cds.on.insert and @cds.on.update","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-1100-2019-05-03","text":"","title":"Version 1.10.0 - 2019-05-03"},{"location":"apis/cds-sql/CHANGELOG/#added_4","text":"Support for composition to-one using $self Service functions update , read , insert , delete and create","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#fixed_16","text":"Expand with compound keys and orderby where order column is not requested Deeply nested expands","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-190-2019-04-16","text":"","title":"Version 1.9.0 - 2019-04-16"},{"location":"apis/cds-sql/CHANGELOG/#fixed_17","text":"Cascading Delete CQN generation in case of transitive model","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-180-2019-03-29","text":"","title":"Version 1.8.0 - 2019-03-29"},{"location":"apis/cds-sql/CHANGELOG/#changed_7","text":"Minor improvements alphabetical aliases instead of md5 in case of expand","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#version-170-2019-03-19","text":"","title":"Version 1.7.0 - 2019-03-19"},{"location":"apis/cds-sql/CHANGELOG/#added_5","text":"Support for 'list' in function arguments Support for from: { ref: [] } in DeleteBuilder Support for Compositions with custom on condition (no and/or)","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#fixed_18","text":"Expanding of on active draft documents lists without $filter Expand of entities with compound key might return duplicate results","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-160-2019-02-25","text":"","title":"Version 1.6.0 - 2019-02-25"},{"location":"apis/cds-sql/CHANGELOG/#added_6","text":"Support for 'func' as defined in cqn spec Support for 'list' in expressions Support for deep insert with recursive entities","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_8","text":"","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_19","text":"Recursion in composition tree Added brackets in oncond Fixed is null / is not null in oncond Falsy values at expanded elements Fixed expand with selected column 'IsActiveEntity'","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-151-2019-02-12","text":"","title":"Version 1.5.1 - 2019-02-12"},{"location":"apis/cds-sql/CHANGELOG/#added_7","text":"Support for sql functions lower, upper, trim, length in $filter and $orderby","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-150-2019-02-06","text":"","title":"Version 1.5.0 - 2019-02-06"},{"location":"apis/cds-sql/CHANGELOG/#added_8","text":"Support for INSERT into ... SELECT ...","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_9","text":"Minimum node version 8.9.0 Improve expand performance","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#version-140-2019-01-22","text":"","title":"Version 1.4.0 - 2019-01-22"},{"location":"apis/cds-sql/CHANGELOG/#added_9","text":"Construct SQLs from CQN which includes placeholder Support draft scenario 'Locked by another user'","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-130-2019-01-11","text":"","title":"Version 1.3.0 - 2019-01-11"},{"location":"apis/cds-sql/CHANGELOG/#added_10","text":"Support for compound keys","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_10","text":"Improve inline detection","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#version-120-2018-12-21","text":"","title":"Version 1.2.0 - 2018-12-21"},{"location":"apis/cds-sql/CHANGELOG/#added_11","text":"Set default values in case of CREATE, UPSERT and adding a child in deep documents Reversed cascade delete","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-110-2018-12-12","text":"","title":"Version 1.1.0 - 2018-12-12"},{"location":"apis/cds-sql/CHANGELOG/#added_12","text":"Support Deep Document CQNs Support for inline Post processing with CQN that uses select *","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#fixed_20","text":"Expand in combination with left outer joins","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-103-2018-11-27","text":"","title":"Version 1.0.3 - 2018-11-27"},{"location":"apis/cds-sql/CHANGELOG/#changed_11","text":"Throw root cause instead of CqnParseError Throw root cause instead of SqlError","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_21","text":"Binary generated wrong SQL Complex CQN with draft and expand for Hana Expand modifies copy instead of original CQN Expand with missing columns Expand in combination with limit Post processing of DateTime and Boolean","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-0120-2018-10-17","text":"Refactoring and changes due to updated dependencies","title":"Version 0.12.0 - 2018-10-17"},{"location":"apis/cds-sql/CHANGELOG/#version-0110-2018-10-04","text":"","title":"Version 0.11.0 - 2018-10-04"},{"location":"apis/cds-sql/CHANGELOG/#added_13","text":"Expanding of drafts entries at list pages Expanding of drafts entries at object pages","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-0100-2018-09-17","text":"","title":"Version 0.10.0 - 2018-09-17"},{"location":"apis/cds-sql/CHANGELOG/#added_14","text":"Support of now/user annotations in structured type Support of expand in combination with contains at where Support of LIMIT/OFFSET, ORDER BY and WHERE at expanded items Custom types on top of associations Support columns: ['*'] at CQN","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-092-2018-09-05","text":"","title":"Version 0.9.2 - 2018-09-05"},{"location":"apis/cds-sql/CHANGELOG/#added_15","text":"SQL generation for SELECT statements that include UNION","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_12","text":"Improved npm-shrinkwrap","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_22","text":"Postprocessing breaks without CSN","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-091-2018-08-28","text":"(Preparation for Release)","title":"Version 0.9.1 - 2018-08-28"},{"location":"apis/cds-sql/CHANGELOG/#version-090-2018-08-28","text":"","title":"Version 0.9.0 - 2018-08-28"},{"location":"apis/cds-sql/CHANGELOG/#changed_13","text":".getColumns includes annotations .deploy of BaseClient uses CDS-Compiler to do database setup","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_23","text":"SQL generation in case of CREATE statements using structured elements containing managed associations Postprocessing of expand to many in plain mode","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-081-2018-08-09","text":"","title":"Version 0.8.1 - 2018-08-09"},{"location":"apis/cds-sql/CHANGELOG/#changed_14","text":"Require submodules on demand","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#version-080-2018-08-07","text":"","title":"Version 0.8.0 - 2018-08-07"},{"location":"apis/cds-sql/CHANGELOG/#added_16","text":"Support for exists in combination with expand Support column annotations '@cds.on.insert', '@cds.on.update', '@odata.on.insert' and '@odata.on.update' Post processing of complex and structured types Support for unary and binary expressions in contains Support for CQN partials at .where","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_15","text":"Renamed SELECT.elements to SELECT.columns SQL Error provides info about the executed query and values in logs","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_24","text":"Deep expands with more than 10 levels Expand to composition and further to one association Structured types at expand could lead to ambiguity","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-070-2018-07-11","text":"","title":"Version 0.7.0 - 2018-07-11"},{"location":"apis/cds-sql/CHANGELOG/#added_17","text":"CREATE supports type cds.Composition Expand supports type cds.Composition Support for structured elements","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#version-060-2018-07-02","text":"","title":"Version 0.6.0 - 2018-07-02"},{"location":"apis/cds-sql/CHANGELOG/#added_18","text":"","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#fixed_25","text":"SQL generation in case of combination of navigation and expand in SELECT statements","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-050-2018-06-25","text":"","title":"Version 0.5.0 - 2018-06-25"},{"location":"apis/cds-sql/CHANGELOG/#added_19","text":"custom builders can now be provided via options in SQL Builder support create with views added SQL Error to hide the internal information from other errors support structured elements support for complex types in Create Builder BaseClient has method .deploy to easily create database artifacts from csn model support for SQL function contains by converting it using like support execution of blocks of statements","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_16","text":"quotation in SQL generation is now configurable (default is plain) support for latest CQN spec changes","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_26","text":"column generation for managed associations CREATE statement with managed association as key resolve $self for expand 1:1 associations can be null","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-040-2018-05-02","text":"","title":"Version 0.4.0 - 2018-05-02"},{"location":"apis/cds-sql/CHANGELOG/#added_20","text":"BaseClient has methods .run & .foreach & .isValid","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_17","text":"support for latest CQN spec changes","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#version-030-2018-04-16","text":"","title":"Version 0.3.0 - 2018-04-16"},{"location":"apis/cds-sql/CHANGELOG/#added_21","text":"support CREATE statements","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#fixed_27","text":"auto-generated columns in expand=* requests","title":"Fixed"},{"location":"apis/cds-sql/CHANGELOG/#version-020-2018-03-16","text":"","title":"Version 0.2.0 - 2018-03-16"},{"location":"apis/cds-sql/CHANGELOG/#added_22","text":"usage of npm-shrinkwrap","title":"Added"},{"location":"apis/cds-sql/CHANGELOG/#changed_18","text":"improved performance for expand in case of one-to-many relations","title":"Changed"},{"location":"apis/cds-sql/CHANGELOG/#fixed_28","text":"ambiguous column name when having multiple expands on same entity","title":"Fixed"},{"location":"apis/cds-sqlite/","text":"cds-sqlite \u00b6 Driver package for access to sqlite database, including setting up the client, configuring all the necessary options to initiate the connection and handling database specifics so that they can be processed on our end. Overview \u00b6 TBD Prerequisites ## \u00b6 @sap/cds-sql Installation ## \u00b6 npm install Usage/Configuration ## \u00b6 TBD Reference \u00b6 TBD","title":"cds-sqlite #"},{"location":"apis/cds-sqlite/#cds-sqlite","text":"Driver package for access to sqlite database, including setting up the client, configuring all the necessary options to initiate the connection and handling database specifics so that they can be processed on our end.","title":"cds-sqlite"},{"location":"apis/cds-sqlite/#overview","text":"TBD","title":"Overview"},{"location":"apis/cds-sqlite/#prerequisites","text":"@sap/cds-sql","title":"Prerequisites ##"},{"location":"apis/cds-sqlite/#installation","text":"npm install","title":"Installation ##"},{"location":"apis/cds-sqlite/#usageconfiguration","text":"TBD","title":"Usage/Configuration ##"},{"location":"apis/cds-sqlite/#reference","text":"TBD","title":"Reference"},{"location":"apis/cds-sqlite/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Version 1.24.0 - 2020-03-19 \u00b6 Added \u00b6 Single timestamp per transaction default timeout 5s for acquiring client from pool Changed \u00b6 deleted concat handling (done in cds-sql) Version 1.23.1 - 2020-02-26 \u00b6 Removed \u00b6 npm-shrinkwrap.json Version 1.23.0 - 2020-02-19 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.23.0 Version 1.22.0 - 2020-02-05 \u00b6 Added \u00b6 Allow setting the journal mode via credentials.journalMode Changed \u00b6 Pool options can once again be overwritten Version 1.21.0 - 2019-12-10 \u00b6 Changed \u00b6 Pool options always set to default Version 1.20.1 - 2019-11-29 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.20.1 Version 1.20.0 - 2019-11-19 \u00b6 Added \u00b6 Conversion of hana's seconds_between function to strftime for sqlite Version 1.19.1 - 2019-10-30 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.19.1 Version 1.19.0 - 2019-10-29 \u00b6 Removed \u00b6 npm-shrinkwrap.json Version 1.18.1 - 2019-10-16 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.18.1 Version 1.18.0 - 2019-10-02 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.18.0 Version 1.17.1 - 2019-09-18 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.17.1 Version 1.17.0 - 2019-09-09 \u00b6 Added \u00b6 Streaming into sqlite Version 1.16.0 - 2019-08-21 \u00b6 Changed \u00b6 Signature of the Client's constructor Version 1.15.0 - 2019-07-23 \u00b6 Added \u00b6 Support multi tenancy for file based database Fixed \u00b6 Streaming supports null values Version 1.14.0 - 2019-07-09 \u00b6 Added \u00b6 Named binding parameters Support files as db in tenant manager Version 1.13.0 - 2019-06-24 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.13.0 Version 1.12.0 - 2019-05-24 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.12.0 Version 1.11.1 - 2019-05-16 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.11.1 Version 1.11.0 - 2019-05-15 \u00b6 Changed \u00b6 Bulk inserts are now traced Version 1.10.0 - 2019-05-03 \u00b6 Added \u00b6 Mitigation for loosely typed columns and imported data service related functions Streaming support via client.stream() Version 1.9.0 - 2019-04-16 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.9.0 Version 1.8.0 - 2019-03-29 \u00b6 Added \u00b6 Support for odata method functions Version 1.7.0 - 2019-03-19 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.7.0 Version 1.6.0 - 2019-02-25 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.6.0 Version 1.5.1 - 2019-02-12 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 1.5.1 Version 1.5.0 - 2019-02-06 \u00b6 Changed \u00b6 Minimum node version 8.9.0 Improve expand performance Version 1.4.0 - 2019-01-22 \u00b6 Added \u00b6 .execute supports placeholders in CQN Version 1.3.0 - 2019-01-11 \u00b6 Changed \u00b6 Use latest version of @sap/cds-sql Version 1.2.0 - 2018-12-21 \u00b6 Added \u00b6 Set default values in case of CREATE, UPSERT and adding a child in deep documents Version 1.1.0 - 2018-12-12 \u00b6 Added \u00b6 Support Deep Document CQNs Version 1.0.3 - 2018-11-27 \u00b6 Added \u00b6 credentials.database can be used instead of parameters host and url Changed \u00b6 Throw db error instead of wrapping it in Sql Error Throw an error if database is not defined instead of fallback to memory Fixed \u00b6 Bulk Insert with $user / $now Post processing of Binary, Boolean, DateTime and Integer64 Version 0.10.0 - 2018-10-17 \u00b6 Refactoring and changes due to updated dependencies Version 0.9.0 - 2018-10-04 \u00b6 Changed \u00b6 Updated version of @sap/cds-sql to 0.11.0 Version 0.8.0 - 2018-09-17 \u00b6 Fixed \u00b6 CQN queries with contains and expand (limitation: expanded columns cannot be part of contains) Version 0.7.1 - 2018-09-05 \u00b6 Changed \u00b6 Improved npm-shrinkwrap Version 0.7.0 - 2018-08-28 \u00b6 Changed \u00b6 API documentation updated Version 0.6.1 - 2018-08-09 \u00b6 Changed \u00b6 Require submodules on demand Version 0.6.0 - 2018-08-07 \u00b6 Added \u00b6 cds.Timestamp and cds.DateTime converted into ISO time format when reading Support for abstract placeholders #now and #user Fixed \u00b6 SQL error hides internal error messages and provides details in log Version 0.5.0 - 2018-06-25 \u00b6 Added \u00b6 support execution of blocks of statements support plain mode of SQL name mapping Changed \u00b6 Added SQL Error to hide the internal information from other errors Fixed \u00b6 CDS injection Version 0.4.0 - 2018-05-02 \u00b6 Changed \u00b6 connect options aligned to spec support for latest CQN spec changes Version 0.3.0 - 2018-04-16 \u00b6 Added \u00b6 support CREATE statements Version 0.2.0 - 2018-03-16 \u00b6 Added \u00b6 usage of npm-shrinkwrap Changed \u00b6 improved performance","title":"Changelog"},{"location":"apis/cds-sqlite/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1240-2020-03-19","text":"","title":"Version 1.24.0 - 2020-03-19"},{"location":"apis/cds-sqlite/CHANGELOG/#added","text":"Single timestamp per transaction default timeout 5s for acquiring client from pool","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#changed","text":"deleted concat handling (done in cds-sql)","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1231-2020-02-26","text":"","title":"Version 1.23.1 - 2020-02-26"},{"location":"apis/cds-sqlite/CHANGELOG/#removed","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1230-2020-02-19","text":"","title":"Version 1.23.0 - 2020-02-19"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_1","text":"Updated version of @sap/cds-sql to 1.23.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1220-2020-02-05","text":"","title":"Version 1.22.0 - 2020-02-05"},{"location":"apis/cds-sqlite/CHANGELOG/#added_1","text":"Allow setting the journal mode via credentials.journalMode","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_2","text":"Pool options can once again be overwritten","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1210-2019-12-10","text":"","title":"Version 1.21.0 - 2019-12-10"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_3","text":"Pool options always set to default","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1201-2019-11-29","text":"","title":"Version 1.20.1 - 2019-11-29"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_4","text":"Updated version of @sap/cds-sql to 1.20.1","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1200-2019-11-19","text":"","title":"Version 1.20.0 - 2019-11-19"},{"location":"apis/cds-sqlite/CHANGELOG/#added_2","text":"Conversion of hana's seconds_between function to strftime for sqlite","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1191-2019-10-30","text":"","title":"Version 1.19.1 - 2019-10-30"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_5","text":"Updated version of @sap/cds-sql to 1.19.1","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1190-2019-10-29","text":"","title":"Version 1.19.0 - 2019-10-29"},{"location":"apis/cds-sqlite/CHANGELOG/#removed_1","text":"npm-shrinkwrap.json","title":"Removed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1181-2019-10-16","text":"","title":"Version 1.18.1 - 2019-10-16"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_6","text":"Updated version of @sap/cds-sql to 1.18.1","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1180-2019-10-02","text":"","title":"Version 1.18.0 - 2019-10-02"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_7","text":"Updated version of @sap/cds-sql to 1.18.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1171-2019-09-18","text":"","title":"Version 1.17.1 - 2019-09-18"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_8","text":"Updated version of @sap/cds-sql to 1.17.1","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1170-2019-09-09","text":"","title":"Version 1.17.0 - 2019-09-09"},{"location":"apis/cds-sqlite/CHANGELOG/#added_3","text":"Streaming into sqlite","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1160-2019-08-21","text":"","title":"Version 1.16.0 - 2019-08-21"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_9","text":"Signature of the Client's constructor","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1150-2019-07-23","text":"","title":"Version 1.15.0 - 2019-07-23"},{"location":"apis/cds-sqlite/CHANGELOG/#added_4","text":"Support multi tenancy for file based database","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#fixed","text":"Streaming supports null values","title":"Fixed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1140-2019-07-09","text":"","title":"Version 1.14.0 - 2019-07-09"},{"location":"apis/cds-sqlite/CHANGELOG/#added_5","text":"Named binding parameters Support files as db in tenant manager","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1130-2019-06-24","text":"","title":"Version 1.13.0 - 2019-06-24"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_10","text":"Updated version of @sap/cds-sql to 1.13.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1120-2019-05-24","text":"","title":"Version 1.12.0 - 2019-05-24"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_11","text":"Updated version of @sap/cds-sql to 1.12.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1111-2019-05-16","text":"","title":"Version 1.11.1 - 2019-05-16"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_12","text":"Updated version of @sap/cds-sql to 1.11.1","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1110-2019-05-15","text":"","title":"Version 1.11.0 - 2019-05-15"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_13","text":"Bulk inserts are now traced","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-1100-2019-05-03","text":"","title":"Version 1.10.0 - 2019-05-03"},{"location":"apis/cds-sqlite/CHANGELOG/#added_6","text":"Mitigation for loosely typed columns and imported data service related functions Streaming support via client.stream()","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-190-2019-04-16","text":"","title":"Version 1.9.0 - 2019-04-16"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_14","text":"Updated version of @sap/cds-sql to 1.9.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-180-2019-03-29","text":"","title":"Version 1.8.0 - 2019-03-29"},{"location":"apis/cds-sqlite/CHANGELOG/#added_7","text":"Support for odata method functions","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-170-2019-03-19","text":"","title":"Version 1.7.0 - 2019-03-19"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_15","text":"Updated version of @sap/cds-sql to 1.7.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-160-2019-02-25","text":"","title":"Version 1.6.0 - 2019-02-25"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_16","text":"Updated version of @sap/cds-sql to 1.6.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-151-2019-02-12","text":"","title":"Version 1.5.1 - 2019-02-12"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_17","text":"Updated version of @sap/cds-sql to 1.5.1","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-150-2019-02-06","text":"","title":"Version 1.5.0 - 2019-02-06"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_18","text":"Minimum node version 8.9.0 Improve expand performance","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-140-2019-01-22","text":"","title":"Version 1.4.0 - 2019-01-22"},{"location":"apis/cds-sqlite/CHANGELOG/#added_8","text":".execute supports placeholders in CQN","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-130-2019-01-11","text":"","title":"Version 1.3.0 - 2019-01-11"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_19","text":"Use latest version of @sap/cds-sql","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-120-2018-12-21","text":"","title":"Version 1.2.0 - 2018-12-21"},{"location":"apis/cds-sqlite/CHANGELOG/#added_9","text":"Set default values in case of CREATE, UPSERT and adding a child in deep documents","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-110-2018-12-12","text":"","title":"Version 1.1.0 - 2018-12-12"},{"location":"apis/cds-sqlite/CHANGELOG/#added_10","text":"Support Deep Document CQNs","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-103-2018-11-27","text":"","title":"Version 1.0.3 - 2018-11-27"},{"location":"apis/cds-sqlite/CHANGELOG/#added_11","text":"credentials.database can be used instead of parameters host and url","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_20","text":"Throw db error instead of wrapping it in Sql Error Throw an error if database is not defined instead of fallback to memory","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#fixed_1","text":"Bulk Insert with $user / $now Post processing of Binary, Boolean, DateTime and Integer64","title":"Fixed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-0100-2018-10-17","text":"Refactoring and changes due to updated dependencies","title":"Version 0.10.0 - 2018-10-17"},{"location":"apis/cds-sqlite/CHANGELOG/#version-090-2018-10-04","text":"","title":"Version 0.9.0 - 2018-10-04"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_21","text":"Updated version of @sap/cds-sql to 0.11.0","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-080-2018-09-17","text":"","title":"Version 0.8.0 - 2018-09-17"},{"location":"apis/cds-sqlite/CHANGELOG/#fixed_2","text":"CQN queries with contains and expand (limitation: expanded columns cannot be part of contains)","title":"Fixed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-071-2018-09-05","text":"","title":"Version 0.7.1 - 2018-09-05"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_22","text":"Improved npm-shrinkwrap","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-070-2018-08-28","text":"","title":"Version 0.7.0 - 2018-08-28"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_23","text":"API documentation updated","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-061-2018-08-09","text":"","title":"Version 0.6.1 - 2018-08-09"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_24","text":"Require submodules on demand","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-060-2018-08-07","text":"","title":"Version 0.6.0 - 2018-08-07"},{"location":"apis/cds-sqlite/CHANGELOG/#added_12","text":"cds.Timestamp and cds.DateTime converted into ISO time format when reading Support for abstract placeholders #now and #user","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#fixed_3","text":"SQL error hides internal error messages and provides details in log","title":"Fixed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-050-2018-06-25","text":"","title":"Version 0.5.0 - 2018-06-25"},{"location":"apis/cds-sqlite/CHANGELOG/#added_13","text":"support execution of blocks of statements support plain mode of SQL name mapping","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_25","text":"Added SQL Error to hide the internal information from other errors","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#fixed_4","text":"CDS injection","title":"Fixed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-040-2018-05-02","text":"","title":"Version 0.4.0 - 2018-05-02"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_26","text":"connect options aligned to spec support for latest CQN spec changes","title":"Changed"},{"location":"apis/cds-sqlite/CHANGELOG/#version-030-2018-04-16","text":"","title":"Version 0.3.0 - 2018-04-16"},{"location":"apis/cds-sqlite/CHANGELOG/#added_14","text":"support CREATE statements","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#version-020-2018-03-16","text":"","title":"Version 0.2.0 - 2018-03-16"},{"location":"apis/cds-sqlite/CHANGELOG/#added_15","text":"usage of npm-shrinkwrap","title":"Added"},{"location":"apis/cds-sqlite/CHANGELOG/#changed_27","text":"improved performance","title":"Changed"},{"location":"apis/cloud-sdk-analytics/","text":"cloud-sdk-analytics \u00b6 This package contains the code we use for collecting usage data. Please note that usage analytics is disabled by default, i.e. you need to explicitly opt-in for data to be collected. For more information on how to opt-in and which data is collected, please refer to this document .","title":"cloud-sdk-analytics"},{"location":"apis/cloud-sdk-analytics/#cloud-sdk-analytics","text":"This package contains the code we use for collecting usage data. Please note that usage analytics is disabled by default, i.e. you need to explicitly opt-in for data to be collected. For more information on how to opt-in and which data is collected, please refer to this document .","title":"cloud-sdk-analytics"},{"location":"apis/cloud-sdk-analytics/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-analytics/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-core/","text":"cloud-sdk-core \u00b6 This package contains the core functionality for the Virtual Data Model (VDM) as well as the Cloud Platform abstractions. Helpful Links \u00b6 Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"cloud-sdk-core"},{"location":"apis/cloud-sdk-core/#cloud-sdk-core","text":"This package contains the core functionality for the Virtual Data Model (VDM) as well as the Cloud Platform abstractions.","title":"cloud-sdk-core"},{"location":"apis/cloud-sdk-core/#helpful-links","text":"Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-core/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-core/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-generator/","text":"@sap/cloud-sdk-generator \u00b6 Generate your own service module using a service specification (.edmx file). Installation \u00b6 npm install @sap/cloud-sdk-generator Usage \u00b6 The generator is primarily meant to be used on the command line: generate-odata-client --inputDir path/to/your/service-specification ( s ) --outputDir path/where/the/modules/are/stored Run generate-odata-client --help for further options. You can also use the generator programatically. You will have to provide the options anyways. import { generateProject } from '@sap/cloud-sdk-generator' ; // initialize generator options based on what you want to do const options : GeneratorOptions = initializeOptions (); // creates a Project datastructure with all sourcefiles based on your options const project = generateProject ( options ); // here you can modify you project if you need to // save the files at the specified location project . save (); // alternatively you can generate and save the project in one step with: generate(options) Helpful Links \u00b6 Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"`@sap/cloud-sdk-generator`"},{"location":"apis/cloud-sdk-generator/#sapcloud-sdk-generator","text":"Generate your own service module using a service specification (.edmx file).","title":"@sap/cloud-sdk-generator"},{"location":"apis/cloud-sdk-generator/#installation","text":"npm install @sap/cloud-sdk-generator","title":"Installation"},{"location":"apis/cloud-sdk-generator/#usage","text":"The generator is primarily meant to be used on the command line: generate-odata-client --inputDir path/to/your/service-specification ( s ) --outputDir path/where/the/modules/are/stored Run generate-odata-client --help for further options. You can also use the generator programatically. You will have to provide the options anyways. import { generateProject } from '@sap/cloud-sdk-generator' ; // initialize generator options based on what you want to do const options : GeneratorOptions = initializeOptions (); // creates a Project datastructure with all sourcefiles based on your options const project = generateProject ( options ); // here you can modify you project if you need to // save the files at the specified location project . save (); // alternatively you can generate and save the project in one step with: generate(options)","title":"Usage"},{"location":"apis/cloud-sdk-generator/#helpful-links","text":"Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-generator/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-generator/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-test-util/","text":"cloud-sdk-test-util \u00b6 Package that contains utility functions for testing, like loading credentials or creating test destinations. Helpful Links \u00b6 Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"cloud-sdk-test-util"},{"location":"apis/cloud-sdk-test-util/#cloud-sdk-test-util","text":"Package that contains utility functions for testing, like loading credentials or creating test destinations.","title":"cloud-sdk-test-util"},{"location":"apis/cloud-sdk-test-util/#helpful-links","text":"Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-test-util/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-test-util/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-util/","text":"cloud-sdk-utils \u00b6 Package that contains general utility functions that we reuse multiple times in the SDK. While primarily designed for internal usage, they might also be benefical for consumers of the SDK. Helpful Links \u00b6 Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"cloud-sdk-utils"},{"location":"apis/cloud-sdk-util/#cloud-sdk-utils","text":"Package that contains general utility functions that we reuse multiple times in the SDK. While primarily designed for internal usage, they might also be benefical for consumers of the SDK.","title":"cloud-sdk-utils"},{"location":"apis/cloud-sdk-util/#helpful-links","text":"Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-util/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-util/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-accounting-document-service/","text":"@sap/cloud-sdk-vdm-accounting-document-service \u00b6 This package contains the OData VDM for the Accounting Document Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Finance - Accounting Analytics Integration (SAP_COM_0303). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-accounting-document-service"},{"location":"apis/cloud-sdk-vdm-accounting-document-service/#sapcloud-sdk-vdm-accounting-document-service","text":"This package contains the OData VDM for the Accounting Document Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Finance - Accounting Analytics Integration (SAP_COM_0303). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-accounting-document-service"},{"location":"apis/cloud-sdk-vdm-accounting-document-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-accounting-document-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-accounting-document-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-attachment-service/","text":"@sap/cloud-sdk-vdm-attachment-service \u00b6 This package contains the OData VDM for the Attachment Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Plant Maintenance Master Data Integration (SAP_COM_0319), Purchase Requisition Integration (SAP_COM_0102), Distributed Manufacturing Integration (SAP_COM_0077), Supplier Invoice Integration (SAP_COM_0057), Billing Integration (SAP_COM_0120), Service Order Integration (SAP_COM_0350), Product Lifecycle Management - Master Data Integration (SAP_COM_0105), Defect Processing Integration (SAP_COM_0153), SAP S/4HANA Procurement Hub - Ariba GB - Hub to Ariba GB Integration (SAP_COM_0292), Legal Document Integration (SAP_COM_0178), SAP S/4HANA Procurement Hub - Central Invoice Satellite Integration (SAP_COM_0516), Finance - Posting Integration (SAP_COM_0002), Joint Venture Partner Billing Files Integration (SAP_COM_0381), Warehousing - Attachment Service Integration (SAP_COM_0386). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-attachment-service"},{"location":"apis/cloud-sdk-vdm-attachment-service/#sapcloud-sdk-vdm-attachment-service","text":"This package contains the OData VDM for the Attachment Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Plant Maintenance Master Data Integration (SAP_COM_0319), Purchase Requisition Integration (SAP_COM_0102), Distributed Manufacturing Integration (SAP_COM_0077), Supplier Invoice Integration (SAP_COM_0057), Billing Integration (SAP_COM_0120), Service Order Integration (SAP_COM_0350), Product Lifecycle Management - Master Data Integration (SAP_COM_0105), Defect Processing Integration (SAP_COM_0153), SAP S/4HANA Procurement Hub - Ariba GB - Hub to Ariba GB Integration (SAP_COM_0292), Legal Document Integration (SAP_COM_0178), SAP S/4HANA Procurement Hub - Central Invoice Satellite Integration (SAP_COM_0516), Finance - Posting Integration (SAP_COM_0002), Joint Venture Partner Billing Files Integration (SAP_COM_0381), Warehousing - Attachment Service Integration (SAP_COM_0386). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-attachment-service"},{"location":"apis/cloud-sdk-vdm-attachment-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-attachment-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-attachment-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bank-detail-service/","text":"@sap/cloud-sdk-vdm-bank-detail-service \u00b6 This package contains the OData VDM for the Bank Detail Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Finance - Bank Integration (SAP_COM_0127), Employee Central Financial Master Data Integration (SAP_COM_0441). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-bank-detail-service"},{"location":"apis/cloud-sdk-vdm-bank-detail-service/#sapcloud-sdk-vdm-bank-detail-service","text":"This package contains the OData VDM for the Bank Detail Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Finance - Bank Integration (SAP_COM_0127), Employee Central Financial Master Data Integration (SAP_COM_0441). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-bank-detail-service"},{"location":"apis/cloud-sdk-vdm-bank-detail-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-bank-detail-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bank-detail-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-batch-service/","text":"@sap/cloud-sdk-vdm-batch-service \u00b6 This package contains the OData VDM for the Batch Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Batch Management OData Integration (SAP_COM_0337). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-batch-service"},{"location":"apis/cloud-sdk-vdm-batch-service/#sapcloud-sdk-vdm-batch-service","text":"This package contains the OData VDM for the Batch Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Batch Management OData Integration (SAP_COM_0337). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-batch-service"},{"location":"apis/cloud-sdk-vdm-batch-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-batch-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-batch-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-comparison-service/","text":"@sap/cloud-sdk-vdm-bill-of-material-comparison-service \u00b6 This package contains the OData VDM for the Bill Of Material Comparison Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-bill-of-material-comparison-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-comparison-service/#sapcloud-sdk-vdm-bill-of-material-comparison-service","text":"This package contains the OData VDM for the Bill Of Material Comparison Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-bill-of-material-comparison-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-comparison-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-bill-of-material-comparison-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-comparison-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-service/","text":"@sap/cloud-sdk-vdm-bill-of-material-service \u00b6 This package contains the OData VDM for the Bill Of Material Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-bill-of-material-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-service/#sapcloud-sdk-vdm-bill-of-material-service","text":"This package contains the OData VDM for the Bill Of Material Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-bill-of-material-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-bill-of-material-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-v2-service/","text":"@sap/cloud-sdk-vdm-bill-of-material-v2-service \u00b6 This package contains the OData VDM for the Bill Of Material V2 Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-bill-of-material-v2-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-v2-service/#sapcloud-sdk-vdm-bill-of-material-v2-service","text":"This package contains the OData VDM for the Bill Of Material V2 Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-bill-of-material-v2-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-v2-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-bill-of-material-v2-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-v2-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-where-used-service/","text":"@sap/cloud-sdk-vdm-bill-of-material-where-used-service \u00b6 This package contains the OData VDM for the Bill Of Material Where Used Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-bill-of-material-where-used-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-where-used-service/#sapcloud-sdk-vdm-bill-of-material-where-used-service","text":"This package contains the OData VDM for the Bill Of Material Where Used Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Product Lifecycle Management - Master Data Integration (SAP_COM_0105). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-bill-of-material-where-used-service"},{"location":"apis/cloud-sdk-vdm-bill-of-material-where-used-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-bill-of-material-where-used-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-bill-of-material-where-used-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-billing-document-request-service/","text":"@sap/cloud-sdk-vdm-billing-document-request-service \u00b6 This package contains the OData VDM for the Billing Document Request Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: External Billing Document Request Integration (SAP_COM_0176). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-billing-document-request-service"},{"location":"apis/cloud-sdk-vdm-billing-document-request-service/#sapcloud-sdk-vdm-billing-document-request-service","text":"This package contains the OData VDM for the Billing Document Request Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: External Billing Document Request Integration (SAP_COM_0176). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-billing-document-request-service"},{"location":"apis/cloud-sdk-vdm-billing-document-request-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-billing-document-request-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-billing-document-request-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-billing-document-service/","text":"@sap/cloud-sdk-vdm-billing-document-service \u00b6 This package contains the OData VDM for the Billing Document Service of SAP S/4HANA Cloud. Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-billing-document-service"},{"location":"apis/cloud-sdk-vdm-billing-document-service/#sapcloud-sdk-vdm-billing-document-service","text":"This package contains the OData VDM for the Billing Document Service of SAP S/4HANA Cloud.","title":"@sap/cloud-sdk-vdm-billing-document-service"},{"location":"apis/cloud-sdk-vdm-billing-document-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-billing-document-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-billing-document-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-area-service/","text":"@sap/cloud-sdk-vdm-business-area-service \u00b6 This package contains the OData VDM for the Business Area Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: SAP Analytics Cloud for Planning Integration (SAP_COM_0087), Finance - Cloud Consolidation Data Collection Integration (SAP_COM_0241). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-business-area-service"},{"location":"apis/cloud-sdk-vdm-business-area-service/#sapcloud-sdk-vdm-business-area-service","text":"This package contains the OData VDM for the Business Area Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: SAP Analytics Cloud for Planning Integration (SAP_COM_0087), Finance - Cloud Consolidation Data Collection Integration (SAP_COM_0241). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-business-area-service"},{"location":"apis/cloud-sdk-vdm-business-area-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-business-area-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-area-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-event-queue-service/","text":"@sap/cloud-sdk-vdm-business-event-queue-service \u00b6 This package contains the OData VDM for the Business Event Queue Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Business Event Handling Integration (SAP_COM_0121), OpenText Business Event Integration (SAP_COM_0007). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-business-event-queue-service"},{"location":"apis/cloud-sdk-vdm-business-event-queue-service/#sapcloud-sdk-vdm-business-event-queue-service","text":"This package contains the OData VDM for the Business Event Queue Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Business Event Handling Integration (SAP_COM_0121), OpenText Business Event Integration (SAP_COM_0007). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-business-event-queue-service"},{"location":"apis/cloud-sdk-vdm-business-event-queue-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-business-event-queue-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-event-queue-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-event-subscription-service/","text":"@sap/cloud-sdk-vdm-business-event-subscription-service \u00b6 This package contains the OData VDM for the Business Event Subscription Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Business Event Handling Integration (SAP_COM_0121), OpenText Business Event Integration (SAP_COM_0007). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-business-event-subscription-service"},{"location":"apis/cloud-sdk-vdm-business-event-subscription-service/#sapcloud-sdk-vdm-business-event-subscription-service","text":"This package contains the OData VDM for the Business Event Subscription Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Business Event Handling Integration (SAP_COM_0121), OpenText Business Event Integration (SAP_COM_0007). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-business-event-subscription-service"},{"location":"apis/cloud-sdk-vdm-business-event-subscription-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-business-event-subscription-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-event-subscription-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-partner-service/","text":"@sap/cloud-sdk-vdm-business-partner-service \u00b6 This package contains the OData VDM for the Business Partner Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: SAP Analytics Cloud for Planning Integration (SAP_COM_0087), Delivery Insights Replication App Integration (SAP_COM_0571), Business Partner, Customer and Supplier Integration (SAP_COM_0008), Excise Tax Integration (SAP_COM_0568). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-business-partner-service"},{"location":"apis/cloud-sdk-vdm-business-partner-service/#sapcloud-sdk-vdm-business-partner-service","text":"This package contains the OData VDM for the Business Partner Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: SAP Analytics Cloud for Planning Integration (SAP_COM_0087), Delivery Insights Replication App Integration (SAP_COM_0571), Business Partner, Customer and Supplier Integration (SAP_COM_0008), Excise Tax Integration (SAP_COM_0568). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-business-partner-service"},{"location":"apis/cloud-sdk-vdm-business-partner-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-business-partner-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-partner-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-situation-service/","text":"@sap/cloud-sdk-vdm-business-situation-service \u00b6 This package contains the OData VDM for the Business Situation Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Business Situation Integration (SAP_COM_0345). You can find additional documentation for this service on help.sap.com . Helpful Links \u00b6 SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"@sap/cloud-sdk-vdm-business-situation-service"},{"location":"apis/cloud-sdk-vdm-business-situation-service/#sapcloud-sdk-vdm-business-situation-service","text":"This package contains the OData VDM for the Business Situation Service of SAP S/4HANA Cloud. This service is part of the following communication scenarios: Business Situation Integration (SAP_COM_0345). You can find additional documentation for this service on help.sap.com .","title":"@sap/cloud-sdk-vdm-business-situation-service"},{"location":"apis/cloud-sdk-vdm-business-situation-service/#helpful-links","text":"SAP Cloud SDK Tutorials on developers.sap.com SAP Cloud SDK on StackOverflow SAP Cloud SDK on answers.sap.com Release notes All versions of this documentation Product page of the SAP Cloud SDK SAP Cloud SDK Continuous Delivery Toolkit Example Applications using the SAP Cloud SDK","title":"Helpful Links"},{"location":"apis/cloud-sdk-vdm-business-situation-service/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/cloud-sdk-vdm-business-situation-service/CHANGELOG/#change-log","text":"All notable changes to this module will be documented centrally in the SAP Cloud SDK release notes .","title":"Change Log"},{"location":"apis/di.code-validation.core/","text":"di.code-validation.core \u00b6 code validation controller for DI. returning issues in code according to validators configured install \u00b6 npm install di.code-validation.core --save-dev CodeValidation API \u00b6 executeForProject ( projectPath , workspaceRootName , configuration , callbackFunction ) basePath - full path for the validated folder location options - an object to set additional options for execution and return values processing. options.pathPrefix - validation issues paths are relative to the project path. _pathPrefix enable to set constant prefix to the returned path. configuration - configuration of the validators to execute. object of type ValidationConfig callbackFunction - callback of results. (TBD: add also failure for callback?) ValidationConfig structure: { \"validators\" : { \"validator1\" : { \"extensions\" : [ '.js' , '.xsjs' ], \"filters\" : { \"levels\" : [ \"error\" , \"warning\" , \"info\" ] } }, \"validator2\" : { \"extensions\" : [ '.new' ], \"filters\" : { \"levels\" : [ \"error\" ] } } .... } } result structure: { \"validator_id\" : { \"issues\" : { \"relative_file_path\" : [ { \"category\" : \"Possible Error\" , \"checker\" : \"validator checker name\" , \"column\" : 1 , \"line\" : 14 , \"message\" : \"some message\" , \"path\" : \"relative_file_path\" , \"ruleId\" : \"optional name of rule\" , \"severity\" : \"error\" } .... ] } .... } } validator API \u00b6 Each validator should implement following API: validateFiles ( validationMetadata , fileResources ) validationMetadata - contains following methods: getRootPath () - workspaceRootName getLevels () - array of levels of issues to return fileResources - array of files to validate (TBD: enable validation by extension of regular expression) getPath () - returns the file full path getText () - returns the text in the file run validation from command line \u00b6 node di.code-validation.core\\bin\\run.js \"project file location\" \"client workspace root path\" --c \"configuration file location\" - file with validation configuration. if not supplied defaults used. Example for configuration file: var configParam = { \"validators\" : { \"di.code-validation.js\" : { \"extensions\" : [ \".js\" , \".xsjs\" ], \"filters\" : { \"levels\" : [ \"error\" , \"warning\" , \"info\" ] } } } }; module . exports = configParam ; --l \"log file\" - location of the outpul log file. default is the execution directory default configuration: \u00b6 validators : { \"di.code-validation.js\" : { extensions : [ \".js\" , \".xsjs\" ] }, \"di.code-validation.xml\" : { extensions : [ \".xml\" ] } }","title":"di.code-validation.core"},{"location":"apis/di.code-validation.core/#dicode-validationcore","text":"code validation controller for DI. returning issues in code according to validators configured","title":"di.code-validation.core"},{"location":"apis/di.code-validation.core/#install","text":"npm install di.code-validation.core --save-dev","title":"install"},{"location":"apis/di.code-validation.core/#codevalidation-api","text":"executeForProject ( projectPath , workspaceRootName , configuration , callbackFunction ) basePath - full path for the validated folder location options - an object to set additional options for execution and return values processing. options.pathPrefix - validation issues paths are relative to the project path. _pathPrefix enable to set constant prefix to the returned path. configuration - configuration of the validators to execute. object of type ValidationConfig callbackFunction - callback of results. (TBD: add also failure for callback?) ValidationConfig structure: { \"validators\" : { \"validator1\" : { \"extensions\" : [ '.js' , '.xsjs' ], \"filters\" : { \"levels\" : [ \"error\" , \"warning\" , \"info\" ] } }, \"validator2\" : { \"extensions\" : [ '.new' ], \"filters\" : { \"levels\" : [ \"error\" ] } } .... } } result structure: { \"validator_id\" : { \"issues\" : { \"relative_file_path\" : [ { \"category\" : \"Possible Error\" , \"checker\" : \"validator checker name\" , \"column\" : 1 , \"line\" : 14 , \"message\" : \"some message\" , \"path\" : \"relative_file_path\" , \"ruleId\" : \"optional name of rule\" , \"severity\" : \"error\" } .... ] } .... } }","title":"CodeValidation API"},{"location":"apis/di.code-validation.core/#validator-api","text":"Each validator should implement following API: validateFiles ( validationMetadata , fileResources ) validationMetadata - contains following methods: getRootPath () - workspaceRootName getLevels () - array of levels of issues to return fileResources - array of files to validate (TBD: enable validation by extension of regular expression) getPath () - returns the file full path getText () - returns the text in the file","title":"validator API"},{"location":"apis/di.code-validation.core/#run-validation-from-command-line","text":"node di.code-validation.core\\bin\\run.js \"project file location\" \"client workspace root path\" --c \"configuration file location\" - file with validation configuration. if not supplied defaults used. Example for configuration file: var configParam = { \"validators\" : { \"di.code-validation.js\" : { \"extensions\" : [ \".js\" , \".xsjs\" ], \"filters\" : { \"levels\" : [ \"error\" , \"warning\" , \"info\" ] } } } }; module . exports = configParam ; --l \"log file\" - location of the outpul log file. default is the execution directory","title":"run validation from command line"},{"location":"apis/di.code-validation.core/#default-configuration","text":"validators : { \"di.code-validation.js\" : { extensions : [ \".js\" , \".xsjs\" ] }, \"di.code-validation.xml\" : { extensions : [ \".xml\" ] } }","title":"default configuration:"},{"location":"apis/di.code-validation.grunt/","text":"di.code-validation.grunt \u00b6 provides grunt tasks for code validation install \u00b6 npm install di.code-validation.grunt --save-dev Usage \u00b6 var fs = require ( 'fs' ); var path = require ( 'path' ); module . exports = function ( grunt ) { \"use strict\" ; var pkg = grunt . file . readJSON ( 'package.json' ); // Project configuration. grunt . initConfig ({ // Task configuration. pkg : pkg , codevalidation : { options : { projectPath : '<path to the project>' , pathPrefix : '<optionally prefix to concat to the project path>' , ignoredPaths : [ < path to folders to skip validaitons for > ...], reporter : \"problems_reporter\" , reporterOptions : { outputFile : path . join ( __dirname , \"code-validation-test.log\" )} } } }); grunt . loadNpmTasks ( 'di.code-validation.grunt' ); grunt . registerTask ( 'validate' , [ 'codevalidation' ]); };","title":"di.code-validation.grunt"},{"location":"apis/di.code-validation.grunt/#dicode-validationgrunt","text":"provides grunt tasks for code validation","title":"di.code-validation.grunt"},{"location":"apis/di.code-validation.grunt/#install","text":"npm install di.code-validation.grunt --save-dev","title":"install"},{"location":"apis/di.code-validation.grunt/#usage","text":"var fs = require ( 'fs' ); var path = require ( 'path' ); module . exports = function ( grunt ) { \"use strict\" ; var pkg = grunt . file . readJSON ( 'package.json' ); // Project configuration. grunt . initConfig ({ // Task configuration. pkg : pkg , codevalidation : { options : { projectPath : '<path to the project>' , pathPrefix : '<optionally prefix to concat to the project path>' , ignoredPaths : [ < path to folders to skip validaitons for > ...], reporter : \"problems_reporter\" , reporterOptions : { outputFile : path . join ( __dirname , \"code-validation-test.log\" )} } } }); grunt . loadNpmTasks ( 'di.code-validation.grunt' ); grunt . registerTask ( 'validate' , [ 'codevalidation' ]); };","title":"Usage"},{"location":"apis/di.code-validation.js/","text":"di.code-validation.js \u00b6 A javascript code validator for DI based on eslint, implements di.code-validation.core API. install \u00b6 npm install di.code-validation.js --save-dev Usage \u00b6 var jsvalidator = require ( \"di.code-validation.js\" ); var ValidationMetadata = require ( \"di.code-validation.core\" ). validationMetadata ; var FileResource = require ( \"di.code-validation.core\" ). fileResource ; var validationMetadata = new ValidationMetadata ( < proLocation > ); var fileResources = []; var fileResource = new FileResource ( < full project path > , < full file path > ); fileResources . push ( fileResource ); var result = jsvalidator . validateFiles ( validationMetadata , fileResources ); result structure { \"category\" : < category for the rule > , \"checker\" : < base linter used > , \"column\" : 0 , \"line\" : 2 , \"helpUrl\" : < url for help documentation > , \"message\" : < message > , \"path\" : < full file path > , \"ruleId\" : < rule id > , \"severity\" : < error / warning / info > }","title":"di.code-validation.js"},{"location":"apis/di.code-validation.js/#dicode-validationjs","text":"A javascript code validator for DI based on eslint, implements di.code-validation.core API.","title":"di.code-validation.js"},{"location":"apis/di.code-validation.js/#install","text":"npm install di.code-validation.js --save-dev","title":"install"},{"location":"apis/di.code-validation.js/#usage","text":"var jsvalidator = require ( \"di.code-validation.js\" ); var ValidationMetadata = require ( \"di.code-validation.core\" ). validationMetadata ; var FileResource = require ( \"di.code-validation.core\" ). fileResource ; var validationMetadata = new ValidationMetadata ( < proLocation > ); var fileResources = []; var fileResource = new FileResource ( < full project path > , < full file path > ); fileResources . push ( fileResource ); var result = jsvalidator . validateFiles ( validationMetadata , fileResources ); result structure { \"category\" : < category for the rule > , \"checker\" : < base linter used > , \"column\" : 0 , \"line\" : 2 , \"helpUrl\" : < url for help documentation > , \"message\" : < message > , \"path\" : < full file path > , \"ruleId\" : < rule id > , \"severity\" : < error / warning / info > }","title":"Usage"},{"location":"apis/di.code-validation.xml/","text":"di.code-validation.xml \u00b6","title":"di.code-validation.xml"},{"location":"apis/di.code-validation.xml/#dicode-validationxml","text":"","title":"di.code-validation.xml"},{"location":"apis/dwf-core/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . [Unreleased] \u00b6 [2.2.1] 2018-01-08 \u00b6 Added \u00b6 Add CHANGELOG.md (this file) and publishable README.md Changed \u00b6 update node dependencies","title":"Changelog"},{"location":"apis/dwf-core/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"apis/dwf-core/CHANGELOG/#unreleased","text":"","title":"[Unreleased]"},{"location":"apis/dwf-core/CHANGELOG/#221-2018-01-08","text":"","title":"[2.2.1] 2018-01-08"},{"location":"apis/dwf-core/CHANGELOG/#added","text":"Add CHANGELOG.md (this file) and publishable README.md","title":"Added"},{"location":"apis/dwf-core/CHANGELOG/#changed","text":"update node dependencies","title":"Changed"},{"location":"apis/dwf-deploy/","text":"dwf-deploy \u00b6 The DWF Deploy - Checks for unsupported design time artefacts - ok (DWF 2.0 SP01) - Prepares the payload for the materialization (i.e. processes the dwfnamespace files) - ok (DWF 2.0 SP01) - Executes the materialization of the design to runtime objects, where the transactional scope is on module level dwf-runtime - ok (DWF 2.0 SP01) - Grants required privileges to the technical user (i.e. to be able to perform the exposed actions) - TODO The implementation is based on xs2/hdideploy.js . + -----------------+ +-----------------+ +-----------------+ | dwf module | | Web IDE | | ... module | | w / dwf - deploy | | | | | + -----------------+ +-----------------+ +-----------------+ | | | | | | \\ / design -> runtime \\ / discover / execute | | | | | | + -----------------------------------------------------------------------+ | dwf - runtime | | types ( toe , dlm ), instances ( toe / chaim , dlm / profile ), actions ( execute ) | + -----------------------------------------------------------------------+ The materialization patterns - .txt - accepted, but not processed - .dwfnamespace - overwrites the default logic for calculating the namespace. Default namespace for the src folder is calculated based on the following setting { \"name\": \"{mta.yaml mta name}.{mta.yaml dwf-module name}.src\", \"subfolder\": \"append\" } - .dwftaskchain - {mta name}/{dwf-module name}/src/.../toeChainExample.dwftaskchain -> {dwf-toe url per extension}/ /toeChainExample - .dwfdlmprofile - {mta name}/{dwf-module name}/src/.../dlmProfileExample.dwfdlmprofile -> {dwf-dlm-backend url per extension} The considered scenarios - deploy/update: version >= 2.0.x - rename: version >= 2.2.x - delete: version >= 2.2.x - delta: version >= 2.2.x","title":"dwf-deploy"},{"location":"apis/dwf-deploy/#dwf-deploy","text":"The DWF Deploy - Checks for unsupported design time artefacts - ok (DWF 2.0 SP01) - Prepares the payload for the materialization (i.e. processes the dwfnamespace files) - ok (DWF 2.0 SP01) - Executes the materialization of the design to runtime objects, where the transactional scope is on module level dwf-runtime - ok (DWF 2.0 SP01) - Grants required privileges to the technical user (i.e. to be able to perform the exposed actions) - TODO The implementation is based on xs2/hdideploy.js . + -----------------+ +-----------------+ +-----------------+ | dwf module | | Web IDE | | ... module | | w / dwf - deploy | | | | | + -----------------+ +-----------------+ +-----------------+ | | | | | | \\ / design -> runtime \\ / discover / execute | | | | | | + -----------------------------------------------------------------------+ | dwf - runtime | | types ( toe , dlm ), instances ( toe / chaim , dlm / profile ), actions ( execute ) | + -----------------------------------------------------------------------+ The materialization patterns - .txt - accepted, but not processed - .dwfnamespace - overwrites the default logic for calculating the namespace. Default namespace for the src folder is calculated based on the following setting { \"name\": \"{mta.yaml mta name}.{mta.yaml dwf-module name}.src\", \"subfolder\": \"append\" } - .dwftaskchain - {mta name}/{dwf-module name}/src/.../toeChainExample.dwftaskchain -> {dwf-toe url per extension}/ /toeChainExample - .dwfdlmprofile - {mta name}/{dwf-module name}/src/.../dlmProfileExample.dwfdlmprofile -> {dwf-dlm-backend url per extension} The considered scenarios - deploy/update: version >= 2.0.x - rename: version >= 2.2.x - delete: version >= 2.2.x - delta: version >= 2.2.x","title":"dwf-deploy"},{"location":"apis/dwf-deploy/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . [2.4.0] - 2018-09-13 \u00b6 Added: - .dwfdlmtablegroup - the design time artifact for modeling text, where the content of the file can be any valid text - .dwfndso - the design time artifact for modeling text, where the content of the file can be any valid text Fixed: - .dwfnamespace - calculation and handling [2.3.0] - 2018-03-05 \u00b6 Added: - Released for DWF 2 SP03 Fixed: - changelog - complies with the 'Keep a Changelog' format - Requires engine ^6.9.1 [2.2.4] - 2017-09-07 \u00b6 Fixed \u00b6 .dwfnamespace - fixed calculation, will require redeploy [2.2.3] - 2017-08-15 \u00b6 Fixed \u00b6 license \u2013 shall have no license [2.2.2] - 2017-08-11 \u00b6 Fixed \u00b6 trace - the version of the module repository - properly to update the providers and object types [2.2.1] - 2017-06-29 \u00b6 Fixed \u00b6 minor fixes dwfdlmprofile - aligns with the general requirements for deployment of design time artefacts log and trace - handles better the sensitive data verbose - traces the details of the request and response [2.2.0] - 2017-05-30 \u00b6 Added \u00b6 .dwfnamespace - schema validation repository - persists the calculated hash in the object instance dwf-template - removes the open source dependencies that are required for its Backend module, because they shall be made available via the dwf-dws-client .dwftaskchain - delta-deployment [2.0.3] - 2017-03-21 \u00b6 Fixed \u00b6 dwf-template - bumps the versions of express and body-parser [2.0.2] - 2017-03-21 \u00b6 Fixed \u00b6 dwf-template - removes the dependency to swagger-express-mw [2.0.1] - 2017-03-14 \u00b6 Added \u00b6 dwf-template - adds the open source dependencies that are required for its Backend module Fixed \u00b6 stdout and stderr - writes synchronously to avoid loss of log output in case of crashes, etc. trace - removes the sensitive information for the traced data dwf-template - adds the dependencies that are required by the Backend module of our dwf-template ssl certificate - loads the certificate by calling xsenv.loadCertificates(). If no certificates are loaded, then falls back to process.env.NODE_TLS_REJECT_UNAUTHORIZED = 0 to avoid rejecting unauthorized backends org_guid and space_guid - fetched from the environment and pushed to the repository [2.0.0] - 2017-02-23 \u00b6 Added \u00b6 dwf module environment - isolation per version, currently used for version 1 repository - updates the dwf repository after dwf service provider is modified .dwfnamespace - the design time artifact for modeling namespaces, wihch are different than the default ones command line arguments - help, version, trace, verbose, exit and rejectUnauthorized .dwftaskchain - batch post for all task chains will replace the old post per task chain, to ensure the deployment transaction of module level .txt - the design time artifact for modeling text, where the content of the file can be any valid text .{any extension} - rejects the deployment of dwf-modules, which contain unsupported file extensions .dwftaskchain - the design time artifact for modeling task chains, where the content of the file shall be a valid stringified json Fixed \u00b6 empty dwf module - Cannot read property 'forEach' of undefined: \\@sap\\dwf-deploy\\lib\\dwf\\repository.js:35 .dwftaskchain - supports nameless designtime files (i.e. .dwftaskchain as a complete file name) service instance - logs the name of the service instance (a.k.a. container) to which is deploying environment - expects the finalized structure for DWF 2.0 SP00 and HANA 2 SP01 the stack trace of an error - will not be lost, but will be traced .dwftaskchain - will check the status code in the response of the post http call .dwftaskchain - will abort the deployment, when two or more designtime files defining the same runtime object .dwftaskchain - the default namespace of the runtime object is now prefixed with {mta.yaml mta name}.{mta.yaml dwf-module name} .dwftaskchain - the name of the runtime object is derived by the file name, but without its file extension","title":"Changelog"},{"location":"apis/dwf-deploy/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"apis/dwf-deploy/CHANGELOG/#240-2018-09-13","text":"Added: - .dwfdlmtablegroup - the design time artifact for modeling text, where the content of the file can be any valid text - .dwfndso - the design time artifact for modeling text, where the content of the file can be any valid text Fixed: - .dwfnamespace - calculation and handling","title":"[2.4.0] - 2018-09-13"},{"location":"apis/dwf-deploy/CHANGELOG/#230-2018-03-05","text":"Added: - Released for DWF 2 SP03 Fixed: - changelog - complies with the 'Keep a Changelog' format - Requires engine ^6.9.1","title":"[2.3.0] - 2018-03-05"},{"location":"apis/dwf-deploy/CHANGELOG/#224-2017-09-07","text":"","title":"[2.2.4] - 2017-09-07"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed","text":".dwfnamespace - fixed calculation, will require redeploy","title":"Fixed"},{"location":"apis/dwf-deploy/CHANGELOG/#223-2017-08-15","text":"","title":"[2.2.3] - 2017-08-15"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed_1","text":"license \u2013 shall have no license","title":"Fixed"},{"location":"apis/dwf-deploy/CHANGELOG/#222-2017-08-11","text":"","title":"[2.2.2] - 2017-08-11"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed_2","text":"trace - the version of the module repository - properly to update the providers and object types","title":"Fixed"},{"location":"apis/dwf-deploy/CHANGELOG/#221-2017-06-29","text":"","title":"[2.2.1] - 2017-06-29"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed_3","text":"minor fixes dwfdlmprofile - aligns with the general requirements for deployment of design time artefacts log and trace - handles better the sensitive data verbose - traces the details of the request and response","title":"Fixed"},{"location":"apis/dwf-deploy/CHANGELOG/#220-2017-05-30","text":"","title":"[2.2.0] - 2017-05-30"},{"location":"apis/dwf-deploy/CHANGELOG/#added","text":".dwfnamespace - schema validation repository - persists the calculated hash in the object instance dwf-template - removes the open source dependencies that are required for its Backend module, because they shall be made available via the dwf-dws-client .dwftaskchain - delta-deployment","title":"Added"},{"location":"apis/dwf-deploy/CHANGELOG/#203-2017-03-21","text":"","title":"[2.0.3] - 2017-03-21"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed_4","text":"dwf-template - bumps the versions of express and body-parser","title":"Fixed"},{"location":"apis/dwf-deploy/CHANGELOG/#202-2017-03-21","text":"","title":"[2.0.2] - 2017-03-21"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed_5","text":"dwf-template - removes the dependency to swagger-express-mw","title":"Fixed"},{"location":"apis/dwf-deploy/CHANGELOG/#201-2017-03-14","text":"","title":"[2.0.1] - 2017-03-14"},{"location":"apis/dwf-deploy/CHANGELOG/#added_1","text":"dwf-template - adds the open source dependencies that are required for its Backend module","title":"Added"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed_6","text":"stdout and stderr - writes synchronously to avoid loss of log output in case of crashes, etc. trace - removes the sensitive information for the traced data dwf-template - adds the dependencies that are required by the Backend module of our dwf-template ssl certificate - loads the certificate by calling xsenv.loadCertificates(). If no certificates are loaded, then falls back to process.env.NODE_TLS_REJECT_UNAUTHORIZED = 0 to avoid rejecting unauthorized backends org_guid and space_guid - fetched from the environment and pushed to the repository","title":"Fixed"},{"location":"apis/dwf-deploy/CHANGELOG/#200-2017-02-23","text":"","title":"[2.0.0] - 2017-02-23"},{"location":"apis/dwf-deploy/CHANGELOG/#added_2","text":"dwf module environment - isolation per version, currently used for version 1 repository - updates the dwf repository after dwf service provider is modified .dwfnamespace - the design time artifact for modeling namespaces, wihch are different than the default ones command line arguments - help, version, trace, verbose, exit and rejectUnauthorized .dwftaskchain - batch post for all task chains will replace the old post per task chain, to ensure the deployment transaction of module level .txt - the design time artifact for modeling text, where the content of the file can be any valid text .{any extension} - rejects the deployment of dwf-modules, which contain unsupported file extensions .dwftaskchain - the design time artifact for modeling task chains, where the content of the file shall be a valid stringified json","title":"Added"},{"location":"apis/dwf-deploy/CHANGELOG/#fixed_7","text":"empty dwf module - Cannot read property 'forEach' of undefined: \\@sap\\dwf-deploy\\lib\\dwf\\repository.js:35 .dwftaskchain - supports nameless designtime files (i.e. .dwftaskchain as a complete file name) service instance - logs the name of the service instance (a.k.a. container) to which is deploying environment - expects the finalized structure for DWF 2.0 SP00 and HANA 2 SP01 the stack trace of an error - will not be lost, but will be traced .dwftaskchain - will check the status code in the response of the post http call .dwftaskchain - will abort the deployment, when two or more designtime files defining the same runtime object .dwftaskchain - the default namespace of the runtime object is now prefixed with {mta.yaml mta name}.{mta.yaml dwf-module name} .dwftaskchain - the name of the runtime object is derived by the file name, but without its file extension","title":"Fixed"},{"location":"apis/dwf-dlm-backend/","text":"dwf-dlm-backend \u00b6 This is the Data Lifecycle Management (DLM) as an npm module.","title":"dwf-dlm-backend"},{"location":"apis/dwf-dlm-backend/#dwf-dlm-backend","text":"This is the Data Lifecycle Management (DLM) as an npm module.","title":"dwf-dlm-backend"},{"location":"apis/dwf-dlm-backend/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . 2.3.0 - 2018-03-02 \u00b6 Added: \u00b6 Released for DWF 2 SP03 Content Validation for tableExtension, tableExternal, and tableInternal extension node Fixed: \u00b6 warning for empty keys for tableExternal, ExtentionNode type ROUNROBIN the content validation the dlm profiles: partition_level_1 content validation - node[2]/../column/key - no key is accecpted, when (extension node and roundrobin) or table external npm-shrinkwrap Schema Validation of dlmProfile :: dlmprofile--> runtime--> node--> action--> view--> \"pruningUnionNode\" renamed as \"pruning\" [2.2.3] -2017-08-30 \u00b6 Added: \u00b6 - Fixed: \u00b6 - [2.2.2] -2017-08-15 \u00b6 Added: \u00b6 - Fixed: \u00b6 dlm profile - content validation [2.2.1] -2017-08-11 \u00b6 Added: \u00b6 - Fixed: \u00b6 start script - exposes the main.js for successful start [2.2.0] -2017-08-11 \u00b6 Added: \u00b6 dlm profile - schema validation (Semantics) dlm profile - content validation Fixed: \u00b6 -","title":"Changelog"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#230-2018-03-02","text":"","title":"2.3.0 - 2018-03-02"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#added","text":"Released for DWF 2 SP03 Content Validation for tableExtension, tableExternal, and tableInternal extension node","title":"Added:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#fixed","text":"warning for empty keys for tableExternal, ExtentionNode type ROUNROBIN the content validation the dlm profiles: partition_level_1 content validation - node[2]/../column/key - no key is accecpted, when (extension node and roundrobin) or table external npm-shrinkwrap Schema Validation of dlmProfile :: dlmprofile--> runtime--> node--> action--> view--> \"pruningUnionNode\" renamed as \"pruning\"","title":"Fixed:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#223-2017-08-30","text":"","title":"[2.2.3] -2017-08-30"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#added_1","text":"-","title":"Added:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#fixed_1","text":"-","title":"Fixed:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#222-2017-08-15","text":"","title":"[2.2.2] -2017-08-15"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#added_2","text":"-","title":"Added:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#fixed_2","text":"dlm profile - content validation","title":"Fixed:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#221-2017-08-11","text":"","title":"[2.2.1] -2017-08-11"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#added_3","text":"-","title":"Added:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#fixed_3","text":"start script - exposes the main.js for successful start","title":"Fixed:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#220-2017-08-11","text":"","title":"[2.2.0] -2017-08-11"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#added_4","text":"dlm profile - schema validation (Semantics) dlm profile - content validation","title":"Added:"},{"location":"apis/dwf-dlm-backend/CHANGELOG/#fixed_4","text":"-","title":"Fixed:"},{"location":"apis/dwf-dws-client/","text":"Data Warehouse Services Client \u00b6 This Node.js package registers the SAP default task types at the Data Warehouse Scheduler that need access to the local HDI and DWF containers of the consuming project. In addition it runs an HTTP server to provide task type related endpoints for value helps and task execution. Usage \u00b6 Add this package as dependency in a standard Node.js module in your XSA application. In your development descriptor mta.yaml ensure that HDI (type com.sap.xs.hdi-container and DWF (type com.sap.xs.dwf-edw-client ) services are bound in the resources section. For example: resources : - name : myapp-dws type : com.sap.xs.dwf-edw-client properties : dwf-edw-client-name : ${service-name} - name : myapp-hdi type : com.sap.xs.hdi-container properties : hdi-container-name : ${service-name} The service instances have to be required by the module consuming this package modules : - name : myapp-Backend type : nodejs path : Backend requires : - name : myapp-hdi - name : myapp-dws In the start script of your Node.js module load this package and instantiate the client for the Task Orchestration Engine of the Data Warehouse Scheduler (TOE): const xsenv = require ( '@sap/xsenv' ); const dwsClient = require ( '@sap/dwf-dws-client' ); const loopBackUrl = JSON . parse ( process . env . VCAP_APPLICATION ). full_application_uris [ 0 ]; const rejectUnauth = true ; const TaskChain = dwsClient . taskChain . createTaskChainClient ( xsenv . getServices ({ dwf : { tag : 'dwf' } }). dwf , loopBackUrl , rejectUnauth ); To allow the scheduler to call the registered endpoints, start an HTTP server and expose the routes. Below, you see an example using express.js . Be aware that this example omits proper authentication and authorization checks which must be implemented for productive use. const PORT = process . env . PORT || 3000 ; const express = require ( 'express' ); const app = express (); TaskChain . addRouter ( app , '/backend' ); app . listen ( PORT , err => { if ( err ) { console . error ( err ); process . exit ( 2 ); } TaskChain . registerTaskGroups ( err1 => { if ( err1 ) { console . error ( err1 ); process . exit ( 1 ); } console . log ( 'Backend module listening on: ' + PORT ); }); });","title":"Data Warehouse Services Client"},{"location":"apis/dwf-dws-client/#data-warehouse-services-client","text":"This Node.js package registers the SAP default task types at the Data Warehouse Scheduler that need access to the local HDI and DWF containers of the consuming project. In addition it runs an HTTP server to provide task type related endpoints for value helps and task execution.","title":"Data Warehouse Services Client"},{"location":"apis/dwf-dws-client/#usage","text":"Add this package as dependency in a standard Node.js module in your XSA application. In your development descriptor mta.yaml ensure that HDI (type com.sap.xs.hdi-container and DWF (type com.sap.xs.dwf-edw-client ) services are bound in the resources section. For example: resources : - name : myapp-dws type : com.sap.xs.dwf-edw-client properties : dwf-edw-client-name : ${service-name} - name : myapp-hdi type : com.sap.xs.hdi-container properties : hdi-container-name : ${service-name} The service instances have to be required by the module consuming this package modules : - name : myapp-Backend type : nodejs path : Backend requires : - name : myapp-hdi - name : myapp-dws In the start script of your Node.js module load this package and instantiate the client for the Task Orchestration Engine of the Data Warehouse Scheduler (TOE): const xsenv = require ( '@sap/xsenv' ); const dwsClient = require ( '@sap/dwf-dws-client' ); const loopBackUrl = JSON . parse ( process . env . VCAP_APPLICATION ). full_application_uris [ 0 ]; const rejectUnauth = true ; const TaskChain = dwsClient . taskChain . createTaskChainClient ( xsenv . getServices ({ dwf : { tag : 'dwf' } }). dwf , loopBackUrl , rejectUnauth ); To allow the scheduler to call the registered endpoints, start an HTTP server and expose the routes. Below, you see an example using express.js . Be aware that this example omits proper authentication and authorization checks which must be implemented for productive use. const PORT = process . env . PORT || 3000 ; const express = require ( 'express' ); const app = express (); TaskChain . addRouter ( app , '/backend' ); app . listen ( PORT , err => { if ( err ) { console . error ( err ); process . exit ( 2 ); } TaskChain . registerTaskGroups ( err1 => { if ( err1 ) { console . error ( err1 ); process . exit ( 1 ); } console . log ( 'Backend module listening on: ' + PORT ); }); });","title":"Usage"},{"location":"apis/dwf-dws-client/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . [2.4.1] - 2018-11-05 \u00b6 Added \u00b6 Set application name while opening db connection. [2.4.0] - 2018-09-14 \u00b6 Changed \u00b6 Check url-api version of DWF runtime / DWF Task Orchestration Engine Update checking service credentials of db service /helpers/dbClient Fix callback handling of module /hanaNative/tasks/getMsgTableNames Switch from ESLint to StandardJS Fix NDSO getOperationInfo calls Replace module \"@sap/hdbext\" by \"hdb\" Correct typos in texts in /i18n/toe.properties Update versions of used modules [2.3.3] - 2018-03-05 \u00b6 Changed \u00b6 Remove default value of message table for task type execute procedure Update versions of used modules and npm-shrinkwrap.json Support value help button for ndso names Limit ndso SQL result to 50 Set Certificate Authority for tasktype load from url [2.3.2] - 2018-01-22 \u00b6 Changed \u00b6 Update versions of used @sap modules and npm-shrinkwrap.json. [2.3.1] - 2018-01-19 \u00b6 Changed \u00b6 Update npm-shrinkwrap.json. Allow empty path parameters for value help services. Correct names of value help placeholders of registered task types. Update versions of used @sap modules. [2.3.0] - 2018-01-12 \u00b6 Added \u00b6 Initial version for Data Warehousing Foundation 2.0 SP03: Adjust the parameter models of the task types to new features provided by the parameter form control.","title":"Changelog"},{"location":"apis/dwf-dws-client/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"apis/dwf-dws-client/CHANGELOG/#241-2018-11-05","text":"","title":"[2.4.1] - 2018-11-05"},{"location":"apis/dwf-dws-client/CHANGELOG/#added","text":"Set application name while opening db connection.","title":"Added"},{"location":"apis/dwf-dws-client/CHANGELOG/#240-2018-09-14","text":"","title":"[2.4.0] - 2018-09-14"},{"location":"apis/dwf-dws-client/CHANGELOG/#changed","text":"Check url-api version of DWF runtime / DWF Task Orchestration Engine Update checking service credentials of db service /helpers/dbClient Fix callback handling of module /hanaNative/tasks/getMsgTableNames Switch from ESLint to StandardJS Fix NDSO getOperationInfo calls Replace module \"@sap/hdbext\" by \"hdb\" Correct typos in texts in /i18n/toe.properties Update versions of used modules","title":"Changed"},{"location":"apis/dwf-dws-client/CHANGELOG/#233-2018-03-05","text":"","title":"[2.3.3] - 2018-03-05"},{"location":"apis/dwf-dws-client/CHANGELOG/#changed_1","text":"Remove default value of message table for task type execute procedure Update versions of used modules and npm-shrinkwrap.json Support value help button for ndso names Limit ndso SQL result to 50 Set Certificate Authority for tasktype load from url","title":"Changed"},{"location":"apis/dwf-dws-client/CHANGELOG/#232-2018-01-22","text":"","title":"[2.3.2] - 2018-01-22"},{"location":"apis/dwf-dws-client/CHANGELOG/#changed_2","text":"Update versions of used @sap modules and npm-shrinkwrap.json.","title":"Changed"},{"location":"apis/dwf-dws-client/CHANGELOG/#231-2018-01-19","text":"","title":"[2.3.1] - 2018-01-19"},{"location":"apis/dwf-dws-client/CHANGELOG/#changed_3","text":"Update npm-shrinkwrap.json. Allow empty path parameters for value help services. Correct names of value help placeholders of registered task types. Update versions of used @sap modules.","title":"Changed"},{"location":"apis/dwf-dws-client/CHANGELOG/#230-2018-01-12","text":"","title":"[2.3.0] - 2018-01-12"},{"location":"apis/dwf-dws-client/CHANGELOG/#added_1","text":"Initial version for Data Warehousing Foundation 2.0 SP03: Adjust the parameter models of the task types to new features provided by the parameter form control.","title":"Added"},{"location":"apis/dwf-generator/","text":"dwf-generator \u00b6 Generating Database Artifacts \u00b6 Database artifacts, that are needed fot the relocation from HANA to remote sources, are generated by DWF-Generator and placed in the database and DWF modules Running executables globally \u00b6 install the module globally $ generate DWF_MODULE example2.dwfdlmprofile,folder\\\\example2.dwf or $ generate -d DWF_MODULE -f example2.dwfdlmprofile,folder\\\\example2.dwf Running executables inside the module package \u00b6 install the module inside a project navigate to the prefix/node_nodules/nodejs-command-line-tool $ npm run generate DWF_MODULE example2.dwfdlmprofile,folder\\\\example2.dwf or $ npm run generate -d DWF_MODULE -f example2.dwfdlmprofile,folder\\\\example2.dwf 'DWF_MODULE' is a folder which contains infomation to generate design time files; 'example2.dwfdlmprofile,folder\\example2.dwf'(no space) are relative paths to dlm profiles (optional) Additional inputs \u00b6 Disable schema and content validation: --dv or --disable-validation Disable modifing yaml file: --dmy or --disable-modify-yaml","title":"dwf-generator"},{"location":"apis/dwf-generator/#dwf-generator","text":"","title":"dwf-generator"},{"location":"apis/dwf-generator/#generating-database-artifacts","text":"Database artifacts, that are needed fot the relocation from HANA to remote sources, are generated by DWF-Generator and placed in the database and DWF modules","title":"Generating Database Artifacts"},{"location":"apis/dwf-generator/#running-executables-globally","text":"install the module globally $ generate DWF_MODULE example2.dwfdlmprofile,folder\\\\example2.dwf or $ generate -d DWF_MODULE -f example2.dwfdlmprofile,folder\\\\example2.dwf","title":"Running executables globally"},{"location":"apis/dwf-generator/#running-executables-inside-the-module-package","text":"install the module inside a project navigate to the prefix/node_nodules/nodejs-command-line-tool $ npm run generate DWF_MODULE example2.dwfdlmprofile,folder\\\\example2.dwf or $ npm run generate -d DWF_MODULE -f example2.dwfdlmprofile,folder\\\\example2.dwf 'DWF_MODULE' is a folder which contains infomation to generate design time files; 'example2.dwfdlmprofile,folder\\example2.dwf'(no space) are relative paths to dlm profiles (optional)","title":"Running executables inside the module package"},{"location":"apis/dwf-generator/#additional-inputs","text":"Disable schema and content validation: --dv or --disable-validation Disable modifing yaml file: --dmy or --disable-modify-yaml","title":"Additional inputs"},{"location":"apis/dwf-generator/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . 2.3.0 - 2018-03-05 \u00b6 Added \u00b6 Released for DWF 2 SP03 dlm - extension node Fixed \u00b6 Disables reading schema from grantor service in local hdi case Adjust placeholders for templates npm-shrinkwrap 2.2.7-1 \u00b6 Added \u00b6 - Fixed \u00b6 Vora to HANA relocation: Skip value validation in the where clause due to performance issues [2.2.6] - 2017-10-23 \u00b6 Added \u00b6 supports service replacement Fixed \u00b6 relocation procedure - vora - Error 256 - sql processing error: \"DWF_20170908_CROSSSCHEMA_DWF_20170908_CROSSSCHEMA_CONTAINER_1\".\"DLM_GEN.dlm.dlm.crossSchema_Vora_SalesOrder::VORA_to_HANA_n2_to_n0\": line 146 col 7 (at pos 7998): sql processing error: Cannot execute null SQL string (NullConversion exception): line 146 col 7 (at pos 7998) relocation procedure - vora - Error: \"db://#V0_KEY_VALUES\": the object cannot be provided more than once [8212002] keeps CHANGELOG.md and README.md in the release [2.2.5] - 2017-10-19 \u00b6 Added \u00b6 - Fixed \u00b6 cleans up modified grantor services in yaml replaces the static with dynamic relocation rule [2.2.4] - 2017-09-01 \u00b6 Added \u00b6 - Fixed \u00b6 - [2.2.3] - 2017-08-15 \u00b6 Added \u00b6 - Fixed \u00b6 - [2.2.2] - 2017-08-11 \u00b6 Added \u00b6 - Fixed \u00b6 - [2.2.1] - 2017-06-29 \u00b6 Added \u00b6 - Fixed \u00b6 - [2.2.0] - 2017-05-30 \u00b6 Added \u00b6 - Fixed \u00b6 -","title":"Changelog"},{"location":"apis/dwf-generator/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"apis/dwf-generator/CHANGELOG/#230-2018-03-05","text":"","title":"2.3.0 - 2018-03-05"},{"location":"apis/dwf-generator/CHANGELOG/#added","text":"Released for DWF 2 SP03 dlm - extension node","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed","text":"Disables reading schema from grantor service in local hdi case Adjust placeholders for templates npm-shrinkwrap","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#227-1","text":"","title":"2.2.7-1"},{"location":"apis/dwf-generator/CHANGELOG/#added_1","text":"-","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_1","text":"Vora to HANA relocation: Skip value validation in the where clause due to performance issues","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#226-2017-10-23","text":"","title":"[2.2.6] - 2017-10-23"},{"location":"apis/dwf-generator/CHANGELOG/#added_2","text":"supports service replacement","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_2","text":"relocation procedure - vora - Error 256 - sql processing error: \"DWF_20170908_CROSSSCHEMA_DWF_20170908_CROSSSCHEMA_CONTAINER_1\".\"DLM_GEN.dlm.dlm.crossSchema_Vora_SalesOrder::VORA_to_HANA_n2_to_n0\": line 146 col 7 (at pos 7998): sql processing error: Cannot execute null SQL string (NullConversion exception): line 146 col 7 (at pos 7998) relocation procedure - vora - Error: \"db://#V0_KEY_VALUES\": the object cannot be provided more than once [8212002] keeps CHANGELOG.md and README.md in the release","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#225-2017-10-19","text":"","title":"[2.2.5] - 2017-10-19"},{"location":"apis/dwf-generator/CHANGELOG/#added_3","text":"-","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_3","text":"cleans up modified grantor services in yaml replaces the static with dynamic relocation rule","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#224-2017-09-01","text":"","title":"[2.2.4] - 2017-09-01"},{"location":"apis/dwf-generator/CHANGELOG/#added_4","text":"-","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_4","text":"-","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#223-2017-08-15","text":"","title":"[2.2.3] - 2017-08-15"},{"location":"apis/dwf-generator/CHANGELOG/#added_5","text":"-","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_5","text":"-","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#222-2017-08-11","text":"","title":"[2.2.2] - 2017-08-11"},{"location":"apis/dwf-generator/CHANGELOG/#added_6","text":"-","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_6","text":"-","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#221-2017-06-29","text":"","title":"[2.2.1] - 2017-06-29"},{"location":"apis/dwf-generator/CHANGELOG/#added_7","text":"-","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_7","text":"-","title":"Fixed"},{"location":"apis/dwf-generator/CHANGELOG/#220-2017-05-30","text":"","title":"[2.2.0] - 2017-05-30"},{"location":"apis/dwf-generator/CHANGELOG/#added_8","text":"-","title":"Added"},{"location":"apis/dwf-generator/CHANGELOG/#fixed_8","text":"-","title":"Fixed"},{"location":"apis/dwf-ndso-backend/","text":"Native DataStore Object (NDSO) Service Backend \u00b6 This Node.js package contains service implementations (tasks) of the Native DataStore Object. The NDSO backend is part of the SAP HANA Data Warehousing Foundation product. As such it is used, for example, by the DataStore Manage UI of the Database Explorer or the Data Warehouse Scheduler. Change Log Be aware that as this being a technical reuse package you are not supposed to consume it directly in a custom application. It is used by the aforementioned SAP products/tools though. NDSO Task Reference \u00b6 NDSO tasks are exposed as simple asynchronous functions activate(tracer, client1, client2, schema, ndso, loadIds, [callback]) \u21d2 Promise \u00b6 Moves data from inbound queue(s) to active data and change log. Writing of active data and change log is done by the HANA core procedure SYS.DSO_ACTIVATE_CHANGES . This operation takes care of - verifying the provided load IDs - setting status of earlier, failed activations to 'DELETED' - compiling procedure options like aggregation behavior and before-image handling - calling the procedure - deleting load data from inbound queue(s) Fulfills : ActivationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace loadIds Array.<integer> load requests to be activated [callback] function callback function addSubscriber(tracer, client1, client2, schema, ndso, subscriberName, [description], [callback]) \u21d2 Promise \u00b6 Adds a new subscriber entry to the subscribers entity Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace subscriberName string name (and key) of the subscriber [description] string optional description [callback] function callback function checkMetadataConsistency(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise \u00b6 Performs consistency checks on the NDSO. The operation fails, if inconsistencies are found Performed checks ensure: - Inbound queues consistency - Change log entries deleted for cleaned up activations - Inbound queue entries deleted for finished activations - Affected requests consistency Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function cleanupChangelog(tracer, client1, client2, schema, ndso, requestIds, [callback]) \u21d2 Promise \u00b6 Cleans up change log. The operation verifies, if the provided activation request IDs can be cleaned up and then deletes them from the change log Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace requestIds Array.<integer> activation requests for which change log shall be deleted [callback] function callback function cleanupMetadata(tracer, client1, client2, schema, ndso, [maxRequestId], [maxTimestamp], [callback]) \u21d2 Promise \u00b6 Cleans up metadata up to either the provided maximal activation request ID or corresponding creation timestamp (whichever is higher). Fulfills : OperationResult Todo [ ] not implemented, i.e., it does not actually delete any data Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [maxRequestId] integer request ID up to which to clean up [maxTimestamp] string ISO 8601 UTC timestamp up to which to clean up [callback] function callback function deleteAll(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise \u00b6 Deletes all NDSO data (main and metadata entities). The operation fails, if there are subscribers Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function deleteRequest(tracer, client1, client2, schema, ndso, requestIds, [callback]) \u21d2 Promise \u00b6 Deletes load requests. The operation verifies, if the provided request IDs can be deleted and then deletes them from the inbound queue(s) Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace requestIds Array.<integer> load requests to be deleted [callback] function callback function deleteWithFilter(tracer, client1, client2, schema, ndso, queryOptions, propagateDeletion, [callback]) \u21d2 Promise \u00b6 Deletes active data by the provided query filter. Optionally writes an activation request into the change log which allows rollback Fulfills : DeleteResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace queryOptions QueryOptions note that for this task, the 'options' (and more specifically, the filter flt ) are actually mandatory because the context is selective deletion from active data which must not be unrestricted (that would be deleteAll) propagateDeletion bool if true, deletions will be added to change log [callback] function callback function getDataStores(tracer, client, schema, [queryOptions], [callback]) \u21d2 Promise \u00b6 Provides a list of NDSOs in the schema Fulfills : DataStores Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema [queryOptions] QueryOptions [callback] function callback function getDataStoreFeature(tracer, client, schema, [callback]) \u21d2 Promise \u00b6 Provides information if the NDSO metamodel exists in the schema. The metamodel is a prerequisite to model NDSOs Fulfills : DataStoreFeature Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema [callback] function callback function getLogForOperation(tracer, client, schema, ndso, operationId, [callback]) \u21d2 Promise \u00b6 Provides the message log for an operation Fulfills : LogForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace operationId integer ID of the operation logs shall be read for [callback] function callback function getMetadata(tracer, client, schema, ndso, [callback]) \u21d2 Promise \u00b6 Provides NDSO metadata Fulfills : Metadata Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function getMonitoringOverview(tracer, client, schema, [queryOptions], [callback]) \u21d2 Promise \u00b6 Provides monitoring relevant information about all NDSOs in the schema. Fulfills : MonitoringOverview Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema [queryOptions] QueryOptions [callback] function callback function getOperationInfo(tracer, client, schema, ndso, [queryOptions], [callback]) \u21d2 Promise \u00b6 Provides general request information Fulfills : OperationInfo Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [queryOptions] QueryOptions [callback] function callback function getOperationsForRequest(tracer, client, schema, ndso, requestId, [callback]) \u21d2 Promise \u00b6 Provides the list of operations that affected a specific request Fulfills : OperationsForRequest Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace requestId integer request ID which to retrieve operations for [callback] function callback function getRequestInfo(tracer, client, schema, ndso, [queryOptions], [callback]) \u21d2 Promise \u00b6 Provides general request information Fulfills : RequestInfo Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [queryOptions] QueryOptions [callback] function callback function getRequestsForActivation(tracer, client, schema, ndso, [maxRequestId], [callback]) \u21d2 Promise \u00b6 Provides requests that can be activated. Condition: - finished load requests - after latest activation - not subject to a deleteRequest operation - (optional) load request ID lower than provided maxRequestId Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [maxRequestId] integer request ID up to which to retrieve load requests [callback] function callback function getRequestsForCleanup(tracer, client, schema, ndso, [maxRequestId], [maxTimestamp], [callback]) \u21d2 Promise \u00b6 Provides requests that can be cleaned up. Condition: - finished activation requests - not subject to rollback/clean-up operation - extracted by all subscribers - (optional) activation request ID less than or equal to provided max ID or timestamp Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [maxRequestId] integer request ID up to which to fetch requests [maxTimestamp] string ISO 8601 UTC timestamp up to which to fetch requests [callback] function callback function getRequestsForDeletion(tracer, client, schema, ndso, [callback]) \u21d2 Promise \u00b6 Provides requests that can be deleted. Condition: - load request failed OR finished and after latest activation - not subject to a deleteRequest operation Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function getRequestsForRollback(tracer, client, schema, ndso, minRequestId, [callback]) \u21d2 Promise \u00b6 Provides requests that can be rolled back. Condition: - finished activation requests - after latest rollback/clean-up operation - not yet extracted by any subscriber (as rollbacks are just deleted from change log, subscribers won't get a corresponding delta corrupting their data) - (optional) load request ID greater than or equal to provided minRequestId Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace minRequestId integer request ID from which to roll back later activations [callback] function callback function getRowcountWithFilter(tracer, client, schema, ndso, queryOptions, [callback]) \u21d2 Promise \u00b6 Provides number of rows in active data filtered by the provided query filter Fulfills : RowcountWithFilter Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace queryOptions QueryOptions note that for this task, the 'options' (and more specifically, the filter flt ) are actually mandatory because this is a preview task for deleteWithFilter [callback] function callback function getSubscribers(tracer, client, schema, ndso, [callback]) \u21d2 Promise \u00b6 Provides a list of subscribers Fulfills : Subscribers Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function removeSubscriber(tracer, client1, client2, schema, ndso, subscriberName, [callback]) \u21d2 Promise \u00b6 Removes a subscriber from the subscribers entity Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace subscriberName string name (and key) of the subscriber [callback] function callback function repairRunningOperations(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise \u00b6 Repairs running operations that are not really running anymore and sets their status to failed. This is done by attempting to retrieve a lock for the corresponding entry in the operation history Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function resetSubscriber(tracer, client1, client2, schema, ndso, subscriberName, [callback]) \u21d2 Promise \u00b6 Resets maxRequestId of a subscriber in the subscribers entity back to 0 Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace subscriberName string name (and key) of the subscriber [callback] function callback function rollback(tracer, client1, client2, schema, ndso, activationIds, [callback]) \u21d2 Promise \u00b6 Restores data from the change log back to active data. Writing of active data and change log is done by the HANA core procedure SYS.DSO_ROLLBACK_CHANGES . This operation takes care of - verifying the provided activation IDs - compiling procedure options like aggregation behavior and before-image handling - calling the procedure Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace activationIds Array.<integer> activation requests to roll back [callback] function callback function storeCsv(tracer, client1, client2, schema, ndso, iqName, data, withHeader, [callback]) \u21d2 Promise \u00b6 Loads CSV data into the provided inbound queue. If the data contain a header row, it is excluded from data but serves as field list for the INSERT statement. Data is generally loaded by just providing the data unaltered to the prepared statement except for binary data types (VARBINARY, BLOB) where a hexadecimal string is expected instead Fulfills : LoadResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace iqName string inbound queue to load the data into data array | string CSV data as array or string withHeader bool load requests to be activated [callback] function callback function storeSql(tracer, client1, client2, schema, ndso, iqName, externalSql, [callback]) \u21d2 Promise \u00b6 Loads data into the provided inbound queue by the FROM clause provided via externalSql . externalSql needs to provide technicalAttributes.recordMode and all semantical column names as the inbound queue (if the source table has different column names, they must be aliased accordingly). Fulfills : LoadResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace iqName string inbound queue to load the data into externalSql string SQL by which to load data (used as FROM clause) [callback] function callback function Example SELECT '' AS \"technicalAttributes.recordMode\" , CUST AS \"CustomerName\" , PRICE AS \"Amount\" FROM CUST_PRICES smokeTest(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise \u00b6 Performs a smoke test on the provided NDSO, executing all tasks, beginning with operations related to subscribers, then deletes all of them and runs deleteAll to have a defined start-state :warning: Only use this in test environments! Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] operationCallback callback function ActivationResult \u00b6 Properties Name Type Description operationId integer ID of the activate operation activationId integer ID of the resulting activation request DeleteResult \u00b6 Properties Name Type Description operationId integer ID of the deleteWithFilter operation [changeLogId] integer ID of the optional activation request DataStores \u00b6 Properties Name Type Description result Array.<string> NDSO names DataStoreFeature \u00b6 Properties Name Type Description isDataStoreActive bool true, if metamodel found [version] string model version LogForOperation \u00b6 Properties Name Type Description result Array.<object> result.posit integer defines message order result.timestamp string ISO 8601 UTC timestamp of message creation result.msgType string message severity result.msgNumber integer numeric message ID result.msgText string message text MetadataMetaTable \u00b6 Properties Name Type Description name string entity name of the meta table fullName string fully qualified and quoted table name including schema and namespace MetadataActiveDataField \u00b6 Properties Name Type Description name string field name isKey bool indicates, if field is a semantical key aggregation string defines before-image behavior (NOP or SUM) sqlDataTypename string HANA data type [typeParam1] integer parameter attribute 1 (e.g. length) [typeParam2] integer parameter attribute 2 (e.g. scale) [defaultValue] string default value MetadataChangeLogField \u00b6 Properties Name Type Description name string field name isKey bool indicates, if field is a semantical key sqlDataTypename string HANA data type MetadataInboundQueueField \u00b6 Properties Name Type Description name string field name isKey bool indicates, if field is a semantical key aggregation string defines aggregation behavior (NOP, MOV, MIN, MAX or SUM) sqlDataTypename string HANA data type [typeParam1] integer parameter attribute 1 (e.g. length) [typeParam2] integer parameter attribute 2 (e.g. scale) [defaultValue] string default value MetadataProcedure \u00b6 Properties Name Type Description name string qualified name of the procedure (with namespace, without schema) ifVersion string interface version of the procedure in the form X.Y (e.g. 1.0), major version incremented for backwards incompatible changes and minor for backwards compatible changes Metadata \u00b6 Properties Name Type Description name string NDSO name snapshotSupport bool if true, every activation will overwrite the complete active data table, i.e., inbound queue data is considered to always be complete operationHistory MetadataMetaTable operation history containing operation ID, timestamp, user, status etc. affectedRequests MetadataMetaTable mapping table of n:m relation of operations to requests aggregationHistory MetadataMetaTable stores aggregation behavior on activation. Needed to account for model changes between activation and rollback logMessages MetadataMetaTable log messages per operation idGen MetadataMetaTable indicates request type (load, activation, general operation). Without sequence, new IDs are drawn based on the content of this table subscribers MetadataMetaTable stores subscribers doing delta-extractions from the change log. The latest extracted activation requests are written by each subscriber and affect housekeeping, like cleanupChangelog activeData object main, reportable data entity activeData.name string entity name of the data table activeData.fullName string fully qualified and quoted table name including schema and namespace activeData.fields Array.<MetadataActiveDataField> [changeLog] object optional data entity to track changes changeLog.name string entity name of the data table changeLog.fullName string fully qualified and quoted table name including schema and namespace changeLog.fields Array.<MetadataChangeLogField> activationQueues Array.<object> one or more data entity to queue inbound data for activation activationQueues.name string entity name of the data table activationQueues.fullName string fully qualified and quoted table name including schema and namespace activationQueues.fields Array.<MetadataInboundQueueField> procedures object.<string, MetadataProcedure> map of supported SQL procedures. Key is the operation identifier, e.g. LOAD sequence string sequence used to draw new IDs metaModel object information about current NDSO metamodel metaModel.version string metamodel version MonitoringTableStats \u00b6 Properties Name Type Description tableName string table name [size] integer table estimated maximal memory size in bytes (not provided, if user lacks authorization) [rows] integer table row count (not provided, if user lacks authorization) MonitoringOverview \u00b6 Properties Name Type Description result Array.<object> result.name string NDSO name result.lastOp string type of the last operation result.lastOpBy string user last changing the last operation result.lastOpAt string ISO 8601 UTC timestamp when the last operation was last changed result.lastOpStatus string status of the last operation result.subscribers integer number of subscribers result.stats object table statistics result.stats.activeData MonitoringTableStats stats for active data entity result.stats.inboundQueues Array.<MonitoringTableStats> stats for inbound queue entities [result.stats.changeLog] MonitoringTableStats optional stats for change log entity [result.message] string optional warning message derived from authorization errors by HANA; thrown, if user lacks authorization for monitoring synonyms (e.g. M_CS_TABLES) OperationInfo \u00b6 Properties Name Type Description result Array.<object> result.operationId integer operation ID result.operation string operation type result.status string operation status result.userName string user last changing the operation result.lastTimestamp string ISO 8601 UTC timestamp when the operation was last changed [result.operationDetails] object optional operation details OperationsForRequest \u00b6 Properties Name Type Description result Array.<object> result.operationId integer operation ID result.operation string operation type result.status string operation status result.userName string user last changing the operation result.lastTimestamp string ISO 8601 UTC timestamp when the operation was last changed result.affectedRequests Array.<integer> related request IDs RequestInfo \u00b6 Properties Name Type Description result Array.<object> result.operationId integer ID of the last operation affecting the request result.operation string type of the last operation affecting the request result.status string status of the last operation affecting the request result.userName string user last changing the operation result.startTimestamp string ISO 8601 UTC timestamp when the operation was started result.lastTimestamp string ISO 8601 UTC timestamp when the operation was last changed result.dependentRequests Array.<integer> related request IDs result.requestStatus string current status of the request (derived from the latest operation affecting it) [result.operationDetails] object optional operation details RowcountWithFilter \u00b6 Properties Name Type Description result Array.<object> result.tableName string fully qualified name of active data table result.rowCount integer total number of rows Subscribers \u00b6 Properties Name Type Description result Array.<object> result.subscriberName string subscriber name result.description string additional description result.userName string user that created the subscriber result.creationTimestamp string ISO 8601 UTC timestamp of the subscriber creation result.maxRequest integer last activation request the subscriber extracted from the change log result.pushNotification string not implemented OperationResult \u00b6 Properties Name Type Description operationId integer ID of the operation LoadResult \u00b6 Properties Name Type Description operationId integer ID of the load operation loadId integer ID of the resulting load request QueryOptions \u00b6 Some tasks offer a parameter queryOptions that allow for backend-side paging, sorting and filtering. The task expects it to be an object like this: Example { lim : 100 , // LIMIT in SQL: returns up to 100 rows off : 200 , // OFFSET in SQL: skips first 200 rows flt : { // builds WHERE in SQL; multiple columns are connected COLUMN1 : 'value1' , // by AND COLUMN2 : 123 , COLUMN3 : [ // array elements for same column are connected by OR { op : 'BT' , // BT resolves to 'BETWEEN ? AND ?' val : [ 10 , 20 ] }, { op : 'EQ' , // EQ resolves to 'IN (?,?,?)' val : [ 95 , 99 , 101 ] }, { op : 'LT' , // LT ('less than') resolves to '< ?' val : 50 // there's also LE ('less or equal') }, { op : 'GT' , // GT ('greater than') resolves to '> ?' val : 'abc' // there's also GE ('greater or equal') } ] }, fltMode : 'PARTIAL' , // instead of 'WHERE = ?' this resolves to 'WHERE LIKE ?' // and wildcards around value (e.g. '%value1%') // default is 'EXACT' ord : [ // builds ORDER BY in SQL { col : 'COLUMN1' // defaults to 'ASC' }, { col : 'COLUMN3' , dir : 'DESC' } ] } RequestsForOperation \u00b6 Properties Name Type Description result Array.<object> result.requestId integer request ID result.userName string user last affecting the request (by operation) result.timestamp string ISO 8601 UTC timestamp when the operation was last changed","title":"Native DataStore Object (NDSO) Service Backend"},{"location":"apis/dwf-ndso-backend/#native-datastore-object-ndso-service-backend","text":"This Node.js package contains service implementations (tasks) of the Native DataStore Object. The NDSO backend is part of the SAP HANA Data Warehousing Foundation product. As such it is used, for example, by the DataStore Manage UI of the Database Explorer or the Data Warehouse Scheduler. Change Log Be aware that as this being a technical reuse package you are not supposed to consume it directly in a custom application. It is used by the aforementioned SAP products/tools though.","title":"Native DataStore Object (NDSO) Service Backend"},{"location":"apis/dwf-ndso-backend/#ndso-task-reference","text":"NDSO tasks are exposed as simple asynchronous functions","title":"NDSO Task Reference"},{"location":"apis/dwf-ndso-backend/#activatetracer-client1-client2-schema-ndso-loadids-callback-promise","text":"Moves data from inbound queue(s) to active data and change log. Writing of active data and change log is done by the HANA core procedure SYS.DSO_ACTIVATE_CHANGES . This operation takes care of - verifying the provided load IDs - setting status of earlier, failed activations to 'DELETED' - compiling procedure options like aggregation behavior and before-image handling - calling the procedure - deleting load data from inbound queue(s) Fulfills : ActivationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace loadIds Array.<integer> load requests to be activated [callback] function callback function","title":"activate(tracer, client1, client2, schema, ndso, loadIds, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#addsubscribertracer-client1-client2-schema-ndso-subscribername-description-callback-promise","text":"Adds a new subscriber entry to the subscribers entity Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace subscriberName string name (and key) of the subscriber [description] string optional description [callback] function callback function","title":"addSubscriber(tracer, client1, client2, schema, ndso, subscriberName, [description], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#checkmetadataconsistencytracer-client1-client2-schema-ndso-callback-promise","text":"Performs consistency checks on the NDSO. The operation fails, if inconsistencies are found Performed checks ensure: - Inbound queues consistency - Change log entries deleted for cleaned up activations - Inbound queue entries deleted for finished activations - Affected requests consistency Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function","title":"checkMetadataConsistency(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#cleanupchangelogtracer-client1-client2-schema-ndso-requestids-callback-promise","text":"Cleans up change log. The operation verifies, if the provided activation request IDs can be cleaned up and then deletes them from the change log Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace requestIds Array.<integer> activation requests for which change log shall be deleted [callback] function callback function","title":"cleanupChangelog(tracer, client1, client2, schema, ndso, requestIds, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#cleanupmetadatatracer-client1-client2-schema-ndso-maxrequestid-maxtimestamp-callback-promise","text":"Cleans up metadata up to either the provided maximal activation request ID or corresponding creation timestamp (whichever is higher). Fulfills : OperationResult Todo [ ] not implemented, i.e., it does not actually delete any data Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [maxRequestId] integer request ID up to which to clean up [maxTimestamp] string ISO 8601 UTC timestamp up to which to clean up [callback] function callback function","title":"cleanupMetadata(tracer, client1, client2, schema, ndso, [maxRequestId], [maxTimestamp], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#deletealltracer-client1-client2-schema-ndso-callback-promise","text":"Deletes all NDSO data (main and metadata entities). The operation fails, if there are subscribers Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function","title":"deleteAll(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#deleterequesttracer-client1-client2-schema-ndso-requestids-callback-promise","text":"Deletes load requests. The operation verifies, if the provided request IDs can be deleted and then deletes them from the inbound queue(s) Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace requestIds Array.<integer> load requests to be deleted [callback] function callback function","title":"deleteRequest(tracer, client1, client2, schema, ndso, requestIds, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#deletewithfiltertracer-client1-client2-schema-ndso-queryoptions-propagatedeletion-callback-promise","text":"Deletes active data by the provided query filter. Optionally writes an activation request into the change log which allows rollback Fulfills : DeleteResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace queryOptions QueryOptions note that for this task, the 'options' (and more specifically, the filter flt ) are actually mandatory because the context is selective deletion from active data which must not be unrestricted (that would be deleteAll) propagateDeletion bool if true, deletions will be added to change log [callback] function callback function","title":"deleteWithFilter(tracer, client1, client2, schema, ndso, queryOptions, propagateDeletion, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getdatastorestracer-client-schema-queryoptions-callback-promise","text":"Provides a list of NDSOs in the schema Fulfills : DataStores Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema [queryOptions] QueryOptions [callback] function callback function","title":"getDataStores(tracer, client, schema, [queryOptions], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getdatastorefeaturetracer-client-schema-callback-promise","text":"Provides information if the NDSO metamodel exists in the schema. The metamodel is a prerequisite to model NDSOs Fulfills : DataStoreFeature Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema [callback] function callback function","title":"getDataStoreFeature(tracer, client, schema, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getlogforoperationtracer-client-schema-ndso-operationid-callback-promise","text":"Provides the message log for an operation Fulfills : LogForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace operationId integer ID of the operation logs shall be read for [callback] function callback function","title":"getLogForOperation(tracer, client, schema, ndso, operationId, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getmetadatatracer-client-schema-ndso-callback-promise","text":"Provides NDSO metadata Fulfills : Metadata Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function","title":"getMetadata(tracer, client, schema, ndso, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getmonitoringoverviewtracer-client-schema-queryoptions-callback-promise","text":"Provides monitoring relevant information about all NDSOs in the schema. Fulfills : MonitoringOverview Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema [queryOptions] QueryOptions [callback] function callback function","title":"getMonitoringOverview(tracer, client, schema, [queryOptions], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getoperationinfotracer-client-schema-ndso-queryoptions-callback-promise","text":"Provides general request information Fulfills : OperationInfo Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [queryOptions] QueryOptions [callback] function callback function","title":"getOperationInfo(tracer, client, schema, ndso, [queryOptions], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getoperationsforrequesttracer-client-schema-ndso-requestid-callback-promise","text":"Provides the list of operations that affected a specific request Fulfills : OperationsForRequest Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace requestId integer request ID which to retrieve operations for [callback] function callback function","title":"getOperationsForRequest(tracer, client, schema, ndso, requestId, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getrequestinfotracer-client-schema-ndso-queryoptions-callback-promise","text":"Provides general request information Fulfills : RequestInfo Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [queryOptions] QueryOptions [callback] function callback function","title":"getRequestInfo(tracer, client, schema, ndso, [queryOptions], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getrequestsforactivationtracer-client-schema-ndso-maxrequestid-callback-promise","text":"Provides requests that can be activated. Condition: - finished load requests - after latest activation - not subject to a deleteRequest operation - (optional) load request ID lower than provided maxRequestId Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [maxRequestId] integer request ID up to which to retrieve load requests [callback] function callback function","title":"getRequestsForActivation(tracer, client, schema, ndso, [maxRequestId], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getrequestsforcleanuptracer-client-schema-ndso-maxrequestid-maxtimestamp-callback-promise","text":"Provides requests that can be cleaned up. Condition: - finished activation requests - not subject to rollback/clean-up operation - extracted by all subscribers - (optional) activation request ID less than or equal to provided max ID or timestamp Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [maxRequestId] integer request ID up to which to fetch requests [maxTimestamp] string ISO 8601 UTC timestamp up to which to fetch requests [callback] function callback function","title":"getRequestsForCleanup(tracer, client, schema, ndso, [maxRequestId], [maxTimestamp], [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getrequestsfordeletiontracer-client-schema-ndso-callback-promise","text":"Provides requests that can be deleted. Condition: - load request failed OR finished and after latest activation - not subject to a deleteRequest operation Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function","title":"getRequestsForDeletion(tracer, client, schema, ndso, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getrequestsforrollbacktracer-client-schema-ndso-minrequestid-callback-promise","text":"Provides requests that can be rolled back. Condition: - finished activation requests - after latest rollback/clean-up operation - not yet extracted by any subscriber (as rollbacks are just deleted from change log, subscribers won't get a corresponding delta corrupting their data) - (optional) load request ID greater than or equal to provided minRequestId Fulfills : RequestsForOperation Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace minRequestId integer request ID from which to roll back later activations [callback] function callback function","title":"getRequestsForRollback(tracer, client, schema, ndso, minRequestId, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getrowcountwithfiltertracer-client-schema-ndso-queryoptions-callback-promise","text":"Provides number of rows in active data filtered by the provided query filter Fulfills : RowcountWithFilter Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace queryOptions QueryOptions note that for this task, the 'options' (and more specifically, the filter flt ) are actually mandatory because this is a preview task for deleteWithFilter [callback] function callback function","title":"getRowcountWithFilter(tracer, client, schema, ndso, queryOptions, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#getsubscriberstracer-client-schema-ndso-callback-promise","text":"Provides a list of subscribers Fulfills : Subscribers Param Type Description tracer object tracer e.g. by @sap/logging client object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function","title":"getSubscribers(tracer, client, schema, ndso, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#removesubscribertracer-client1-client2-schema-ndso-subscribername-callback-promise","text":"Removes a subscriber from the subscribers entity Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace subscriberName string name (and key) of the subscriber [callback] function callback function","title":"removeSubscriber(tracer, client1, client2, schema, ndso, subscriberName, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#repairrunningoperationstracer-client1-client2-schema-ndso-callback-promise","text":"Repairs running operations that are not really running anymore and sets their status to failed. This is done by attempting to retrieve a lock for the corresponding entry in the operation history Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] function callback function","title":"repairRunningOperations(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#resetsubscribertracer-client1-client2-schema-ndso-subscribername-callback-promise","text":"Resets maxRequestId of a subscriber in the subscribers entity back to 0 Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace subscriberName string name (and key) of the subscriber [callback] function callback function","title":"resetSubscriber(tracer, client1, client2, schema, ndso, subscriberName, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#rollbacktracer-client1-client2-schema-ndso-activationids-callback-promise","text":"Restores data from the change log back to active data. Writing of active data and change log is done by the HANA core procedure SYS.DSO_ROLLBACK_CHANGES . This operation takes care of - verifying the provided activation IDs - compiling procedure options like aggregation behavior and before-image handling - calling the procedure Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace activationIds Array.<integer> activation requests to roll back [callback] function callback function","title":"rollback(tracer, client1, client2, schema, ndso, activationIds, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#storecsvtracer-client1-client2-schema-ndso-iqname-data-withheader-callback-promise","text":"Loads CSV data into the provided inbound queue. If the data contain a header row, it is excluded from data but serves as field list for the INSERT statement. Data is generally loaded by just providing the data unaltered to the prepared statement except for binary data types (VARBINARY, BLOB) where a hexadecimal string is expected instead Fulfills : LoadResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace iqName string inbound queue to load the data into data array | string CSV data as array or string withHeader bool load requests to be activated [callback] function callback function","title":"storeCsv(tracer, client1, client2, schema, ndso, iqName, data, withHeader, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#storesqltracer-client1-client2-schema-ndso-iqname-externalsql-callback-promise","text":"Loads data into the provided inbound queue by the FROM clause provided via externalSql . externalSql needs to provide technicalAttributes.recordMode and all semantical column names as the inbound queue (if the source table has different column names, they must be aliased accordingly). Fulfills : LoadResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace iqName string inbound queue to load the data into externalSql string SQL by which to load data (used as FROM clause) [callback] function callback function Example SELECT '' AS \"technicalAttributes.recordMode\" , CUST AS \"CustomerName\" , PRICE AS \"Amount\" FROM CUST_PRICES","title":"storeSql(tracer, client1, client2, schema, ndso, iqName, externalSql, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#smoketesttracer-client1-client2-schema-ndso-callback-promise","text":"Performs a smoke test on the provided NDSO, executing all tasks, beginning with operations related to subscribers, then deletes all of them and runs deleteAll to have a defined start-state :warning: Only use this in test environments! Fulfills : OperationResult Param Type Description tracer object tracer e.g. by @sap/logging client1 object DB client by node-hdb or @sap/hana-client client2 object DB client by node-hdb or @sap/hana-client schema string DB schema ndso string full DataStore name with namespace [callback] operationCallback callback function","title":"smokeTest(tracer, client1, client2, schema, ndso, [callback]) \u21d2 Promise"},{"location":"apis/dwf-ndso-backend/#activationresult","text":"Properties Name Type Description operationId integer ID of the activate operation activationId integer ID of the resulting activation request","title":"ActivationResult"},{"location":"apis/dwf-ndso-backend/#deleteresult","text":"Properties Name Type Description operationId integer ID of the deleteWithFilter operation [changeLogId] integer ID of the optional activation request","title":"DeleteResult"},{"location":"apis/dwf-ndso-backend/#datastores","text":"Properties Name Type Description result Array.<string> NDSO names","title":"DataStores"},{"location":"apis/dwf-ndso-backend/#datastorefeature","text":"Properties Name Type Description isDataStoreActive bool true, if metamodel found [version] string model version","title":"DataStoreFeature"},{"location":"apis/dwf-ndso-backend/#logforoperation","text":"Properties Name Type Description result Array.<object> result.posit integer defines message order result.timestamp string ISO 8601 UTC timestamp of message creation result.msgType string message severity result.msgNumber integer numeric message ID result.msgText string message text","title":"LogForOperation"},{"location":"apis/dwf-ndso-backend/#metadatametatable","text":"Properties Name Type Description name string entity name of the meta table fullName string fully qualified and quoted table name including schema and namespace","title":"MetadataMetaTable"},{"location":"apis/dwf-ndso-backend/#metadataactivedatafield","text":"Properties Name Type Description name string field name isKey bool indicates, if field is a semantical key aggregation string defines before-image behavior (NOP or SUM) sqlDataTypename string HANA data type [typeParam1] integer parameter attribute 1 (e.g. length) [typeParam2] integer parameter attribute 2 (e.g. scale) [defaultValue] string default value","title":"MetadataActiveDataField"},{"location":"apis/dwf-ndso-backend/#metadatachangelogfield","text":"Properties Name Type Description name string field name isKey bool indicates, if field is a semantical key sqlDataTypename string HANA data type","title":"MetadataChangeLogField"},{"location":"apis/dwf-ndso-backend/#metadatainboundqueuefield","text":"Properties Name Type Description name string field name isKey bool indicates, if field is a semantical key aggregation string defines aggregation behavior (NOP, MOV, MIN, MAX or SUM) sqlDataTypename string HANA data type [typeParam1] integer parameter attribute 1 (e.g. length) [typeParam2] integer parameter attribute 2 (e.g. scale) [defaultValue] string default value","title":"MetadataInboundQueueField"},{"location":"apis/dwf-ndso-backend/#metadataprocedure","text":"Properties Name Type Description name string qualified name of the procedure (with namespace, without schema) ifVersion string interface version of the procedure in the form X.Y (e.g. 1.0), major version incremented for backwards incompatible changes and minor for backwards compatible changes","title":"MetadataProcedure"},{"location":"apis/dwf-ndso-backend/#metadata","text":"Properties Name Type Description name string NDSO name snapshotSupport bool if true, every activation will overwrite the complete active data table, i.e., inbound queue data is considered to always be complete operationHistory MetadataMetaTable operation history containing operation ID, timestamp, user, status etc. affectedRequests MetadataMetaTable mapping table of n:m relation of operations to requests aggregationHistory MetadataMetaTable stores aggregation behavior on activation. Needed to account for model changes between activation and rollback logMessages MetadataMetaTable log messages per operation idGen MetadataMetaTable indicates request type (load, activation, general operation). Without sequence, new IDs are drawn based on the content of this table subscribers MetadataMetaTable stores subscribers doing delta-extractions from the change log. The latest extracted activation requests are written by each subscriber and affect housekeeping, like cleanupChangelog activeData object main, reportable data entity activeData.name string entity name of the data table activeData.fullName string fully qualified and quoted table name including schema and namespace activeData.fields Array.<MetadataActiveDataField> [changeLog] object optional data entity to track changes changeLog.name string entity name of the data table changeLog.fullName string fully qualified and quoted table name including schema and namespace changeLog.fields Array.<MetadataChangeLogField> activationQueues Array.<object> one or more data entity to queue inbound data for activation activationQueues.name string entity name of the data table activationQueues.fullName string fully qualified and quoted table name including schema and namespace activationQueues.fields Array.<MetadataInboundQueueField> procedures object.<string, MetadataProcedure> map of supported SQL procedures. Key is the operation identifier, e.g. LOAD sequence string sequence used to draw new IDs metaModel object information about current NDSO metamodel metaModel.version string metamodel version","title":"Metadata"},{"location":"apis/dwf-ndso-backend/#monitoringtablestats","text":"Properties Name Type Description tableName string table name [size] integer table estimated maximal memory size in bytes (not provided, if user lacks authorization) [rows] integer table row count (not provided, if user lacks authorization)","title":"MonitoringTableStats"},{"location":"apis/dwf-ndso-backend/#monitoringoverview","text":"Properties Name Type Description result Array.<object> result.name string NDSO name result.lastOp string type of the last operation result.lastOpBy string user last changing the last operation result.lastOpAt string ISO 8601 UTC timestamp when the last operation was last changed result.lastOpStatus string status of the last operation result.subscribers integer number of subscribers result.stats object table statistics result.stats.activeData MonitoringTableStats stats for active data entity result.stats.inboundQueues Array.<MonitoringTableStats> stats for inbound queue entities [result.stats.changeLog] MonitoringTableStats optional stats for change log entity [result.message] string optional warning message derived from authorization errors by HANA; thrown, if user lacks authorization for monitoring synonyms (e.g. M_CS_TABLES)","title":"MonitoringOverview"},{"location":"apis/dwf-ndso-backend/#operationinfo","text":"Properties Name Type Description result Array.<object> result.operationId integer operation ID result.operation string operation type result.status string operation status result.userName string user last changing the operation result.lastTimestamp string ISO 8601 UTC timestamp when the operation was last changed [result.operationDetails] object optional operation details","title":"OperationInfo"},{"location":"apis/dwf-ndso-backend/#operationsforrequest","text":"Properties Name Type Description result Array.<object> result.operationId integer operation ID result.operation string operation type result.status string operation status result.userName string user last changing the operation result.lastTimestamp string ISO 8601 UTC timestamp when the operation was last changed result.affectedRequests Array.<integer> related request IDs","title":"OperationsForRequest"},{"location":"apis/dwf-ndso-backend/#requestinfo","text":"Properties Name Type Description result Array.<object> result.operationId integer ID of the last operation affecting the request result.operation string type of the last operation affecting the request result.status string status of the last operation affecting the request result.userName string user last changing the operation result.startTimestamp string ISO 8601 UTC timestamp when the operation was started result.lastTimestamp string ISO 8601 UTC timestamp when the operation was last changed result.dependentRequests Array.<integer> related request IDs result.requestStatus string current status of the request (derived from the latest operation affecting it) [result.operationDetails] object optional operation details","title":"RequestInfo"},{"location":"apis/dwf-ndso-backend/#rowcountwithfilter","text":"Properties Name Type Description result Array.<object> result.tableName string fully qualified name of active data table result.rowCount integer total number of rows","title":"RowcountWithFilter"},{"location":"apis/dwf-ndso-backend/#subscribers","text":"Properties Name Type Description result Array.<object> result.subscriberName string subscriber name result.description string additional description result.userName string user that created the subscriber result.creationTimestamp string ISO 8601 UTC timestamp of the subscriber creation result.maxRequest integer last activation request the subscriber extracted from the change log result.pushNotification string not implemented","title":"Subscribers"},{"location":"apis/dwf-ndso-backend/#operationresult","text":"Properties Name Type Description operationId integer ID of the operation","title":"OperationResult"},{"location":"apis/dwf-ndso-backend/#loadresult","text":"Properties Name Type Description operationId integer ID of the load operation loadId integer ID of the resulting load request","title":"LoadResult"},{"location":"apis/dwf-ndso-backend/#queryoptions","text":"Some tasks offer a parameter queryOptions that allow for backend-side paging, sorting and filtering. The task expects it to be an object like this: Example { lim : 100 , // LIMIT in SQL: returns up to 100 rows off : 200 , // OFFSET in SQL: skips first 200 rows flt : { // builds WHERE in SQL; multiple columns are connected COLUMN1 : 'value1' , // by AND COLUMN2 : 123 , COLUMN3 : [ // array elements for same column are connected by OR { op : 'BT' , // BT resolves to 'BETWEEN ? AND ?' val : [ 10 , 20 ] }, { op : 'EQ' , // EQ resolves to 'IN (?,?,?)' val : [ 95 , 99 , 101 ] }, { op : 'LT' , // LT ('less than') resolves to '< ?' val : 50 // there's also LE ('less or equal') }, { op : 'GT' , // GT ('greater than') resolves to '> ?' val : 'abc' // there's also GE ('greater or equal') } ] }, fltMode : 'PARTIAL' , // instead of 'WHERE = ?' this resolves to 'WHERE LIKE ?' // and wildcards around value (e.g. '%value1%') // default is 'EXACT' ord : [ // builds ORDER BY in SQL { col : 'COLUMN1' // defaults to 'ASC' }, { col : 'COLUMN3' , dir : 'DESC' } ] }","title":"QueryOptions"},{"location":"apis/dwf-ndso-backend/#requestsforoperation","text":"Properties Name Type Description result Array.<object> result.requestId integer request ID result.userName string user last affecting the request (by operation) result.timestamp string ISO 8601 UTC timestamp when the operation was last changed","title":"RequestsForOperation"},{"location":"apis/dwf-ndso-backend/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . [Unreleased] \u00b6 nothing yet [2.2.0] - 2018-08-15 \u00b6 Changed \u00b6 addSubscriber and resetSubscriber operations now fail if there is no change log modeled changed expected metamodel version for generated NDSOs from 1.2.0 to 2.0.0. While the metamodel itself does not contain incompatible changes, previously deployed NDSOs won't be operable after upgrading the metdamodel and require manual migration. This is intended but from the user's perspective a breaking change which shall be reflected by a new major version according to semver - getMetadata now also returns typeParam1, typeParam2 and defaultValue for active data fields Fixed \u00b6 Fix storeCSV to only ignore actually empty rows (before, it also filtered those only containing special characters). Also made check for line-endings agnostic of the operating system [2.1.0] - 2018-07-06 \u00b6 Added \u00b6 Generated NDSOs are supported Enhance metadata object to include sequence, procedures and metamodel information Support generated synonyms ( DataWarehouse.DataStore namespace) for DB objects Implemented checkMetadataConsistency task Changed \u00b6 Added to operation storeSQL default handling for NULL values in columns defined as TIMESTAMP Fixed \u00b6 Fix storeCSV to ignore empty lines [2.0.2] - 2018-04-17 \u00b6 Fixed \u00b6 Fix getRequestsFor Deletion to still provide loads if multiple loads are done before a partial activation (before, the remaining loads were not returned) [2.0.1] - 2018-04-16 \u00b6 Fixed \u00b6 Fix getRequestsForActivation to still provide loads if multiple loads are done before a partial activation (before, the remaining loads were not returned) Fix repairRunningOperations to update lastTimestamp column in the operationHistory table Fix start messages for add-, reset- and removeSubscriber (showed '{0}' instead of subscriber name) [2.0.0] - 2018-04-13 \u00b6 Added \u00b6 complete NDSO task reference on README (generated by jsdoc-to-markdown ) support more query options Changed \u00b6 Incompatible: Rewrite task getOperationInfo to now take generic query options instead of dedicated filter parameters Incompatible: Rewrite tasks getRowcountWithFilter and deleteWithFilter to now filter by generic query options instead of using a provided where clause Incompatible: added default handling to operation storeSQL if the source data contains NULL values. This required to explicitly list the columns in the underlying SQL statement which effectively means, that the provided SQL serving as FROM clause needs to provide the exact same column names as the corresponding inbound queue has. As that was not required before, old statements may not work anymore deleteWithFilter now writes filter instead of where into operationDetails Lists of request IDs are now shortened for more than 5 requests in log and tracing messages (affects, for example, activate and rollback operations) cleanupChangelog now writes requestCount and requestList into operationDetails. requestList is shortened the same way as log entries Reworked log messages (e.g. expanded 'lines' suffix by a dedicated detail message listing how many rows have been inserted, updated, deleted as it has been only for activate and rollback before) cleanupChangelog is now rejected without writing an operation when run on NDSO without change log Minor performance improvement for getMetadata Minor improvement of CSV checks (removes empty semicolons and final line breaks) Fixed \u00b6 Fix getRequestsForActivation and getRequestsForDeletion to also consider running activations/deletions (the affected load requests are not returned anymore) Fix getRequestsForActivation to not fail without maxRequestId Fix getRequestsForDeletion to also provide failed loads before last activation Fix getRequestsForCleanup to also consider running rollbacks/clean-ups (the affected activation requests are not returned anymore) Fix getRequestsForRollback to exclude requests that have been extracted by subscribers as rollbacks are just deleted from change log Fix rollback for aggregation-related model changes. Before, when activating with a SUM aggregation, then changing the model e.g. to a MOV aggregation a rollback would not treat the before-image as negated because that information was taken from active data, not the aggregation history. As a result, data was likely corrupted after such a rollback Fix deleteWithFilter to also write aggregation history if called with propagateDeletion . In combination with the fix for rollback, this would have resulted in data corruption after rollback of a deletion Fix operation timestamps by updating the operation status once more before the final commit Removed \u00b6 Remove checksum handling; hashes are neither verified nor updated anymore Remove setConfig as there was no supported global config anymore anyway Remove dependency to async [1.4.0] - 2018-02-06 \u00b6 Added \u00b6 Promise support by all tasks (just omit callback to use it) storeCSV now supports NDSOs with binary types ( VARBINARY and BLOB ). To utilize this, provide data as hexadecimal strings, data is inserted via HEXTOBIN SQL function Changed \u00b6 Incompatible: queryOption 'ord' now array as order is relevant and object property order is unspecified queryOption 'flt' now supports multiple values. Refer to README for details deleteWithFilter now writes where instead of sWhere into operationDetails Slight performance improvement overall by caching repeatedly retrieved metadata Complete refactoring of smokeTest, increasing coverage and significantly improving performance getDatastoreFeature now checks for existence of NDSO meta model instead of a runtime environment variable. It also returns the meta model version getMetadata now returns defaultValue s for inbound queue fields Removed \u00b6 setConfig option earlyCallback [1.3.1] - 2017-12-18 \u00b6 Fixed \u00b6 Fix timeout issue in smokeTest [1.3.0] - 2017-12-15 \u00b6 Changed \u00b6 Incompatible : Remove custom format YYYYMMDDHH24MISS for timestamps, now ISO 8601 UTC strings ( YYYY-MM-DD\"T\"HH24:MI:SS.FF3\"Z\" ) are sent and expected for filtering Incompatible : Rewrite task getRequestInfo: now takes generic query options instead of multiple query parameters returns flat array as result instead of splitting loads and activations fix typo in dependentRequests property significant performance improvement by pushing whole logic to HANA Deprecated \u00b6 setConfig option earlyCallback shall not be used anymore and will be removed soon. [1.2.0] - 2017-12-12 \u00b6 Added \u00b6 Add new task getMonitoringOverview that fetches all NDSOs of the provided schema and provides information relevant for monitoring, like the last operation and stats like table sizes and row count. Note that the latter requires access to the monitoring views SYS.M_CS_TABLE and SYS.M_RS_TABLE . - Add queryOptions to task getDataStores which support filtering, sorting and paging. Refer to README for details - Add support for drawing request IDs from sequence. To do so the sequence must be named as annotation @DataStore.sequence: 'name with namespace' . When introducing a sequence for existing NDSOs, you should define RESET BY according to the maximum value in the idGenerator table. Note that that table will continue to be updated even if IDs are drawn by sequence. Changed \u00b6 Provide detail message with modified rows after operations activate and rollback also for alternative client @sap/hana-client Write application user into metadata tables, if available (falls back to the technical CURRENT_USER if not) Fixed \u00b6 Fix crash in getOperationsForRequest if no operation found (may happen during deleteAll) Fix message logging for failed operations. It used to throw an error like 'statement.execBatch undefined' [1.1.1] - 2017-11-20 \u00b6 Fixed \u00b6 Fix getRequestsForActivation to return multiple requests again Fix activation for multiple inbound queues Fix logging of activation procedure parameters (was missing change log info) [1.1.0] - 2017-11-07 \u00b6 Added \u00b6 Support for alternative HANA client @sap/hana-client Changed \u00b6 Improve log for activate/rollback: procedure result is now added as proper log messages, not technical JSON (only for node-hdb client) Use most recent version of async Fixed \u00b6 Follow-up fix of error handling if operation cannot be started Fix rollback error if previous rollback failed [1.0.5] - 2017-10-24 \u00b6 Changed \u00b6 operation status of checkMetadataConsistency now reflects consistency result, i.e., if there is an error the operation status will be FAILED getRowcountWithFilter can now be called without the superfluous second DB client, i.e., with tracer, client, schema, ndso, whereClause, callback . The signature stays compatible though, the second client is just optional Fixed \u00b6 Fix smokeTest status polling which exited too early because smokeTest uses the same DB connections for all operations and therefore sees status 'FINISHED' before it is committed. Now it polls for an internal indicator instead Fix error handling if operation cannot be started (e.g. called with not existing NDSO name) Fix repairRunningOperations. It used to check the runningOperations entity but with introduction of startOperation that is written in the first commit without locking again. The repair operation now checks the operationHistory instead because the status update is the first update after the first commit. [1.0.4] - 2017-10-13 \u00b6 Changed \u00b6 Close database connections for operations when earlyCallback is active Improve README.md [1.0.3] - 2017-10-12 \u00b6 Fixed \u00b6 Fix task smokeTest to also support earlyCallback option. It used to return immediately, so the still running operations could interfere with test clean-up procedures [1.0.2] - 2017-10-11 \u00b6 Fixed \u00b6 Fix number of written lines in various operation success messages Fix list of deletable load requests (task getRequestsForDeletion); used to return also activated and already deleted load requests Fix list of requests for rollback (task getRequestsForRollback); used to return also requests that the change log has meanwhile been cleared for (resulted in technical error during rollback: 'Unique constraint violation') [1.0.1] - 2017-10-06 \u00b6 Added \u00b6 Add CHANGELOG.md (this file) and publishable README.md Add new task setConfig that allows to set options by a key-value object. Currently, only option earlyCallback is supported which makes operations call the main callback function already after drawing IDs and writing the operation into the history. This fixes various timeout issues when executing operations in the HRTT Manage UI. Fixed \u00b6 Fix side-effect of disabling autocommit. In case of errors also the affectedRequests entity was rolled back which resulted in an inconsistency and, for example, failing load or activation requests were not shown on the UI. Fix checksum calculation for LargeBinary (BLOB) fields as casting to VARCHAR is invalid. As a result such NDSOs could not be activated. [1.0.0] - 2017-09-29 \u00b6 Added \u00b6 First release of this package; based on code from @sap/dwf-dws-client and the Database Explorer (HANA Runtime Tools, HRTT) Changed \u00b6 Exclude internal helpers from the tasks folder which now only contains real tasks to be invoked by a consumer Fixed \u00b6 Fix checksum handling in task CheckMetadataConsistency. It now works like the check on Activate.","title":"Changelog"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#unreleased","text":"nothing yet","title":"[Unreleased]"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#220-2018-08-15","text":"","title":"[2.2.0] - 2018-08-15"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed","text":"addSubscriber and resetSubscriber operations now fail if there is no change log modeled changed expected metamodel version for generated NDSOs from 1.2.0 to 2.0.0. While the metamodel itself does not contain incompatible changes, previously deployed NDSOs won't be operable after upgrading the metdamodel and require manual migration. This is intended but from the user's perspective a breaking change which shall be reflected by a new major version according to semver - getMetadata now also returns typeParam1, typeParam2 and defaultValue for active data fields","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed","text":"Fix storeCSV to only ignore actually empty rows (before, it also filtered those only containing special characters). Also made check for line-endings agnostic of the operating system","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#210-2018-07-06","text":"","title":"[2.1.0] - 2018-07-06"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#added","text":"Generated NDSOs are supported Enhance metadata object to include sequence, procedures and metamodel information Support generated synonyms ( DataWarehouse.DataStore namespace) for DB objects Implemented checkMetadataConsistency task","title":"Added"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_1","text":"Added to operation storeSQL default handling for NULL values in columns defined as TIMESTAMP","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_1","text":"Fix storeCSV to ignore empty lines","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#202-2018-04-17","text":"","title":"[2.0.2] - 2018-04-17"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_2","text":"Fix getRequestsFor Deletion to still provide loads if multiple loads are done before a partial activation (before, the remaining loads were not returned)","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#201-2018-04-16","text":"","title":"[2.0.1] - 2018-04-16"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_3","text":"Fix getRequestsForActivation to still provide loads if multiple loads are done before a partial activation (before, the remaining loads were not returned) Fix repairRunningOperations to update lastTimestamp column in the operationHistory table Fix start messages for add-, reset- and removeSubscriber (showed '{0}' instead of subscriber name)","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#200-2018-04-13","text":"","title":"[2.0.0] - 2018-04-13"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#added_1","text":"complete NDSO task reference on README (generated by jsdoc-to-markdown ) support more query options","title":"Added"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_2","text":"Incompatible: Rewrite task getOperationInfo to now take generic query options instead of dedicated filter parameters Incompatible: Rewrite tasks getRowcountWithFilter and deleteWithFilter to now filter by generic query options instead of using a provided where clause Incompatible: added default handling to operation storeSQL if the source data contains NULL values. This required to explicitly list the columns in the underlying SQL statement which effectively means, that the provided SQL serving as FROM clause needs to provide the exact same column names as the corresponding inbound queue has. As that was not required before, old statements may not work anymore deleteWithFilter now writes filter instead of where into operationDetails Lists of request IDs are now shortened for more than 5 requests in log and tracing messages (affects, for example, activate and rollback operations) cleanupChangelog now writes requestCount and requestList into operationDetails. requestList is shortened the same way as log entries Reworked log messages (e.g. expanded 'lines' suffix by a dedicated detail message listing how many rows have been inserted, updated, deleted as it has been only for activate and rollback before) cleanupChangelog is now rejected without writing an operation when run on NDSO without change log Minor performance improvement for getMetadata Minor improvement of CSV checks (removes empty semicolons and final line breaks)","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_4","text":"Fix getRequestsForActivation and getRequestsForDeletion to also consider running activations/deletions (the affected load requests are not returned anymore) Fix getRequestsForActivation to not fail without maxRequestId Fix getRequestsForDeletion to also provide failed loads before last activation Fix getRequestsForCleanup to also consider running rollbacks/clean-ups (the affected activation requests are not returned anymore) Fix getRequestsForRollback to exclude requests that have been extracted by subscribers as rollbacks are just deleted from change log Fix rollback for aggregation-related model changes. Before, when activating with a SUM aggregation, then changing the model e.g. to a MOV aggregation a rollback would not treat the before-image as negated because that information was taken from active data, not the aggregation history. As a result, data was likely corrupted after such a rollback Fix deleteWithFilter to also write aggregation history if called with propagateDeletion . In combination with the fix for rollback, this would have resulted in data corruption after rollback of a deletion Fix operation timestamps by updating the operation status once more before the final commit","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#removed","text":"Remove checksum handling; hashes are neither verified nor updated anymore Remove setConfig as there was no supported global config anymore anyway Remove dependency to async","title":"Removed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#140-2018-02-06","text":"","title":"[1.4.0] - 2018-02-06"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#added_2","text":"Promise support by all tasks (just omit callback to use it) storeCSV now supports NDSOs with binary types ( VARBINARY and BLOB ). To utilize this, provide data as hexadecimal strings, data is inserted via HEXTOBIN SQL function","title":"Added"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_3","text":"Incompatible: queryOption 'ord' now array as order is relevant and object property order is unspecified queryOption 'flt' now supports multiple values. Refer to README for details deleteWithFilter now writes where instead of sWhere into operationDetails Slight performance improvement overall by caching repeatedly retrieved metadata Complete refactoring of smokeTest, increasing coverage and significantly improving performance getDatastoreFeature now checks for existence of NDSO meta model instead of a runtime environment variable. It also returns the meta model version getMetadata now returns defaultValue s for inbound queue fields","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#removed_1","text":"setConfig option earlyCallback","title":"Removed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#131-2017-12-18","text":"","title":"[1.3.1] - 2017-12-18"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_5","text":"Fix timeout issue in smokeTest","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#130-2017-12-15","text":"","title":"[1.3.0] - 2017-12-15"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_4","text":"Incompatible : Remove custom format YYYYMMDDHH24MISS for timestamps, now ISO 8601 UTC strings ( YYYY-MM-DD\"T\"HH24:MI:SS.FF3\"Z\" ) are sent and expected for filtering Incompatible : Rewrite task getRequestInfo: now takes generic query options instead of multiple query parameters returns flat array as result instead of splitting loads and activations fix typo in dependentRequests property significant performance improvement by pushing whole logic to HANA","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#deprecated","text":"setConfig option earlyCallback shall not be used anymore and will be removed soon.","title":"Deprecated"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#120-2017-12-12","text":"","title":"[1.2.0] - 2017-12-12"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#added_3","text":"Add new task getMonitoringOverview that fetches all NDSOs of the provided schema and provides information relevant for monitoring, like the last operation and stats like table sizes and row count. Note that the latter requires access to the monitoring views SYS.M_CS_TABLE and SYS.M_RS_TABLE . - Add queryOptions to task getDataStores which support filtering, sorting and paging. Refer to README for details - Add support for drawing request IDs from sequence. To do so the sequence must be named as annotation @DataStore.sequence: 'name with namespace' . When introducing a sequence for existing NDSOs, you should define RESET BY according to the maximum value in the idGenerator table. Note that that table will continue to be updated even if IDs are drawn by sequence.","title":"Added"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_5","text":"Provide detail message with modified rows after operations activate and rollback also for alternative client @sap/hana-client Write application user into metadata tables, if available (falls back to the technical CURRENT_USER if not)","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_6","text":"Fix crash in getOperationsForRequest if no operation found (may happen during deleteAll) Fix message logging for failed operations. It used to throw an error like 'statement.execBatch undefined'","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#111-2017-11-20","text":"","title":"[1.1.1] - 2017-11-20"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_7","text":"Fix getRequestsForActivation to return multiple requests again Fix activation for multiple inbound queues Fix logging of activation procedure parameters (was missing change log info)","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#110-2017-11-07","text":"","title":"[1.1.0] - 2017-11-07"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#added_4","text":"Support for alternative HANA client @sap/hana-client","title":"Added"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_6","text":"Improve log for activate/rollback: procedure result is now added as proper log messages, not technical JSON (only for node-hdb client) Use most recent version of async","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_8","text":"Follow-up fix of error handling if operation cannot be started Fix rollback error if previous rollback failed","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#105-2017-10-24","text":"","title":"[1.0.5] - 2017-10-24"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_7","text":"operation status of checkMetadataConsistency now reflects consistency result, i.e., if there is an error the operation status will be FAILED getRowcountWithFilter can now be called without the superfluous second DB client, i.e., with tracer, client, schema, ndso, whereClause, callback . The signature stays compatible though, the second client is just optional","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_9","text":"Fix smokeTest status polling which exited too early because smokeTest uses the same DB connections for all operations and therefore sees status 'FINISHED' before it is committed. Now it polls for an internal indicator instead Fix error handling if operation cannot be started (e.g. called with not existing NDSO name) Fix repairRunningOperations. It used to check the runningOperations entity but with introduction of startOperation that is written in the first commit without locking again. The repair operation now checks the operationHistory instead because the status update is the first update after the first commit.","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#104-2017-10-13","text":"","title":"[1.0.4] - 2017-10-13"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_8","text":"Close database connections for operations when earlyCallback is active Improve README.md","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#103-2017-10-12","text":"","title":"[1.0.3] - 2017-10-12"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_10","text":"Fix task smokeTest to also support earlyCallback option. It used to return immediately, so the still running operations could interfere with test clean-up procedures","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#102-2017-10-11","text":"","title":"[1.0.2] - 2017-10-11"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_11","text":"Fix number of written lines in various operation success messages Fix list of deletable load requests (task getRequestsForDeletion); used to return also activated and already deleted load requests Fix list of requests for rollback (task getRequestsForRollback); used to return also requests that the change log has meanwhile been cleared for (resulted in technical error during rollback: 'Unique constraint violation')","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#101-2017-10-06","text":"","title":"[1.0.1] - 2017-10-06"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#added_5","text":"Add CHANGELOG.md (this file) and publishable README.md Add new task setConfig that allows to set options by a key-value object. Currently, only option earlyCallback is supported which makes operations call the main callback function already after drawing IDs and writing the operation into the history. This fixes various timeout issues when executing operations in the HRTT Manage UI.","title":"Added"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_12","text":"Fix side-effect of disabling autocommit. In case of errors also the affectedRequests entity was rolled back which resulted in an inconsistency and, for example, failing load or activation requests were not shown on the UI. Fix checksum calculation for LargeBinary (BLOB) fields as casting to VARCHAR is invalid. As a result such NDSOs could not be activated.","title":"Fixed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#100-2017-09-29","text":"","title":"[1.0.0] - 2017-09-29"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#added_6","text":"First release of this package; based on code from @sap/dwf-dws-client and the Database Explorer (HANA Runtime Tools, HRTT)","title":"Added"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#changed_9","text":"Exclude internal helpers from the tasks folder which now only contains real tasks to be invoked by a consumer","title":"Changed"},{"location":"apis/dwf-ndso-backend/CHANGELOG/#fixed_13","text":"Fix checksum handling in task CheckMetadataConsistency. It now works like the check on Activate.","title":"Fixed"},{"location":"apis/e2e-trace/","text":"@sap/e2e-trace \u00b6 Node.js package with end to end tracing capabilities. Overview \u00b6 SAP Passport \u00b6 SAP Passports allow to identify a specific request in an end-to-end scenario involving several components communicating with each other. This is especially helpful in the task of following the state of a business transaction across different systems. To achieve that, the client should send a special header ('sap-passport') containing the SAP Passport to the first component. The SAP Passport is a hex string with a special structure. The client can send one via a browser plugin or via SAPUI5 application frontend. Whenever an SAP Passport comes into a component, this component should also include the unique identifiers of the SAP Passport in its logs/traces, update it with component specific data and then forward it to the next system. See the diagram below: An application receives an SAP Passport in the 'sap-passport' header. The same header is used when the SAP Passport is getting forwarded over the HTTP protocol to another system. If it is being sent to HANA, the SAP Passport should be set as the 'SAP_PASSPORT' session variable of the database connection. API \u00b6 Loading the package: var SAPPassport = require ( '@sap/e2e-trace' ). Passport ; Creating an SAP Passport instance function requestHandler ( req , res ) { var encodedPassport = req . headers [ SAPPassport . HEADER_NAME ]; if ( encodedPassport ) { var passport = new SAPPassport ( encodedPassport ); } } The library provides a constant for the 'sap-passport' header: SAPPassport.HEADER_NAME . The passport variable is an instance with which you may read/modify the SAP Passport in your component. Reading the unique identifiers of an SAP Passport var identifiers = passport . readUniqueIdentifiers (); The returned value (assigned to the identifiers variable) is an object that has the following properties: transactionID , rootContextID , connectionID , connectionCounter . These SAP Passport fields got to be present in the logs/traces of the component. If you are using the sap-logging library, refer to its documentation to check whether the specific version is capable of handling SAP Passports or not. Updating the SAP Passport - this is done right before forwarding it to the next component. passport . update ({ previousComponent : 'my-application' , connectionID : '00112233445566778899AABBCCDDEEFF' , connectionCounter : 36 }); This method takes an object with the following properties: Property Value Mandatory Semantics previousComponent ASCII string. Up to 32 characters. This is the name of the current component which is about to make an outbound connection to another component. Defaults to XSA Node.js . connectionID GUID, 16-byte hex yes Every connection between the current component and the next component should have an ID which is passed as that property. connectionCounter Positive integer, up to 4 bytes yes States for which time the connection with the given connectionID is being reused. Compacting the SAP Passport - HANA DB has a limitation over the SAP Passport size. This is why it is recommended to call the method compact before forwarding an SAP Passport to HANA. passport . compact (); Generating a hex string out of the updated SAP Passport - the SAP Passport can be send to other components in this format. var http = require ( 'http' ); var url = require ( 'url' ); var encodedPassport = passport . serialize (); var options = url . parse ( 'http://my-host:1234/my/path' ); options . headers = {}; options . headers [ SAPPassport . HEADER_NAME ] = encodedPassport ; var request = http . request ( options ); request . on ( 'error' , function ( err ) { /* ... */ }); request . on ( 'response' , function ( response ) { /* ... */ }); request . end (); DSR records \u00b6 Distributed Statistics Records contain statistical information regarding an incoming request. The library writes every record on the standard output in a JSON format. Gathering DSR statistics is triggered when a request containing an SAP passport is received. API \u00b6 var connect = require ( 'connect' ); var createDsrMiddleware = require ( '@sap/e2e-trace' ). createDsrMiddleware ; var app = connect (); app . use ( createDsrMiddleware ()); app . use ( '/path' , function ( req , res , next ) { // ... }); The DSR middleware (can be used with frameworks like connect and express ) should be the first middleware in the request processing flow. Example DSR record: { \"action\" : \"https://host:5555/path?a=1&b=2\" , \"receivedBytes\" : 1230 , \"sentBytes\" : 110 , \"respTime\" : 18 , \"transId\" : \"104A7DB661D31EE69DE912281546ED81\" , \"userId\" : \"n.a.\" , \"startTime\" : 1473506434377 } Properties in a DSR record: Property Description startTime Time at which request processing starts (milliseconds elapsed since 1 January 1970 00:00:00 UTC). action The requested URL. receivedBytes Number of bytes the incoming HTTP request contains (lengths of request line, headers section and body included). Note : due to a bug in Node.js, this field might be 0 in some runtime versions. Refer to the engines/node property in package.json for recommended Node.js versions. sentBytes Number of bytes the outgoing HTTP response contains (lengths of status line, headers section and body included). respTime Number of milliseconds spent in request processing (until the whole outgoing HTTP response has been handed off to the operating system for transmission over the network). transId The Transaction ID field of the SAP Passport that has triggered the DSR record. userId User ID of the current user taken from the request object. Defaults to n.a. .","title":"@sap/e2e-trace"},{"location":"apis/e2e-trace/#sape2e-trace","text":"Node.js package with end to end tracing capabilities.","title":"@sap/e2e-trace"},{"location":"apis/e2e-trace/#overview","text":"","title":"Overview"},{"location":"apis/e2e-trace/#sap-passport","text":"SAP Passports allow to identify a specific request in an end-to-end scenario involving several components communicating with each other. This is especially helpful in the task of following the state of a business transaction across different systems. To achieve that, the client should send a special header ('sap-passport') containing the SAP Passport to the first component. The SAP Passport is a hex string with a special structure. The client can send one via a browser plugin or via SAPUI5 application frontend. Whenever an SAP Passport comes into a component, this component should also include the unique identifiers of the SAP Passport in its logs/traces, update it with component specific data and then forward it to the next system. See the diagram below: An application receives an SAP Passport in the 'sap-passport' header. The same header is used when the SAP Passport is getting forwarded over the HTTP protocol to another system. If it is being sent to HANA, the SAP Passport should be set as the 'SAP_PASSPORT' session variable of the database connection.","title":"SAP Passport"},{"location":"apis/e2e-trace/#api","text":"Loading the package: var SAPPassport = require ( '@sap/e2e-trace' ). Passport ; Creating an SAP Passport instance function requestHandler ( req , res ) { var encodedPassport = req . headers [ SAPPassport . HEADER_NAME ]; if ( encodedPassport ) { var passport = new SAPPassport ( encodedPassport ); } } The library provides a constant for the 'sap-passport' header: SAPPassport.HEADER_NAME . The passport variable is an instance with which you may read/modify the SAP Passport in your component. Reading the unique identifiers of an SAP Passport var identifiers = passport . readUniqueIdentifiers (); The returned value (assigned to the identifiers variable) is an object that has the following properties: transactionID , rootContextID , connectionID , connectionCounter . These SAP Passport fields got to be present in the logs/traces of the component. If you are using the sap-logging library, refer to its documentation to check whether the specific version is capable of handling SAP Passports or not. Updating the SAP Passport - this is done right before forwarding it to the next component. passport . update ({ previousComponent : 'my-application' , connectionID : '00112233445566778899AABBCCDDEEFF' , connectionCounter : 36 }); This method takes an object with the following properties: Property Value Mandatory Semantics previousComponent ASCII string. Up to 32 characters. This is the name of the current component which is about to make an outbound connection to another component. Defaults to XSA Node.js . connectionID GUID, 16-byte hex yes Every connection between the current component and the next component should have an ID which is passed as that property. connectionCounter Positive integer, up to 4 bytes yes States for which time the connection with the given connectionID is being reused. Compacting the SAP Passport - HANA DB has a limitation over the SAP Passport size. This is why it is recommended to call the method compact before forwarding an SAP Passport to HANA. passport . compact (); Generating a hex string out of the updated SAP Passport - the SAP Passport can be send to other components in this format. var http = require ( 'http' ); var url = require ( 'url' ); var encodedPassport = passport . serialize (); var options = url . parse ( 'http://my-host:1234/my/path' ); options . headers = {}; options . headers [ SAPPassport . HEADER_NAME ] = encodedPassport ; var request = http . request ( options ); request . on ( 'error' , function ( err ) { /* ... */ }); request . on ( 'response' , function ( response ) { /* ... */ }); request . end ();","title":"API"},{"location":"apis/e2e-trace/#dsr-records","text":"Distributed Statistics Records contain statistical information regarding an incoming request. The library writes every record on the standard output in a JSON format. Gathering DSR statistics is triggered when a request containing an SAP passport is received.","title":"DSR records"},{"location":"apis/e2e-trace/#api_1","text":"var connect = require ( 'connect' ); var createDsrMiddleware = require ( '@sap/e2e-trace' ). createDsrMiddleware ; var app = connect (); app . use ( createDsrMiddleware ()); app . use ( '/path' , function ( req , res , next ) { // ... }); The DSR middleware (can be used with frameworks like connect and express ) should be the first middleware in the request processing flow. Example DSR record: { \"action\" : \"https://host:5555/path?a=1&b=2\" , \"receivedBytes\" : 1230 , \"sentBytes\" : 110 , \"respTime\" : 18 , \"transId\" : \"104A7DB661D31EE69DE912281546ED81\" , \"userId\" : \"n.a.\" , \"startTime\" : 1473506434377 } Properties in a DSR record: Property Description startTime Time at which request processing starts (milliseconds elapsed since 1 January 1970 00:00:00 UTC). action The requested URL. receivedBytes Number of bytes the incoming HTTP request contains (lengths of request line, headers section and body included). Note : due to a bug in Node.js, this field might be 0 in some runtime versions. Refer to the engines/node property in package.json for recommended Node.js versions. sentBytes Number of bytes the outgoing HTTP response contains (lengths of status line, headers section and body included). respTime Number of milliseconds spent in request processing (until the whole outgoing HTTP response has been handed off to the operating system for transmission over the network). transId The Transaction ID field of the SAP Passport that has triggered the DSR record. userId User ID of the current user taken from the request object. Defaults to n.a. .","title":"API"},{"location":"apis/e2e-trace/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 2.1.0 - 2019-12-06 \u00b6 Added \u00b6 Support for Node.js 12.x 2.0.0 - 2019-04-25 \u00b6 Removed \u00b6 Support for Node.js v0.12 and v4 1.4.1 - 2019-01-15 \u00b6 Fixed \u00b6 Update shrinkwrap 1.4.0 - 2019-01-15 \u00b6 Added \u00b6 Node.js version 10 support 1.3.0 - 2018-01-19 \u00b6 Added \u00b6 npm-shrinkwrap.json 1.2.0 - 2018-01-08 \u00b6 Added \u00b6 CHANGELOG.md Node.js version 8 support 1.1.3 - 2017-07-04 \u00b6 Removed \u00b6 Remove lodash as a productive dependency. 1.1.2 - 2017-01-24 \u00b6 Changed \u00b6 Rename package to use sap scope.","title":"Change Log"},{"location":"apis/e2e-trace/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/e2e-trace/CHANGELOG/#210-2019-12-06","text":"","title":"2.1.0 - 2019-12-06"},{"location":"apis/e2e-trace/CHANGELOG/#added","text":"Support for Node.js 12.x","title":"Added"},{"location":"apis/e2e-trace/CHANGELOG/#200-2019-04-25","text":"","title":"2.0.0 - 2019-04-25"},{"location":"apis/e2e-trace/CHANGELOG/#removed","text":"Support for Node.js v0.12 and v4","title":"Removed"},{"location":"apis/e2e-trace/CHANGELOG/#141-2019-01-15","text":"","title":"1.4.1 - 2019-01-15"},{"location":"apis/e2e-trace/CHANGELOG/#fixed","text":"Update shrinkwrap","title":"Fixed"},{"location":"apis/e2e-trace/CHANGELOG/#140-2019-01-15","text":"","title":"1.4.0 - 2019-01-15"},{"location":"apis/e2e-trace/CHANGELOG/#added_1","text":"Node.js version 10 support","title":"Added"},{"location":"apis/e2e-trace/CHANGELOG/#130-2018-01-19","text":"","title":"1.3.0 - 2018-01-19"},{"location":"apis/e2e-trace/CHANGELOG/#added_2","text":"npm-shrinkwrap.json","title":"Added"},{"location":"apis/e2e-trace/CHANGELOG/#120-2018-01-08","text":"","title":"1.2.0 - 2018-01-08"},{"location":"apis/e2e-trace/CHANGELOG/#added_3","text":"CHANGELOG.md Node.js version 8 support","title":"Added"},{"location":"apis/e2e-trace/CHANGELOG/#113-2017-07-04","text":"","title":"1.1.3 - 2017-07-04"},{"location":"apis/e2e-trace/CHANGELOG/#removed_1","text":"Remove lodash as a productive dependency.","title":"Removed"},{"location":"apis/e2e-trace/CHANGELOG/#112-2017-01-24","text":"","title":"1.1.2 - 2017-01-24"},{"location":"apis/e2e-trace/CHANGELOG/#changed","text":"Rename package to use sap scope.","title":"Changed"},{"location":"apis/edm-converters/","text":"@sap/edm-converters \u00b6 This module provides several model converters. The following converters are currently supported: OData V2 EDM model (XML Format) to OData V4 EDM (JSON Format) (details Readme ) OData V4 EDM model (XML Format) to OData V4 EDM (JSON Format) (details Readme ) Each converter is contained in separate folder inside the lib folder. A detailed description of a converter is provided in the README.md of each converter sub-folder, or you may check the API documentation in the index.js and other files. Please note that it is also possible to compile an HTML version of the API documentation with: cd @sap/edm-converters npm install # this will install the development dependencies npm run doc # this will generate the documentation (If the module is installed into the global node package folder, use npm root -g to find and navigate to it.) Usage scenario \u00b6 The model converters can be used to convert the OData EDMX V2 or EDMX V4 model of a remote service into the EDM V4 JSON format. This EDM V4 JSON format can then be used with the OData Consumption library in module @sap/odata-v4 to consume remote OData services. The converters can be called via commandline or programmtically via an API Installation \u00b6 The @sap/edm-converters provide a commandline interface and a API for use with node. Installation commandline interface \u00b6 If you want to use the commandline interface we recommend to install the @sap/edm-converters with npm install -g @sap/edm-converters Installing it globally eases the usage of the converters from any folder. If you do so, then after installation the convert_edm symlink/script should be created. You can test this with calling convert_edm -v to show the converter version. Installation for API usage \u00b6 If you want to used the converters from your node application, then you can either install it locally or global. Just add: const converters = require ( '@sap/edm-converters' ) : The converter can then be accessed via: converters . MetadataConverterFactory . createEdmxV20ToJsonV40 ( < option > ); or converters . MetadataConverterFactory . createEdmxV40ToJsonV40 ( < option > ); Please check the API documentation in lib/<converter>/index.js for documentation about the parameters of the converter. Console usage \u00b6 All converters follow the following pattern convert_edm <converter> <file to be converted> <further arguments> Note: Currently absolute path as well as relative path to your model is supported. Currently the converters edmxV20ToJsonV40 and edmxV40ToJsonV40 are supported. Common sample arguments are: -i, --input <file to be converted> Input file to be converted --inputdir <input directory> Containing the source files, if is relative -o, --output <output file> Target file to be generated --outputdir <output directory> Output directory, if target file is relative or more files are generated -l, --loglevel Use 'e'/'i'(default)/'d' to show log information (e=error-log, i=info-log ,d=debug-log) -t, --target Omit or set to 'cs02' to produce the Oasis CSDL 4.01-CS02 format; if the Oasis CSDL Json 4.01-CS01 format should be produced, set to 'cs01'. The CS01 format can be used as the EDM JSON to bootstrap the Okra library. Converters may have additional options. Please see below on how to show documentation about this converters. Get help \u00b6 Get console help: \u00b6 convert_edm --help Get distinct converter help: \u00b6 convert_edm edmxV40ToJsonV40 --help Releases and Milestones \u00b6 Changelog","title":"Index"},{"location":"apis/edm-converters/#sapedm-converters","text":"This module provides several model converters. The following converters are currently supported: OData V2 EDM model (XML Format) to OData V4 EDM (JSON Format) (details Readme ) OData V4 EDM model (XML Format) to OData V4 EDM (JSON Format) (details Readme ) Each converter is contained in separate folder inside the lib folder. A detailed description of a converter is provided in the README.md of each converter sub-folder, or you may check the API documentation in the index.js and other files. Please note that it is also possible to compile an HTML version of the API documentation with: cd @sap/edm-converters npm install # this will install the development dependencies npm run doc # this will generate the documentation (If the module is installed into the global node package folder, use npm root -g to find and navigate to it.)","title":"@sap/edm-converters"},{"location":"apis/edm-converters/#usage-scenario","text":"The model converters can be used to convert the OData EDMX V2 or EDMX V4 model of a remote service into the EDM V4 JSON format. This EDM V4 JSON format can then be used with the OData Consumption library in module @sap/odata-v4 to consume remote OData services. The converters can be called via commandline or programmtically via an API","title":"Usage scenario"},{"location":"apis/edm-converters/#installation","text":"The @sap/edm-converters provide a commandline interface and a API for use with node.","title":"Installation"},{"location":"apis/edm-converters/#installation-commandline-interface","text":"If you want to use the commandline interface we recommend to install the @sap/edm-converters with npm install -g @sap/edm-converters Installing it globally eases the usage of the converters from any folder. If you do so, then after installation the convert_edm symlink/script should be created. You can test this with calling convert_edm -v to show the converter version.","title":"Installation commandline interface"},{"location":"apis/edm-converters/#installation-for-api-usage","text":"If you want to used the converters from your node application, then you can either install it locally or global. Just add: const converters = require ( '@sap/edm-converters' ) : The converter can then be accessed via: converters . MetadataConverterFactory . createEdmxV20ToJsonV40 ( < option > ); or converters . MetadataConverterFactory . createEdmxV40ToJsonV40 ( < option > ); Please check the API documentation in lib/<converter>/index.js for documentation about the parameters of the converter.","title":"Installation for API usage"},{"location":"apis/edm-converters/#console-usage","text":"All converters follow the following pattern convert_edm <converter> <file to be converted> <further arguments> Note: Currently absolute path as well as relative path to your model is supported. Currently the converters edmxV20ToJsonV40 and edmxV40ToJsonV40 are supported. Common sample arguments are: -i, --input <file to be converted> Input file to be converted --inputdir <input directory> Containing the source files, if is relative -o, --output <output file> Target file to be generated --outputdir <output directory> Output directory, if target file is relative or more files are generated -l, --loglevel Use 'e'/'i'(default)/'d' to show log information (e=error-log, i=info-log ,d=debug-log) -t, --target Omit or set to 'cs02' to produce the Oasis CSDL 4.01-CS02 format; if the Oasis CSDL Json 4.01-CS01 format should be produced, set to 'cs01'. The CS01 format can be used as the EDM JSON to bootstrap the Okra library. Converters may have additional options. Please see below on how to show documentation about this converters.","title":"Console usage"},{"location":"apis/edm-converters/#get-help","text":"","title":"Get help"},{"location":"apis/edm-converters/#get-console-help","text":"convert_edm --help","title":"Get console help:"},{"location":"apis/edm-converters/#get-distinct-converter-help","text":"convert_edm edmxV40ToJsonV40 --help","title":"Get distinct converter help:"},{"location":"apis/edm-converters/#releases-and-milestones","text":"Changelog","title":"Releases and Milestones"},{"location":"apis/edm-converters/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Unreleased \u00b6 [1.0.30] - 2020-05-19 \u00b6 Fixed \u00b6 Added fix to link enum Types to property in entity sets for V4. [1.0.29] - 2020-05-08 \u00b6 [1.0.27] - 2020-05-07 \u00b6 [1.0.26] - 2020-05-05 \u00b6 Fixed \u00b6 Added fix for several missing entity sets which are stemming from the same entity For Mock Server Use Case V4. Added \u00b6 support for node.js version 12 Removed \u00b6 support for node.js versions 6 and 8 due to their end of life [1.0.21] - 2019-09-17 \u00b6 Fixed \u00b6 Added fix for entities having more than one navigation property. Now all navigation property bindings are rendered correctly in OData V4 output (before only the last was added to the output). [2.0.0] - 2019-09-13 \u00b6 Added \u00b6 CSN Generation For Mock Server Use Case V2. [1.0.3] - 2019-03-29 \u00b6 Fixed \u00b6 CSN Generation Fixes For Mock Server Use Case V4. [1.0.1] - 2019-03-21 \u00b6 [1.0.0] - 2019-03-08 \u00b6 Added \u00b6 EDMXV4 to EDMV4 JSON Converter EDMV4 JSON to CSN Converter EDMXV2 to EDMV4 JSON Converter EDMXV2 to CSN Converter [0.0.18] - 2019-03-07 \u00b6 Test Release. Not for productive usage \u00b6 [0.0.17] - 2019-03-06 \u00b6 Test Release. Not for productive usage \u00b6 [0.0.16] - 2019-03-06 \u00b6 Added \u00b6 Add new -t,--target option to produce OData Node.js csdl json custom format Changed \u00b6 Remove Temporal vocabulary from autoloading Improve error message if XML elements can't be resolved Change generated $Collection = 'true' to true boolean for functions generated from function imports $Nullable is not set on NavigationProperty collections anymore. Improve error message if XML elements can't be resolved Change generated $Collection = 'true' to true boolean for functions generated from function imports [0.0.15] - 2018-12-12 \u00b6 Added \u00b6 OData V2-XML to OData V4-JSON converter - Add $Collection to EntitySets [0.0.14] - 2018-11-30 \u00b6 [0.0.13] - 2018-11-30 \u00b6 Test Release. Not for productive usage \u00b6 [0.0.12] - 2018-11-29 \u00b6 Added \u00b6 Autoloading for oasis default vocabularies Add following changes: Remove $Kind from EntityContainer EntitySets,Singletons and add $Collection to EntitySets See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1231 V4 Converter Now a missing referenced document does not break the processing On execution end there is a new callback parameter providing all missing referenced documents and corresponding uris Removed \u00b6 Change output conversion of Constant Expressions (will be provided later): See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1221 [0.0.11] - 2018-11-06 \u00b6 [0.0.10] - 2018-11-06 \u00b6 [0.0.9] - 2018-11-06 \u00b6 Changed \u00b6 Change output conversion of Constant Expressions See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1221 Remove $Kind from EntityContainer entities See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1231 [0.0.8] - 2018-10-18 \u00b6 [0.0.7] - 2018-10-16 \u00b6 [0.0.6] - 2018-10-16 \u00b6 [0.0.5] - 2018-09-27 \u00b6 [0.0.4] - 2018-09-25 \u00b6 [0.0.3] - 2018-09-13 \u00b6 [0.0.2] - 2018-08-22 \u00b6 Added \u00b6 Release version 0.0.1 (alpha version)","title":"Change Log"},{"location":"apis/edm-converters/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/edm-converters/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"apis/edm-converters/CHANGELOG/#1030-2020-05-19","text":"","title":"[1.0.30] - 2020-05-19"},{"location":"apis/edm-converters/CHANGELOG/#fixed","text":"Added fix to link enum Types to property in entity sets for V4.","title":"Fixed"},{"location":"apis/edm-converters/CHANGELOG/#1029-2020-05-08","text":"","title":"[1.0.29] - 2020-05-08"},{"location":"apis/edm-converters/CHANGELOG/#1027-2020-05-07","text":"","title":"[1.0.27] - 2020-05-07"},{"location":"apis/edm-converters/CHANGELOG/#1026-2020-05-05","text":"","title":"[1.0.26] - 2020-05-05"},{"location":"apis/edm-converters/CHANGELOG/#fixed_1","text":"Added fix for several missing entity sets which are stemming from the same entity For Mock Server Use Case V4.","title":"Fixed"},{"location":"apis/edm-converters/CHANGELOG/#added","text":"support for node.js version 12","title":"Added"},{"location":"apis/edm-converters/CHANGELOG/#removed","text":"support for node.js versions 6 and 8 due to their end of life","title":"Removed"},{"location":"apis/edm-converters/CHANGELOG/#1021-2019-09-17","text":"","title":"[1.0.21] - 2019-09-17"},{"location":"apis/edm-converters/CHANGELOG/#fixed_2","text":"Added fix for entities having more than one navigation property. Now all navigation property bindings are rendered correctly in OData V4 output (before only the last was added to the output).","title":"Fixed"},{"location":"apis/edm-converters/CHANGELOG/#200-2019-09-13","text":"","title":"[2.0.0] - 2019-09-13"},{"location":"apis/edm-converters/CHANGELOG/#added_1","text":"CSN Generation For Mock Server Use Case V2.","title":"Added"},{"location":"apis/edm-converters/CHANGELOG/#103-2019-03-29","text":"","title":"[1.0.3] - 2019-03-29"},{"location":"apis/edm-converters/CHANGELOG/#fixed_3","text":"CSN Generation Fixes For Mock Server Use Case V4.","title":"Fixed"},{"location":"apis/edm-converters/CHANGELOG/#101-2019-03-21","text":"","title":"[1.0.1] - 2019-03-21"},{"location":"apis/edm-converters/CHANGELOG/#100-2019-03-08","text":"","title":"[1.0.0] - 2019-03-08"},{"location":"apis/edm-converters/CHANGELOG/#added_2","text":"EDMXV4 to EDMV4 JSON Converter EDMV4 JSON to CSN Converter EDMXV2 to EDMV4 JSON Converter EDMXV2 to CSN Converter","title":"Added"},{"location":"apis/edm-converters/CHANGELOG/#0018-2019-03-07","text":"","title":"[0.0.18] - 2019-03-07"},{"location":"apis/edm-converters/CHANGELOG/#test-release-not-for-productive-usage","text":"","title":"Test Release. Not for productive usage"},{"location":"apis/edm-converters/CHANGELOG/#0017-2019-03-06","text":"","title":"[0.0.17] - 2019-03-06"},{"location":"apis/edm-converters/CHANGELOG/#test-release-not-for-productive-usage_1","text":"","title":"Test Release. Not for productive usage"},{"location":"apis/edm-converters/CHANGELOG/#0016-2019-03-06","text":"","title":"[0.0.16] - 2019-03-06"},{"location":"apis/edm-converters/CHANGELOG/#added_3","text":"Add new -t,--target option to produce OData Node.js csdl json custom format","title":"Added"},{"location":"apis/edm-converters/CHANGELOG/#changed","text":"Remove Temporal vocabulary from autoloading Improve error message if XML elements can't be resolved Change generated $Collection = 'true' to true boolean for functions generated from function imports $Nullable is not set on NavigationProperty collections anymore. Improve error message if XML elements can't be resolved Change generated $Collection = 'true' to true boolean for functions generated from function imports","title":"Changed"},{"location":"apis/edm-converters/CHANGELOG/#0015-2018-12-12","text":"","title":"[0.0.15] - 2018-12-12"},{"location":"apis/edm-converters/CHANGELOG/#added_4","text":"OData V2-XML to OData V4-JSON converter - Add $Collection to EntitySets","title":"Added"},{"location":"apis/edm-converters/CHANGELOG/#0014-2018-11-30","text":"","title":"[0.0.14] - 2018-11-30"},{"location":"apis/edm-converters/CHANGELOG/#0013-2018-11-30","text":"","title":"[0.0.13] - 2018-11-30"},{"location":"apis/edm-converters/CHANGELOG/#test-release-not-for-productive-usage_2","text":"","title":"Test Release. Not for productive usage"},{"location":"apis/edm-converters/CHANGELOG/#0012-2018-11-29","text":"","title":"[0.0.12] - 2018-11-29"},{"location":"apis/edm-converters/CHANGELOG/#added_5","text":"Autoloading for oasis default vocabularies Add following changes: Remove $Kind from EntityContainer EntitySets,Singletons and add $Collection to EntitySets See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1231 V4 Converter Now a missing referenced document does not break the processing On execution end there is a new callback parameter providing all missing referenced documents and corresponding uris","title":"Added"},{"location":"apis/edm-converters/CHANGELOG/#removed_1","text":"Change output conversion of Constant Expressions (will be provided later): See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1221","title":"Removed"},{"location":"apis/edm-converters/CHANGELOG/#0011-2018-11-06","text":"","title":"[0.0.11] - 2018-11-06"},{"location":"apis/edm-converters/CHANGELOG/#0010-2018-11-06","text":"","title":"[0.0.10] - 2018-11-06"},{"location":"apis/edm-converters/CHANGELOG/#009-2018-11-06","text":"","title":"[0.0.9] - 2018-11-06"},{"location":"apis/edm-converters/CHANGELOG/#changed_1","text":"Change output conversion of Constant Expressions See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1221 Remove $Kind from EntityContainer entities See OASIS Issue: https://issues.oasis-open.org/browse/ODATA-1231","title":"Changed"},{"location":"apis/edm-converters/CHANGELOG/#008-2018-10-18","text":"","title":"[0.0.8] - 2018-10-18"},{"location":"apis/edm-converters/CHANGELOG/#007-2018-10-16","text":"","title":"[0.0.7] - 2018-10-16"},{"location":"apis/edm-converters/CHANGELOG/#006-2018-10-16","text":"","title":"[0.0.6] - 2018-10-16"},{"location":"apis/edm-converters/CHANGELOG/#005-2018-09-27","text":"","title":"[0.0.5] - 2018-09-27"},{"location":"apis/edm-converters/CHANGELOG/#004-2018-09-25","text":"","title":"[0.0.4] - 2018-09-25"},{"location":"apis/edm-converters/CHANGELOG/#003-2018-09-13","text":"","title":"[0.0.3] - 2018-09-13"},{"location":"apis/edm-converters/CHANGELOG/#002-2018-08-22","text":"","title":"[0.0.2] - 2018-08-22"},{"location":"apis/edm-converters/CHANGELOG/#added_6","text":"Release version 0.0.1 (alpha version)","title":"Added"},{"location":"apis/edmx2csn/","text":"Getting started \u00b6 Table of Contents \u00b6 Overview Installation Usage Constraints Overview \u00b6 EDMX2CSN is a command line utility that will convert an OData V2 model (EDMX) to a CSN (JSON) file. The primary use case for this utility is when you're building an extension application that connects to a remote OData V2 data source such as S4HANA. In such a case, converting the EDMX model from the OData V2 data source to CSN is the first step you take, along with defining the CDS data model, in order to define the CDS service model for your application. Installation \u00b6 Install the EDMX2CSN utility from one of the following repositories: Nexus milestones registry or npm registry: npm config set registry <local nexus milestone or https://registry.npmjs.org/> or releases registry: npm config set registry <local nexus release or https://registry.npmjs.org/> Do not add direct dependency to edmx2csn github project! npm does not support snapshots via nexus. The only possibility is to download manually a snapshot and install it. Install the EDMX2CSN utility using npm: npm install \"@sap/edmx2csn\" As an alternative to step 2, maintain your package.json dependencies as follows: package.json \"dependencies\": { \"@sap/edmx2csn\": \"*\" } Usage \u00b6 The compiler with its options is invoked like any other npm/Unix command: To generate CSN file from an EDMX File: a) Windows: $homedir >./node_modules/.bin/edmx2csn.cmd -i ${ input_folder } /metadata.xml -o ${ output_folder } -f b) Linux: $homedir >./node_modules/.bin/edmx2csn.sh -i ${ input_folder } /metadata.xml -o ${ output_folder } -f To generate CSN file from an EDMX URL: a) Windows: $homedir >./node_modules/.bin/edmx2csn.cmd -i ${ service_url } / $metadata -o ${ output_folder } b) Linux: $homedir >./node_modules/.bin/edmx2csn.sh -i ${ service_url } / $metadata -o ${ output_folder } Constraints \u00b6 1) Supports only OData V2 services. 2) Supports only publicly available OData service URLs (for example, http://services.odata.org/V2/OData/OData.svc/$metadata). 3) Multiple schemas are not supported (for example, http://services.odata.org/V2/Northwind/Northwind.svc/$metadata). 4) Function imports in EDMX are not supported.","title":"Getting started"},{"location":"apis/edmx2csn/#getting-started","text":"","title":"Getting started"},{"location":"apis/edmx2csn/#table-of-contents","text":"Overview Installation Usage Constraints","title":"Table of Contents"},{"location":"apis/edmx2csn/#overview","text":"EDMX2CSN is a command line utility that will convert an OData V2 model (EDMX) to a CSN (JSON) file. The primary use case for this utility is when you're building an extension application that connects to a remote OData V2 data source such as S4HANA. In such a case, converting the EDMX model from the OData V2 data source to CSN is the first step you take, along with defining the CDS data model, in order to define the CDS service model for your application.","title":"Overview"},{"location":"apis/edmx2csn/#installation","text":"Install the EDMX2CSN utility from one of the following repositories: Nexus milestones registry or npm registry: npm config set registry <local nexus milestone or https://registry.npmjs.org/> or releases registry: npm config set registry <local nexus release or https://registry.npmjs.org/> Do not add direct dependency to edmx2csn github project! npm does not support snapshots via nexus. The only possibility is to download manually a snapshot and install it. Install the EDMX2CSN utility using npm: npm install \"@sap/edmx2csn\" As an alternative to step 2, maintain your package.json dependencies as follows: package.json \"dependencies\": { \"@sap/edmx2csn\": \"*\" }","title":"Installation"},{"location":"apis/edmx2csn/#usage","text":"The compiler with its options is invoked like any other npm/Unix command: To generate CSN file from an EDMX File: a) Windows: $homedir >./node_modules/.bin/edmx2csn.cmd -i ${ input_folder } /metadata.xml -o ${ output_folder } -f b) Linux: $homedir >./node_modules/.bin/edmx2csn.sh -i ${ input_folder } /metadata.xml -o ${ output_folder } -f To generate CSN file from an EDMX URL: a) Windows: $homedir >./node_modules/.bin/edmx2csn.cmd -i ${ service_url } / $metadata -o ${ output_folder } b) Linux: $homedir >./node_modules/.bin/edmx2csn.sh -i ${ service_url } / $metadata -o ${ output_folder }","title":"Usage"},{"location":"apis/edmx2csn/#constraints","text":"1) Supports only OData V2 services. 2) Supports only publicly available OData service URLs (for example, http://services.odata.org/V2/OData/OData.svc/$metadata). 3) Multiple schemas are not supported (for example, http://services.odata.org/V2/Northwind/Northwind.svc/$metadata). 4) Function imports in EDMX are not supported.","title":"Constraints"},{"location":"apis/edmx2csn/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Unreleased \u00b6 [1.0.9] - 2020-03-17 \u00b6 [1.0.8] - 2019-08-16 \u00b6 Fixed \u00b6 Fixed an issue with version tag in CSN. [1.0.7] - 2019-08-05 \u00b6 Fixed \u00b6 Fixed an issue to pick the Cardinality when Association and AssociatioSet Name are different. Added version tag. [1.0.6] - 2018-12-04 \u00b6 Fixed \u00b6 Renamed the attribute targetMax to max . Replaced the CSN syntax onCond used in associations with on . [1.0.5] - 2018-10-03 \u00b6 Fixed \u00b6 Edm.DateTimeOffset is now mapped to Date for any property having the attribute sap:display-format=\"Date\" . Errors generated from this tool is now propagated back to the system process that invokes this tool. [1.0.4] - 2018-09-24 \u00b6 Fixed \u00b6 Edm.single is now mapped to DecimalFloat in the HANA database. Fixed an issue when mapping navigation in the OData model to onCond in the CSN model. New option -p has been added to ignore @cds.persistence.skip annotation specified on any entity in the model. [1.0.3] - 2018-08-20 \u00b6 Fixed \u00b6 Modified open source dependency to a specific version. [1.0.2] - 2018-08-13 \u00b6 Fixed \u00b6 Converts inherited complex types and entities from the OData model to CSN equivalent. [1.0.1] - 2018-05-30 \u00b6 Added \u00b6 The annotation @cds.persistence.skip:true is added for all entities in the converted CSN file. [1.0.0] - 2018-05-02 \u00b6 Added \u00b6 Performs basic OData V2 metadata validation Converts OData V2 entities/properties to CSN entities/elements Converts OData V2 complex types to CSN structures Converts OData V2 entity navigations to CSN associations","title":"Change Log"},{"location":"apis/edmx2csn/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/edmx2csn/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"apis/edmx2csn/CHANGELOG/#109-2020-03-17","text":"","title":"[1.0.9] - 2020-03-17"},{"location":"apis/edmx2csn/CHANGELOG/#108-2019-08-16","text":"","title":"[1.0.8] - 2019-08-16"},{"location":"apis/edmx2csn/CHANGELOG/#fixed","text":"Fixed an issue with version tag in CSN.","title":"Fixed"},{"location":"apis/edmx2csn/CHANGELOG/#107-2019-08-05","text":"","title":"[1.0.7] - 2019-08-05"},{"location":"apis/edmx2csn/CHANGELOG/#fixed_1","text":"Fixed an issue to pick the Cardinality when Association and AssociatioSet Name are different. Added version tag.","title":"Fixed"},{"location":"apis/edmx2csn/CHANGELOG/#106-2018-12-04","text":"","title":"[1.0.6] - 2018-12-04"},{"location":"apis/edmx2csn/CHANGELOG/#fixed_2","text":"Renamed the attribute targetMax to max . Replaced the CSN syntax onCond used in associations with on .","title":"Fixed"},{"location":"apis/edmx2csn/CHANGELOG/#105-2018-10-03","text":"","title":"[1.0.5] - 2018-10-03"},{"location":"apis/edmx2csn/CHANGELOG/#fixed_3","text":"Edm.DateTimeOffset is now mapped to Date for any property having the attribute sap:display-format=\"Date\" . Errors generated from this tool is now propagated back to the system process that invokes this tool.","title":"Fixed"},{"location":"apis/edmx2csn/CHANGELOG/#104-2018-09-24","text":"","title":"[1.0.4] - 2018-09-24"},{"location":"apis/edmx2csn/CHANGELOG/#fixed_4","text":"Edm.single is now mapped to DecimalFloat in the HANA database. Fixed an issue when mapping navigation in the OData model to onCond in the CSN model. New option -p has been added to ignore @cds.persistence.skip annotation specified on any entity in the model.","title":"Fixed"},{"location":"apis/edmx2csn/CHANGELOG/#103-2018-08-20","text":"","title":"[1.0.3] - 2018-08-20"},{"location":"apis/edmx2csn/CHANGELOG/#fixed_5","text":"Modified open source dependency to a specific version.","title":"Fixed"},{"location":"apis/edmx2csn/CHANGELOG/#102-2018-08-13","text":"","title":"[1.0.2] - 2018-08-13"},{"location":"apis/edmx2csn/CHANGELOG/#fixed_6","text":"Converts inherited complex types and entities from the OData model to CSN equivalent.","title":"Fixed"},{"location":"apis/edmx2csn/CHANGELOG/#101-2018-05-30","text":"","title":"[1.0.1] - 2018-05-30"},{"location":"apis/edmx2csn/CHANGELOG/#added","text":"The annotation @cds.persistence.skip:true is added for all entities in the converted CSN file.","title":"Added"},{"location":"apis/edmx2csn/CHANGELOG/#100-2018-05-02","text":"","title":"[1.0.0] - 2018-05-02"},{"location":"apis/edmx2csn/CHANGELOG/#added_1","text":"Performs basic OData V2 metadata validation Converts OData V2 entities/properties to CSN entities/elements Converts OData V2 complex types to CSN structures Converts OData V2 entity navigations to CSN associations","title":"Added"},{"location":"apis/eslint-plugin-webide-feature/","text":"ESLint plugin for SAP Web IDE features \u00b6 Table of contents \u00b6 Overview Usage List of rules Overview \u00b6 This is the eslint plugin for Web IDE features. It contains a set of eslint rules and recommended ESLint configuration for static code checks to be used by Web IDE feature developers. Usage \u00b6 Add linting to tests \u00b6 To add this package as a dependency in your package.json file, do the following: Under the \"scripts\" section, add: \"lint\": \"eslint src\" Under the \"scripts\" section, add: \"npm run lint\" to the test section: \"test\": \"npm run lint && ...\" Under the \"devDependencies\" section, add the following dependency: \"@sap/eslint-plugin-webide-feature\": \"a.b.c\" Add .eslintrc.json file with the following content: { \"plugins\" : [ \"@sap/webide-feature\" ], \"extends\" : \"plugin:@sap/webide-feature/recommended-internal\" } The linting checks will be executed as part of tests. Please note that each version of this ESLint plugin corresponds to certain version of SAP Web IDE. As cloud version of SAP Web IDE is continiously updated it is strongly recommended to update the version of this plugin as soon as it is released. To update your feature to use the latest version of ESLint plugin, run: npm install --save-exact @sap/eslint-plugin-webide-feature@latest Fix existing lint issues \u00b6 After you have added linting, please execute it with npm run lint . Do not worry if you see lots of warnings and errors most of the can be fixed automatically with --fix option of ESLint , by running node_modules/.bin/eslint src --fix . Remaining issues can be fixed manually or ignored by using special comments or overrding recommended configuration values . To fix the issues manually please refer to the documentation of specific rule. List of rules \u00b6 Rule Description Recommended Severity no-private-methods Do not invoke private methods Error no-private-apis Do not invoke private methods Warning bundled-uris-valid \"bundledPlugins\" and \"bundledFeatures\" arrays items must start with \"file:\" and have valid uri Error no-deprecated-fields package.json file should contain neither deprecatedPluginExtensions nor deprecatedConfigIncludes fields Warning feature-description-valid package.json file must contain description field Warning homepage-url-valid package.json file must contain a homepage field with a valid path Warning package-json-exists package.json file must exist in feature's root folder Error consistent-ids each package.json and plugin.json file must has consistent ids Error feature-name-valid package.json file must contain name field Error no-optional-features package.json file must not contain optionalBundledFeatures field Error feature-author-valid package.json file must contain an author field with name and icon Warning feature-version-valid package.json file must contain a version field Error webide-dependencies-consistent \"webideDependencies\" section should be declared properly Error plugin-name-valid plugin.json file must contain name field Error plugin-provides-valid service and interface file references in \"plugin.json\" file must be valid Error no-unused-required-services All required services of a plugin must be in use Warning valid-json-files All JSON files in a feature must be valid Error","title":"ESLint plugin for SAP Web IDE features"},{"location":"apis/eslint-plugin-webide-feature/#eslint-plugin-for-sap-web-ide-features","text":"","title":"ESLint plugin for SAP Web IDE features"},{"location":"apis/eslint-plugin-webide-feature/#table-of-contents","text":"Overview Usage List of rules","title":"Table of contents"},{"location":"apis/eslint-plugin-webide-feature/#overview","text":"This is the eslint plugin for Web IDE features. It contains a set of eslint rules and recommended ESLint configuration for static code checks to be used by Web IDE feature developers.","title":"Overview"},{"location":"apis/eslint-plugin-webide-feature/#usage","text":"","title":"Usage"},{"location":"apis/eslint-plugin-webide-feature/#add-linting-to-tests","text":"To add this package as a dependency in your package.json file, do the following: Under the \"scripts\" section, add: \"lint\": \"eslint src\" Under the \"scripts\" section, add: \"npm run lint\" to the test section: \"test\": \"npm run lint && ...\" Under the \"devDependencies\" section, add the following dependency: \"@sap/eslint-plugin-webide-feature\": \"a.b.c\" Add .eslintrc.json file with the following content: { \"plugins\" : [ \"@sap/webide-feature\" ], \"extends\" : \"plugin:@sap/webide-feature/recommended-internal\" } The linting checks will be executed as part of tests. Please note that each version of this ESLint plugin corresponds to certain version of SAP Web IDE. As cloud version of SAP Web IDE is continiously updated it is strongly recommended to update the version of this plugin as soon as it is released. To update your feature to use the latest version of ESLint plugin, run: npm install --save-exact @sap/eslint-plugin-webide-feature@latest","title":"Add linting to tests"},{"location":"apis/eslint-plugin-webide-feature/#fix-existing-lint-issues","text":"After you have added linting, please execute it with npm run lint . Do not worry if you see lots of warnings and errors most of the can be fixed automatically with --fix option of ESLint , by running node_modules/.bin/eslint src --fix . Remaining issues can be fixed manually or ignored by using special comments or overrding recommended configuration values . To fix the issues manually please refer to the documentation of specific rule.","title":"Fix existing lint issues"},{"location":"apis/eslint-plugin-webide-feature/#list-of-rules","text":"Rule Description Recommended Severity no-private-methods Do not invoke private methods Error no-private-apis Do not invoke private methods Warning bundled-uris-valid \"bundledPlugins\" and \"bundledFeatures\" arrays items must start with \"file:\" and have valid uri Error no-deprecated-fields package.json file should contain neither deprecatedPluginExtensions nor deprecatedConfigIncludes fields Warning feature-description-valid package.json file must contain description field Warning homepage-url-valid package.json file must contain a homepage field with a valid path Warning package-json-exists package.json file must exist in feature's root folder Error consistent-ids each package.json and plugin.json file must has consistent ids Error feature-name-valid package.json file must contain name field Error no-optional-features package.json file must not contain optionalBundledFeatures field Error feature-author-valid package.json file must contain an author field with name and icon Warning feature-version-valid package.json file must contain a version field Error webide-dependencies-consistent \"webideDependencies\" section should be declared properly Error plugin-name-valid plugin.json file must contain name field Error plugin-provides-valid service and interface file references in \"plugin.json\" file must be valid Error no-unused-required-services All required services of a plugin must be in use Warning valid-json-files All JSON files in a feature must be valid Error","title":"List of rules"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/","text":"Changelog for Eslint Plugin Web IDE Feature \u00b6 All notable changes to this project will be documented in this file. 1.3.22 - 14/03/2019 \u00b6 Added \u00b6 Added support for service aliases. 1.3.21 - 28/11/2018 \u00b6 Fixed \u00b6 The rule \"no-private-apis\" was fixed to show errors when service is private and uses a method. 1.3.20 - 25/11/2018 \u00b6 Fixed \u00b6 The rule \"plugin-provides-valid\" was fixed to reduce the number of false positive warnings 1.3.19 - 28/10/2018 \u00b6 Fixed \u00b6 The rule \"no-private-apis\" was fixed to reduce the number of false positive warnings 1.3.17 - 14/08/2018 \u00b6 Fixed \u00b6 Fixed relative url in configs files. 1.3.16 - 09/08/2018 \u00b6 Added \u00b6 Added recommended-new.json - only webide-eslint related checks 1.3.15 - 26/04/2018 \u00b6 Updated \u00b6 Update package version. 1.3.14 - 26/04/2018 \u00b6 Updated \u00b6 Update Web IDE package version in dev-dependencies. 1.3.13 - 28/02/2018 \u00b6 Fixed \u00b6 The rule \"no-private-apis\" reports errors with empty service name: 'error The \"\" service is a \"private\" service'. The rule \"no-private-methods\" crashes with error: \"Cannot read property 'startsWith' of undefined\". The rule \"feature-description-valid\" severity has changed from \"error\" to \"warn\". The rule \"unicorn/prefer-starts-ends-with\" is turned off. 1.3.12 - 15/02/2018 \u00b6 Added \u00b6 Added recommended-internal.json - the recommended rules configuration for internal webide feature developers. Fixed \u00b6 Tied the SDK version used by no-private-apis rule to the latest Web IDE version. 1.3.7 - 31/01/2018 \u00b6 Fixed \u00b6 Fixed bundled-uris-valid - added validity checks for more use cases (for example, uris with white spaces) Fixed consistent-ids - fixed consistency check of bundled features ids Fixed no-unused-required-services - added check for not used required services (via oContext.service and not via this.context.service) Fixed handling of ignored paths Formatting rules were excluded from recommended config 1.3.4 - 16/01/2018 \u00b6 Added \u00b6 Added no-private-apis to rules library Added bundled-uris-valid to rules library Added no-deprecated-fields to rules library Added homepage-url-valid to rules library Added consistent-ids to rules library Added no-optional-features to rules library Added feature-author-valid to rules library Added webide-dependencies-consistent to rules library Added plugin-name-valid to rules library Added plugin-provides-valid to rules library Added valid-json-files to rules library Added no-unused-required-services to rules library Removed \u00b6 Removed plugin-path from rules library Removed requires-services from rules library Renamed \u00b6 Renamed packagejson-description to feature-description-valid in rules library Renamed packagejson-exists to package-json-exists in rules library Renamed packagejson-name to feature-name-valid in rules library Renamed packagejson-version to feature-version-valid in rules library Fixed \u00b6 Problem with \"Unused required service\" rule - dot service names services/methods implemented within my feature are all flagged as private .eslintignore not working good with linter 1.2.3 - 20/12/2017 \u00b6 This is the initial version of Eslint Plugin Web IDE Feature. It contains a set of eslint rules for static code checks to be used by Web IDE feature developers. Added \u00b6 Added no-private-methods to rules library Added packagejson-description to rules library Added packagejson-exists to rules library Added packagejson-name to rules library Added packagejson-version to rules library Added plugin-path to rules library Added requires-services to rules library","title":"Changelog for Eslint Plugin Web IDE Feature"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#changelog-for-eslint-plugin-web-ide-feature","text":"All notable changes to this project will be documented in this file.","title":"Changelog for Eslint Plugin Web IDE Feature"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1322-14032019","text":"","title":"1.3.22 - 14/03/2019"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#added","text":"Added support for service aliases.","title":"Added"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1321-28112018","text":"","title":"1.3.21 - 28/11/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed","text":"The rule \"no-private-apis\" was fixed to show errors when service is private and uses a method.","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1320-25112018","text":"","title":"1.3.20 - 25/11/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed_1","text":"The rule \"plugin-provides-valid\" was fixed to reduce the number of false positive warnings","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1319-28102018","text":"","title":"1.3.19 - 28/10/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed_2","text":"The rule \"no-private-apis\" was fixed to reduce the number of false positive warnings","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1317-14082018","text":"","title":"1.3.17 - 14/08/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed_3","text":"Fixed relative url in configs files.","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1316-09082018","text":"","title":"1.3.16 - 09/08/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#added_1","text":"Added recommended-new.json - only webide-eslint related checks","title":"Added"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1315-26042018","text":"","title":"1.3.15 - 26/04/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#updated","text":"Update package version.","title":"Updated"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1314-26042018","text":"","title":"1.3.14 - 26/04/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#updated_1","text":"Update Web IDE package version in dev-dependencies.","title":"Updated"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1313-28022018","text":"","title":"1.3.13 - 28/02/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed_4","text":"The rule \"no-private-apis\" reports errors with empty service name: 'error The \"\" service is a \"private\" service'. The rule \"no-private-methods\" crashes with error: \"Cannot read property 'startsWith' of undefined\". The rule \"feature-description-valid\" severity has changed from \"error\" to \"warn\". The rule \"unicorn/prefer-starts-ends-with\" is turned off.","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#1312-15022018","text":"","title":"1.3.12 - 15/02/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#added_2","text":"Added recommended-internal.json - the recommended rules configuration for internal webide feature developers.","title":"Added"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed_5","text":"Tied the SDK version used by no-private-apis rule to the latest Web IDE version.","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#137-31012018","text":"","title":"1.3.7 - 31/01/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed_6","text":"Fixed bundled-uris-valid - added validity checks for more use cases (for example, uris with white spaces) Fixed consistent-ids - fixed consistency check of bundled features ids Fixed no-unused-required-services - added check for not used required services (via oContext.service and not via this.context.service) Fixed handling of ignored paths Formatting rules were excluded from recommended config","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#134-16012018","text":"","title":"1.3.4 - 16/01/2018"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#added_3","text":"Added no-private-apis to rules library Added bundled-uris-valid to rules library Added no-deprecated-fields to rules library Added homepage-url-valid to rules library Added consistent-ids to rules library Added no-optional-features to rules library Added feature-author-valid to rules library Added webide-dependencies-consistent to rules library Added plugin-name-valid to rules library Added plugin-provides-valid to rules library Added valid-json-files to rules library Added no-unused-required-services to rules library","title":"Added"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#removed","text":"Removed plugin-path from rules library Removed requires-services from rules library","title":"Removed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#renamed","text":"Renamed packagejson-description to feature-description-valid in rules library Renamed packagejson-exists to package-json-exists in rules library Renamed packagejson-name to feature-name-valid in rules library Renamed packagejson-version to feature-version-valid in rules library","title":"Renamed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#fixed_7","text":"Problem with \"Unused required service\" rule - dot service names services/methods implemented within my feature are all flagged as private .eslintignore not working good with linter","title":"Fixed"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#123-20122017","text":"This is the initial version of Eslint Plugin Web IDE Feature. It contains a set of eslint rules for static code checks to be used by Web IDE feature developers.","title":"1.2.3 - 20/12/2017"},{"location":"apis/eslint-plugin-webide-feature/CHANGELOG/#added_4","text":"Added no-private-methods to rules library Added packagejson-description to rules library Added packagejson-exists to rules library Added packagejson-name to rules library Added packagejson-version to rules library Added plugin-path to rules library Added requires-services to rules library","title":"Added"},{"location":"apis/faas/","text":"@sap/faas \u00b6 Provides the SAP Cloud Platform Functions runtime for Node.js and basic SDK features. Table of contents \u00b6 Overview Package Install Service Instances Naming Rules Function Projects Project Attributes Secrets and Config Maps Service References Functions Function Triggers HTTP Timer AMQP CloudEvents Function Runtime API Global Variables Handler Exceptions Handler Parameter: event Handler Parameter: context Function Test Function Debugging Function Unit Test Overview \u00b6 SAP Cloud Platform Functions are provided as a service ( FaaS ). Developers can focus on pure application logic while writing the code, whereas FaaS takes responsibility to run the code in a secure, reliable and cost-efficient way. Technically, FaaS runs on Kubernetes ( K8s ). Artifact deployments are managed using a service API, also running in K8s, next to the runtime of course. The overall architecture would allow integration of different serverless runtimes. However, currently K8s is used. In Cloud Foundry ( CF ) service xsf-runtime (Extension Factory, serverless runtime) is used as entry point. Each service instance represents a K8s namespace in a shared cluster. All artifacts deployed to a given service will end up as resource in the corresponding namespace. K8s namespaces (Faas tenants) are strictly isolated from each other. Function development is based on projects, using file faas.json as manifest. Any local IDE as well as WebIDE (Wing) can be used for implementation. Package \u00b6 This package comprises two functional parts. First, it provides the function runtime for Node.js (version 8.11.3 or higher): * runtime components as such * http server to run (or debug) functions locally * test runner to support function unit tests Secondly, it offers basic SDK functionality by installing command faas-sdk : * check project consistency * create and test deployment files ( values.yaml ) The function code is provided with usual js files. 'use strict' ; /** * @param {FaasEvent} event * @param {FaasContext} context * @return {Promise|*} */ module . exports = function ( event , context ) { const rval = context . getSecretValueJSON ( 'my-secret-1' , 'rv.json' ); return rval . Info . Success ; }; Different trigger types are supported to invoke functions under various conditions. Secrets provide an appropriate storage for credentials. Config maps can be used in addition for any further settings. Install \u00b6 There are two FaaS client tools, waiting to support local development: * faas-sdk : supports the development phase, checks project consistency, runs functions locally in a similar environments like in K8s , enables unit test implementation * faas-cli : used to manage artifact deployment into K8s , uses FaaS instances in the Cloud Foundry as entry point Let's start: * Install Node.js (version 8.11.3 or higher): * Download from https://nodejs.org/en/download/ * Install Node.js runtime * Test installation with node -v and npm -v * Add SAP NPM Registry to your npm configuration for all @sap scoped modules. * Run npm config set \"@sap:registry=https://npm.sap.com\" * Test installation with npm show @sap/faas version * Install faas-sdk : * Run npm install @sap/faas -g * Test installation with faas-sdk version * Install faas-cli : * Go to https://tools.hana.ondemand.com/#cloud * Search for \"SAP Cloud Platform Functions Tools\" * Install one binary, test via faas-cli version * Install Cloud Foundry CLI : * Download latest release: https://github.com/cloudfoundry/cli/releases * Install binaries, test via cf version Update the local IDE of your choice and install plugins for Node.js. Finally, enable language support for Node.js and JavaScript (ECMAScript 6): You may also find these links helpful: Javascript Reference and NodeJS Reference The natural home of a FaaS project is a git repository. Based on that you can later easily switch between local IDE and SAP Web IDE. In the long term FaaS runtime may also support knative builds, fetching project files directly from git. Hence, we recommend to set up a git repository for your project from the beginning. Naming Rules \u00b6 All runtime artifacts need a name that matches the following constraints: * Only lower case characters [a-z] and numbers [0-9] and - can be used. * Separator - must not appear at the begin or the end of the name. * Maximum length is restricted to 60 characters. This applies to: * secrets * config maps * service references * functions * triggers * project names and * project version identifiers Secret and config map keys (names of its entries) are usually based on file names. That's why it may contain . as well, but not at the beginning or the end. Function Projects \u00b6 We recommend using FaaS projects, as this simplifies development tasks. Each project is defined with just one file, called faas.json . Usually, it will reside next to a package.json file. A first project can easily be created with an empty folder and the following command: faas-sdk init -p ./my-test It will create a simple project with one function, one secret, one http trigger and simple unit tests. After npm install all unit tests, local test run and K8s deployment will work immediately. Continue with renaming artifacts and modifying the function code. A first example defines one single function build-qrcode . The source code is provided with file .\\lib\\iso-time.js . And the HTTP trigger build-qrcode will invoke the function. { \"project\" : \"qrcode-producer\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"build-qrcode\" : { \"module\" : \"iso-time.js\" } }, \"triggers\" : { \"build-qrcode\" : { \"type\" : \"HTTP\" , \"function\" : \"build-qrcode\" } } } A second example shows one project defining two functions, both implemented in the same module file. In this case the module file main.js exports two function handlers f1 and f2 . { \"project\" : \"chain\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"chain-func1\" : { \"module\" : \"main.js\" , \"handler\" : \"f1\" }, \"chain-func2\" : { \"module\" : \"main.js\" , \"handler\" : \"f2\" } }, \"triggers\" : { \"chain-simple\" : { \"type\" : \"HTTP\" , \"function\" : \"chain-func1\" } } } Project Attributes \u00b6 At the top level of faas.json the following fields can be defined: * project : used as label for all runtime artifacts (see restrictions to naming rules ) * version : used as label for all runtime artifacts (see restrictions to naming rules ) Specific to the runtime: * runtime : used to select the runtime, currently only nodejs8 is supported * library : base directory for all source code file references, just to reduce redundancy Runtime artifacts: * secrets : collection of secrets, used to store credentials, api keys and the like * configs : collection of config maps, used for less critical, configuration-like settings, that shall not be hard-coded * functions : collection of functions that this project defines * triggers : collection of triggers, different types with individual settings Each runtime artifact collection uses the object name as json key field. The name must be unique per artifact type in the scope of one K8s namespace (that is, service instance). For example: * Multiple namespaces may define their own secret test1 . * In one namespace there might be a function test1 and a secret test1 in parallel. * However, there will be only one secret test1 in one namespace at a time, even if two different projects are used to deploy it. No assumptions are made regarding the separation of projects. In particular, FaaS runtime will not prevent multiple projects from deploying any artifacts concurrently. Secrets and Config Maps \u00b6 Technically, secrets and config maps share the same structure. A local directory containing one or more files is used for declaration. All files together must not exceed a total size of 1Mb. { \"project\" : \"example\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"secrets\" : { \"sec1\" : { \"source\" : \"./data/sec1\" } }, \"configs\" : { \"cfg1\" : { \"source\" : \"./data/cfg1\" } } } In addition to the unique object name, for example, sec1 or cfg1 , only one attribute is required: * source : relative path to the data directory The data directory and its contained files define the data model and default values. As the files will most likely show up in a git repository you may wish to see placeholder values first, later replaced (dynamically) by valid credentials, for instance. Both tools, faas-sdk and faas-cli , support a simple mechanism for that: a deployment file with a predefined structure. Take this as an example: secret-values : sec1 : rv.json : Info : Success : Demo Failure : Todo Code : Success : A Failure : X text : Nice Test! Here, values are defined for secret sec1 , and its two files rv.json and text . For json or yaml files also single object attributes inside the file can be replaced. Arrays are handled as one value only. In the case of other files e.g. text or binary data, the whole file content can be replaced. To initialize such a deployment file based on specific secret definitions run inside the project: faas-sdk init-values -y values.yaml The command will search faas.json starting from the current working directory. Once found it will add the content of secret and config map files to the deployment file values.yaml . As no directory is specified it will be stored in folder deploy (to be ignored by git) next to faas.json . After adjusting the deployment file content you can start a local test run: faas-sdk run -y values.yaml And for cloud deployment it can be used as well: faas-cli project deploy -y ./deploy/values.yaml -s my-cf-service -k my-cf-service-key These deployment files can also be used to define mock data for function unit tests . Service References \u00b6 Besides the option to use secrets there is a more simple way to provide credentials of SAP CP platform services to functions or triggers. First, you can use the command line tool to transfer service keys to a secure store in the faas runtime: * Run cf login * Run faas-cli login * Run faas-cli service register -s <service-name> -b <service-key> To list all registered services (for your faas tenant, means service instance): * Run faas-cli service list Then you can define in your project a service reference, for example to an enterprise messaging instance: { \"services\" : { \"my-ems\" : { \"type\" : \"enterprise-messaging\" , \"instance\" : \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\" , \"key\" : \"xxx\" } } } Finally, use the alias my-ems inside faas.json at trigger definitions and/or within function code. The specific values of the reference can be provided with deploy values as well. Functions \u00b6 Let's start with an example again: { \"project\" : \"example\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"my-new-fnc\" : { \"module\" : \"index.js\" , \"handler\" : \"\" , \"secrets\" : [ \"sec-xbem\" , \"sec-ebaas\" ], \"configs\" : [], \"timeout\" : 180 , \"maxBody\" : \"1MiB\" } } } In addition to the unique object name my-new-fnc the following attributes can be provided: * module : source code file that exports the function handler (it may require other files of course) * handler : only needed if module.exports appears as an object where handler can be found as attribute * httpApi : indicates whether or not HTTP request and response are required by the function handler * secrets : array of secrets used by the function * configs : array of config maps used by the function * timeout : seconds the function can run, minimum between 10 and 180 seconds * maxBody : limit for body size (payload) of incoming requests provided to the function, default 1MiB The function handler may require built-in modules, further local module files or external packages. External dependencies (or devDependencies, for example for unit testing) are defined as usual in package.json . An important entry in devDependencies is @sap/faas . It allows the implementation of function unit tests. Furthermore, it offers type definitions that your local IDE may use for code proposals. { \"dependencies\" : { }, \"devDependencies\" : { \"@sap/faas\" : \">=0.7.6\" } } The function handler in file \u00ecndex.js may look like this: 'use strict' ; /** * @namespace Faas * @typedef {import(\"@sap/faas\").Faas.Event} Faas.Event * @typedef {import(\"@sap/faas\").Faas.Context} Faas.Context */ /** * @param {Faas.Event} event * @param {Faas.Context} context * @return {Promise<*>|*} */ module . exports = function ( event , context ) { const rval = context . getSecretValueJSON ( 'sec1' , 'rv.json' ); return rval . Info . Success ; }; Please note how jsdoc annotations are used to declare the types. With that IDE shall support you in finding methods and attributes of event and context while typing. Function Triggers \u00b6 Functions are invoked by triggers. A single function may be referenced by multiple trigger instances of different types. In principle a single trigger may also invoke different functions, e.g. an AMQP trigger with multiple rules. The following types are supported: * HTTP * Timer * AMQP * CloudEvents A first example shows how triggers are defined in principle within faas.json : { \"project\" : \"example\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"my-new-fnc\" : { \"module\" : \"index.js\" } }, \"triggers\" : { \"demo\" : { \"type\" : \"HTTP\" , \"function\" : \"my-fnc-01\" }, \"job1\" : { \"type\" : \"Timer\" , \"schedule\" : \"0/15 * * * *\" , \"function\" : \"my-fnc-02\" } } } Trigger demo will provide an HTTP endpoint. For each received HTTP request the function my-fnc-01 will be invoked. In parallel trigger job1 will call function my-fnc-02 each quarter of an hour. HTTP Trigger \u00b6 For each trigger instance an external HTTP endpoint will be created. Each incoming request will be forwarded to the function, except those for method 'OPTIONS'. The result of the function will be returned as response. Attributes : * function : the function to call Example : { \"triggers\" : { \"demo\" : { \"type\" : \"HTTP\" , \"function\" : \"my-new-fnc\" } } } Be aware that the endpoint is public visible. So far authentication/authorization has to be handled by the function code. It is planned to support automated oauth token validation in future. Timer Trigger \u00b6 A single Timer trigger defines a schedule, optionally with timezone to call a selected function. Different schedule formats are supported: simple duration every 1 minute and 30 seconds: 1m30s , every 15 seconds 15s , every 1 hour 30 minutes and 15 seconds: 1h30m15s cron expression, spec conform , 5 fields ``` \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday; 7 is also Sunday on some systems) \u2502 \u2502 \u2502 \u2502 \u2502 ``` cron expression, additional field for seconds, 6 fields ``` \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 second (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday; 7 is also Sunday on some systems) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ``` Together with cron expressions also a timezone can be of importance, typically when scheduling for hours. Valid timezone values follow Iana timezone database . Attributes : * schedule : duration or cron expression, which defines the execution interval * timezone : optional, timezone * function : the function to call Examples for schedule and timezone : schedule timezone execution 30s every 30 seconds, start immediately, 10:15:12, 10:15:42, 10:16:12 ... 1h30m every one and a half hour, 10:12:10, 11:42:10, 13:12:10, 14:42:10 ... 0 * * * * each full hour 0/15 * * * * each quarter of an hour 0/15 * * * * * each 15 seconds, 10:00:00, 10:00:15, 10:00:30, 10:00:45, 10:01:00 ... 30 4 * * * Asia/Tokyo each day 04:30, Tokyo time 15 8 * * * Europe/Berlin each day 08:15, Berlin time 20-24/2 * * * * each hour the 20th, 22nd and 24th minute The minimum interval of a timer is 1 second, runtime will either round up or raise an error if syntax is wrong. If a function call takes longer than the scheduled interval, the timer will skip those calls and log this accordingly. If a function can not be reached, the timer will repeat to try this a defined number of times with a growing delay. Updates to timer definitions may require a timer restart, which may be of importance when scheduling hours or longer intervals. For example, if you define a timer schedule of 1h and change the timer 5 minutes before execution to 1h30m you will have to wait full 1h30m for the next call. A timer is restarted if schedule or timezone change, otherwise it is only updated, keeping the calculated point in time for the next execution. AMQP Trigger \u00b6 This trigger type invokes functions as message consumers. As long business events are transported via messages the trigger can also be seen as a business event trigger. Depending on rules functions are selected based on message properties. The function results can optionally be sent as new messages. If the function execution fails the corresponding message can also be forwarded to an error topic. Technically the trigger behaves like an AMQP 1.0 client. It will connect to any peer either via WebSocket (with or without OAuth credentials flow) or via plain TCP, most likely using SASL credentials. Usually, the peer will be a message broker like Enterprise Messaging provides it for example. Attributes : * service : a service alias, it must be defined in the same project * secret : a secret that provides credentials to connect if no service reference is provided * config : a config map that provides the amqp link settings and binding rules Usually, the secret can be re-used by multiple triggers as it provides just connection data for a messaging broker. The config map will be trigger specific, providing link settings (to address queues or topics) as well as binding rules. Secret Entries : * dial or dial.json : destination data like host, port, use of websocket or not, oauth credentials if needed * sasl or sasl.json : SASL mechanism (ANONYMOUS, PLAIN), corresponding parameters if plain TCP connections are used Config Entries : * amqp or amqp.json : definition of AMQP links and sessions to use, addresses, settle modes and so on * bind or bind.json : rules to select functions based on message properties and to specify result and error handling It will be important to use a deployment file (values.yaml) to provide real credentials and settings for a specific deployment. Those data must not be stored in the secret and config defintion fields directly, as you probably will not wish to see it on git. CloudEvents Trigger \u00b6 This trigger allows you to subscribe CloudEvents and to define a rule-based function invocation. It works similar to an AMQP trigger, but does not require secret or config map. Instead it is completely defined within faas.json . Furthermore, it will configure the messaging service automatically with the project deployment. { \"functions\" : { \"ce-coffee-handler\" : { \"module\" : \"index.js\" , \"services\" : [] } }, \"triggers\" : { \"my-ce\" : { \"type\" : \"CloudEvents\" , \"service\" : \"my-ems\" , \"rules\" : [ { \"ce-source\" : \"\" , \"ce-type\" : \"com.sap.coffee.required\" , \"function\" : \"ce-coffee-handler\" , \"failure\" : \"accept\" }, { \"ce-source\" : \"\" , \"ce-type\" : \"com.sap.coffee.produced\" , \"function\" : \"ce-coffee-handler\" , \"failure\" : \"accept\" }, { \"ce-source\" : \"\" , \"ce-type\" : \"com.sap.coffee.consumed\" , \"function\" : \"ce-coffee-handler\" , \"failure\" : \"accept\" } ] } } } While deployment the referenced messaging service will be called to create a queue and topic subscriptions according to the given rules. For one single message only one single rule is applied, the first that matches. Currently SAP Enterprise Messaging is supported. The list may be extended according to development requests you raise. Function Runtime API \u00b6 The function handler is implemented as usual (anonymous) function, receiving two parameters: event and context . It may return a simple value directly or a Promise to handle asynchronous execution. As a consequence, async and await may be used as well. Global Variables \u00b6 Multiple calls may arrive in parallel in one Node.js instance. Each call will be handled in a sandbox . This means global variables of the main file are never shared and never reused. However, the sandbox does not cover globals of any dependent file. Hence, global variables in required modules must be handled with care if it cannot be avoided. Valid examples for those globals could be: * A cache for access tokens, not retrieved for each single call * Protocol clients that manage a permanent network connection, e.g. to a message broker Still, there is no guarantee that a Node.js instance is running for a certain time, but in fact such a cache or reused client will be reused many times and will improve overall performance significantly. Handler Exceptions \u00b6 The function code can throw an exception at any point in time to stop processing unexpected internal state. In this case an HTTP caller for example will receive response status code 500 (internal server error) only. Error details will be added to the function log. faas-cli can be used to retrieve log entries. Handler Parameter: event \u00b6 Provides attributes and methods related to a single function invocation. Attributes : * auth : authorization data * type : first part of HTTP authorization header, e.g. Basic , Bearer , ..: * credentials : plain data corresponding to type * ce : cloud event context attributes , only defined if available * specVersion : version of the CloudEvents specification which the event uses * source : event producer \"sap/app/01\" * type : event type, e.g. \"sap.common.alert\" * id : ID of the event * subject : subject of the event * time : timestamp of when the event happened * dataContentType : data encoding format * dataSchema : link to the schema that the data attribute adheres to * data : event payload, please note event.ce.data will always be equal to event.data * extensions : additional metadata not covered by the specification * data : payload data (HTTP body) related to invocation, depending on the received content type, either string , Buffer or Object , data can always be found here, with or without cloud event. * http : only defined if explicitly requested, provides access to HTTP request and response if available Methods : * decodeJsonWebToken():{ header: object, payload: object, signature: string } : Decodes event credentials as JSON WebToken (JWT). Returns null if the mechanism is not 'Bearer' or if the token has no valid JWT structure. Does not validate the token signature, as this has been done by the calling trigger already. The token itself is provided in field event.auth.credentials . * decodeUserPassword():{ user: string, password: string } : Decodes event credentials as basic authentication data. Returns null if the mechanism is not 'Basic' or if the credentials do not match the expected structure. Does not validate the credentials against any provider, as this will be function logic already. * setBadRequest() : Sets the event status to bad request . Event will not be processed, handler may still add data to the response, for example as hint. In contrast, throwing any error would be treated as internal error. * setUnauthorized() : Sets the event status to unauthorized . Event will not be processed, handler may still add data to the response, for example as hint. In contrast, throwing any error would be treated as internal error. * getContentType():string : Provides the received content type. In the case of cloud events it will be taken from the event itself. Data are provided accordingly, this means as object in case of json -format or as string or Buffer otherwise. * setResponseType(string) : Defines the response content type explicitly. Otherwise callers' accepted types will be compared with the return data type and best matches will be used. Fallback strategy is based on the returned data type only. * getResponseStream(contentType):WritableStream : The response content type is defined and the corresponding stream is returned. It is possible to write data directly to the stream or to pipe data from other streams. The function handler shall return a Promise to the runtime to indicate the asynchronous end of processing. * sendResponseEvent(ce) : The cloud event is returned as result of function execution. Http-Triggers would return it to the caller. AMQP or CE trigger can send the event, depending on its configuration. Source will be adjusted. If the function returns a simple value without defining the content type, a matching response content type will be selected automatically. And if the client was sending an HTTP request with Accept header this will also be taken into account. Handler Parameter: context \u00b6 Provides attributes and methods related to the current process. Attributes : * funcName : function name * timeoutMS : milliseconds that the function is allowed to run Methods : (runtime nodejs8 provides the same methods, but not async) * async getServiceCredentials(faas-json-alias) : provides service credentials as binary data (Buffer) * __ async getServiceCredentialsString(faas-json-alias) __: provides service credentials as text * async getServiceCredentialsJSON(faas-json-alias) : provides service credentials as parsed JSON data * __ async getSecretValueStream(name, key) __: provides secret value stream * __ async getSecretValue(name, key) __: provides secret value as binary data (Buffer) * __ async getSecretValueString(name, key) __: provides secret value as text * __ async getSecretValueJSON(name, key) __: provides secret value as parsed JSON data * __ async getSecretValueYAML(name, key) __: provides secret value as parsed YAML data * __ async getConfigValueStream(name, key) __: provides config value stream * __ async getConfigValue(name, key) __: provides config value as binary data (Buffer) * __ async getConfigValueString(name, key) __: provides config value as text * __ async getConfigValueJSON(name, key) __: provides config value as parsed JSON data * __ async getConfigValueYAML(name, key) __: provides config value as parsed YAML data * __ async callFunction(name, content): response __: Calls another function by name within the same __K8s__ namespace, content.data provides the request payload, content.type the request content type. response.data contains the received payload, response.type the received content type. Special handling with runtime nodejs8 : the method accepts a JsCallback as third parameter or returns a promise otherwise. * __ getFunctionEndpoint(name):string` : Only available with enabled HTTP API, expects a function name (inside the same __K8s namespace) and returns the corresponding HTTP endpoint. The object is reused for all function calls within the current Node.js instance, but attributes must not be changed. Function Test \u00b6 The following command runs all functions of a project locally: faas-sdk run -r 7777 -y values.yaml It will search faas.json starting from the current working directory. After reading all declarations one HTTP server starts listening at the given port. The URL for each function is printed to the console. Each function will find the same environment like in the cloud later on. Use any HTTP client or just a Web browser to call it. Function Debugging \u00b6 To debug function code in a local IDE, usually a debug configuration is needed: * Install @sap/faas as devDependency. * Create a debug configuration in your local IDE for Node.js. * Use ./node_modules/@sap/faas/lib/cli.js as file to execute. * Use run as cli argument. * Use this directory or just another underneath faas.json as working directory. * Set break points and invoke a function via browser or HTTP client. Function Unit Tests \u00b6 Finally, also unit tests for functions can be implemented. Here, @sap/faas provides a test method. It will do the following: * Start an HTTP server as described before. * Execute the provided test callback. * Shut down the server afterwards. As entry point the same context object is provided that functions see at runtime. It allows to call functions and to read secret or config map values, at this point of course starting from the local files. A deployment file can be provided to apply mock data. The following example uses a well-known test framework, even if @sap/faas does not enforce its usage. /*jshint mocha:true*/ 'use strict' ; const assert = require ( 'assert' ); const faas = require ( '@sap/faas' ); describe ( 'hello secret example' , () => { // ************************************************************************************************ it ( 'using default values' , ( done ) => { faas . test ( done , { }, async ( context ) => { const result = await context . callFunction ( 'hello-secret' , {}); assert . equal ( result . type , 'text/plain; charset=utf-8' ); assert . equal ( result . data , 'Demo' ); } ); }); // ************************************************************************************************ it ( 'using deploy values' , ( done ) => { faas . test ( done , { 'deploy-values' : '../mock/values.yaml' }, async ( context ) => { const result = await context . callFunction ( 'hello-secret' , {}); assert . equal ( result . type , 'text/plain; charset=utf-8' ); assert . equal ( result . data , 'Nice Test!' ); } ); }); // ************************************************************************************************ it ( 'read secret text' , ( done ) => { faas . test ( done , { }, async ( context ) => { assert . equal ( context . getSecretValueString ( 'sec1' , 'text' ), 'Hello World!' ); } ); }); // ************************************************************************************************ it ( 'read secret json' , ( done ) => { faas . test ( done , { }, async ( context ) => { assert . deepStrictEqual ( context . getSecretValueJSON ( 'sec1' , 'rv.json' ), { \"Info\" : { \"Success\" : \"Demo\" , \"Failure\" : \"Todo\" }, \"Code\" : { \"Success\" : \"A\" , \"Failure\" : \"X\" } }); } ); }); // ************************************************************************************************ });","title":"@sap/faas"},{"location":"apis/faas/#sapfaas","text":"Provides the SAP Cloud Platform Functions runtime for Node.js and basic SDK features.","title":"@sap/faas"},{"location":"apis/faas/#table-of-contents","text":"Overview Package Install Service Instances Naming Rules Function Projects Project Attributes Secrets and Config Maps Service References Functions Function Triggers HTTP Timer AMQP CloudEvents Function Runtime API Global Variables Handler Exceptions Handler Parameter: event Handler Parameter: context Function Test Function Debugging Function Unit Test","title":"Table of contents"},{"location":"apis/faas/#overview","text":"SAP Cloud Platform Functions are provided as a service ( FaaS ). Developers can focus on pure application logic while writing the code, whereas FaaS takes responsibility to run the code in a secure, reliable and cost-efficient way. Technically, FaaS runs on Kubernetes ( K8s ). Artifact deployments are managed using a service API, also running in K8s, next to the runtime of course. The overall architecture would allow integration of different serverless runtimes. However, currently K8s is used. In Cloud Foundry ( CF ) service xsf-runtime (Extension Factory, serverless runtime) is used as entry point. Each service instance represents a K8s namespace in a shared cluster. All artifacts deployed to a given service will end up as resource in the corresponding namespace. K8s namespaces (Faas tenants) are strictly isolated from each other. Function development is based on projects, using file faas.json as manifest. Any local IDE as well as WebIDE (Wing) can be used for implementation.","title":"Overview"},{"location":"apis/faas/#package","text":"This package comprises two functional parts. First, it provides the function runtime for Node.js (version 8.11.3 or higher): * runtime components as such * http server to run (or debug) functions locally * test runner to support function unit tests Secondly, it offers basic SDK functionality by installing command faas-sdk : * check project consistency * create and test deployment files ( values.yaml ) The function code is provided with usual js files. 'use strict' ; /** * @param {FaasEvent} event * @param {FaasContext} context * @return {Promise|*} */ module . exports = function ( event , context ) { const rval = context . getSecretValueJSON ( 'my-secret-1' , 'rv.json' ); return rval . Info . Success ; }; Different trigger types are supported to invoke functions under various conditions. Secrets provide an appropriate storage for credentials. Config maps can be used in addition for any further settings.","title":"Package"},{"location":"apis/faas/#install","text":"There are two FaaS client tools, waiting to support local development: * faas-sdk : supports the development phase, checks project consistency, runs functions locally in a similar environments like in K8s , enables unit test implementation * faas-cli : used to manage artifact deployment into K8s , uses FaaS instances in the Cloud Foundry as entry point Let's start: * Install Node.js (version 8.11.3 or higher): * Download from https://nodejs.org/en/download/ * Install Node.js runtime * Test installation with node -v and npm -v * Add SAP NPM Registry to your npm configuration for all @sap scoped modules. * Run npm config set \"@sap:registry=https://npm.sap.com\" * Test installation with npm show @sap/faas version * Install faas-sdk : * Run npm install @sap/faas -g * Test installation with faas-sdk version * Install faas-cli : * Go to https://tools.hana.ondemand.com/#cloud * Search for \"SAP Cloud Platform Functions Tools\" * Install one binary, test via faas-cli version * Install Cloud Foundry CLI : * Download latest release: https://github.com/cloudfoundry/cli/releases * Install binaries, test via cf version Update the local IDE of your choice and install plugins for Node.js. Finally, enable language support for Node.js and JavaScript (ECMAScript 6): You may also find these links helpful: Javascript Reference and NodeJS Reference The natural home of a FaaS project is a git repository. Based on that you can later easily switch between local IDE and SAP Web IDE. In the long term FaaS runtime may also support knative builds, fetching project files directly from git. Hence, we recommend to set up a git repository for your project from the beginning.","title":"Install"},{"location":"apis/faas/#naming-rules","text":"All runtime artifacts need a name that matches the following constraints: * Only lower case characters [a-z] and numbers [0-9] and - can be used. * Separator - must not appear at the begin or the end of the name. * Maximum length is restricted to 60 characters. This applies to: * secrets * config maps * service references * functions * triggers * project names and * project version identifiers Secret and config map keys (names of its entries) are usually based on file names. That's why it may contain . as well, but not at the beginning or the end.","title":"Naming Rules"},{"location":"apis/faas/#function-projects","text":"We recommend using FaaS projects, as this simplifies development tasks. Each project is defined with just one file, called faas.json . Usually, it will reside next to a package.json file. A first project can easily be created with an empty folder and the following command: faas-sdk init -p ./my-test It will create a simple project with one function, one secret, one http trigger and simple unit tests. After npm install all unit tests, local test run and K8s deployment will work immediately. Continue with renaming artifacts and modifying the function code. A first example defines one single function build-qrcode . The source code is provided with file .\\lib\\iso-time.js . And the HTTP trigger build-qrcode will invoke the function. { \"project\" : \"qrcode-producer\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"build-qrcode\" : { \"module\" : \"iso-time.js\" } }, \"triggers\" : { \"build-qrcode\" : { \"type\" : \"HTTP\" , \"function\" : \"build-qrcode\" } } } A second example shows one project defining two functions, both implemented in the same module file. In this case the module file main.js exports two function handlers f1 and f2 . { \"project\" : \"chain\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"chain-func1\" : { \"module\" : \"main.js\" , \"handler\" : \"f1\" }, \"chain-func2\" : { \"module\" : \"main.js\" , \"handler\" : \"f2\" } }, \"triggers\" : { \"chain-simple\" : { \"type\" : \"HTTP\" , \"function\" : \"chain-func1\" } } }","title":"Function Projects"},{"location":"apis/faas/#project-attributes","text":"At the top level of faas.json the following fields can be defined: * project : used as label for all runtime artifacts (see restrictions to naming rules ) * version : used as label for all runtime artifacts (see restrictions to naming rules ) Specific to the runtime: * runtime : used to select the runtime, currently only nodejs8 is supported * library : base directory for all source code file references, just to reduce redundancy Runtime artifacts: * secrets : collection of secrets, used to store credentials, api keys and the like * configs : collection of config maps, used for less critical, configuration-like settings, that shall not be hard-coded * functions : collection of functions that this project defines * triggers : collection of triggers, different types with individual settings Each runtime artifact collection uses the object name as json key field. The name must be unique per artifact type in the scope of one K8s namespace (that is, service instance). For example: * Multiple namespaces may define their own secret test1 . * In one namespace there might be a function test1 and a secret test1 in parallel. * However, there will be only one secret test1 in one namespace at a time, even if two different projects are used to deploy it. No assumptions are made regarding the separation of projects. In particular, FaaS runtime will not prevent multiple projects from deploying any artifacts concurrently.","title":"Project Attributes"},{"location":"apis/faas/#secrets-and-config-maps","text":"Technically, secrets and config maps share the same structure. A local directory containing one or more files is used for declaration. All files together must not exceed a total size of 1Mb. { \"project\" : \"example\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"secrets\" : { \"sec1\" : { \"source\" : \"./data/sec1\" } }, \"configs\" : { \"cfg1\" : { \"source\" : \"./data/cfg1\" } } } In addition to the unique object name, for example, sec1 or cfg1 , only one attribute is required: * source : relative path to the data directory The data directory and its contained files define the data model and default values. As the files will most likely show up in a git repository you may wish to see placeholder values first, later replaced (dynamically) by valid credentials, for instance. Both tools, faas-sdk and faas-cli , support a simple mechanism for that: a deployment file with a predefined structure. Take this as an example: secret-values : sec1 : rv.json : Info : Success : Demo Failure : Todo Code : Success : A Failure : X text : Nice Test! Here, values are defined for secret sec1 , and its two files rv.json and text . For json or yaml files also single object attributes inside the file can be replaced. Arrays are handled as one value only. In the case of other files e.g. text or binary data, the whole file content can be replaced. To initialize such a deployment file based on specific secret definitions run inside the project: faas-sdk init-values -y values.yaml The command will search faas.json starting from the current working directory. Once found it will add the content of secret and config map files to the deployment file values.yaml . As no directory is specified it will be stored in folder deploy (to be ignored by git) next to faas.json . After adjusting the deployment file content you can start a local test run: faas-sdk run -y values.yaml And for cloud deployment it can be used as well: faas-cli project deploy -y ./deploy/values.yaml -s my-cf-service -k my-cf-service-key These deployment files can also be used to define mock data for function unit tests .","title":"Secrets and Config Maps"},{"location":"apis/faas/#service-references","text":"Besides the option to use secrets there is a more simple way to provide credentials of SAP CP platform services to functions or triggers. First, you can use the command line tool to transfer service keys to a secure store in the faas runtime: * Run cf login * Run faas-cli login * Run faas-cli service register -s <service-name> -b <service-key> To list all registered services (for your faas tenant, means service instance): * Run faas-cli service list Then you can define in your project a service reference, for example to an enterprise messaging instance: { \"services\" : { \"my-ems\" : { \"type\" : \"enterprise-messaging\" , \"instance\" : \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\" , \"key\" : \"xxx\" } } } Finally, use the alias my-ems inside faas.json at trigger definitions and/or within function code. The specific values of the reference can be provided with deploy values as well.","title":"Service References"},{"location":"apis/faas/#functions","text":"Let's start with an example again: { \"project\" : \"example\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"my-new-fnc\" : { \"module\" : \"index.js\" , \"handler\" : \"\" , \"secrets\" : [ \"sec-xbem\" , \"sec-ebaas\" ], \"configs\" : [], \"timeout\" : 180 , \"maxBody\" : \"1MiB\" } } } In addition to the unique object name my-new-fnc the following attributes can be provided: * module : source code file that exports the function handler (it may require other files of course) * handler : only needed if module.exports appears as an object where handler can be found as attribute * httpApi : indicates whether or not HTTP request and response are required by the function handler * secrets : array of secrets used by the function * configs : array of config maps used by the function * timeout : seconds the function can run, minimum between 10 and 180 seconds * maxBody : limit for body size (payload) of incoming requests provided to the function, default 1MiB The function handler may require built-in modules, further local module files or external packages. External dependencies (or devDependencies, for example for unit testing) are defined as usual in package.json . An important entry in devDependencies is @sap/faas . It allows the implementation of function unit tests. Furthermore, it offers type definitions that your local IDE may use for code proposals. { \"dependencies\" : { }, \"devDependencies\" : { \"@sap/faas\" : \">=0.7.6\" } } The function handler in file \u00ecndex.js may look like this: 'use strict' ; /** * @namespace Faas * @typedef {import(\"@sap/faas\").Faas.Event} Faas.Event * @typedef {import(\"@sap/faas\").Faas.Context} Faas.Context */ /** * @param {Faas.Event} event * @param {Faas.Context} context * @return {Promise<*>|*} */ module . exports = function ( event , context ) { const rval = context . getSecretValueJSON ( 'sec1' , 'rv.json' ); return rval . Info . Success ; }; Please note how jsdoc annotations are used to declare the types. With that IDE shall support you in finding methods and attributes of event and context while typing.","title":"Functions"},{"location":"apis/faas/#function-triggers","text":"Functions are invoked by triggers. A single function may be referenced by multiple trigger instances of different types. In principle a single trigger may also invoke different functions, e.g. an AMQP trigger with multiple rules. The following types are supported: * HTTP * Timer * AMQP * CloudEvents A first example shows how triggers are defined in principle within faas.json : { \"project\" : \"example\" , \"version\" : \"0.0.1\" , \"runtime\" : \"nodejs8\" , \"library\" : \"./lib\" , \"functions\" : { \"my-new-fnc\" : { \"module\" : \"index.js\" } }, \"triggers\" : { \"demo\" : { \"type\" : \"HTTP\" , \"function\" : \"my-fnc-01\" }, \"job1\" : { \"type\" : \"Timer\" , \"schedule\" : \"0/15 * * * *\" , \"function\" : \"my-fnc-02\" } } } Trigger demo will provide an HTTP endpoint. For each received HTTP request the function my-fnc-01 will be invoked. In parallel trigger job1 will call function my-fnc-02 each quarter of an hour.","title":"Function Triggers"},{"location":"apis/faas/#http-trigger","text":"For each trigger instance an external HTTP endpoint will be created. Each incoming request will be forwarded to the function, except those for method 'OPTIONS'. The result of the function will be returned as response. Attributes : * function : the function to call Example : { \"triggers\" : { \"demo\" : { \"type\" : \"HTTP\" , \"function\" : \"my-new-fnc\" } } } Be aware that the endpoint is public visible. So far authentication/authorization has to be handled by the function code. It is planned to support automated oauth token validation in future.","title":"HTTP Trigger"},{"location":"apis/faas/#timer-trigger","text":"A single Timer trigger defines a schedule, optionally with timezone to call a selected function. Different schedule formats are supported: simple duration every 1 minute and 30 seconds: 1m30s , every 15 seconds 15s , every 1 hour 30 minutes and 15 seconds: 1h30m15s cron expression, spec conform , 5 fields ``` \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday; 7 is also Sunday on some systems) \u2502 \u2502 \u2502 \u2502 \u2502 ``` cron expression, additional field for seconds, 6 fields ``` \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 second (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0 - 6) (Sunday to Saturday; 7 is also Sunday on some systems) \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 ``` Together with cron expressions also a timezone can be of importance, typically when scheduling for hours. Valid timezone values follow Iana timezone database . Attributes : * schedule : duration or cron expression, which defines the execution interval * timezone : optional, timezone * function : the function to call Examples for schedule and timezone : schedule timezone execution 30s every 30 seconds, start immediately, 10:15:12, 10:15:42, 10:16:12 ... 1h30m every one and a half hour, 10:12:10, 11:42:10, 13:12:10, 14:42:10 ... 0 * * * * each full hour 0/15 * * * * each quarter of an hour 0/15 * * * * * each 15 seconds, 10:00:00, 10:00:15, 10:00:30, 10:00:45, 10:01:00 ... 30 4 * * * Asia/Tokyo each day 04:30, Tokyo time 15 8 * * * Europe/Berlin each day 08:15, Berlin time 20-24/2 * * * * each hour the 20th, 22nd and 24th minute The minimum interval of a timer is 1 second, runtime will either round up or raise an error if syntax is wrong. If a function call takes longer than the scheduled interval, the timer will skip those calls and log this accordingly. If a function can not be reached, the timer will repeat to try this a defined number of times with a growing delay. Updates to timer definitions may require a timer restart, which may be of importance when scheduling hours or longer intervals. For example, if you define a timer schedule of 1h and change the timer 5 minutes before execution to 1h30m you will have to wait full 1h30m for the next call. A timer is restarted if schedule or timezone change, otherwise it is only updated, keeping the calculated point in time for the next execution.","title":"Timer Trigger"},{"location":"apis/faas/#amqp-trigger","text":"This trigger type invokes functions as message consumers. As long business events are transported via messages the trigger can also be seen as a business event trigger. Depending on rules functions are selected based on message properties. The function results can optionally be sent as new messages. If the function execution fails the corresponding message can also be forwarded to an error topic. Technically the trigger behaves like an AMQP 1.0 client. It will connect to any peer either via WebSocket (with or without OAuth credentials flow) or via plain TCP, most likely using SASL credentials. Usually, the peer will be a message broker like Enterprise Messaging provides it for example. Attributes : * service : a service alias, it must be defined in the same project * secret : a secret that provides credentials to connect if no service reference is provided * config : a config map that provides the amqp link settings and binding rules Usually, the secret can be re-used by multiple triggers as it provides just connection data for a messaging broker. The config map will be trigger specific, providing link settings (to address queues or topics) as well as binding rules. Secret Entries : * dial or dial.json : destination data like host, port, use of websocket or not, oauth credentials if needed * sasl or sasl.json : SASL mechanism (ANONYMOUS, PLAIN), corresponding parameters if plain TCP connections are used Config Entries : * amqp or amqp.json : definition of AMQP links and sessions to use, addresses, settle modes and so on * bind or bind.json : rules to select functions based on message properties and to specify result and error handling It will be important to use a deployment file (values.yaml) to provide real credentials and settings for a specific deployment. Those data must not be stored in the secret and config defintion fields directly, as you probably will not wish to see it on git.","title":"AMQP Trigger"},{"location":"apis/faas/#cloudevents-trigger","text":"This trigger allows you to subscribe CloudEvents and to define a rule-based function invocation. It works similar to an AMQP trigger, but does not require secret or config map. Instead it is completely defined within faas.json . Furthermore, it will configure the messaging service automatically with the project deployment. { \"functions\" : { \"ce-coffee-handler\" : { \"module\" : \"index.js\" , \"services\" : [] } }, \"triggers\" : { \"my-ce\" : { \"type\" : \"CloudEvents\" , \"service\" : \"my-ems\" , \"rules\" : [ { \"ce-source\" : \"\" , \"ce-type\" : \"com.sap.coffee.required\" , \"function\" : \"ce-coffee-handler\" , \"failure\" : \"accept\" }, { \"ce-source\" : \"\" , \"ce-type\" : \"com.sap.coffee.produced\" , \"function\" : \"ce-coffee-handler\" , \"failure\" : \"accept\" }, { \"ce-source\" : \"\" , \"ce-type\" : \"com.sap.coffee.consumed\" , \"function\" : \"ce-coffee-handler\" , \"failure\" : \"accept\" } ] } } } While deployment the referenced messaging service will be called to create a queue and topic subscriptions according to the given rules. For one single message only one single rule is applied, the first that matches. Currently SAP Enterprise Messaging is supported. The list may be extended according to development requests you raise.","title":"CloudEvents Trigger"},{"location":"apis/faas/#function-runtime-api","text":"The function handler is implemented as usual (anonymous) function, receiving two parameters: event and context . It may return a simple value directly or a Promise to handle asynchronous execution. As a consequence, async and await may be used as well.","title":"Function Runtime API"},{"location":"apis/faas/#global-variables","text":"Multiple calls may arrive in parallel in one Node.js instance. Each call will be handled in a sandbox . This means global variables of the main file are never shared and never reused. However, the sandbox does not cover globals of any dependent file. Hence, global variables in required modules must be handled with care if it cannot be avoided. Valid examples for those globals could be: * A cache for access tokens, not retrieved for each single call * Protocol clients that manage a permanent network connection, e.g. to a message broker Still, there is no guarantee that a Node.js instance is running for a certain time, but in fact such a cache or reused client will be reused many times and will improve overall performance significantly.","title":"Global Variables"},{"location":"apis/faas/#handler-exceptions","text":"The function code can throw an exception at any point in time to stop processing unexpected internal state. In this case an HTTP caller for example will receive response status code 500 (internal server error) only. Error details will be added to the function log. faas-cli can be used to retrieve log entries.","title":"Handler Exceptions"},{"location":"apis/faas/#handler-parameter-event","text":"Provides attributes and methods related to a single function invocation. Attributes : * auth : authorization data * type : first part of HTTP authorization header, e.g. Basic , Bearer , ..: * credentials : plain data corresponding to type * ce : cloud event context attributes , only defined if available * specVersion : version of the CloudEvents specification which the event uses * source : event producer \"sap/app/01\" * type : event type, e.g. \"sap.common.alert\" * id : ID of the event * subject : subject of the event * time : timestamp of when the event happened * dataContentType : data encoding format * dataSchema : link to the schema that the data attribute adheres to * data : event payload, please note event.ce.data will always be equal to event.data * extensions : additional metadata not covered by the specification * data : payload data (HTTP body) related to invocation, depending on the received content type, either string , Buffer or Object , data can always be found here, with or without cloud event. * http : only defined if explicitly requested, provides access to HTTP request and response if available Methods : * decodeJsonWebToken():{ header: object, payload: object, signature: string } : Decodes event credentials as JSON WebToken (JWT). Returns null if the mechanism is not 'Bearer' or if the token has no valid JWT structure. Does not validate the token signature, as this has been done by the calling trigger already. The token itself is provided in field event.auth.credentials . * decodeUserPassword():{ user: string, password: string } : Decodes event credentials as basic authentication data. Returns null if the mechanism is not 'Basic' or if the credentials do not match the expected structure. Does not validate the credentials against any provider, as this will be function logic already. * setBadRequest() : Sets the event status to bad request . Event will not be processed, handler may still add data to the response, for example as hint. In contrast, throwing any error would be treated as internal error. * setUnauthorized() : Sets the event status to unauthorized . Event will not be processed, handler may still add data to the response, for example as hint. In contrast, throwing any error would be treated as internal error. * getContentType():string : Provides the received content type. In the case of cloud events it will be taken from the event itself. Data are provided accordingly, this means as object in case of json -format or as string or Buffer otherwise. * setResponseType(string) : Defines the response content type explicitly. Otherwise callers' accepted types will be compared with the return data type and best matches will be used. Fallback strategy is based on the returned data type only. * getResponseStream(contentType):WritableStream : The response content type is defined and the corresponding stream is returned. It is possible to write data directly to the stream or to pipe data from other streams. The function handler shall return a Promise to the runtime to indicate the asynchronous end of processing. * sendResponseEvent(ce) : The cloud event is returned as result of function execution. Http-Triggers would return it to the caller. AMQP or CE trigger can send the event, depending on its configuration. Source will be adjusted. If the function returns a simple value without defining the content type, a matching response content type will be selected automatically. And if the client was sending an HTTP request with Accept header this will also be taken into account.","title":"Handler Parameter: event"},{"location":"apis/faas/#handler-parameter-context","text":"Provides attributes and methods related to the current process. Attributes : * funcName : function name * timeoutMS : milliseconds that the function is allowed to run Methods : (runtime nodejs8 provides the same methods, but not async) * async getServiceCredentials(faas-json-alias) : provides service credentials as binary data (Buffer) * __ async getServiceCredentialsString(faas-json-alias) __: provides service credentials as text * async getServiceCredentialsJSON(faas-json-alias) : provides service credentials as parsed JSON data * __ async getSecretValueStream(name, key) __: provides secret value stream * __ async getSecretValue(name, key) __: provides secret value as binary data (Buffer) * __ async getSecretValueString(name, key) __: provides secret value as text * __ async getSecretValueJSON(name, key) __: provides secret value as parsed JSON data * __ async getSecretValueYAML(name, key) __: provides secret value as parsed YAML data * __ async getConfigValueStream(name, key) __: provides config value stream * __ async getConfigValue(name, key) __: provides config value as binary data (Buffer) * __ async getConfigValueString(name, key) __: provides config value as text * __ async getConfigValueJSON(name, key) __: provides config value as parsed JSON data * __ async getConfigValueYAML(name, key) __: provides config value as parsed YAML data * __ async callFunction(name, content): response __: Calls another function by name within the same __K8s__ namespace, content.data provides the request payload, content.type the request content type. response.data contains the received payload, response.type the received content type. Special handling with runtime nodejs8 : the method accepts a JsCallback as third parameter or returns a promise otherwise. * __ getFunctionEndpoint(name):string` : Only available with enabled HTTP API, expects a function name (inside the same __K8s namespace) and returns the corresponding HTTP endpoint. The object is reused for all function calls within the current Node.js instance, but attributes must not be changed.","title":"Handler Parameter: context"},{"location":"apis/faas/#function-test","text":"The following command runs all functions of a project locally: faas-sdk run -r 7777 -y values.yaml It will search faas.json starting from the current working directory. After reading all declarations one HTTP server starts listening at the given port. The URL for each function is printed to the console. Each function will find the same environment like in the cloud later on. Use any HTTP client or just a Web browser to call it.","title":"Function Test"},{"location":"apis/faas/#function-debugging","text":"To debug function code in a local IDE, usually a debug configuration is needed: * Install @sap/faas as devDependency. * Create a debug configuration in your local IDE for Node.js. * Use ./node_modules/@sap/faas/lib/cli.js as file to execute. * Use run as cli argument. * Use this directory or just another underneath faas.json as working directory. * Set break points and invoke a function via browser or HTTP client.","title":"Function Debugging"},{"location":"apis/faas/#function-unit-tests","text":"Finally, also unit tests for functions can be implemented. Here, @sap/faas provides a test method. It will do the following: * Start an HTTP server as described before. * Execute the provided test callback. * Shut down the server afterwards. As entry point the same context object is provided that functions see at runtime. It allows to call functions and to read secret or config map values, at this point of course starting from the local files. A deployment file can be provided to apply mock data. The following example uses a well-known test framework, even if @sap/faas does not enforce its usage. /*jshint mocha:true*/ 'use strict' ; const assert = require ( 'assert' ); const faas = require ( '@sap/faas' ); describe ( 'hello secret example' , () => { // ************************************************************************************************ it ( 'using default values' , ( done ) => { faas . test ( done , { }, async ( context ) => { const result = await context . callFunction ( 'hello-secret' , {}); assert . equal ( result . type , 'text/plain; charset=utf-8' ); assert . equal ( result . data , 'Demo' ); } ); }); // ************************************************************************************************ it ( 'using deploy values' , ( done ) => { faas . test ( done , { 'deploy-values' : '../mock/values.yaml' }, async ( context ) => { const result = await context . callFunction ( 'hello-secret' , {}); assert . equal ( result . type , 'text/plain; charset=utf-8' ); assert . equal ( result . data , 'Nice Test!' ); } ); }); // ************************************************************************************************ it ( 'read secret text' , ( done ) => { faas . test ( done , { }, async ( context ) => { assert . equal ( context . getSecretValueString ( 'sec1' , 'text' ), 'Hello World!' ); } ); }); // ************************************************************************************************ it ( 'read secret json' , ( done ) => { faas . test ( done , { }, async ( context ) => { assert . deepStrictEqual ( context . getSecretValueJSON ( 'sec1' , 'rv.json' ), { \"Info\" : { \"Success\" : \"Demo\" , \"Failure\" : \"Todo\" }, \"Code\" : { \"Success\" : \"A\" , \"Failure\" : \"X\" } }); } ); }); // ************************************************************************************************ });","title":"Function Unit Tests"},{"location":"apis/faas/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . [0.7.7] - 2020-03-12 \u00b6 [0.7.6] - 2020-03-12 \u00b6 [0.7.5] - 2020-03-11 \u00b6 fixed: special handling for cloudevent response in function call, e.g. in unit tests [0.7.4] - 2020-03-09 \u00b6 [0.7.3] - 2020-03-06 \u00b6 [0.7.2] - 2020-01-31 \u00b6 fixed: code completion for vscode and intellij [0.7.1] - 2020-01-28 \u00b6 fixed: service credentials, provide only credentials content [0.7.0] - 2020-01-24 \u00b6 optimized runtime (full separation of sdk support) added: context methods for service credentials added: event.setBadRequest() added: event.setUnauthorized() [0.6.3] - 2019-09-23 \u00b6 fixed: function codes console.log() reaches runtime log in Node.js 10 or higher [0.6.2] - 2019-05-21 \u00b6 fixed: README.md, explain faas instance descriptor fixed: cleanup dependencies for example fixed: cleanup dependencies for project template updated dev dependencies, e.g. nyc for code coverage [0.6.0] - 2019-02-15 \u00b6 [0.5.1] - 2018-12-18 \u00b6 Added \u00b6 initial version documentation command faas-cli init project init deploy values local run support unit test support","title":"Change Log"},{"location":"apis/faas/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/faas/CHANGELOG/#077-2020-03-12","text":"","title":"[0.7.7] - 2020-03-12"},{"location":"apis/faas/CHANGELOG/#076-2020-03-12","text":"","title":"[0.7.6] - 2020-03-12"},{"location":"apis/faas/CHANGELOG/#075-2020-03-11","text":"fixed: special handling for cloudevent response in function call, e.g. in unit tests","title":"[0.7.5] - 2020-03-11"},{"location":"apis/faas/CHANGELOG/#074-2020-03-09","text":"","title":"[0.7.4] - 2020-03-09"},{"location":"apis/faas/CHANGELOG/#073-2020-03-06","text":"","title":"[0.7.3] - 2020-03-06"},{"location":"apis/faas/CHANGELOG/#072-2020-01-31","text":"fixed: code completion for vscode and intellij","title":"[0.7.2] - 2020-01-31"},{"location":"apis/faas/CHANGELOG/#071-2020-01-28","text":"fixed: service credentials, provide only credentials content","title":"[0.7.1] - 2020-01-28"},{"location":"apis/faas/CHANGELOG/#070-2020-01-24","text":"optimized runtime (full separation of sdk support) added: context methods for service credentials added: event.setBadRequest() added: event.setUnauthorized()","title":"[0.7.0] - 2020-01-24"},{"location":"apis/faas/CHANGELOG/#063-2019-09-23","text":"fixed: function codes console.log() reaches runtime log in Node.js 10 or higher","title":"[0.6.3] - 2019-09-23"},{"location":"apis/faas/CHANGELOG/#062-2019-05-21","text":"fixed: README.md, explain faas instance descriptor fixed: cleanup dependencies for example fixed: cleanup dependencies for project template updated dev dependencies, e.g. nyc for code coverage","title":"[0.6.2] - 2019-05-21"},{"location":"apis/faas/CHANGELOG/#060-2019-02-15","text":"","title":"[0.6.0] - 2019-02-15"},{"location":"apis/faas/CHANGELOG/#051-2018-12-18","text":"","title":"[0.5.1] - 2018-12-18"},{"location":"apis/faas/CHANGELOG/#added","text":"initial version documentation command faas-cli init project init deploy values local run support unit test support","title":"Added"},{"location":"apis/fibers/","text":"fibers(1) -- Fiber support for v8 and Node \u00b6 Fibers, sometimes called coroutines , are a powerful tool which expose an API to jump between multiple call stacks from within a single thread. This can be useful to make code written for a synchronous library play nicely in an asynchronous environment. INSTALLING \u00b6 via npm \u00b6 npm install fibers You're done! (see \"supported platforms\" below if you run into errors) from source \u00b6 git clone git://github.com/laverdet/node-fibers.git cd node-fibers npm install Note: node-fibers uses node-gyp for building. To manually invoke the build process, you can use node-gyp rebuild . This will put the compiled extension in build/Release/fibers.node . However, when you do require('fibers') , it will expect the module to be in, for example, bin/linux-x64-v8-3.11/fibers.node . You can manually put the module here every time you build, or you can use the included build script. Either npm install or node build -f will do this for you. If you are going to be hacking on node-fibers, it may be worthwhile to first do node-gyp configure and then for subsequent rebuilds you can just do node-gyp build which will be faster than a full npm install or node-gyp rebuild . meteor users please read this \u00b6 If you're trying to get meteor running and you ended up at this page you're probably doing something wrong. Please uninstall all versions of NodeJS and Meteor, then start over. See meteor#5124 for more information. supported platforms \u00b6 If you are running nodejs version 10.x or 12.x on Linux, OS X, or Windows (7 or later) then you should be able to install fibers from npm just fine. If you are running nodejs v8.x then you will need to use npm install fibers@3 . If you are running nodejs v6.x then you will need to use npm install fibers@2 . For nodejs v4.x you can use npm install fibers@1 . If you are running an older (or newer) version of node or some other operating system you will have to compile fibers on your system. (special thanks to Jeroen Janssen for his work on fibers in Windows) If you do end up needing to compile fibers first make sure you have node-gyp installed as a global dependency ( npm install -g node-gyp ), and that you have setup your build environment by following the instructions at node-gyp . Ubuntu-flavored Linux users may need to run sudo apt-get install g++ as well. EXAMPLES \u00b6 The examples below describe basic use of Fiber , but note that it is not recommended to use Fiber without an abstraction in between your code and fibers. See \"FUTURES\" below for additional information. Sleep \u00b6 This is a quick example of how you can write sleep() with fibers. Note that while the sleep() call is blocking inside the fiber, node is able to handle other events. $ cat sleep.js var Fiber = require ( 'fibers' ); function sleep ( ms ) { var fiber = Fiber . current ; setTimeout ( function () { fiber . run (); }, ms ); Fiber . yield (); } Fiber ( function () { console . log ( 'wait... ' + new Date ); sleep ( 1000 ); console . log ( 'ok... ' + new Date ); }). run (); console . log ( 'back in main' ); $ node sleep.js wait... Fri Jan 21 2011 22 :42:04 GMT+0900 ( JST ) back in main ok... Fri Jan 21 2011 22 :42:05 GMT+0900 ( JST ) Incremental Generator \u00b6 Yielding execution will resume back in the fiber right where you left off. You can also pass values back and forth through yield() and run(). Again, the node event loop is never blocked while this script is running. $ cat generator.js var Fiber = require ( 'fibers' ); var inc = Fiber ( function ( start ) { var total = start ; while ( true ) { total += Fiber . yield ( total ); } }); for ( var ii = inc . run ( 1 ); ii <= 10 ; ii = inc . run ( 1 )) { console . log ( ii ); } $ node generator.js 1 2 3 4 5 6 7 8 9 10 Fibonacci Generator \u00b6 Expanding on the incremental generator above, we can create a generator which returns a new Fibonacci number with each invocation. You can compare this with the ECMAScript Harmony Generator Fibonacci example. $ cat fibonacci.js var Fiber = require ( 'fibers' ); // Generator function. Returns a function which returns incrementing // Fibonacci numbers with each call. function Fibonacci () { // Create a new fiber which yields sequential Fibonacci numbers var fiber = Fiber ( function () { Fiber . yield ( 0 ); // F(0) -> 0 var prev = 0 , curr = 1 ; while ( true ) { Fiber . yield ( curr ); var tmp = prev + curr ; prev = curr ; curr = tmp ; } }); // Return a bound handle to `run` on this fiber return fiber . run . bind ( fiber ); } // Initialize a new Fibonacci sequence and iterate up to 1597 var seq = Fibonacci (); for ( var ii = seq (); ii <= 1597 ; ii = seq ()) { console . log ( ii ); } $ node fibonacci.js 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597 Basic Exceptions \u00b6 Fibers are exception-safe; exceptions will continue travelling through fiber boundaries: $ cat error.js var Fiber = require ( 'fibers' ); var fn = Fiber ( function () { console . log ( 'async work here...' ); Fiber . yield (); console . log ( 'still working...' ); Fiber . yield (); console . log ( 'just a little bit more...' ); Fiber . yield (); throw new Error ( 'oh crap!' ); }); try { while ( true ) { fn . run (); } } catch ( e ) { console . log ( 'safely caught that error!' ); console . log ( e . stack ); } console . log ( 'done!' ); $ node error.js async work here... still working... just a little bit more... safely caught that error! Error: oh crap! at error.js:11:9 done ! FUTURES \u00b6 Using the Fiber class without an abstraction in between your code and the raw API is not recommended . Fiber is meant to implement the smallest amount of functionality in order make possible many different programming patterns. This makes the Fiber class relatively lousy to work with directly, but extremely powerful when coupled with a decent abstraction. There is no right answer for which abstraction is right for you and your project. Included with node-fibers is an implementation of \"futures\" which is fiber-aware. Usage of this library is documented below. There are several other externally-maintained options which can be found on the wiki . You should feel encouraged to be creative with fibers and build a solution which works well with your project. For instance, Future is not a good abstraction to use if you want to build a generator function (see Fibonacci example above). Using Future to wrap existing node functions. At no point is the node event loop blocked: $ cat ls.js var Future = require ( 'fibers/future' ); var fs = Future . wrap ( require ( 'fs' )); Future . task ( function () { // Get a list of files in the directory var fileNames = fs . readdirFuture ( '.' ). wait (); console . log ( 'Found ' + fileNames . length + ' files' ); // Stat each file var stats = []; for ( var ii = 0 ; ii < fileNames . length ; ++ ii ) { stats . push ( fs . statFuture ( fileNames [ ii ])); } stats . map ( function ( f ) { f . wait () }); // Print file size for ( var ii = 0 ; ii < fileNames . length ; ++ ii ) { console . log ( fileNames [ ii ] + ': ' + stats [ ii ]. get (). size ); } }). detach (); $ node ls.js Found 11 files bin: 4096 fibers.js: 1708 .gitignore: 37 README.md: 8664 future.js: 5833 .git: 4096 LICENSE: 1054 src: 4096 ls.js: 860 Makefile: 436 package.json: 684 The future API is designed to make it easy to move between classic callback-style code and fiber-aware waiting code: $ cat sleep.js var Future = require ( 'fibers/future' ), wait = Future . wait ; // This function returns a future which resolves after a timeout. This // demonstrates manually resolving futures. function sleep ( ms ) { var future = new Future ; setTimeout ( function () { future . return (); }, ms ); return future ; } // You can create functions which automatically run in their own fiber and // return futures that resolve when the fiber returns (this probably sounds // confusing.. just play with it to understand). var calcTimerDelta = function ( ms ) { var start = new Date ; sleep ( ms ). wait (); return new Date - start ; }. future (); // <-- important! // And futures also include node-friendly callbacks if you don't want to use // wait() calcTimerDelta ( 2000 ). resolve ( function ( err , val ) { console . log ( 'Set timer for 2000ms, waited ' + val + 'ms' ); }); $ node sleep.js Set timer for 2000ms, waited 2009ms API DOCUMENTATION \u00b6 Fiber's definition looks something like this: /** * Instantiate a new Fiber. You may invoke this either as a function or as * a constructor; the behavior is the same. * * When run() is called on this fiber for the first time, `fn` will be * invoked as the first frame on a new stack. Execution will continue on * this new stack until `fn` returns, or Fiber.yield() is called. * * After the function returns the fiber is reset to original state and * may be restarted with another call to run(). */ function Fiber ( fn ) { [ native code ] } /** * `Fiber.current` will contain the currently-running Fiber. It will be * `undefined` if there is no fiber (i.e. the main stack of execution). * * See \"Garbage Collection\" for more information on responsible use of * `Fiber.current`. */ Fiber . current = undefined ; /** * `Fiber.yield()` will halt execution of the current fiber and return control * back to original caller of run(). If an argument is supplied to yield(), * run() will return that value. * * When run() is called again, yield() will return. * * Note that this function is a global to allow for correct garbage * collection. This results in no loss of functionality because it is only * valid to yield from the currently running fiber anyway. * * Note also that `yield` is a reserved word in Javascript. This is normally * not an issue, however some code linters may complain. Rest assured that it * will run fine now and in future versions of Javascript. */ Fiber . yield = function ( param ) { [ native code ] } /** * run() will start execution of this Fiber, or if it is currently yielding, * it will resume execution. If an argument is supplied, this argument will * be passed to the fiber, either as the first parameter to the main * function [if the fiber has not been started] or as the return value of * yield() [if the fiber is currently yielding]. * * This function will return either the parameter passed to yield(), or the * returned value from the fiber's main function. */ Fiber . prototype . run = function ( param ) { [ native code ] } /** * reset() will terminate a running Fiber and restore it to its original * state, as if it had returned execution. * * This is accomplished by causing yield() to throw an exception, and any * futher calls to yield() will also throw an exception. This continues * until the fiber has completely unwound and returns. * * If the fiber returns a value it will be returned by reset(). * * If the fiber is not running, reset() will have no effect. */ Fiber . prototype . reset = function () { [ native code ] } /** * throwInto() will cause a currently yielding fiber's yield() call to * throw instead of return gracefully. This can be useful for notifying a * fiber that you are no longer interested in its task, and that it should * give up. * * Note that if the fiber does not handle the exception it will continue to * bubble up and throwInto() will throw the exception right back at you. */ Fiber . prototype . throwInto = function ( exception ) { [ native code ] } Future's definition looks something like this: /** * Returns a future-function which, when run, starts running the target * function and returns a future for the result. * * Example usage: * var funcy = function(arg) { * return arg+1; * }.future(); * * funcy(1).wait(); // returns 2 */ Function . prototype . future = function () { ... } /** * Future object, instantiated with the new operator. */ function Future () {} /** * Wrap a node-style async function to return a future in place of using a callback. * * fn - the function or object to wrap * array - indicates that this callback will return more than 1 argument after `err`. For example, * `child_process.exec()` returns [err, stdout, stderr] * suffix - appends a string to every method that was overridden, if you passed an object * * Example usage: Future.wrap(asyncFunction)(arg1).wait() */ Future . wrap = function ( fn , multi , suffix ) { ... } /** * Invoke a function that will be run in its own fiber context and return a future to its return * value. * * Example: * Future.task(function() { * // You can safely `wait` on stuff here * }).detach(); */ Future . task = function ( fn ) { ... } /** * Wait on a series of futures and then return. If the futures throw an exception this function * /won't/ throw it back. You can get the value of the future by calling get() on it directly. If * you want to wait on a single future you're better off calling future.wait() on the instance. * * Example usage: Future.wait(aFuture, anotherFuture) */ Future . wait = function ( /* ... */ ) { ... } /** * Return the value of this future. If the future hasn't resolved yet this will throw an error. */ Future . prototype . get = function () { ... } /** * Mark this future as returned. All pending callbacks will be invoked immediately. * * value - the value to return when get() or wait() is called. * * Example usage: aFuture.return(value) */ Future . prototype . return = function ( value ) { ... } /** * Throw from this future as returned. All pending callbacks will be invoked immediately. * Note that execution will continue normally after running this method, * so make sure you exit appropriately after running throw() * * error - the error to throw when get() or wait() is called. * * Example usage: aFuture.throw(new Error(\"Something borked\")) */ Future . prototype . throw = function ( error ) { ... } /** * \"detach\" this future. Basically this is useful if you want to run a task in a future, you * aren't interested in its return value, but if it throws you don't want the exception to be * lost. If this fiber throws, an exception will be thrown to the event loop and node will * probably fall down. */ Future . prototype . detach = function () { ... } /** * Returns whether or not this future has resolved yet. */ Future . prototype . isResolved = function () { ... } /** * Returns a node-style function which will mark this future as resolved when called. * * Example usage: * var errback = aFuture.resolver(); * asyncFunction(arg1, arg2, etc, errback) * var result = aFuture.wait(); */ Future . prototype . resolver = function () { ... } /** * Waits for this future to resolve and then invokes a callback. * * If only one argument is passed it is a standard function(err, val){} errback. * * If two arguments are passed, the first argument is a future which will be thrown to in the case * of error, and the second is a function(val){} callback. */ Future . prototype . resolve = function ( /* errback or future, callback */ ) { ... } /** * Propogate results to another future. * * Example usage: future1.proxy(future2) // future2 gets automatically resolved with however future1 resolves */ Future . prototype . proxy = function ( future ) { ... } /** * Differs from its functional counterpart in that it actually resolves the future. Thus if the * future threw, future.wait() will throw. */ Future . prototype . wait = function () { ... } /** * Support for converting a Future to and from ES6 Promises. */ Future . fromPromise = function ( promise ) { ... } Future . prototype . promise = function () { ... } GARBAGE COLLECTION \u00b6 If you intend to build generators, iterators, or \"lazy lists\", you should be aware that all fibers must eventually unwind. This is implemented by causing yield() to throw unconditionally when the library is trying to unwind your fiber-- either because reset() was called, or all handles to the fiber were lost and v8 wants to delete it. Something like this will, at some point, cause an infinite loop in your application: var fiber = Fiber ( function () { while ( true ) { try { Fiber . yield (); } catch ( e ) {} } }); fiber . run (); If you either call reset() on this fiber, or the v8 garbage collector decides it is no longer in use, the fiber library will attempt to unwind the fiber by causing all calls to yield() to throw. However, if you catch these exceptions and continue anyway, an infinite loop will occur. There are other garbage collection issues that occur with misuse of fiber handles. If you grab a handle to a fiber from within itself, you should make sure that the fiber eventually unwinds. This application will leak memory: var fiber = Fiber ( function () { var that = Fiber . current ; Fiber . yield (); } fiber . run (); fiber = undefined ; There is no way to get back into the fiber that was started, however it's impossible for v8's garbage collector to detect this. With a handle to the fiber still outstanding, v8 will never garbage collect it and the stack will remain in memory until the application exits. Thus, you should take care when grabbing references to Fiber.current .","title":"Index"},{"location":"apis/fibers/#fibers1-fiber-support-for-v8-and-node","text":"Fibers, sometimes called coroutines , are a powerful tool which expose an API to jump between multiple call stacks from within a single thread. This can be useful to make code written for a synchronous library play nicely in an asynchronous environment.","title":"fibers(1) -- Fiber support for v8 and Node"},{"location":"apis/fibers/#installing","text":"","title":"INSTALLING"},{"location":"apis/fibers/#via-npm","text":"npm install fibers You're done! (see \"supported platforms\" below if you run into errors)","title":"via npm"},{"location":"apis/fibers/#from-source","text":"git clone git://github.com/laverdet/node-fibers.git cd node-fibers npm install Note: node-fibers uses node-gyp for building. To manually invoke the build process, you can use node-gyp rebuild . This will put the compiled extension in build/Release/fibers.node . However, when you do require('fibers') , it will expect the module to be in, for example, bin/linux-x64-v8-3.11/fibers.node . You can manually put the module here every time you build, or you can use the included build script. Either npm install or node build -f will do this for you. If you are going to be hacking on node-fibers, it may be worthwhile to first do node-gyp configure and then for subsequent rebuilds you can just do node-gyp build which will be faster than a full npm install or node-gyp rebuild .","title":"from source"},{"location":"apis/fibers/#meteor-users-please-read-this","text":"If you're trying to get meteor running and you ended up at this page you're probably doing something wrong. Please uninstall all versions of NodeJS and Meteor, then start over. See meteor#5124 for more information.","title":"meteor users please read this"},{"location":"apis/fibers/#supported-platforms","text":"If you are running nodejs version 10.x or 12.x on Linux, OS X, or Windows (7 or later) then you should be able to install fibers from npm just fine. If you are running nodejs v8.x then you will need to use npm install fibers@3 . If you are running nodejs v6.x then you will need to use npm install fibers@2 . For nodejs v4.x you can use npm install fibers@1 . If you are running an older (or newer) version of node or some other operating system you will have to compile fibers on your system. (special thanks to Jeroen Janssen for his work on fibers in Windows) If you do end up needing to compile fibers first make sure you have node-gyp installed as a global dependency ( npm install -g node-gyp ), and that you have setup your build environment by following the instructions at node-gyp . Ubuntu-flavored Linux users may need to run sudo apt-get install g++ as well.","title":"supported platforms"},{"location":"apis/fibers/#examples","text":"The examples below describe basic use of Fiber , but note that it is not recommended to use Fiber without an abstraction in between your code and fibers. See \"FUTURES\" below for additional information.","title":"EXAMPLES"},{"location":"apis/fibers/#sleep","text":"This is a quick example of how you can write sleep() with fibers. Note that while the sleep() call is blocking inside the fiber, node is able to handle other events. $ cat sleep.js var Fiber = require ( 'fibers' ); function sleep ( ms ) { var fiber = Fiber . current ; setTimeout ( function () { fiber . run (); }, ms ); Fiber . yield (); } Fiber ( function () { console . log ( 'wait... ' + new Date ); sleep ( 1000 ); console . log ( 'ok... ' + new Date ); }). run (); console . log ( 'back in main' ); $ node sleep.js wait... Fri Jan 21 2011 22 :42:04 GMT+0900 ( JST ) back in main ok... Fri Jan 21 2011 22 :42:05 GMT+0900 ( JST )","title":"Sleep"},{"location":"apis/fibers/#incremental-generator","text":"Yielding execution will resume back in the fiber right where you left off. You can also pass values back and forth through yield() and run(). Again, the node event loop is never blocked while this script is running. $ cat generator.js var Fiber = require ( 'fibers' ); var inc = Fiber ( function ( start ) { var total = start ; while ( true ) { total += Fiber . yield ( total ); } }); for ( var ii = inc . run ( 1 ); ii <= 10 ; ii = inc . run ( 1 )) { console . log ( ii ); } $ node generator.js 1 2 3 4 5 6 7 8 9 10","title":"Incremental Generator"},{"location":"apis/fibers/#fibonacci-generator","text":"Expanding on the incremental generator above, we can create a generator which returns a new Fibonacci number with each invocation. You can compare this with the ECMAScript Harmony Generator Fibonacci example. $ cat fibonacci.js var Fiber = require ( 'fibers' ); // Generator function. Returns a function which returns incrementing // Fibonacci numbers with each call. function Fibonacci () { // Create a new fiber which yields sequential Fibonacci numbers var fiber = Fiber ( function () { Fiber . yield ( 0 ); // F(0) -> 0 var prev = 0 , curr = 1 ; while ( true ) { Fiber . yield ( curr ); var tmp = prev + curr ; prev = curr ; curr = tmp ; } }); // Return a bound handle to `run` on this fiber return fiber . run . bind ( fiber ); } // Initialize a new Fibonacci sequence and iterate up to 1597 var seq = Fibonacci (); for ( var ii = seq (); ii <= 1597 ; ii = seq ()) { console . log ( ii ); } $ node fibonacci.js 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597","title":"Fibonacci Generator"},{"location":"apis/fibers/#basic-exceptions","text":"Fibers are exception-safe; exceptions will continue travelling through fiber boundaries: $ cat error.js var Fiber = require ( 'fibers' ); var fn = Fiber ( function () { console . log ( 'async work here...' ); Fiber . yield (); console . log ( 'still working...' ); Fiber . yield (); console . log ( 'just a little bit more...' ); Fiber . yield (); throw new Error ( 'oh crap!' ); }); try { while ( true ) { fn . run (); } } catch ( e ) { console . log ( 'safely caught that error!' ); console . log ( e . stack ); } console . log ( 'done!' ); $ node error.js async work here... still working... just a little bit more... safely caught that error! Error: oh crap! at error.js:11:9 done !","title":"Basic Exceptions"},{"location":"apis/fibers/#futures","text":"Using the Fiber class without an abstraction in between your code and the raw API is not recommended . Fiber is meant to implement the smallest amount of functionality in order make possible many different programming patterns. This makes the Fiber class relatively lousy to work with directly, but extremely powerful when coupled with a decent abstraction. There is no right answer for which abstraction is right for you and your project. Included with node-fibers is an implementation of \"futures\" which is fiber-aware. Usage of this library is documented below. There are several other externally-maintained options which can be found on the wiki . You should feel encouraged to be creative with fibers and build a solution which works well with your project. For instance, Future is not a good abstraction to use if you want to build a generator function (see Fibonacci example above). Using Future to wrap existing node functions. At no point is the node event loop blocked: $ cat ls.js var Future = require ( 'fibers/future' ); var fs = Future . wrap ( require ( 'fs' )); Future . task ( function () { // Get a list of files in the directory var fileNames = fs . readdirFuture ( '.' ). wait (); console . log ( 'Found ' + fileNames . length + ' files' ); // Stat each file var stats = []; for ( var ii = 0 ; ii < fileNames . length ; ++ ii ) { stats . push ( fs . statFuture ( fileNames [ ii ])); } stats . map ( function ( f ) { f . wait () }); // Print file size for ( var ii = 0 ; ii < fileNames . length ; ++ ii ) { console . log ( fileNames [ ii ] + ': ' + stats [ ii ]. get (). size ); } }). detach (); $ node ls.js Found 11 files bin: 4096 fibers.js: 1708 .gitignore: 37 README.md: 8664 future.js: 5833 .git: 4096 LICENSE: 1054 src: 4096 ls.js: 860 Makefile: 436 package.json: 684 The future API is designed to make it easy to move between classic callback-style code and fiber-aware waiting code: $ cat sleep.js var Future = require ( 'fibers/future' ), wait = Future . wait ; // This function returns a future which resolves after a timeout. This // demonstrates manually resolving futures. function sleep ( ms ) { var future = new Future ; setTimeout ( function () { future . return (); }, ms ); return future ; } // You can create functions which automatically run in their own fiber and // return futures that resolve when the fiber returns (this probably sounds // confusing.. just play with it to understand). var calcTimerDelta = function ( ms ) { var start = new Date ; sleep ( ms ). wait (); return new Date - start ; }. future (); // <-- important! // And futures also include node-friendly callbacks if you don't want to use // wait() calcTimerDelta ( 2000 ). resolve ( function ( err , val ) { console . log ( 'Set timer for 2000ms, waited ' + val + 'ms' ); }); $ node sleep.js Set timer for 2000ms, waited 2009ms","title":"FUTURES"},{"location":"apis/fibers/#api-documentation","text":"Fiber's definition looks something like this: /** * Instantiate a new Fiber. You may invoke this either as a function or as * a constructor; the behavior is the same. * * When run() is called on this fiber for the first time, `fn` will be * invoked as the first frame on a new stack. Execution will continue on * this new stack until `fn` returns, or Fiber.yield() is called. * * After the function returns the fiber is reset to original state and * may be restarted with another call to run(). */ function Fiber ( fn ) { [ native code ] } /** * `Fiber.current` will contain the currently-running Fiber. It will be * `undefined` if there is no fiber (i.e. the main stack of execution). * * See \"Garbage Collection\" for more information on responsible use of * `Fiber.current`. */ Fiber . current = undefined ; /** * `Fiber.yield()` will halt execution of the current fiber and return control * back to original caller of run(). If an argument is supplied to yield(), * run() will return that value. * * When run() is called again, yield() will return. * * Note that this function is a global to allow for correct garbage * collection. This results in no loss of functionality because it is only * valid to yield from the currently running fiber anyway. * * Note also that `yield` is a reserved word in Javascript. This is normally * not an issue, however some code linters may complain. Rest assured that it * will run fine now and in future versions of Javascript. */ Fiber . yield = function ( param ) { [ native code ] } /** * run() will start execution of this Fiber, or if it is currently yielding, * it will resume execution. If an argument is supplied, this argument will * be passed to the fiber, either as the first parameter to the main * function [if the fiber has not been started] or as the return value of * yield() [if the fiber is currently yielding]. * * This function will return either the parameter passed to yield(), or the * returned value from the fiber's main function. */ Fiber . prototype . run = function ( param ) { [ native code ] } /** * reset() will terminate a running Fiber and restore it to its original * state, as if it had returned execution. * * This is accomplished by causing yield() to throw an exception, and any * futher calls to yield() will also throw an exception. This continues * until the fiber has completely unwound and returns. * * If the fiber returns a value it will be returned by reset(). * * If the fiber is not running, reset() will have no effect. */ Fiber . prototype . reset = function () { [ native code ] } /** * throwInto() will cause a currently yielding fiber's yield() call to * throw instead of return gracefully. This can be useful for notifying a * fiber that you are no longer interested in its task, and that it should * give up. * * Note that if the fiber does not handle the exception it will continue to * bubble up and throwInto() will throw the exception right back at you. */ Fiber . prototype . throwInto = function ( exception ) { [ native code ] } Future's definition looks something like this: /** * Returns a future-function which, when run, starts running the target * function and returns a future for the result. * * Example usage: * var funcy = function(arg) { * return arg+1; * }.future(); * * funcy(1).wait(); // returns 2 */ Function . prototype . future = function () { ... } /** * Future object, instantiated with the new operator. */ function Future () {} /** * Wrap a node-style async function to return a future in place of using a callback. * * fn - the function or object to wrap * array - indicates that this callback will return more than 1 argument after `err`. For example, * `child_process.exec()` returns [err, stdout, stderr] * suffix - appends a string to every method that was overridden, if you passed an object * * Example usage: Future.wrap(asyncFunction)(arg1).wait() */ Future . wrap = function ( fn , multi , suffix ) { ... } /** * Invoke a function that will be run in its own fiber context and return a future to its return * value. * * Example: * Future.task(function() { * // You can safely `wait` on stuff here * }).detach(); */ Future . task = function ( fn ) { ... } /** * Wait on a series of futures and then return. If the futures throw an exception this function * /won't/ throw it back. You can get the value of the future by calling get() on it directly. If * you want to wait on a single future you're better off calling future.wait() on the instance. * * Example usage: Future.wait(aFuture, anotherFuture) */ Future . wait = function ( /* ... */ ) { ... } /** * Return the value of this future. If the future hasn't resolved yet this will throw an error. */ Future . prototype . get = function () { ... } /** * Mark this future as returned. All pending callbacks will be invoked immediately. * * value - the value to return when get() or wait() is called. * * Example usage: aFuture.return(value) */ Future . prototype . return = function ( value ) { ... } /** * Throw from this future as returned. All pending callbacks will be invoked immediately. * Note that execution will continue normally after running this method, * so make sure you exit appropriately after running throw() * * error - the error to throw when get() or wait() is called. * * Example usage: aFuture.throw(new Error(\"Something borked\")) */ Future . prototype . throw = function ( error ) { ... } /** * \"detach\" this future. Basically this is useful if you want to run a task in a future, you * aren't interested in its return value, but if it throws you don't want the exception to be * lost. If this fiber throws, an exception will be thrown to the event loop and node will * probably fall down. */ Future . prototype . detach = function () { ... } /** * Returns whether or not this future has resolved yet. */ Future . prototype . isResolved = function () { ... } /** * Returns a node-style function which will mark this future as resolved when called. * * Example usage: * var errback = aFuture.resolver(); * asyncFunction(arg1, arg2, etc, errback) * var result = aFuture.wait(); */ Future . prototype . resolver = function () { ... } /** * Waits for this future to resolve and then invokes a callback. * * If only one argument is passed it is a standard function(err, val){} errback. * * If two arguments are passed, the first argument is a future which will be thrown to in the case * of error, and the second is a function(val){} callback. */ Future . prototype . resolve = function ( /* errback or future, callback */ ) { ... } /** * Propogate results to another future. * * Example usage: future1.proxy(future2) // future2 gets automatically resolved with however future1 resolves */ Future . prototype . proxy = function ( future ) { ... } /** * Differs from its functional counterpart in that it actually resolves the future. Thus if the * future threw, future.wait() will throw. */ Future . prototype . wait = function () { ... } /** * Support for converting a Future to and from ES6 Promises. */ Future . fromPromise = function ( promise ) { ... } Future . prototype . promise = function () { ... }","title":"API DOCUMENTATION"},{"location":"apis/fibers/#garbage-collection","text":"If you intend to build generators, iterators, or \"lazy lists\", you should be aware that all fibers must eventually unwind. This is implemented by causing yield() to throw unconditionally when the library is trying to unwind your fiber-- either because reset() was called, or all handles to the fiber were lost and v8 wants to delete it. Something like this will, at some point, cause an infinite loop in your application: var fiber = Fiber ( function () { while ( true ) { try { Fiber . yield (); } catch ( e ) {} } }); fiber . run (); If you either call reset() on this fiber, or the v8 garbage collector decides it is no longer in use, the fiber library will attempt to unwind the fiber by causing all calls to yield() to throw. However, if you catch these exceptions and continue anyway, an infinite loop will occur. There are other garbage collection issues that occur with misuse of fiber handles. If you grab a handle to a fiber from within itself, you should make sure that the fiber eventually unwinds. This application will leak memory: var fiber = Fiber ( function () { var that = Fiber . current ; Fiber . yield (); } fiber . run (); fiber = undefined ; There is no way to get back into the fiber that was started, however it's impossible for v8's garbage collector to detect this. With a handle to the fiber still outstanding, v8 will never garbage collect it and the stack will remain in memory until the application exits. Thus, you should take care when grabbing references to Fiber.current .","title":"GARBAGE COLLECTION"},{"location":"apis/fibers/ISSUE_TEMPLATE/","text":"","title":"ISSUE TEMPLATE"},{"location":"apis/fibrous/","text":"Fibrous \u00b6 Easily mix asynchronous and synchronous programming styles in node.js. Benefits \u00b6 Easy-to-follow flow control for both serial and parallel execution Complete stack traces, even for exceptions thrown within callbacks No boilerplate code for error and exception handling Conforms to standard node async API Install \u00b6 Fibrous requires node version 0.6.x or greater. npm install fibrous Examples \u00b6 Would you rather write this: var updateUser = function ( id , attributes , callback ) { User . findOne ( id , function ( err , user ) { if ( err ) return callback ( err ); user . set ( attributes ); user . save ( function ( err , updated ) { if ( err ) return callback ( err ); console . log ( \"Updated\" , updated ); callback ( null , updated ); }); }); }); Or this, which behaves identically to calling code: var updateUser = fibrous ( function ( id , attributes ) { user = User . sync . findOne ( id ); user . set ( attributes ); updated = user . sync . save (); console . log ( \"Updated\" , updated ); return updated ; }); Or even better, with CoffeeScript : updateUser = fibrous (id, attributes) -> user = User . sync . findOne ( id ) user . set ( attributes ) updated = user . sync . save () console . log ( \"Updated\" , updated ) updated Without Fibrous \u00b6 Using standard node callback-style APIs without fibrous, we write (from the fs docs ): fs . readFile ( '/etc/passwd' , function ( err , data ) { if ( err ) throw err ; console . log ( data ); }); Using sync \u00b6 Using fibrous, we write: data = fs . sync . readFile ( '/etc/passwd' ); console . log ( data ); Using future \u00b6 This is the same as writing: future = fs . future . readFile ( '/etc/passwd' ); data = future . wait (); console . log ( data ); Waiting for Multiple Futures \u00b6 Or for multiple files read asynchronously: futures = [ fs . future . readFile ( '/etc/passwd' ), fs . future . readFile ( '/etc/hosts' ) ]; data = fibrous . wait ( futures ); console . log ( data [ 0 ], data [ 1 ]); Note that fs.sync.readFile is not the same as fs.readFileSync . The latter blocks while the former allows the process to continue while waiting for the file read to complete. Make It Fibrous \u00b6 Fibrous uses node-fibers behind the scenes. wait and sync (which uses wait internally) require that they are called within a fiber. Fibrous provides two easy ways to do this. 1. fibrous Function Wrapper \u00b6 Pass any function to fibrous and it returns a function that conforms to standard node async APIs with a callback as the last argument. The callback expects err as the first argument and the function result as the second. Any exception thrown will be passed to the callback as an error. var asynFunc = fibrous ( function () { return fs . sync . readFile ( '/etc/passwd' ); }); is functionally equivalent to: var asyncFunc = function ( callback ) { fs . readFile ( '/etc/passwd' , function ( err , data ) { if ( err ) return callback ( err ); callback ( null , data ); }); } With coffeescript, the fibrous version is even cleaner: asyncFunc = fibrous -> fs . sync . readFile ( '/etc/passwd' ) fibrous ensures that the passed function is running in an existing fiber (from higher up the call stack) or will create a new fiber if one does not already exist. 2. Express/Connect Middleware \u00b6 Fibrous provides connect middleware that ensures that every request runs in a fiber. If you are using express , you'll want to use this middleware. var express = require ( 'express' ); var fibrous = require ( 'fibrous' ); var app = express (); app . use ( fibrous . middleware ); app . get ( '/' , function ( req , res ){ data = fs . sync . readFile ( './index.html' , 'utf8' ); res . send ( data ); }); 3. Wrap-and-run with fibrous.run \u00b6 fibrous.run is a utility function that creates a fibrous function then executes it. Provide a callback to handle any errors and the return value of the passed function (if you need it). If you don't provide a callback and there is an error, run will throw the error which will produce an uncaught exception. That may be okay for quick and dirty work but is probably a bad idea in production code. fibrous . run ( function () { var data = fs . sync . readFile ( '/etc/passwd' ); console . log ( data . toString ()); return data ; }, function ( err , returnValue ) { console . log ( \"Handle both async and sync errors here\" , err ); }); 4. Waiting on a callback \u00b6 Sometimes you need to wait for a callback to happen that does not conform to err, result format (for example streams). In this case the following pattern works well: var stream = < your stream > function wait ( callback ) { stream . on ( 'close' , function ( code ) { callback ( null , code ); }); } var code = wait . sync (); Details \u00b6 Error Handling / Exceptions \u00b6 In the above examples, if readFile produces an error, the fibrous versions (both sync and wait ) will throw an exception. Additionally, the stack trace will include the stack of the calling code unlike exceptions typically thrown from within callback. Testing \u00b6 Fibrous provides a test helper for jasmine-node that ensures that beforeEach , it , and afterEach run in a fiber. Require it in your shared spec_helper file or in the spec files where you want to use fibrous. require ( 'fibrous/lib/jasmine_spec_helper' ); describe ( 'My Spec' , function () { it ( 'tests something asynchronous' , function () { data = fs . sync . readFile ( '/etc/password' ); expect ( data . length ). toBeGreaterThan ( 0 ); }); }); If an asynchronous method called through fibrous produces an error, the spec helper will fail the spec. mocha-fibers provides a fiber wrapper for mocha . If you write a helper for other testing frameworks, we'd love to include it in the project. Console \u00b6 Fibrous makes it much easier to work with asynchronous methods in an interactive console, or REPL. If you find yourself in an interactive session, you can require fibrous so that you can use future . > fs = require('fs'); > require('fibrous'); > data = fs.future.readFile('/etc/passwd', 'utf8'); > data.get() In this example, data.get() will return the result of the future, provided you have waited long enough for the future to complete. (The time it takes to type the next line is almost always long enough.) You can't use sync in the above scenario because a fiber has not been created so you can't call wait on a future. Fibrous does provide a bin script that creates a new interactive console where each command is run in a fiber so you can use sync. If you install fibrous with npm install -g fibrous or have ./node_modules/.bin on your path, you can just run: $ fibrous Starting fibrous node REPL... > fs = require ( 'fs' ) ; > data = fs.sync.readFile ( '/etc/passwd' , 'utf8' ) ; > console.log ( data ) ; ## # User Database # ... Or for a CoffeeScript REPL: $ fibrous -c [ or --coffee ] Starting fibrous coffee REPL... coffee> fs = require 'fs' coffee> data = fs.sync.readFile '/etc/passwd' , 'utf8' coffee> console.log data ## # User Database # ... Gotchas \u00b6 The first time you call sync or future on an object, it builds the sync and future proxies so if you add a method to the object later, it will not be proxied. With Express and bodyParser or json \u00b6 You might be getting an error in Express that you are not in context of a fiber even after adding fibrous.middleware to your stack. This can happen if you added it before express.json() or express.bodyParser() . Here's an example: // might not work app . use ( fibrous . middleware ); app . use ( express . bodyParser ()); // or app . use ( fibrous . middleware ); app . use ( express . json ()); // should work app . use ( express . bodyParser ()); app . use ( fibrous . middleware ); // or app . use ( express . json ()); app . use ( fibrous . middleware ); Behind The Scenes \u00b6 Futures \u00b6 Fibrous uses the Future implementation from node-fibers . future.wait waits for the future to resolve then returns the result while allowing the process to continue. fibrous.wait accepts a single future, multiple future arguments or an array of futures. It returns the result of the future if passed just one, or an array of results if passed multiple. future.get returns the result of the resolved future or throws an exception if not yet resolved. Object & Function mixins \u00b6 Fibrous mixes future and sync into Function.prototype so you can use them directly as in: readFile = require ( 'fs' ). readFile ; data = readFile . sync ( '/etc/passwd' ); Fibrous adds future and sync to Object.prototype correctly so they are not enumerable. These proxy methods also ignore all getters, even those that may return functions. If you need to call a getter with fibrous that returns an asynchronous function, you can do: func = obj . getter func . future . call ( obj , args ) Disclaimer \u00b6 Some people don't like libraries that mix in to Object.prototype and Function.prototype. If that's how you feel, then fibrous is probably not for you. We've been careful to mix in 'right' so that we don't change property enumeration and find that the benefits of having sync and future available without explicitly wrapping objects or functions are worth the philosophical tradeoffs. Contributing \u00b6 git clone git://github.com/goodeggs/fibrous.git npm install npm test Fibrous is written in coffeescript with source in src/ compiled to lib/ . Tests are written with jasmine-node in spec/ . Run tests with npm test which will also compile the coffeescript to lib/ . Pull requests are welcome. Please provide tests for your changes and features. Thanks! Contributors \u00b6 Randy Puro ( randypuro ) Alon Salant ( asalant ) Bob Zoller ( bobzoller )","title":"Index"},{"location":"apis/fibrous/#fibrous","text":"Easily mix asynchronous and synchronous programming styles in node.js.","title":"Fibrous"},{"location":"apis/fibrous/#benefits","text":"Easy-to-follow flow control for both serial and parallel execution Complete stack traces, even for exceptions thrown within callbacks No boilerplate code for error and exception handling Conforms to standard node async API","title":"Benefits"},{"location":"apis/fibrous/#install","text":"Fibrous requires node version 0.6.x or greater. npm install fibrous","title":"Install"},{"location":"apis/fibrous/#examples","text":"Would you rather write this: var updateUser = function ( id , attributes , callback ) { User . findOne ( id , function ( err , user ) { if ( err ) return callback ( err ); user . set ( attributes ); user . save ( function ( err , updated ) { if ( err ) return callback ( err ); console . log ( \"Updated\" , updated ); callback ( null , updated ); }); }); }); Or this, which behaves identically to calling code: var updateUser = fibrous ( function ( id , attributes ) { user = User . sync . findOne ( id ); user . set ( attributes ); updated = user . sync . save (); console . log ( \"Updated\" , updated ); return updated ; }); Or even better, with CoffeeScript : updateUser = fibrous (id, attributes) -> user = User . sync . findOne ( id ) user . set ( attributes ) updated = user . sync . save () console . log ( \"Updated\" , updated ) updated","title":"Examples"},{"location":"apis/fibrous/#without-fibrous","text":"Using standard node callback-style APIs without fibrous, we write (from the fs docs ): fs . readFile ( '/etc/passwd' , function ( err , data ) { if ( err ) throw err ; console . log ( data ); });","title":"Without Fibrous"},{"location":"apis/fibrous/#using-sync","text":"Using fibrous, we write: data = fs . sync . readFile ( '/etc/passwd' ); console . log ( data );","title":"Using sync"},{"location":"apis/fibrous/#using-future","text":"This is the same as writing: future = fs . future . readFile ( '/etc/passwd' ); data = future . wait (); console . log ( data );","title":"Using future"},{"location":"apis/fibrous/#waiting-for-multiple-futures","text":"Or for multiple files read asynchronously: futures = [ fs . future . readFile ( '/etc/passwd' ), fs . future . readFile ( '/etc/hosts' ) ]; data = fibrous . wait ( futures ); console . log ( data [ 0 ], data [ 1 ]); Note that fs.sync.readFile is not the same as fs.readFileSync . The latter blocks while the former allows the process to continue while waiting for the file read to complete.","title":"Waiting for Multiple Futures"},{"location":"apis/fibrous/#make-it-fibrous","text":"Fibrous uses node-fibers behind the scenes. wait and sync (which uses wait internally) require that they are called within a fiber. Fibrous provides two easy ways to do this.","title":"Make It Fibrous"},{"location":"apis/fibrous/#1-fibrous-function-wrapper","text":"Pass any function to fibrous and it returns a function that conforms to standard node async APIs with a callback as the last argument. The callback expects err as the first argument and the function result as the second. Any exception thrown will be passed to the callback as an error. var asynFunc = fibrous ( function () { return fs . sync . readFile ( '/etc/passwd' ); }); is functionally equivalent to: var asyncFunc = function ( callback ) { fs . readFile ( '/etc/passwd' , function ( err , data ) { if ( err ) return callback ( err ); callback ( null , data ); }); } With coffeescript, the fibrous version is even cleaner: asyncFunc = fibrous -> fs . sync . readFile ( '/etc/passwd' ) fibrous ensures that the passed function is running in an existing fiber (from higher up the call stack) or will create a new fiber if one does not already exist.","title":"1. fibrous Function Wrapper"},{"location":"apis/fibrous/#2-expressconnect-middleware","text":"Fibrous provides connect middleware that ensures that every request runs in a fiber. If you are using express , you'll want to use this middleware. var express = require ( 'express' ); var fibrous = require ( 'fibrous' ); var app = express (); app . use ( fibrous . middleware ); app . get ( '/' , function ( req , res ){ data = fs . sync . readFile ( './index.html' , 'utf8' ); res . send ( data ); });","title":"2. Express/Connect Middleware"},{"location":"apis/fibrous/#3-wrap-and-run-with-fibrousrun","text":"fibrous.run is a utility function that creates a fibrous function then executes it. Provide a callback to handle any errors and the return value of the passed function (if you need it). If you don't provide a callback and there is an error, run will throw the error which will produce an uncaught exception. That may be okay for quick and dirty work but is probably a bad idea in production code. fibrous . run ( function () { var data = fs . sync . readFile ( '/etc/passwd' ); console . log ( data . toString ()); return data ; }, function ( err , returnValue ) { console . log ( \"Handle both async and sync errors here\" , err ); });","title":"3. Wrap-and-run with fibrous.run"},{"location":"apis/fibrous/#4-waiting-on-a-callback","text":"Sometimes you need to wait for a callback to happen that does not conform to err, result format (for example streams). In this case the following pattern works well: var stream = < your stream > function wait ( callback ) { stream . on ( 'close' , function ( code ) { callback ( null , code ); }); } var code = wait . sync ();","title":"4. Waiting on a callback"},{"location":"apis/fibrous/#details","text":"","title":"Details"},{"location":"apis/fibrous/#error-handling-exceptions","text":"In the above examples, if readFile produces an error, the fibrous versions (both sync and wait ) will throw an exception. Additionally, the stack trace will include the stack of the calling code unlike exceptions typically thrown from within callback.","title":"Error Handling / Exceptions"},{"location":"apis/fibrous/#testing","text":"Fibrous provides a test helper for jasmine-node that ensures that beforeEach , it , and afterEach run in a fiber. Require it in your shared spec_helper file or in the spec files where you want to use fibrous. require ( 'fibrous/lib/jasmine_spec_helper' ); describe ( 'My Spec' , function () { it ( 'tests something asynchronous' , function () { data = fs . sync . readFile ( '/etc/password' ); expect ( data . length ). toBeGreaterThan ( 0 ); }); }); If an asynchronous method called through fibrous produces an error, the spec helper will fail the spec. mocha-fibers provides a fiber wrapper for mocha . If you write a helper for other testing frameworks, we'd love to include it in the project.","title":"Testing"},{"location":"apis/fibrous/#console","text":"Fibrous makes it much easier to work with asynchronous methods in an interactive console, or REPL. If you find yourself in an interactive session, you can require fibrous so that you can use future . > fs = require('fs'); > require('fibrous'); > data = fs.future.readFile('/etc/passwd', 'utf8'); > data.get() In this example, data.get() will return the result of the future, provided you have waited long enough for the future to complete. (The time it takes to type the next line is almost always long enough.) You can't use sync in the above scenario because a fiber has not been created so you can't call wait on a future. Fibrous does provide a bin script that creates a new interactive console where each command is run in a fiber so you can use sync. If you install fibrous with npm install -g fibrous or have ./node_modules/.bin on your path, you can just run: $ fibrous Starting fibrous node REPL... > fs = require ( 'fs' ) ; > data = fs.sync.readFile ( '/etc/passwd' , 'utf8' ) ; > console.log ( data ) ; ## # User Database # ... Or for a CoffeeScript REPL: $ fibrous -c [ or --coffee ] Starting fibrous coffee REPL... coffee> fs = require 'fs' coffee> data = fs.sync.readFile '/etc/passwd' , 'utf8' coffee> console.log data ## # User Database # ...","title":"Console"},{"location":"apis/fibrous/#gotchas","text":"The first time you call sync or future on an object, it builds the sync and future proxies so if you add a method to the object later, it will not be proxied.","title":"Gotchas"},{"location":"apis/fibrous/#with-express-and-bodyparser-or-json","text":"You might be getting an error in Express that you are not in context of a fiber even after adding fibrous.middleware to your stack. This can happen if you added it before express.json() or express.bodyParser() . Here's an example: // might not work app . use ( fibrous . middleware ); app . use ( express . bodyParser ()); // or app . use ( fibrous . middleware ); app . use ( express . json ()); // should work app . use ( express . bodyParser ()); app . use ( fibrous . middleware ); // or app . use ( express . json ()); app . use ( fibrous . middleware );","title":"With Express and bodyParser or json"},{"location":"apis/fibrous/#behind-the-scenes","text":"","title":"Behind The Scenes"},{"location":"apis/fibrous/#futures","text":"Fibrous uses the Future implementation from node-fibers . future.wait waits for the future to resolve then returns the result while allowing the process to continue. fibrous.wait accepts a single future, multiple future arguments or an array of futures. It returns the result of the future if passed just one, or an array of results if passed multiple. future.get returns the result of the resolved future or throws an exception if not yet resolved.","title":"Futures"},{"location":"apis/fibrous/#object-function-mixins","text":"Fibrous mixes future and sync into Function.prototype so you can use them directly as in: readFile = require ( 'fs' ). readFile ; data = readFile . sync ( '/etc/passwd' ); Fibrous adds future and sync to Object.prototype correctly so they are not enumerable. These proxy methods also ignore all getters, even those that may return functions. If you need to call a getter with fibrous that returns an asynchronous function, you can do: func = obj . getter func . future . call ( obj , args )","title":"Object &amp; Function mixins"},{"location":"apis/fibrous/#disclaimer","text":"Some people don't like libraries that mix in to Object.prototype and Function.prototype. If that's how you feel, then fibrous is probably not for you. We've been careful to mix in 'right' so that we don't change property enumeration and find that the benefits of having sync and future available without explicitly wrapping objects or functions are worth the philosophical tradeoffs.","title":"Disclaimer"},{"location":"apis/fibrous/#contributing","text":"git clone git://github.com/goodeggs/fibrous.git npm install npm test Fibrous is written in coffeescript with source in src/ compiled to lib/ . Tests are written with jasmine-node in spec/ . Run tests with npm test which will also compile the coffeescript to lib/ . Pull requests are welcome. Please provide tests for your changes and features. Thanks!","title":"Contributing"},{"location":"apis/fibrous/#contributors","text":"Randy Puro ( randypuro ) Alon Salant ( asalant ) Bob Zoller ( bobzoller )","title":"Contributors"},{"location":"apis/fibrous/LICENSE/","text":"(The MIT License) Copyright (c) 2012 Good Eggs, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"LICENSE"},{"location":"apis/generator-cds/","text":"generator-cds \u00b6 Mission Goals \u00b6 simple, fast, reliable works in different environments: win, linux, mac, command line, web ide, vs code, eclipse, ... creates a minimal project which compiles and can be deployed supports iterative project creation, e.g. create simple project first and add ui in a second run on the same project uses standard technology, is extendable Installation \u00b6 This module is intended to be used within @sap/cds project and not as standalone library or cli.","title":"generator-cds"},{"location":"apis/generator-cds/#generator-cds","text":"","title":"generator-cds"},{"location":"apis/generator-cds/#mission-goals","text":"simple, fast, reliable works in different environments: win, linux, mac, command line, web ide, vs code, eclipse, ... creates a minimal project which compiles and can be deployed supports iterative project creation, e.g. create simple project first and add ui in a second run on the same project uses standard technology, is extendable","title":"Mission Goals"},{"location":"apis/generator-cds/#installation","text":"This module is intended to be used within @sap/cds project and not as standalone library or cli.","title":"Installation"},{"location":"apis/generator-cds/CHANGELOG/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . [2.14.2] \u00b6 Changed \u00b6 Use @sap/hana-client instead of hdb npm library. Use 512M as default disk-quota . [2.14.1] \u00b6 Changed \u00b6 Updated minimist and yaml npm library versions. Use cds build command instead of cds build/all . [2.14.0] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.39.0 . [2.13.2] \u00b6 Changed \u00b6 Engine entry for Nodejs is now ^10 || ^12 in srv and root package.json. [2.13.1] \u00b6 Removed \u00b6 Remove engines.node entry in package.json for db folder. [2.13.0] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.38.0 . Fixed \u00b6 Add engine entry for Nodejs 12.0 to package.json. [2.12.2] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.37.1 . [2.12.1] \u00b6 Feature \u00b6 Change warning text when used directly on command line. [2.12.0] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.37.0 . [2.11.3] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.36.2 . [2.11.2] \u00b6 Fixed \u00b6 Do not use maven dependency slf4j in pom.xml anymore when technology is Java. [2.11.1] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.36.1 . [2.11.0] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.36.0 . [2.10.2] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.35.4 . Fixed \u00b6 Improved launch config for VS Code to enable debugging. [2.10.1] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.35.2 . Fixed \u00b6 Create launch config file with reference to cds.js instead of npx. [2.10.0] \u00b6 Feature \u00b6 Add csv sample data for books, authors and orders Use Maven Java Archetype version 1.35.0 . Fixed \u00b6 Add missing entries to generated .gitignore file. [2.9.0] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.34.1 . [2.8.3] \u00b6 Feature \u00b6 Use cds environment parameter cds_version to specify used cds version in semver format. [2.8.2] \u00b6 Fixed \u00b6 Add debug profile in srv pom.xml . [2.8.1] \u00b6 Fixed \u00b6 Clean up pom.xml generation. [2.8.0] \u00b6 Fixed \u00b6 Use service plan for uaa configuration based on environment. [2.7.0] \u00b6 Fix creation of root level pom.xml Fix integration tests for Odata version 4 [2.6.3] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.32.5 . No npm install is done if project is located in a monorepo, where node modules is managed by e.g. lerna. Fixed \u00b6 Improve console output when project creation is done. [2.6.2] \u00b6 Fixed \u00b6 Add missing integration tests for OData version 4 . Feature \u00b6 Use Maven Java Archetype version 1.32.3 . [2.6.1] \u00b6 Fixed \u00b6 Jacoco support for java based srv modules. Issue warning if user calls cds init help instead of cds help init [2.6.0] \u00b6 Features \u00b6 Use default names for database ( db ) and service ( srv ) folders. Use v2 and v4 as OData version values. Fixed \u00b6 Add missing prompt descriptions. [2.5.1] \u00b6 Fixed \u00b6 Fix support for theia based generator. Temp folder deletion via native os call. Feature \u00b6 Use Maven Java Archetype version 1.32.0 . [2.5.0] \u00b6 Features \u00b6 Add parameter --pipeline to create pipeline specific files. Add integration tests if user selects db and srv with srv technology java. [2.4.12] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.31.3 . Fixed \u00b6 Use new maven group id for ngdbc driver. [2.4.11] \u00b6 Feature \u00b6 Use Maven Java Archetype version 1.31.1 . Fixed \u00b6 Add logger to API so environment can inject specific loggers. [2.4.10] \u00b6 Fixed \u00b6 Add default-*.json and connection.properties to root level .gitignore file. Feature \u00b6 Use Maven Java Archetype version 1.30.1 . [2.4.9] \u00b6 Fixed \u00b6 Stop creation when required npm library cannot be found. Enhance reporting of internal errors. [2.4.8] \u00b6 Fixed \u00b6 Create correct odata version entry in root package.json. [2.4.7] \u00b6 Fixed \u00b6 Add mta_archives to .gitignore file. Create directory entry in pom.xml to avoid errors when importing project. [2.4.6] \u00b6 Fixed \u00b6 Add folder name to created hdi container name. Reuse existing hdi container when creating a srv module. Show npm install output in console by default. Use ISC as standard license in generated project. [2.4.5] \u00b6 Fixed \u00b6 Only add disk-quota when not using java as srv technology. Do not add logback.xml to pom.xml excludes for java srv. Add cds.folders entry to root level package.json. Create sqlite3 development dependency for db technology sqlite. Add all folders specified in --modules to cds.requires section in project root package.json. Add odata.version entry to root level package.json. Features \u00b6 Use plugin version 2.0.0.0 in generated .hdiconfig file. Using fix archetype version 1.28.1 for java srv projects. [2.4.4] \u00b6 Fixed \u00b6 Using managed service uaa in mta.yaml [2.4.3] \u00b6 Fixed \u00b6 Empty mta.yaml was not parsed correctly. Empty package.json prevented correct project setup, cds build problems occurred afterwards. [2.4.2] \u00b6 Fixed \u00b6 Bug in package.json generation [2.4.1] \u00b6 Fixed \u00b6 Bug in file overwrite handling Features \u00b6 When running init on existing project, generator copies missing files but leaves existing. If parameter --force is present the generator overwrites entries in mta.yaml rather than reuse existing [2.4.0] \u00b6 Features \u00b6 Deprecate add module (replace with init --modules) Remove command line coloring Simplify internal CLI (CLI will be deprecated in the near future) Do not allow projects outside current working folder, e.g. init ../../some/where/else is not allowed No output at all (not even error messages) when using --quiet Create a module folder even if it is empty based on the supplied options Parameter --modules only supports one folder of each type Fixed \u00b6 Bug in mta.yaml creation which resulted in missing/invalid uaa entry Removal of existing tasks in .cdsrc.json during add module [2.3.10] \u00b6 Features \u00b6 Support named module folders, e.g. --modules myDB:db creates a db folder named myDB, while --modules db creates a db folder named db Enhance output when using --debug flag [2.3.9] \u00b6 Fixed \u00b6 Use existing UAA instance in mta.yaml, if file exists","title":"Changelog"},{"location":"apis/generator-cds/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Changelog"},{"location":"apis/generator-cds/CHANGELOG/#2142","text":"","title":"[2.14.2]"},{"location":"apis/generator-cds/CHANGELOG/#changed","text":"Use @sap/hana-client instead of hdb npm library. Use 512M as default disk-quota .","title":"Changed"},{"location":"apis/generator-cds/CHANGELOG/#2141","text":"","title":"[2.14.1]"},{"location":"apis/generator-cds/CHANGELOG/#changed_1","text":"Updated minimist and yaml npm library versions. Use cds build command instead of cds build/all .","title":"Changed"},{"location":"apis/generator-cds/CHANGELOG/#2140","text":"","title":"[2.14.0]"},{"location":"apis/generator-cds/CHANGELOG/#feature","text":"Use Maven Java Archetype version 1.39.0 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#2132","text":"","title":"[2.13.2]"},{"location":"apis/generator-cds/CHANGELOG/#changed_2","text":"Engine entry for Nodejs is now ^10 || ^12 in srv and root package.json.","title":"Changed"},{"location":"apis/generator-cds/CHANGELOG/#2131","text":"","title":"[2.13.1]"},{"location":"apis/generator-cds/CHANGELOG/#removed","text":"Remove engines.node entry in package.json for db folder.","title":"Removed"},{"location":"apis/generator-cds/CHANGELOG/#2130","text":"","title":"[2.13.0]"},{"location":"apis/generator-cds/CHANGELOG/#feature_1","text":"Use Maven Java Archetype version 1.38.0 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#fixed","text":"Add engine entry for Nodejs 12.0 to package.json.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#2122","text":"","title":"[2.12.2]"},{"location":"apis/generator-cds/CHANGELOG/#feature_2","text":"Use Maven Java Archetype version 1.37.1 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#2121","text":"","title":"[2.12.1]"},{"location":"apis/generator-cds/CHANGELOG/#feature_3","text":"Change warning text when used directly on command line.","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#2120","text":"","title":"[2.12.0]"},{"location":"apis/generator-cds/CHANGELOG/#feature_4","text":"Use Maven Java Archetype version 1.37.0 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#2113","text":"","title":"[2.11.3]"},{"location":"apis/generator-cds/CHANGELOG/#feature_5","text":"Use Maven Java Archetype version 1.36.2 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#2112","text":"","title":"[2.11.2]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_1","text":"Do not use maven dependency slf4j in pom.xml anymore when technology is Java.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#2111","text":"","title":"[2.11.1]"},{"location":"apis/generator-cds/CHANGELOG/#feature_6","text":"Use Maven Java Archetype version 1.36.1 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#2110","text":"","title":"[2.11.0]"},{"location":"apis/generator-cds/CHANGELOG/#feature_7","text":"Use Maven Java Archetype version 1.36.0 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#2102","text":"","title":"[2.10.2]"},{"location":"apis/generator-cds/CHANGELOG/#feature_8","text":"Use Maven Java Archetype version 1.35.4 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#fixed_2","text":"Improved launch config for VS Code to enable debugging.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#2101","text":"","title":"[2.10.1]"},{"location":"apis/generator-cds/CHANGELOG/#feature_9","text":"Use Maven Java Archetype version 1.35.2 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#fixed_3","text":"Create launch config file with reference to cds.js instead of npx.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#2100","text":"","title":"[2.10.0]"},{"location":"apis/generator-cds/CHANGELOG/#feature_10","text":"Add csv sample data for books, authors and orders Use Maven Java Archetype version 1.35.0 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#fixed_4","text":"Add missing entries to generated .gitignore file.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#290","text":"","title":"[2.9.0]"},{"location":"apis/generator-cds/CHANGELOG/#feature_11","text":"Use Maven Java Archetype version 1.34.1 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#283","text":"","title":"[2.8.3]"},{"location":"apis/generator-cds/CHANGELOG/#feature_12","text":"Use cds environment parameter cds_version to specify used cds version in semver format.","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#282","text":"","title":"[2.8.2]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_5","text":"Add debug profile in srv pom.xml .","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#281","text":"","title":"[2.8.1]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_6","text":"Clean up pom.xml generation.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#280","text":"","title":"[2.8.0]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_7","text":"Use service plan for uaa configuration based on environment.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#270","text":"Fix creation of root level pom.xml Fix integration tests for Odata version 4","title":"[2.7.0]"},{"location":"apis/generator-cds/CHANGELOG/#263","text":"","title":"[2.6.3]"},{"location":"apis/generator-cds/CHANGELOG/#feature_13","text":"Use Maven Java Archetype version 1.32.5 . No npm install is done if project is located in a monorepo, where node modules is managed by e.g. lerna.","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#fixed_8","text":"Improve console output when project creation is done.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#262","text":"","title":"[2.6.2]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_9","text":"Add missing integration tests for OData version 4 .","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#feature_14","text":"Use Maven Java Archetype version 1.32.3 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#261","text":"","title":"[2.6.1]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_10","text":"Jacoco support for java based srv modules. Issue warning if user calls cds init help instead of cds help init","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#260","text":"","title":"[2.6.0]"},{"location":"apis/generator-cds/CHANGELOG/#features","text":"Use default names for database ( db ) and service ( srv ) folders. Use v2 and v4 as OData version values.","title":"Features"},{"location":"apis/generator-cds/CHANGELOG/#fixed_11","text":"Add missing prompt descriptions.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#251","text":"","title":"[2.5.1]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_12","text":"Fix support for theia based generator. Temp folder deletion via native os call.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#feature_15","text":"Use Maven Java Archetype version 1.32.0 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#250","text":"","title":"[2.5.0]"},{"location":"apis/generator-cds/CHANGELOG/#features_1","text":"Add parameter --pipeline to create pipeline specific files. Add integration tests if user selects db and srv with srv technology java.","title":"Features"},{"location":"apis/generator-cds/CHANGELOG/#2412","text":"","title":"[2.4.12]"},{"location":"apis/generator-cds/CHANGELOG/#feature_16","text":"Use Maven Java Archetype version 1.31.3 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#fixed_13","text":"Use new maven group id for ngdbc driver.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#2411","text":"","title":"[2.4.11]"},{"location":"apis/generator-cds/CHANGELOG/#feature_17","text":"Use Maven Java Archetype version 1.31.1 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#fixed_14","text":"Add logger to API so environment can inject specific loggers.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#2410","text":"","title":"[2.4.10]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_15","text":"Add default-*.json and connection.properties to root level .gitignore file.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#feature_18","text":"Use Maven Java Archetype version 1.30.1 .","title":"Feature"},{"location":"apis/generator-cds/CHANGELOG/#249","text":"","title":"[2.4.9]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_16","text":"Stop creation when required npm library cannot be found. Enhance reporting of internal errors.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#248","text":"","title":"[2.4.8]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_17","text":"Create correct odata version entry in root package.json.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#247","text":"","title":"[2.4.7]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_18","text":"Add mta_archives to .gitignore file. Create directory entry in pom.xml to avoid errors when importing project.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#246","text":"","title":"[2.4.6]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_19","text":"Add folder name to created hdi container name. Reuse existing hdi container when creating a srv module. Show npm install output in console by default. Use ISC as standard license in generated project.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#245","text":"","title":"[2.4.5]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_20","text":"Only add disk-quota when not using java as srv technology. Do not add logback.xml to pom.xml excludes for java srv. Add cds.folders entry to root level package.json. Create sqlite3 development dependency for db technology sqlite. Add all folders specified in --modules to cds.requires section in project root package.json. Add odata.version entry to root level package.json.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#features_2","text":"Use plugin version 2.0.0.0 in generated .hdiconfig file. Using fix archetype version 1.28.1 for java srv projects.","title":"Features"},{"location":"apis/generator-cds/CHANGELOG/#244","text":"","title":"[2.4.4]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_21","text":"Using managed service uaa in mta.yaml","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#243","text":"","title":"[2.4.3]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_22","text":"Empty mta.yaml was not parsed correctly. Empty package.json prevented correct project setup, cds build problems occurred afterwards.","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#242","text":"","title":"[2.4.2]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_23","text":"Bug in package.json generation","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#241","text":"","title":"[2.4.1]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_24","text":"Bug in file overwrite handling","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#features_3","text":"When running init on existing project, generator copies missing files but leaves existing. If parameter --force is present the generator overwrites entries in mta.yaml rather than reuse existing","title":"Features"},{"location":"apis/generator-cds/CHANGELOG/#240","text":"","title":"[2.4.0]"},{"location":"apis/generator-cds/CHANGELOG/#features_4","text":"Deprecate add module (replace with init --modules) Remove command line coloring Simplify internal CLI (CLI will be deprecated in the near future) Do not allow projects outside current working folder, e.g. init ../../some/where/else is not allowed No output at all (not even error messages) when using --quiet Create a module folder even if it is empty based on the supplied options Parameter --modules only supports one folder of each type","title":"Features"},{"location":"apis/generator-cds/CHANGELOG/#fixed_25","text":"Bug in mta.yaml creation which resulted in missing/invalid uaa entry Removal of existing tasks in .cdsrc.json during add module","title":"Fixed"},{"location":"apis/generator-cds/CHANGELOG/#2310","text":"","title":"[2.3.10]"},{"location":"apis/generator-cds/CHANGELOG/#features_5","text":"Support named module folders, e.g. --modules myDB:db creates a db folder named myDB, while --modules db creates a db folder named db Enhance output when using --debug flag","title":"Features"},{"location":"apis/generator-cds/CHANGELOG/#239","text":"","title":"[2.3.9]"},{"location":"apis/generator-cds/CHANGELOG/#fixed_26","text":"Use existing UAA instance in mta.yaml, if file exists","title":"Fixed"},{"location":"apis/grunt-sapui5-bestpractice-build/","text":"grunt-sapui5-bestpractice-build \u00b6 Grunt tasks for SAP WebIDE. Pre-requisites \u00b6 Make sure that you have installed npm version >=5.6.0. Getting Started \u00b6 If you haven't used Grunt before, be sure to check out the Getting Started guide, as it explains how to create a Gruntfile as well as install and use Grunt plugins. Once you're familiar with that process, you may install this plugin with this command: npm install @sap/grunt-sapui5-bestpractice-build --save-dev OR add the following package.json to your application { \"name\" : \"<your-project-name>\" , \"version\" : \"0.0.1\" , \"description\" : \"Project description\" , \"private\" : true , \"devDependencies\" : { \"@sap/grunt-sapui5-bestpractice-build\" : \"1.X.X\" } } Once the plugin has been installed, it may be enabled inside your wcGruntfile.js: module . exports = function ( grunt ) { 'use strict' ; grunt . loadNpmTasks ( \"@sap/grunt-sapui5-bestpractice-build\" ); grunt . config . merge ({ compatVersion : \"1.56\" , deploy_mode : \"html_repo\" }); grunt . registerTask ( \"default\" , [ \"clean\" , \"lint\" , \"build\" ]); }; Optional Parameters: \"compatVersion\" - UI5 version in which the built artifact will be deployed. \"deploy_mode\" - Indication whether the deployed artifact will be hosted by an HTML5 repository. If so, the value should be \"html_repo\".","title":"grunt-sapui5-bestpractice-build"},{"location":"apis/grunt-sapui5-bestpractice-build/#grunt-sapui5-bestpractice-build","text":"Grunt tasks for SAP WebIDE.","title":"grunt-sapui5-bestpractice-build"},{"location":"apis/grunt-sapui5-bestpractice-build/#pre-requisites","text":"Make sure that you have installed npm version >=5.6.0.","title":"Pre-requisites"},{"location":"apis/grunt-sapui5-bestpractice-build/#getting-started","text":"If you haven't used Grunt before, be sure to check out the Getting Started guide, as it explains how to create a Gruntfile as well as install and use Grunt plugins. Once you're familiar with that process, you may install this plugin with this command: npm install @sap/grunt-sapui5-bestpractice-build --save-dev OR add the following package.json to your application { \"name\" : \"<your-project-name>\" , \"version\" : \"0.0.1\" , \"description\" : \"Project description\" , \"private\" : true , \"devDependencies\" : { \"@sap/grunt-sapui5-bestpractice-build\" : \"1.X.X\" } } Once the plugin has been installed, it may be enabled inside your wcGruntfile.js: module . exports = function ( grunt ) { 'use strict' ; grunt . loadNpmTasks ( \"@sap/grunt-sapui5-bestpractice-build\" ); grunt . config . merge ({ compatVersion : \"1.56\" , deploy_mode : \"html_repo\" }); grunt . registerTask ( \"default\" , [ \"clean\" , \"lint\" , \"build\" ]); }; Optional Parameters: \"compatVersion\" - UI5 version in which the built artifact will be deployed. \"deploy_mode\" - Indication whether the deployed artifact will be hosted by an HTML5 repository. If so, the value should be \"html_repo\".","title":"Getting Started"},{"location":"apis/grunt-sapui5-bestpractice-test/","text":"Running Unit and Integration Tests \u00b6 This module is used to support running unit and integration tests via a Grunt task. Preconditions \u00b6 The .npmrc file should contain the following line: @sap:registry=https://npm.sap.com/ Usage \u00b6 Copy this command and run it. npm install --save-dev @sap/grunt-sapui5-bestpractice-test This will add the grunt-sapui5-bestpractice-test module to your package.json file. 2. Add the following script to your package.json file to enable running the unit and integration tests via npm. \"scripts\": { \"test\": \"grunt unit_and_integration_tests\" } Add this code to the Gruntfile.js file. grunt.loadNpmTasks(\"@sap/grunt-sapui5-bestpractice-test\"); grunt.registerTask(\"unit_and_integration_tests\", [ \"test\" ] ); grunt.config.merge({ coverage_threshold: { statements: 0, branches: 100, functions: 0, lines: 0 } }); 4. Run the unit and integration tests. npm test","title":"Running Unit and Integration Tests"},{"location":"apis/grunt-sapui5-bestpractice-test/#running-unit-and-integration-tests","text":"This module is used to support running unit and integration tests via a Grunt task.","title":"Running Unit and Integration Tests"},{"location":"apis/grunt-sapui5-bestpractice-test/#preconditions","text":"The .npmrc file should contain the following line: @sap:registry=https://npm.sap.com/","title":"Preconditions"},{"location":"apis/grunt-sapui5-bestpractice-test/#usage","text":"Copy this command and run it. npm install --save-dev @sap/grunt-sapui5-bestpractice-test This will add the grunt-sapui5-bestpractice-test module to your package.json file. 2. Add the following script to your package.json file to enable running the unit and integration tests via npm. \"scripts\": { \"test\": \"grunt unit_and_integration_tests\" } Add this code to the Gruntfile.js file. grunt.loadNpmTasks(\"@sap/grunt-sapui5-bestpractice-test\"); grunt.registerTask(\"unit_and_integration_tests\", [ \"test\" ] ); grunt.config.merge({ coverage_threshold: { statements: 0, branches: 100, functions: 0, lines: 0 } }); 4. Run the unit and integration tests. npm test","title":"Usage"},{"location":"apis/grunt-tests-webide-bestpractice/","text":"tests-grunt \u00b6 Node module to support unit and integration tests via a grunt task The module is a sub module of the web ide best practice please see: https://www.sap.com/developer/tutorials/webide-grunt-basic.html","title":"tests-grunt"},{"location":"apis/grunt-tests-webide-bestpractice/#tests-grunt","text":"Node module to support unit and integration tests via a grunt task The module is a sub module of the web ide best practice please see: https://www.sap.com/developer/tutorials/webide-grunt-basic.html","title":"tests-grunt"},{"location":"apis/hana-client/","text":"@sap/hana-client \u00b6 This is the official Node.js driver for SAP HANA . It is used to connect, issue SQL queries, and obtain result sets. Install \u00b6 npm install @sap/hana-client Prerequisites \u00b6 This driver communicates with the native HANA libraries, and thus requires platform-specific native binaries. The official hosted version includes precompiled libraries for Linux, Windows and Mac OS X. The @sap/hana-client driver supports node.js 4.x, 6.x, 8.x, 10.x and 12.x. Help Guide \u00b6 The SAP HANA Node.js Driver help guide and API reference can be found on help.sap.com . Getting Started \u00b6 var hana = require ( '@sap/hana-client' ); var conn = hana . createConnection (); var conn_params = { serverNode : 'myserver:30015' , uid : 'system' , pwd : 'Password123' }; conn . connect ( conn_params , function ( err ) { if ( err ) throw err ; conn . exec ( 'SELECT Name, Description FROM Products WHERE id = ?' , [ 301 ], function ( err , result ) { if ( err ) throw err ; console . log ( 'Name: ' , result [ 0 ]. Name , ', Description: ' , result [ 0 ]. Description ); // output --> Name: Tee Shirt, Description: V-neck conn . disconnect (); }) }); Establish a database connection \u00b6 Connecting \u00b6 A database connection object is created by calling createConnection . The connection is established by calling the connection object's connect method, and passing in an object representing connection parameters. Example: Connecting over TCP/IP \u00b6 conn . connect ({ host : 'myserver' , port : '30015' , uid : 'system' , pwd : 'Password123' }); Disconnecting \u00b6 conn . disconnect ( function ( err ) { if ( err ) throw err ; console . log ( 'Disconnected' ); }); Direct Statement Execution \u00b6 Direct statement execution is the simplest way to execute SQL statements. The inputs are the SQL command to be executed, and an optional array of positional arguments. The result is returned using callbacks. The type of returned result depends on the kind of statement. DDL Statement \u00b6 In the case of a successful DDL Statement, nothing is returned. conn . exec ( 'CREATE TABLE Test (id INTEGER PRIMARY KEY, msg VARCHAR(128))' , function ( err , result ) { if ( err ) throw err ; console . log ( 'Table Test created!' ); }); DML Statement \u00b6 In the case of a DML Statement the number of affectedRows is returned. conn . exec ( \"INSERT INTO Test VALUES(1, 'Hello')\" , function ( err , affectedRows ) { if ( err ) throw err ; console . log ( 'Number of affected rows:' , affectedRows ); }); Query \u00b6 The exec function is a convenient way to completely retrieve the result of a query. In this case all selected rows are fetched and returned in the callback. conn . exec ( \"SELECT * FROM Test WHERE id < 5\" , function ( err , rows ) { if ( err ) throw err ; console . log ( 'Rows:' , rows ); }); Values in the query can be substitued with JavaScript variables by using ? placeholders in the query, and passing an array of positional arguments. conn . exec ( \"SELECT * FROM Test WHERE id BETWEEN ? AND ?\" , [ 5 , 8 ], function ( err , rows ) { if ( err ) throw err ; console . log ( 'Rows:' , rows ); }); Prepared Statement Execution \u00b6 Prepare a Statement \u00b6 The connection returns a statement object which can be executed multiple times. conn . prepare ( 'SELECT * FROM Test WHERE id = ?' , function ( err , stmt ){ if ( err ) throw err ; // do something with the statement }); Execute a Statement \u00b6 The execution of a prepared statement is similar to the direct statement execution. The first parameter of exec function is an array with positional parameters. stmt . exec ([ 16 ], function ( err , rows ) { if ( err ) throw err ; console . log ( \"Rows: \" , rows ); }); Execute a Batch Statement \u00b6 The execution of a prepared batch statement is similar to the direct statement execution. The first parameter of execBatch function is an array with positional parameters. var stmt = conn . prepare ( \"INSERT INTO Customers(ID, NAME) VALUES(?, ?)\" ); stmt . execBatch ([[ 1 , 'Company 1' ], [ 2 , 'Company 2' ]], function ( err , rows ) { if ( err ) throw err ; console . log ( \"Rows: \" , rows ); }); Execute a Query \u00b6 The execution of a prepared query is similar to the direct statement execution. The first parameter of execQuery function is an array with positional parameters. var stmt = conn . prepare ( \"SELECT * FROM Customers WHERE ID >= ? AND ID < ?\" ); stmt . execQuery ([ 100 , 200 ], function ( err , rs ) { if ( err ) throw err ; var rows = []; while ( rs . next ()) { rows . push ( rs . getValues ()); } console . log ( \"Rows: \" , rows ); }); Drop Statement \u00b6 stmt . drop ( function ( err ) { if ( err ) throw err ; }); Transaction Handling \u00b6 Transactions are automatically commited. Setting autocommit to false implicitly starts a new transaction that must be explicitly committed, or rolled back. Commit a Transaction \u00b6 conn . setAutoCommit ( false ); // Execute some statements conn . commit ( function ( err ) { if ( err ) throw err ; console . log ( 'Transaction commited.' ); }); Rollback a Transaction \u00b6 conn . setAutoCommit ( false ); // Execute some statements conn . rollback ( function ( err ) { if ( err ) throw err ; console . log ( 'Transaction rolled back.' ); }); Resources \u00b6 SAP HANA Documentation","title":"@sap/hana-client"},{"location":"apis/hana-client/#saphana-client","text":"This is the official Node.js driver for SAP HANA . It is used to connect, issue SQL queries, and obtain result sets.","title":"@sap/hana-client"},{"location":"apis/hana-client/#install","text":"npm install @sap/hana-client","title":"Install"},{"location":"apis/hana-client/#prerequisites","text":"This driver communicates with the native HANA libraries, and thus requires platform-specific native binaries. The official hosted version includes precompiled libraries for Linux, Windows and Mac OS X. The @sap/hana-client driver supports node.js 4.x, 6.x, 8.x, 10.x and 12.x.","title":"Prerequisites"},{"location":"apis/hana-client/#help-guide","text":"The SAP HANA Node.js Driver help guide and API reference can be found on help.sap.com .","title":"Help Guide"},{"location":"apis/hana-client/#getting-started","text":"var hana = require ( '@sap/hana-client' ); var conn = hana . createConnection (); var conn_params = { serverNode : 'myserver:30015' , uid : 'system' , pwd : 'Password123' }; conn . connect ( conn_params , function ( err ) { if ( err ) throw err ; conn . exec ( 'SELECT Name, Description FROM Products WHERE id = ?' , [ 301 ], function ( err , result ) { if ( err ) throw err ; console . log ( 'Name: ' , result [ 0 ]. Name , ', Description: ' , result [ 0 ]. Description ); // output --> Name: Tee Shirt, Description: V-neck conn . disconnect (); }) });","title":"Getting Started"},{"location":"apis/hana-client/#establish-a-database-connection","text":"","title":"Establish a database connection"},{"location":"apis/hana-client/#connecting","text":"A database connection object is created by calling createConnection . The connection is established by calling the connection object's connect method, and passing in an object representing connection parameters.","title":"Connecting"},{"location":"apis/hana-client/#example-connecting-over-tcpip","text":"conn . connect ({ host : 'myserver' , port : '30015' , uid : 'system' , pwd : 'Password123' });","title":"Example: Connecting over TCP/IP"},{"location":"apis/hana-client/#disconnecting","text":"conn . disconnect ( function ( err ) { if ( err ) throw err ; console . log ( 'Disconnected' ); });","title":"Disconnecting"},{"location":"apis/hana-client/#direct-statement-execution","text":"Direct statement execution is the simplest way to execute SQL statements. The inputs are the SQL command to be executed, and an optional array of positional arguments. The result is returned using callbacks. The type of returned result depends on the kind of statement.","title":"Direct Statement Execution"},{"location":"apis/hana-client/#ddl-statement","text":"In the case of a successful DDL Statement, nothing is returned. conn . exec ( 'CREATE TABLE Test (id INTEGER PRIMARY KEY, msg VARCHAR(128))' , function ( err , result ) { if ( err ) throw err ; console . log ( 'Table Test created!' ); });","title":"DDL Statement"},{"location":"apis/hana-client/#dml-statement","text":"In the case of a DML Statement the number of affectedRows is returned. conn . exec ( \"INSERT INTO Test VALUES(1, 'Hello')\" , function ( err , affectedRows ) { if ( err ) throw err ; console . log ( 'Number of affected rows:' , affectedRows ); });","title":"DML Statement"},{"location":"apis/hana-client/#query","text":"The exec function is a convenient way to completely retrieve the result of a query. In this case all selected rows are fetched and returned in the callback. conn . exec ( \"SELECT * FROM Test WHERE id < 5\" , function ( err , rows ) { if ( err ) throw err ; console . log ( 'Rows:' , rows ); }); Values in the query can be substitued with JavaScript variables by using ? placeholders in the query, and passing an array of positional arguments. conn . exec ( \"SELECT * FROM Test WHERE id BETWEEN ? AND ?\" , [ 5 , 8 ], function ( err , rows ) { if ( err ) throw err ; console . log ( 'Rows:' , rows ); });","title":"Query"},{"location":"apis/hana-client/#prepared-statement-execution","text":"","title":"Prepared Statement Execution"},{"location":"apis/hana-client/#prepare-a-statement","text":"The connection returns a statement object which can be executed multiple times. conn . prepare ( 'SELECT * FROM Test WHERE id = ?' , function ( err , stmt ){ if ( err ) throw err ; // do something with the statement });","title":"Prepare a Statement"},{"location":"apis/hana-client/#execute-a-statement","text":"The execution of a prepared statement is similar to the direct statement execution. The first parameter of exec function is an array with positional parameters. stmt . exec ([ 16 ], function ( err , rows ) { if ( err ) throw err ; console . log ( \"Rows: \" , rows ); });","title":"Execute a Statement"},{"location":"apis/hana-client/#execute-a-batch-statement","text":"The execution of a prepared batch statement is similar to the direct statement execution. The first parameter of execBatch function is an array with positional parameters. var stmt = conn . prepare ( \"INSERT INTO Customers(ID, NAME) VALUES(?, ?)\" ); stmt . execBatch ([[ 1 , 'Company 1' ], [ 2 , 'Company 2' ]], function ( err , rows ) { if ( err ) throw err ; console . log ( \"Rows: \" , rows ); });","title":"Execute a Batch Statement"},{"location":"apis/hana-client/#execute-a-query","text":"The execution of a prepared query is similar to the direct statement execution. The first parameter of execQuery function is an array with positional parameters. var stmt = conn . prepare ( \"SELECT * FROM Customers WHERE ID >= ? AND ID < ?\" ); stmt . execQuery ([ 100 , 200 ], function ( err , rs ) { if ( err ) throw err ; var rows = []; while ( rs . next ()) { rows . push ( rs . getValues ()); } console . log ( \"Rows: \" , rows ); });","title":"Execute a Query"},{"location":"apis/hana-client/#drop-statement","text":"stmt . drop ( function ( err ) { if ( err ) throw err ; });","title":"Drop Statement"},{"location":"apis/hana-client/#transaction-handling","text":"Transactions are automatically commited. Setting autocommit to false implicitly starts a new transaction that must be explicitly committed, or rolled back.","title":"Transaction Handling"},{"location":"apis/hana-client/#commit-a-transaction","text":"conn . setAutoCommit ( false ); // Execute some statements conn . commit ( function ( err ) { if ( err ) throw err ; console . log ( 'Transaction commited.' ); });","title":"Commit a Transaction"},{"location":"apis/hana-client/#rollback-a-transaction","text":"conn . setAutoCommit ( false ); // Execute some statements conn . rollback ( function ( err ) { if ( err ) throw err ; console . log ( 'Transaction rolled back.' ); });","title":"Rollback a Transaction"},{"location":"apis/hana-client/#resources","text":"SAP HANA Documentation","title":"Resources"},{"location":"apis/hana-client/CHANGELOG/","text":"Hana Client 2.4.x Drivers \u00b6 Version 2.4.196 \u00b6 Changes: \u00b6 Issue Number 246837: node.js process crashes while executing a statement created by Stream.createProcStatement() when connection is closed. Issue Number 245618: Application crashes with 'Check failed: IsGlobalEmpty()'. Issue Number 244631: Fix Memory leaks caused by warnings. Underlying SQLDBC changes: \u00b6 Issue Number 244599: Long-running plan execution cannot be canceled. Version 2.4.194 \u00b6 Changes: \u00b6 Issue Number 239769: Using HanaLobStream produced an incorrect streaming result of NULL value. Underlying SQLDBC changes: \u00b6 Issue Number 244509: The wrong error message was displayed when the cseKeyStorePassword property was missing Issue Number 237977: When bulk fetching rows into buffers from a ResultSet, the driver may have returned success when an error occurred while fetching data. Issue Number 236457: There were several SQLDBC tracing issues with flushing disabled and trace only on error Issue Number 241887: VARCHARMODE session variable was not visible using the ClientInfo interface when connecting with ABAPVARCHARMODE=1 Version 2.4.191 \u00b6 Changes: \u00b6 Issue Number 242230: Possible crash on queries with TEXT columns Underlying SQLDBC changes: \u00b6 Issue Number 243053: When specifying HOSTNAME environment variable and using both JDBC and SQLDBC-based drivers to connect with SecureStore entries, or Client Side Encryption operations, the JDBC operations could have failed Issue Number 240995: Reading BLOB longer than SQLDBC packet size limit resulted in silent truncation Issue Number 238492: There was no way for S/4 HANA to check if all internal connections for routing were valid on a distributed system Version 2.4.186 \u00b6 Underlying SQLDBC changes: \u00b6 Issue Number 243922: WebSockets would have only reported 'HTTP Exception' from HTTP errors Issue Number 236729: HANA Client for Linux x86_64 was not backwards compatible with Red Hat Enterprise Linux 5 Version 2.4.182 \u00b6 Changes: \u00b6 Bug 236802: SQLDBC 2.4.132 and later may infinitely loop on reading finished NCLOB into a more than large enough UCS2 destination buffer if the payload contains non-BMP characters Version 2.4.177 \u00b6 Changes: \u00b6 Bug: 233849 - [node] The ResultSet object could be prematurely freed by node.js GC Version 2.4.171 \u00b6 Changes: \u00b6 Bug: 233849 - [node] fix heap-use-after-free Underlying SQLDBC changes: \u00b6 Bug: 233843 - [SQLDBC] SNI is not set correctly when sslValidateCertificate is false Bug: 231977 - [SQLDBC] ALTER CLIENTSIDE ENCRYPTION COLUMN KEY ADD KEYCOPY ENCRYPTED WITH KEYPAIR fails with error -10429: Encryption of Column Encryption Key failed: Failed to create temporary Key ID table Bug: 231823 - [SQLDBC] Corrupted debug trace Version 2.4.167 \u00b6 Underlying SQLDBC changes: \u00b6 Bug: 233843 - [SQLDBC] SNI is not set correctly when sslValidateCertificate is false Bug: 228317 - [SQLDBC] Audit log APPLICATION_USER_NAME column is single character on slave node and it works fine on master node Version 2.4.162 \u00b6 Underlying SQLDBC changes: \u00b6 Bug: 230135 - [SQLDBC] SQLDBC will now trace the initial connection reply packet Bug: 229397 - [SQLDBC] Fixed incorrect reporting of rows-affected for LOB datatype Bug: 228712 - [SQLDBC] DBSL could have given a Secure store error: Timeout waiting for the secure store access lock Version 2.4.155 \u00b6 Underlying SQLDBC changes: \u00b6 Bug: 228735 - [SQLDBC] Unintialized scalar value in Connection Bug: 226661 - [SQLDBC] Client not work well with deferred_lob_writing ON Version 2.4.154 \u00b6 Changes: \u00b6 Bug: 225625 - [node] \"stderr maxBuffer length exceeded\" error when deploying an mtar to CF Underlying SQLDBC changes: \u00b6 Bug: 220794 - [SQLDBC] Enable frequent TCP keepalive probes Version 2.4.153 \u00b6 Changes: \u00b6 Bug: 221808 - [node] mdx get_axisinfo return garbage data Underlying SQLDBC changes: \u00b6 Bug: 225784 - [SQLDBC] Crash when OOM during error reporting Bug: 224703 - [SQLDBC] Send networkGroup in DBConnectInfo Version 2.4.151 \u00b6 Underlying SQLDBC changes: \u00b6 Bug: 225299 - [SQLDBC] Show tracing category & level at start of restarted trace files Bug: 224855 - [SQLDBC] Windows trace file archiving stop at first copy Bug: 224764 - [SQLDBC] crash at: time::Transaction::xa_remote_rollback - Assertion failed: is_global_coordinator_ Bug: 223866 - [SQLDBC] Include original value in conversion failure situations Bug: 223751 - [SQLDBC] Remove RANGE_RESTRICTION test against CE server Bug: 192870 - [SQLDBC] Support returning TIMESTAMP with 'T' seperator instead of space (like ISO 8601) Version 2.4.144 (HANA 2.0 SPS03 Rev 37.02) \u00b6 Changes: \u00b6 Bug: 217819 - [node] getColumnInfo on stored procedure result: accumulates column infos after multiple executions Underlying SQLDBC changes: \u00b6 Bug: 223345 - [SQLDBC] Adjust/remove SQLDBC tests on master due to XSEngine removal Bug: 218913 - [SQLDBC] Support HTTP CONNECT Proxy connections Bug: 218677 - [SQLDBC] Server-side WebSocket pings disconnect client Version 2.4.142 (HANA 2.0 SPS04 Rev 41) \u00b6 Changes: \u00b6 Bug: 221035 - [node] Wrong results for Node.js client with option rowsAsArray Underlying SQLDBC changes: \u00b6 Bug: 221067 - [SQLDBC] Detect when connected to a cloud edition server Bug: 220794 - [SQLDBC] Enable frequent TCP keepalive probes Bug: 218956 - [SQLDBC] SQLDBC pass to a null value to hana server Bug: 218917 - [SQLDBC] Error -10333 when SAPR3 prepare call with IN ITAB Bug: 196975 - [SQLDBC] UCS-2 non-BMP (U+10000) conversions to UTF-8 are incorrect Bug: 177745 - [SQLDBC] improve SQLDBC handling of exceptions and OOM Version 2.4.139 (HANA 2.0 SPS03 Rev037.01) \u00b6 Changes \u00b6 Bug: 219118 - [node] Improve performance of fetching data from date, time, timestamp columns Bug: 217395 - [node] need a way to check if output parameter is null and get its length Underlying SQLDBC changes \u00b6 Bug: 215654 - [SQLDBC] Invalid number of row counts returned (0, expected 4) Bug: 213867 - [SQLDBC] Columns which appear after the encrypted column in the SELECT list do not have the correct length Bug: 117546 - [SQLDBC] DBACOCKPIT SQLDBC trace integration issue Version 2.4.126 (SP04 Takt 12, Rev 40) \u00b6 Changes \u00b6 Bug: 210467 - [node] Value of inout clob procedure parameter lost Bug: 210265 - [node] HanaProcStatement does not close result sets Bug: 208719 - [node] Batch inserts with null value leading to data corruption Underlying SQLDBC changes \u00b6 Bug: 212792 - [SQLDBC] Unexpected numeric overflow Bug: 212269 - [SQLDBC] Support 0x80 Proxy Authentication for Cloud Connector Bug: 210821 - [SQLDBC] Client crashes during connect after self-assignment of SQLDBC_ConnectProperties object Bug: 210818 - [SQLDBC] Access violation while inserting empty string Bug: 210341 - [SQLDBC] The SP04 converter for INTEGRAL to ASCII conversion is almost 2 times slower than the SP03 one Bug: 210340 - [SQLDBC] The SP04 converter for REAL to ASCII conversion is 3 times slower than the SP03 one Bug: 208245 - [SQLDBC] FDA partition-aware routing ignored partition information update Bug: 201548 - [SQLDBC] secondary connections need to send SessionContext - required for workload replay Bug: 177745 - [SQLDBC] improve SQLDBC handling of exceptions and OOM Hana Client 2.3.x Drivers \u00b6 Version 2.3.152 \u00b6 Changes \u00b6 Bug: 214413 - [node] NVARCHAR columns truncated by Connection.exec Bug: 210467 - [node] Value of inout clob procedure parameter lost Bug: 210265 - [node] HanaProcStatement does not close result sets Bug: 200139 - [node] Segmentation fault errors in Node.js client Bug: 193735 - [node] executeBatch incorrectly inserting invalid data Underlying SQLDBC changes \u00b6 Bug: 212269 - [SQLDBC] Support 0x80 Proxy Authentication for Cloud Connector Bug: 210818 - [SQLDBC] Access violation while inserting empty string Bug: 208370 - [SQLDBC] SP03/04 is 10 times slower than SP02 on fetching data from numeric columns when the data is bound with CHAR Bug: 208245 - [SQLDBC] FDA partition-aware routing ignored partition information update Version 2.3.144 \u00b6 Changes \u00b6 Bug: 170890 - [node] Feature request: Introduce a way to configure query timeout Bug: 208719 - [node] Batch inserts with null value leading to data corruption Bug: 207730 - [node] Data corruption (decimal data type) with execBatch Bug: 202061 - [node] nodejs is killed by @sap/hana-client Underlying SQLDBC changes: \u00b6 Bug: 212269 - [SQLDBC] Support 0x80 Proxy Authentication for Cloud Connector Bug: 209416 - [SQLDBC] Much slower to fetch a value from a bool column than from a tinyint column Bug: 207692 - [SQLDBC] [dbcapi] SQL strings are always assumed to be ASCII encoding Bug: 205486 - [SQLDBC] Implicit XA join at prepare time Bug: 204378 - [SQLDBC] Big endian client or server corruption during range partitioning Bug: 180821 - [SQLDBC] improve sqldbc tracing Version 2.3.134 \u00b6 Note: This version includes node 10 support. Changes \u00b6 Bug: 207088 - [node] hana-client throws error when inserting UTF8 value into NCLOB column Bug: 203323 - [node] crash in ~executeBaton Bug: 202025 - [node] crash in hana-client master snapshot during HRTT-service component tests Bug: 201692 - [node] GetParameterValues() may return different values for queries executed using exec and execQuery Bug: 200139 - [node] Segmentation fault errors in Node.js client Bug: 197590 - [node] AddressSanitizer: heap-buffer-overflow in statement.cpp:644 Underlying SQLDBC changes \u00b6 Bug: 206695 - [SQLDBC] Always send ClientInfo APPLICATION / APPLICATIONUSER in ClientInfo Bug: 205558 - [SQLDBC] Cannot set isolation level as described in docs Bug: 205486 - [SQLDBC] Implicit XA join at prepare time Bug: 205420 - [SQLDBC] SQL code: -10923 occurred while accessing table USR01 Bug: 202117 - [SQLDBC] Websocket connection to port with no listener hangs on Windows Bug: 201991 - [SQLDBC] Change limit of READLOBREQUEST requested chunk size to be at most packet size - 1KB instead of 1KB*124 Bug: 201333 - [SQLDBC] Always cache cookies for all authentication methods Bug: 201180 - [SQLDBC] Coverity failure - CID 175085 - dereference after null check Bug: 199762 - [SQLDBC] result set and parameters incorrect after prepare, alter, routed execute Bug: 197565 - [SQLDBC] Support 32bit fetchsize Bug: 188197 - [SQLDBC] specifying hosts for multiple unrelated systems can cause issues for multiple connections Version 2.3.130 \u00b6 Changes \u00b6 Bug: 201050 - [node] HANA client crashes if ResultSet is closed while async next is running Bug: 198780 - [node] Prepare happens twice for same statement execution (non distributed), impacts performance Bug: 198599 - [node] empty DATE & TIMESTAMP causes crash/memory leak with prepared statements Bug: 198300 - [node] executeQuery crashes if no parameters passed in Bug: 197989 - [node] Node crashes with core dumps were found Bug: 197914 - [node] nodejs application server memory increases even after drop and disconnect Bug: 196801 - [node] Node driver crashes in getParameterValue Bug: 186681 - [node] Fatal error when fetching a CLOB value of ~500MB Underlying SQLDBC changes \u00b6 Bug: 199481 - [SQLDBC] Cursor holdability not correctly sent to the server Bug: 199218 - [SQLDBC] Certain years cause DATE values to be incorrectly returned as NULL with DFV=1 Bug: 197444 - [SQLDBC] CSE test failures report misleading error messages Bug: 197279 - [SQLDBC] Unable to lock newly created table with active distributed statement routing Bug: 188197 - [SQLDBC] specifying hosts for multiple unrelated systems can cause issues for multiple connections Bug: 184551 - [SQLDBC] fix Performance regression Bug: 183778 - [SQLDBC] CESU-8 -> UTF-8 conversions don't work, CESU-8 isn't used in the SQLDBC protocol Bug: 163009 - [SQLDBC] SQLDBC client can send out-of-date StatementContext resulting in server internal errors or incorrect transaction behaviour Version 2.3.123 \u00b6 Changes \u00b6 Bug: 196993 - [node] - Segmentation fault in stmt.getRowStatus() Bug: 196811 - [node] - AddressSanitizer: heap-use-after-free in getResultSet() Underlying SQLDBC changes \u00b6 Bug: 196981 - [SQLDBC] - Remove at the end of trace file Bug: 196540 - [SQLDBC] - SystemReplicationIntegrationTest testReconnectBehaviour, testBackOffTimerRetry sporadic failures Bug: 195187 - [SQLDBC] - enabling autocommit with write txn \"Invalid transaction state\" error Bug: 197118 - [SQLDBC] - Crash in SQLDBC::Connection::updateTopology Bug: 189159 - [SQLDBC] - Fix \"-10429: Failed to open the key store file. Opening of the Keystore failed.\" Version 2.3.122 \u00b6 Changes \u00b6 Bug: 179616 - [node] - Stream.createStatement does not support parameter bindings with an array of arrays Bug: 194801 - [node] - NCLOB output parameter truncated Bug: 191764 - [node] - crash in hana Node driver Bug: 178638 - [node] - Expose named constants for Isolation Level Bug: 186986 - [node] - HanaProcStatement: add possibility to have ColumnInfo on output tables (both output table parameters and SELECT results) Bug: 183202 - [node] - Column info does not distinguish between column name and alias Version 2.3.121 \u00b6 Changes \u00b6 Bug: 185046 - [node] - Batch insert: specify which group has been inserted successfully and which not Underlying SQLDBC changes \u00b6 Bug: 182656 - [SQLDBC] - [Decimal38, DFV=8] Performance regression (30%) in benchCppPsaloadBarrier.py (elapsed time) Version 2.3.120 \u00b6 Changes \u00b6 Bug: 194578 - [node] - @sap/hana-client could not be installed on Mac OS X 10.13.6 - node-gyp build fatal error: 'thread' file not found Version 2.3.119 (Rev 33) \u00b6 Underlying SQLDBC changes \u00b6 Bug: 189502 - [SQLDBC] - core file produced if the OS400 version of R3trans connects to the database using the HDB client Version 2.3.118-ms \u00b6 Changes \u00b6 Bug: 190151 - [node] - node driver returns incorrect values for large DECIMAL and SMALLDECIMAL types Underlying SQLDBC changes \u00b6 Bug: 194315 - [SQLDBC] - Crash at PreparedStatement::getObject() if passed negative param-index Bug: 191790 - [SQLDBC] - Wrong function name when using TO_VARCHAR function in GENERATED ALWAYS AS clause Bug: 193427 - [SQLDBC] - Non terminated input string access overflow Version 2.3.117 (Rev 33 RC3) \u00b6 Underlying SQLDBC changes \u00b6 Bug: 189511 - [SQLDBC] - Hierarchy Warning as error Version 2.3.115 (Rev 33 RC2) \u00b6 Changes \u00b6 Bug: 187823 - [node] - Error message from query is truncated Bug: 186963 - [node] - Procedures, output parameters with unicode characters not readable Bug: 186399 - [node] - Error when using DDL Statement in dynamic SQL Bug: 184557 - [node] - node driver memory leak Bug: 186462 - [node] - executeBatch doesn't return error if callback function isn't provided Underlying SQLDBC changes \u00b6 Bug: 184711 - [SQLDBC] Vulnerabilities in trace files Bug: 186830 - [SQLDBC] Coverity 33397, 171110 Version 2.3.112 \u00b6 Note: This version contains the dependent module debug@3.1.0 and ms@2.0.0 to address security issues in those modules. Changes \u00b6 Bug 184286 - Coverity CID 169674 - Resource leak in object Bug 182045 - Preparing SQL statement returns error \"Unhandled SQLDBC type '32'\" Underlying SQLDBC changes \u00b6 Bug 189083 - FDA fetch next after warning Bug 189856 - error when AA hint based routing to down secondary or bad VolumeIds Bug 184710 - [hdbkeystore] Imported key pairs are not validated Bug 172302 - conversion error on bulk execute should fail all rows to match server behavior Bug 184128 - [SQLDBC] Decrypted data and keys are not wiped Bug 186707 - HE2E:H2SP4:Trying to encrypt a decimal column gets error Version 2.3.108 \u00b6 Changes \u00b6 Bug: 183789 - hana_client crashes when single sign-on attempted Bug: 186603 - Crash in hana_node driver when using ResultSet.prototype.getData() for a NULL value Underlying SQLDBC changes \u00b6 Bug: 185978 - Invalid numeric value for parameter/column (3) source type DECIMAL, target type FIXED16 Bug: 184670 - Batch insert with decimals does not work Bug: 186968 - SQLDBC-based clients on Windows and 32-bit Linux platforms use an invalid value for a Randomly encrypted NULL for a TIMESTAMP column Bug: 172302 - conversion error on bulk execute should fail all rows to match server behavior Bug: 183982 - [SQLDBC] Allow override of APPLICATION / APPLICATIONUSER Bug: 185435 - SQL Error \"-10901 No space left in request packet\" during FOR ALL ENTRIES FDA Bug: 182050 - large clientinfo that fills packet causes client crash or failures Bug: 184700 - node.js driver ignored databasename connect parameter Bug: 184107 - [SQLDBC] WebSockets does not have a thread to return responses for ping/pong Bug: 165561 - Netweaver workprocess crashes from SQLDBC Version 2.3.106 \u00b6 Changes \u00b6 Bug: 184700 - node.js driver ignored databasename connect parameter Version 2.3.102 \u00b6 Changes \u00b6 Bug: 184700 [nodejs] - Replace SQLDBC connection parameter serverDb with databasename Bug: 184409 [nodejs] - HXE: SQL error while accessing data base explorer from cockpit UI Bug: 182956 [SQLDBC] - SQLDBC should clear all write lobs before silent re-execution for stale metadata Bug: 183012 [SQLDBC] - Support siteType connection property in the SQLDBC driver. Bug: 183521 [SQLDBC] - StatementContext FlagSet now tests appropriate bit for A/A fallback Bug: 180790 [SQLDBC] - Add socket timeout support Bug: 182950 [SQLDBC] - Implement support for Client-side Encrypted Decimal38 Bug: 182230 [SQLDBC] - dfv8 error source expectation change Bug: 182476 [SQLDBC] - Fetching a BOOLEAN value as string Host Type returns \"TRUE\" or \"FALSE\" instead of \"1\" or \"0\" Bug: 181236 [nodejs] - Executing a DELETE statement returns undefined if the data doesn't exist, and make default CharSet=UTF-8 for node driver The above bug fix also fixes the following bug reports: - Bug: 183239 - Unicode problem - HANA node.js client return wrong results \"???\" - Bug: 183364 - Error: result set has not been fetched yet when selecting an NCHAR column - Bug: 183368 - Unicode characters not readable when using a stream Version 2.3.99 \u00b6 Changes \u00b6 Bug: 172007 - WebSockets cannot reliably detect socket failures for reconnect logic Bug: 180692 - enable TLS 1.2 in openssl versions pre 1.1.0 Bug: 181793 - [SQLDBC] WebSockets do not support ping/pong for DBaaS Version 2.3.92-rel \u00b6 Changes \u00b6 Bug: 179911 - Array type returned by Connection.execute is truncated Bug: 179717 - node.js client crashes the app if a JS error happens in parallel Bug: 179718 - a procedure call via createProcStatement doesn't include the object for scalar results Bug: 178819 - Cannot fetch spatial types using stream Version 2.3.78 \u00b6 Changes \u00b6 Bug: 178841 - Resultset.getValues returns incorrect data for double/real/float Version 2.3.75 \u00b6 Changes \u00b6 Bug: 178226 - MDX SELECT returns no results Version 2.3.67 \u00b6 Note: This version contains HappyMake-built binaries for Linux x64. Changes \u00b6 Bug: 176354 - prepared-statement.exec doesn't support parameter bindings with an array of arrays Bug: 176359 - result objects of procedure calls are different in node-hdb vs. hana-client Bug: 176361 - node-hdb treats undefined in parameters bindings as null, hana-client reports an error Bug: 176397 - Process exits unexpectedly when 'setWarningCallback' is used Bug: 174396 - DVF8 SQLDBC_SQLTypes for ODBC and DBCAPI Version 2.3.65-ms \u00b6 Changes \u00b6 Bug: 175368 - Authentication fails if password contains a semicolon (;) Bug: 176053 - instanceNumber connection property not supported Bug: 175381 - [DBCAPI] Lob data could be truncated Bug: 174309 - [SQLDBC] detect ResultSetPart overrun (DEV_ASSERTS in ResultDataIterator needed to be converted to runtime errors to prevent undefined behavior due to incorrect RESULTSET parts) Version 2.3.63-ms \u00b6 Changes \u00b6 Bug: 175602 - Error when inserting zero-length stream into HANA through node client Bug: 175368 - Authentication fails if password contains a semicolon Bug: 175712 - Intermittent failures when inserting blobs into HANA through streams Version 2.3.59-ms \u00b6 Changes \u00b6 Bug: 170723 - crash in dbcapi_get_function_code Bug: 170934 - Failed Client Conti: node.js giving regex_error Bug: 174161 - [DBCAPI] - DBCAPI reuses previous ResultSet bindings when fetching more results for a multi-resultset query Bug: 173705 - garbage collector causes sporadic crashes Enhancement: PPC BE support Enhancement: Node 8 support Version 2.3.41 \u00b6 Changes \u00b6 Bug: 169885 - Connection pooling Version 2.3.40 \u00b6 Changes \u00b6 Bug: 169668 - wrong value returned from ResultSet.getValue(N) Bug: 169674 - Main thread blocks when destroying a statement through garbage collector Bug: 168663 - Cannot unset client info Version 2.3.39 (Nexus Release, Takt5) \u00b6 Changes \u00b6 Bug: 160073 - Cannot create TLS-encrypted connection using certificate string Version 2.3.38 \u00b6 Changes \u00b6 Bug: 167516 - Crash if integer input parameter is given an empty string Bug: 167524 - Crash when iterating an empty result set or a result set is not fully consumed Bug: 167504 - No way to specify multiple hosts for connection Bug: 167517 - Data type 53 incorrect in TypeCode.js Bug: 167531 - Cannot determine if a Connection is connected Bug: 167112 - Streaming API -- insert statement returns \"undefined\" result Version 2.3.31 \u00b6 Changes \u00b6 Bug: 162268 - statement options are not supported in statement.exec Bug: 165051 - Coverity CID 140729 - Dereference before null check Version 2.3.28 \u00b6 Changes \u00b6 Bug: 163582 - MDX SELECT is not handled properly Version 2.3.27 \u00b6 Changes \u00b6 Bug: 163070 - clientsBarrier.seq fails - node4 test crashes Bug: 163236 - Failed Client Conti: NodeJS crashing on master Bug: 163374 - node driver returns incorrect numbers for large BIGINT Bug: 163375 - node driver returns incorrect unicode strings for NCLOB Version 2.3.23 \u00b6 Changes \u00b6 Bug: 162924 - dbcapi crashes when fetching multiple resultsets Version 2.3.21 (Nexus Release, Takt 3, npm.sap.com) \u00b6 Changes \u00b6 Bug: 162265 - end() is not available out-of-the-box Hana 2 SP02 Drivers \u00b6 Version 2.2.64 \u00b6 Underling SQLDBC changes \u00b6 Bug: 181384 - [SQLDBC] - LOB data got lost in batch mode if the lob data length greater than a network packet size Bug: 182139 - [SQLDBC] - Error -10922 (200501) Write transaction already started on other connection in ABAP report Bug: 180790 - [SQLDBC] - SDA query failure due to connection timeout error -10807 (Add socket timeout support) Bug: 155895 - [SQLDBC] - Insert of timestamps as strings behaves different between cursor.execute() and cursor.executemany() Bug: 182476 - [SQLDBC] - Fetching a BOOLEAN value as string Host Type returns \\\"TRUE\\\" or \\\"FALSE\\\" instead of \\\"1\\\" or \\\"0\\\" Version 2.2.62 \u00b6 Changes \u00b6 Bug: 178226 - [node] - MDX SELECT returns no results Bug: 179911 - [node] - Array type returned by Connection.execute is truncated Bug: 176397 - [node] - Process exits unexpectedly when 'setWarningCallback' is used Bug: 175459 - [SQLDBC] - error message improvement for numeric overflow Bug: 178841 - [node] - Resultset.getValues returns incorrect data for double/real/float Bug: 178680 - [SQLDBC] - Access violation while batch-inserting BLOB-placeholder in expression Bug: 180561 - [SQLDBC] - BasisClient lacks CRASH_ASSERT_* macros Bug: 178819 - [node] - Cannot fetch spatial types using stream Underling SQLDBC changes \u00b6 Bug: 175459 - [SQLDBC] - error message improvement for numeric overflow Bug: 178680 - [SQLDBC] - Access violation while batch-inserting BLOB-placeholder in expression Bug: 180561 - [SQLDBC] - BasisClient lacks CRASH_ASSERT_* macros Version 2.2.57 \u00b6 Changes \u00b6 Bug: 175712 - [node] - Intermittent failures when inserting blobs into HANA through streams Bug: 173705 - [node] - garbage collector causes sporadic crashes Bug: 175368 - [node] - Authentication fails if password contains a semicolon (;) Bug: 176053 - [node] - instanceNumber connection property not supported Bug: 169885 - [node] - Connection pooling Underling SQLDBC changes \u00b6 Bug: 174651 - [SQLDBC] - Network compression assertions on non-rel builds on distributed system Bug: 168750 - [SQLDBC] - Many transactions were blocked by record locks right after secondary replication was registered, and record locks were never released Bug: 176544 - [SQLDBC] - testJtClientsDistributed table placement should be default Version 2.2.53 \u00b6 Changes \u00b6 Bug: 170723 - [node] - crash in dbcapi_get_function_code Bug: 169885 - [node] - Connection pooling Underling SQLDBC changes \u00b6 Bug: 170954 - [SQLDBC] - The second part can be off by a second for the timestamp output param in a procedure call Bug: 171387 - [SQLDBC] - Trace content removal too aggressive Bug: 174788 - [SQLDBC] - Statement routing not working for batch updates if 1-level part. key in the set-clause Bug: 168697 - [SQLDBC] - DLL Autocommit setting will get lost on reconnect Bug: 163336 - [SQLDBC] - General error;600 failed routed execution: anchor is switched in runtime: line 0 col 0 (at pos 0) after topology changed on SDA source site Bug: 171093 - [SQLDBC] - SQL level tracing should imply DISTRIBUTION tracing but does not Bug: 174161 - [SQLDBC] - DBCAPI reuses previous ResultSet bindings when fetching more results for a multi-resultset query Version 2.2.39 (included in Rev 24 ; 2.00.024) \u00b6 Changes \u00b6 Bug: 169668 - wrong value returned from ResultSet.getValue(N) Bug: 169674 - Main thread blocks when destroying a statement through garbage collector Bug: 168663 - Cannot unset client info Version 2.2.37 \u00b6 Changes \u00b6 Bug: 160073 - Cannot create TLS-encrypted connection using certificate string Bug: 167516 - Crash if integer input parameter is given an empty string Bug: 167524 - Crash when iterating an empty result set or a result set is not fully consumed Bug: 167504 - No way to specify multiple hosts for connection Bug: 167517 - Data type 53 incorrect in TypeCode.js Bug: 167531 - Cannot determine if a Connection is connected Bug: 160073 - Cannot create TLS-encrypted connection using certificate string Bug: 167112 - Streaming API -- insert statement returns \"undefined\" result Version 2.2.35 (included in Rev 23 ; 2.00.023) \u00b6 Changes \u00b6 Bug: 162268 - statement options are not supported in statement.exec Bug: 165051 - Coverity CID 140729 - Dereference before null check Bug: 163582 - MDX SELECT is not handled properly Bug: 163070 - clientsBarrier.seq fails - node4 test crashes Bug: 163236 - Failed Client Conti: NodeJS crashing on master Version 2.2.34 \u00b6 Changes \u00b6 Bug: 163374 - node driver returns incorrect numbers for large BIGINT Bug: 163375 - node driver returns incorrect unicode strings for NCLOB Bug: 160968 - Failed Client Conti: ADO.NET - ColumnMapping tests fail sporadically but often Version 2.2.31 \u00b6 Changes \u00b6 Bug: 162924 - dbcapi crashes when fetching multiple resultsets Version 2.2.28 (included in 2.00.022) \u00b6 Changes \u00b6 Bug: 162265 - end() is not available out-of-the-box Bug: 160083 - Writing a stream from an HTTP IncomingMessage hangs Bug: 160422 - Writing a stream that is not an instance of Readable crashes Bug: 156392 - crash in ResultSet.getValues() Bug: 159735 - Need to know total number of rows returned without fetching each one Bug: 159649 - crash in getInputParameters Bug: 160416 - Need a way to close a stream early Version 2.2.27 \u00b6 Changes \u00b6 Bug: 154982 - clients.seq fails - node tests on Windows fail with RC = 65280 Bug: 156105 - executing procedure call with CLOB output parameter very slow Bug: 156119 - How to insert data from a stream Bug: 150587 - cannot call stored procedures with named parameters Version 2.2.25 (included in 2.00.021) \u00b6 Changes \u00b6 Bug: 156388 - Readable streams are not implemented correctly Bug: 156389 - ResultSet.close() is not available as an async method Bug: 156133 - Cannot determine if a statement was dropped Bug: 156146 - INOUT parameter gets wrong value and type, depending on input parameter type Bug: 155535 - If no parameters passed to stmt.execQuery, cannot get output parameter values Bug: 156386 - ResultSet.getValues() crashes if connection was closed Bug: 153647 - wrong number of arguments in callback from exec for DDL Bug: 153657 - passing too many parameters should return an error Bug: 153674 - getParameterValue for boolean type returns invalid value Version 2.2.24 \u00b6 Changes \u00b6 Bug: 153503 - params for statement.exec (and connection.exec) should not include output parameters Bug: 153506 - Cannot get value for output parameter if no input param provided Bug: 153656 - cannot get value from inout parameter Bug: 153683 - setClientInfo() doesn't work as expected Version 2.2.22 (included in 2.00.020) \u00b6 Changes \u00b6 Bug: 152564 - Error doesn't have stack trace Version 2.2.20 (initial version) \u00b6 Changes \u00b6 Bug: 152218 - wrong number of arguments in callback of connect Bug: 150564 - \"No more result\" error Bug: 150561 - wrong number of arguments in callback from commit and rollback Bug: 150546 - crash in Connection::setClientInfo() Bug: 150165 - getParameterValue doesn't work Bug: 148776 - node.js client crashes when used in generic-pool with connections in parallel Bug: 148128 - Exception from ExecuteReader when executing select with long case block Bug: 145975 - warnings are (sometimes) fatal Bug: 145953 - APIs are too picky Bug: 145974 - Column metadata unavailable outside of the streaming interface Bug: 145971 - Need isClosed() function on a streaming ResultSet Bug: 145970 - need access to parameter metadata Bug: 145976 - data type codes do not align with protocol/node-hdb","title":"Hana Client 2.4.x Drivers"},{"location":"apis/hana-client/CHANGELOG/#hana-client-24x-drivers","text":"","title":"Hana Client 2.4.x Drivers"},{"location":"apis/hana-client/CHANGELOG/#version-24196","text":"","title":"Version 2.4.196"},{"location":"apis/hana-client/CHANGELOG/#changes","text":"Issue Number 246837: node.js process crashes while executing a statement created by Stream.createProcStatement() when connection is closed. Issue Number 245618: Application crashes with 'Check failed: IsGlobalEmpty()'. Issue Number 244631: Fix Memory leaks caused by warnings.","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes","text":"Issue Number 244599: Long-running plan execution cannot be canceled.","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24194","text":"","title":"Version 2.4.194"},{"location":"apis/hana-client/CHANGELOG/#changes_1","text":"Issue Number 239769: Using HanaLobStream produced an incorrect streaming result of NULL value.","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_1","text":"Issue Number 244509: The wrong error message was displayed when the cseKeyStorePassword property was missing Issue Number 237977: When bulk fetching rows into buffers from a ResultSet, the driver may have returned success when an error occurred while fetching data. Issue Number 236457: There were several SQLDBC tracing issues with flushing disabled and trace only on error Issue Number 241887: VARCHARMODE session variable was not visible using the ClientInfo interface when connecting with ABAPVARCHARMODE=1","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24191","text":"","title":"Version 2.4.191"},{"location":"apis/hana-client/CHANGELOG/#changes_2","text":"Issue Number 242230: Possible crash on queries with TEXT columns","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_2","text":"Issue Number 243053: When specifying HOSTNAME environment variable and using both JDBC and SQLDBC-based drivers to connect with SecureStore entries, or Client Side Encryption operations, the JDBC operations could have failed Issue Number 240995: Reading BLOB longer than SQLDBC packet size limit resulted in silent truncation Issue Number 238492: There was no way for S/4 HANA to check if all internal connections for routing were valid on a distributed system","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24186","text":"","title":"Version 2.4.186"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_3","text":"Issue Number 243922: WebSockets would have only reported 'HTTP Exception' from HTTP errors Issue Number 236729: HANA Client for Linux x86_64 was not backwards compatible with Red Hat Enterprise Linux 5","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24182","text":"","title":"Version 2.4.182"},{"location":"apis/hana-client/CHANGELOG/#changes_3","text":"Bug 236802: SQLDBC 2.4.132 and later may infinitely loop on reading finished NCLOB into a more than large enough UCS2 destination buffer if the payload contains non-BMP characters","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24177","text":"","title":"Version 2.4.177"},{"location":"apis/hana-client/CHANGELOG/#changes_4","text":"Bug: 233849 - [node] The ResultSet object could be prematurely freed by node.js GC","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24171","text":"","title":"Version 2.4.171"},{"location":"apis/hana-client/CHANGELOG/#changes_5","text":"Bug: 233849 - [node] fix heap-use-after-free","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_4","text":"Bug: 233843 - [SQLDBC] SNI is not set correctly when sslValidateCertificate is false Bug: 231977 - [SQLDBC] ALTER CLIENTSIDE ENCRYPTION COLUMN KEY ADD KEYCOPY ENCRYPTED WITH KEYPAIR fails with error -10429: Encryption of Column Encryption Key failed: Failed to create temporary Key ID table Bug: 231823 - [SQLDBC] Corrupted debug trace","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24167","text":"","title":"Version 2.4.167"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_5","text":"Bug: 233843 - [SQLDBC] SNI is not set correctly when sslValidateCertificate is false Bug: 228317 - [SQLDBC] Audit log APPLICATION_USER_NAME column is single character on slave node and it works fine on master node","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24162","text":"","title":"Version 2.4.162"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_6","text":"Bug: 230135 - [SQLDBC] SQLDBC will now trace the initial connection reply packet Bug: 229397 - [SQLDBC] Fixed incorrect reporting of rows-affected for LOB datatype Bug: 228712 - [SQLDBC] DBSL could have given a Secure store error: Timeout waiting for the secure store access lock","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24155","text":"","title":"Version 2.4.155"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_7","text":"Bug: 228735 - [SQLDBC] Unintialized scalar value in Connection Bug: 226661 - [SQLDBC] Client not work well with deferred_lob_writing ON","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24154","text":"","title":"Version 2.4.154"},{"location":"apis/hana-client/CHANGELOG/#changes_6","text":"Bug: 225625 - [node] \"stderr maxBuffer length exceeded\" error when deploying an mtar to CF","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_8","text":"Bug: 220794 - [SQLDBC] Enable frequent TCP keepalive probes","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24153","text":"","title":"Version 2.4.153"},{"location":"apis/hana-client/CHANGELOG/#changes_7","text":"Bug: 221808 - [node] mdx get_axisinfo return garbage data","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_9","text":"Bug: 225784 - [SQLDBC] Crash when OOM during error reporting Bug: 224703 - [SQLDBC] Send networkGroup in DBConnectInfo","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24151","text":"","title":"Version 2.4.151"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_10","text":"Bug: 225299 - [SQLDBC] Show tracing category & level at start of restarted trace files Bug: 224855 - [SQLDBC] Windows trace file archiving stop at first copy Bug: 224764 - [SQLDBC] crash at: time::Transaction::xa_remote_rollback - Assertion failed: is_global_coordinator_ Bug: 223866 - [SQLDBC] Include original value in conversion failure situations Bug: 223751 - [SQLDBC] Remove RANGE_RESTRICTION test against CE server Bug: 192870 - [SQLDBC] Support returning TIMESTAMP with 'T' seperator instead of space (like ISO 8601)","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24144-hana-20-sps03-rev-3702","text":"","title":"Version 2.4.144 (HANA 2.0 SPS03 Rev 37.02)"},{"location":"apis/hana-client/CHANGELOG/#changes_8","text":"Bug: 217819 - [node] getColumnInfo on stored procedure result: accumulates column infos after multiple executions","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_11","text":"Bug: 223345 - [SQLDBC] Adjust/remove SQLDBC tests on master due to XSEngine removal Bug: 218913 - [SQLDBC] Support HTTP CONNECT Proxy connections Bug: 218677 - [SQLDBC] Server-side WebSocket pings disconnect client","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24142-hana-20-sps04-rev-41","text":"","title":"Version 2.4.142 (HANA 2.0 SPS04 Rev 41)"},{"location":"apis/hana-client/CHANGELOG/#changes_9","text":"Bug: 221035 - [node] Wrong results for Node.js client with option rowsAsArray","title":"Changes:"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_12","text":"Bug: 221067 - [SQLDBC] Detect when connected to a cloud edition server Bug: 220794 - [SQLDBC] Enable frequent TCP keepalive probes Bug: 218956 - [SQLDBC] SQLDBC pass to a null value to hana server Bug: 218917 - [SQLDBC] Error -10333 when SAPR3 prepare call with IN ITAB Bug: 196975 - [SQLDBC] UCS-2 non-BMP (U+10000) conversions to UTF-8 are incorrect Bug: 177745 - [SQLDBC] improve SQLDBC handling of exceptions and OOM","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-24139-hana-20-sps03-rev03701","text":"","title":"Version 2.4.139 (HANA 2.0 SPS03 Rev037.01)"},{"location":"apis/hana-client/CHANGELOG/#changes_10","text":"Bug: 219118 - [node] Improve performance of fetching data from date, time, timestamp columns Bug: 217395 - [node] need a way to check if output parameter is null and get its length","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_13","text":"Bug: 215654 - [SQLDBC] Invalid number of row counts returned (0, expected 4) Bug: 213867 - [SQLDBC] Columns which appear after the encrypted column in the SELECT list do not have the correct length Bug: 117546 - [SQLDBC] DBACOCKPIT SQLDBC trace integration issue","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-24126-sp04-takt-12-rev-40","text":"","title":"Version 2.4.126 (SP04 Takt 12, Rev 40)"},{"location":"apis/hana-client/CHANGELOG/#changes_11","text":"Bug: 210467 - [node] Value of inout clob procedure parameter lost Bug: 210265 - [node] HanaProcStatement does not close result sets Bug: 208719 - [node] Batch inserts with null value leading to data corruption","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_14","text":"Bug: 212792 - [SQLDBC] Unexpected numeric overflow Bug: 212269 - [SQLDBC] Support 0x80 Proxy Authentication for Cloud Connector Bug: 210821 - [SQLDBC] Client crashes during connect after self-assignment of SQLDBC_ConnectProperties object Bug: 210818 - [SQLDBC] Access violation while inserting empty string Bug: 210341 - [SQLDBC] The SP04 converter for INTEGRAL to ASCII conversion is almost 2 times slower than the SP03 one Bug: 210340 - [SQLDBC] The SP04 converter for REAL to ASCII conversion is 3 times slower than the SP03 one Bug: 208245 - [SQLDBC] FDA partition-aware routing ignored partition information update Bug: 201548 - [SQLDBC] secondary connections need to send SessionContext - required for workload replay Bug: 177745 - [SQLDBC] improve SQLDBC handling of exceptions and OOM","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#hana-client-23x-drivers","text":"","title":"Hana Client 2.3.x Drivers"},{"location":"apis/hana-client/CHANGELOG/#version-23152","text":"","title":"Version 2.3.152"},{"location":"apis/hana-client/CHANGELOG/#changes_12","text":"Bug: 214413 - [node] NVARCHAR columns truncated by Connection.exec Bug: 210467 - [node] Value of inout clob procedure parameter lost Bug: 210265 - [node] HanaProcStatement does not close result sets Bug: 200139 - [node] Segmentation fault errors in Node.js client Bug: 193735 - [node] executeBatch incorrectly inserting invalid data","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_15","text":"Bug: 212269 - [SQLDBC] Support 0x80 Proxy Authentication for Cloud Connector Bug: 210818 - [SQLDBC] Access violation while inserting empty string Bug: 208370 - [SQLDBC] SP03/04 is 10 times slower than SP02 on fetching data from numeric columns when the data is bound with CHAR Bug: 208245 - [SQLDBC] FDA partition-aware routing ignored partition information update","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23144","text":"","title":"Version 2.3.144"},{"location":"apis/hana-client/CHANGELOG/#changes_13","text":"Bug: 170890 - [node] Feature request: Introduce a way to configure query timeout Bug: 208719 - [node] Batch inserts with null value leading to data corruption Bug: 207730 - [node] Data corruption (decimal data type) with execBatch Bug: 202061 - [node] nodejs is killed by @sap/hana-client","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_16","text":"Bug: 212269 - [SQLDBC] Support 0x80 Proxy Authentication for Cloud Connector Bug: 209416 - [SQLDBC] Much slower to fetch a value from a bool column than from a tinyint column Bug: 207692 - [SQLDBC] [dbcapi] SQL strings are always assumed to be ASCII encoding Bug: 205486 - [SQLDBC] Implicit XA join at prepare time Bug: 204378 - [SQLDBC] Big endian client or server corruption during range partitioning Bug: 180821 - [SQLDBC] improve sqldbc tracing","title":"Underlying SQLDBC changes:"},{"location":"apis/hana-client/CHANGELOG/#version-23134","text":"Note: This version includes node 10 support.","title":"Version 2.3.134"},{"location":"apis/hana-client/CHANGELOG/#changes_14","text":"Bug: 207088 - [node] hana-client throws error when inserting UTF8 value into NCLOB column Bug: 203323 - [node] crash in ~executeBaton Bug: 202025 - [node] crash in hana-client master snapshot during HRTT-service component tests Bug: 201692 - [node] GetParameterValues() may return different values for queries executed using exec and execQuery Bug: 200139 - [node] Segmentation fault errors in Node.js client Bug: 197590 - [node] AddressSanitizer: heap-buffer-overflow in statement.cpp:644","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_17","text":"Bug: 206695 - [SQLDBC] Always send ClientInfo APPLICATION / APPLICATIONUSER in ClientInfo Bug: 205558 - [SQLDBC] Cannot set isolation level as described in docs Bug: 205486 - [SQLDBC] Implicit XA join at prepare time Bug: 205420 - [SQLDBC] SQL code: -10923 occurred while accessing table USR01 Bug: 202117 - [SQLDBC] Websocket connection to port with no listener hangs on Windows Bug: 201991 - [SQLDBC] Change limit of READLOBREQUEST requested chunk size to be at most packet size - 1KB instead of 1KB*124 Bug: 201333 - [SQLDBC] Always cache cookies for all authentication methods Bug: 201180 - [SQLDBC] Coverity failure - CID 175085 - dereference after null check Bug: 199762 - [SQLDBC] result set and parameters incorrect after prepare, alter, routed execute Bug: 197565 - [SQLDBC] Support 32bit fetchsize Bug: 188197 - [SQLDBC] specifying hosts for multiple unrelated systems can cause issues for multiple connections","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23130","text":"","title":"Version 2.3.130"},{"location":"apis/hana-client/CHANGELOG/#changes_15","text":"Bug: 201050 - [node] HANA client crashes if ResultSet is closed while async next is running Bug: 198780 - [node] Prepare happens twice for same statement execution (non distributed), impacts performance Bug: 198599 - [node] empty DATE & TIMESTAMP causes crash/memory leak with prepared statements Bug: 198300 - [node] executeQuery crashes if no parameters passed in Bug: 197989 - [node] Node crashes with core dumps were found Bug: 197914 - [node] nodejs application server memory increases even after drop and disconnect Bug: 196801 - [node] Node driver crashes in getParameterValue Bug: 186681 - [node] Fatal error when fetching a CLOB value of ~500MB","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_18","text":"Bug: 199481 - [SQLDBC] Cursor holdability not correctly sent to the server Bug: 199218 - [SQLDBC] Certain years cause DATE values to be incorrectly returned as NULL with DFV=1 Bug: 197444 - [SQLDBC] CSE test failures report misleading error messages Bug: 197279 - [SQLDBC] Unable to lock newly created table with active distributed statement routing Bug: 188197 - [SQLDBC] specifying hosts for multiple unrelated systems can cause issues for multiple connections Bug: 184551 - [SQLDBC] fix Performance regression Bug: 183778 - [SQLDBC] CESU-8 -> UTF-8 conversions don't work, CESU-8 isn't used in the SQLDBC protocol Bug: 163009 - [SQLDBC] SQLDBC client can send out-of-date StatementContext resulting in server internal errors or incorrect transaction behaviour","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23123","text":"","title":"Version 2.3.123"},{"location":"apis/hana-client/CHANGELOG/#changes_16","text":"Bug: 196993 - [node] - Segmentation fault in stmt.getRowStatus() Bug: 196811 - [node] - AddressSanitizer: heap-use-after-free in getResultSet()","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_19","text":"Bug: 196981 - [SQLDBC] - Remove at the end of trace file Bug: 196540 - [SQLDBC] - SystemReplicationIntegrationTest testReconnectBehaviour, testBackOffTimerRetry sporadic failures Bug: 195187 - [SQLDBC] - enabling autocommit with write txn \"Invalid transaction state\" error Bug: 197118 - [SQLDBC] - Crash in SQLDBC::Connection::updateTopology Bug: 189159 - [SQLDBC] - Fix \"-10429: Failed to open the key store file. Opening of the Keystore failed.\"","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23122","text":"","title":"Version 2.3.122"},{"location":"apis/hana-client/CHANGELOG/#changes_17","text":"Bug: 179616 - [node] - Stream.createStatement does not support parameter bindings with an array of arrays Bug: 194801 - [node] - NCLOB output parameter truncated Bug: 191764 - [node] - crash in hana Node driver Bug: 178638 - [node] - Expose named constants for Isolation Level Bug: 186986 - [node] - HanaProcStatement: add possibility to have ColumnInfo on output tables (both output table parameters and SELECT results) Bug: 183202 - [node] - Column info does not distinguish between column name and alias","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-23121","text":"","title":"Version 2.3.121"},{"location":"apis/hana-client/CHANGELOG/#changes_18","text":"Bug: 185046 - [node] - Batch insert: specify which group has been inserted successfully and which not","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_20","text":"Bug: 182656 - [SQLDBC] - [Decimal38, DFV=8] Performance regression (30%) in benchCppPsaloadBarrier.py (elapsed time)","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23120","text":"","title":"Version 2.3.120"},{"location":"apis/hana-client/CHANGELOG/#changes_19","text":"Bug: 194578 - [node] - @sap/hana-client could not be installed on Mac OS X 10.13.6 - node-gyp build fatal error: 'thread' file not found","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-23119-rev-33","text":"","title":"Version 2.3.119 (Rev 33)"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_21","text":"Bug: 189502 - [SQLDBC] - core file produced if the OS400 version of R3trans connects to the database using the HDB client","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23118-ms","text":"","title":"Version 2.3.118-ms"},{"location":"apis/hana-client/CHANGELOG/#changes_20","text":"Bug: 190151 - [node] - node driver returns incorrect values for large DECIMAL and SMALLDECIMAL types","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_22","text":"Bug: 194315 - [SQLDBC] - Crash at PreparedStatement::getObject() if passed negative param-index Bug: 191790 - [SQLDBC] - Wrong function name when using TO_VARCHAR function in GENERATED ALWAYS AS clause Bug: 193427 - [SQLDBC] - Non terminated input string access overflow","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23117-rev-33-rc3","text":"","title":"Version 2.3.117 (Rev 33 RC3)"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_23","text":"Bug: 189511 - [SQLDBC] - Hierarchy Warning as error","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23115-rev-33-rc2","text":"","title":"Version 2.3.115 (Rev 33 RC2)"},{"location":"apis/hana-client/CHANGELOG/#changes_21","text":"Bug: 187823 - [node] - Error message from query is truncated Bug: 186963 - [node] - Procedures, output parameters with unicode characters not readable Bug: 186399 - [node] - Error when using DDL Statement in dynamic SQL Bug: 184557 - [node] - node driver memory leak Bug: 186462 - [node] - executeBatch doesn't return error if callback function isn't provided","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_24","text":"Bug: 184711 - [SQLDBC] Vulnerabilities in trace files Bug: 186830 - [SQLDBC] Coverity 33397, 171110","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23112","text":"Note: This version contains the dependent module debug@3.1.0 and ms@2.0.0 to address security issues in those modules.","title":"Version 2.3.112"},{"location":"apis/hana-client/CHANGELOG/#changes_22","text":"Bug 184286 - Coverity CID 169674 - Resource leak in object Bug 182045 - Preparing SQL statement returns error \"Unhandled SQLDBC type '32'\"","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_25","text":"Bug 189083 - FDA fetch next after warning Bug 189856 - error when AA hint based routing to down secondary or bad VolumeIds Bug 184710 - [hdbkeystore] Imported key pairs are not validated Bug 172302 - conversion error on bulk execute should fail all rows to match server behavior Bug 184128 - [SQLDBC] Decrypted data and keys are not wiped Bug 186707 - HE2E:H2SP4:Trying to encrypt a decimal column gets error","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23108","text":"","title":"Version 2.3.108"},{"location":"apis/hana-client/CHANGELOG/#changes_23","text":"Bug: 183789 - hana_client crashes when single sign-on attempted Bug: 186603 - Crash in hana_node driver when using ResultSet.prototype.getData() for a NULL value","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underlying-sqldbc-changes_26","text":"Bug: 185978 - Invalid numeric value for parameter/column (3) source type DECIMAL, target type FIXED16 Bug: 184670 - Batch insert with decimals does not work Bug: 186968 - SQLDBC-based clients on Windows and 32-bit Linux platforms use an invalid value for a Randomly encrypted NULL for a TIMESTAMP column Bug: 172302 - conversion error on bulk execute should fail all rows to match server behavior Bug: 183982 - [SQLDBC] Allow override of APPLICATION / APPLICATIONUSER Bug: 185435 - SQL Error \"-10901 No space left in request packet\" during FOR ALL ENTRIES FDA Bug: 182050 - large clientinfo that fills packet causes client crash or failures Bug: 184700 - node.js driver ignored databasename connect parameter Bug: 184107 - [SQLDBC] WebSockets does not have a thread to return responses for ping/pong Bug: 165561 - Netweaver workprocess crashes from SQLDBC","title":"Underlying SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-23106","text":"","title":"Version 2.3.106"},{"location":"apis/hana-client/CHANGELOG/#changes_24","text":"Bug: 184700 - node.js driver ignored databasename connect parameter","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-23102","text":"","title":"Version 2.3.102"},{"location":"apis/hana-client/CHANGELOG/#changes_25","text":"Bug: 184700 [nodejs] - Replace SQLDBC connection parameter serverDb with databasename Bug: 184409 [nodejs] - HXE: SQL error while accessing data base explorer from cockpit UI Bug: 182956 [SQLDBC] - SQLDBC should clear all write lobs before silent re-execution for stale metadata Bug: 183012 [SQLDBC] - Support siteType connection property in the SQLDBC driver. Bug: 183521 [SQLDBC] - StatementContext FlagSet now tests appropriate bit for A/A fallback Bug: 180790 [SQLDBC] - Add socket timeout support Bug: 182950 [SQLDBC] - Implement support for Client-side Encrypted Decimal38 Bug: 182230 [SQLDBC] - dfv8 error source expectation change Bug: 182476 [SQLDBC] - Fetching a BOOLEAN value as string Host Type returns \"TRUE\" or \"FALSE\" instead of \"1\" or \"0\" Bug: 181236 [nodejs] - Executing a DELETE statement returns undefined if the data doesn't exist, and make default CharSet=UTF-8 for node driver The above bug fix also fixes the following bug reports: - Bug: 183239 - Unicode problem - HANA node.js client return wrong results \"???\" - Bug: 183364 - Error: result set has not been fetched yet when selecting an NCHAR column - Bug: 183368 - Unicode characters not readable when using a stream","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2399","text":"","title":"Version 2.3.99"},{"location":"apis/hana-client/CHANGELOG/#changes_26","text":"Bug: 172007 - WebSockets cannot reliably detect socket failures for reconnect logic Bug: 180692 - enable TLS 1.2 in openssl versions pre 1.1.0 Bug: 181793 - [SQLDBC] WebSockets do not support ping/pong for DBaaS","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2392-rel","text":"","title":"Version 2.3.92-rel"},{"location":"apis/hana-client/CHANGELOG/#changes_27","text":"Bug: 179911 - Array type returned by Connection.execute is truncated Bug: 179717 - node.js client crashes the app if a JS error happens in parallel Bug: 179718 - a procedure call via createProcStatement doesn't include the object for scalar results Bug: 178819 - Cannot fetch spatial types using stream","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2378","text":"","title":"Version 2.3.78"},{"location":"apis/hana-client/CHANGELOG/#changes_28","text":"Bug: 178841 - Resultset.getValues returns incorrect data for double/real/float","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2375","text":"","title":"Version 2.3.75"},{"location":"apis/hana-client/CHANGELOG/#changes_29","text":"Bug: 178226 - MDX SELECT returns no results","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2367","text":"Note: This version contains HappyMake-built binaries for Linux x64.","title":"Version 2.3.67"},{"location":"apis/hana-client/CHANGELOG/#changes_30","text":"Bug: 176354 - prepared-statement.exec doesn't support parameter bindings with an array of arrays Bug: 176359 - result objects of procedure calls are different in node-hdb vs. hana-client Bug: 176361 - node-hdb treats undefined in parameters bindings as null, hana-client reports an error Bug: 176397 - Process exits unexpectedly when 'setWarningCallback' is used Bug: 174396 - DVF8 SQLDBC_SQLTypes for ODBC and DBCAPI","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2365-ms","text":"","title":"Version 2.3.65-ms"},{"location":"apis/hana-client/CHANGELOG/#changes_31","text":"Bug: 175368 - Authentication fails if password contains a semicolon (;) Bug: 176053 - instanceNumber connection property not supported Bug: 175381 - [DBCAPI] Lob data could be truncated Bug: 174309 - [SQLDBC] detect ResultSetPart overrun (DEV_ASSERTS in ResultDataIterator needed to be converted to runtime errors to prevent undefined behavior due to incorrect RESULTSET parts)","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2363-ms","text":"","title":"Version 2.3.63-ms"},{"location":"apis/hana-client/CHANGELOG/#changes_32","text":"Bug: 175602 - Error when inserting zero-length stream into HANA through node client Bug: 175368 - Authentication fails if password contains a semicolon Bug: 175712 - Intermittent failures when inserting blobs into HANA through streams","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2359-ms","text":"","title":"Version 2.3.59-ms"},{"location":"apis/hana-client/CHANGELOG/#changes_33","text":"Bug: 170723 - crash in dbcapi_get_function_code Bug: 170934 - Failed Client Conti: node.js giving regex_error Bug: 174161 - [DBCAPI] - DBCAPI reuses previous ResultSet bindings when fetching more results for a multi-resultset query Bug: 173705 - garbage collector causes sporadic crashes Enhancement: PPC BE support Enhancement: Node 8 support","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2341","text":"","title":"Version 2.3.41"},{"location":"apis/hana-client/CHANGELOG/#changes_34","text":"Bug: 169885 - Connection pooling","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2340","text":"","title":"Version 2.3.40"},{"location":"apis/hana-client/CHANGELOG/#changes_35","text":"Bug: 169668 - wrong value returned from ResultSet.getValue(N) Bug: 169674 - Main thread blocks when destroying a statement through garbage collector Bug: 168663 - Cannot unset client info","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2339-nexus-release-takt5","text":"","title":"Version 2.3.39 (Nexus Release, Takt5)"},{"location":"apis/hana-client/CHANGELOG/#changes_36","text":"Bug: 160073 - Cannot create TLS-encrypted connection using certificate string","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2338","text":"","title":"Version 2.3.38"},{"location":"apis/hana-client/CHANGELOG/#changes_37","text":"Bug: 167516 - Crash if integer input parameter is given an empty string Bug: 167524 - Crash when iterating an empty result set or a result set is not fully consumed Bug: 167504 - No way to specify multiple hosts for connection Bug: 167517 - Data type 53 incorrect in TypeCode.js Bug: 167531 - Cannot determine if a Connection is connected Bug: 167112 - Streaming API -- insert statement returns \"undefined\" result","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2331","text":"","title":"Version 2.3.31"},{"location":"apis/hana-client/CHANGELOG/#changes_38","text":"Bug: 162268 - statement options are not supported in statement.exec Bug: 165051 - Coverity CID 140729 - Dereference before null check","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2328","text":"","title":"Version 2.3.28"},{"location":"apis/hana-client/CHANGELOG/#changes_39","text":"Bug: 163582 - MDX SELECT is not handled properly","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2327","text":"","title":"Version 2.3.27"},{"location":"apis/hana-client/CHANGELOG/#changes_40","text":"Bug: 163070 - clientsBarrier.seq fails - node4 test crashes Bug: 163236 - Failed Client Conti: NodeJS crashing on master Bug: 163374 - node driver returns incorrect numbers for large BIGINT Bug: 163375 - node driver returns incorrect unicode strings for NCLOB","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2323","text":"","title":"Version 2.3.23"},{"location":"apis/hana-client/CHANGELOG/#changes_41","text":"Bug: 162924 - dbcapi crashes when fetching multiple resultsets","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2321-nexus-release-takt-3-npmsapcom","text":"","title":"Version 2.3.21 (Nexus Release, Takt 3, npm.sap.com)"},{"location":"apis/hana-client/CHANGELOG/#changes_42","text":"Bug: 162265 - end() is not available out-of-the-box","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#hana-2-sp02-drivers","text":"","title":"Hana 2 SP02 Drivers"},{"location":"apis/hana-client/CHANGELOG/#version-2264","text":"","title":"Version 2.2.64"},{"location":"apis/hana-client/CHANGELOG/#underling-sqldbc-changes","text":"Bug: 181384 - [SQLDBC] - LOB data got lost in batch mode if the lob data length greater than a network packet size Bug: 182139 - [SQLDBC] - Error -10922 (200501) Write transaction already started on other connection in ABAP report Bug: 180790 - [SQLDBC] - SDA query failure due to connection timeout error -10807 (Add socket timeout support) Bug: 155895 - [SQLDBC] - Insert of timestamps as strings behaves different between cursor.execute() and cursor.executemany() Bug: 182476 - [SQLDBC] - Fetching a BOOLEAN value as string Host Type returns \\\"TRUE\\\" or \\\"FALSE\\\" instead of \\\"1\\\" or \\\"0\\\"","title":"Underling SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-2262","text":"","title":"Version 2.2.62"},{"location":"apis/hana-client/CHANGELOG/#changes_43","text":"Bug: 178226 - [node] - MDX SELECT returns no results Bug: 179911 - [node] - Array type returned by Connection.execute is truncated Bug: 176397 - [node] - Process exits unexpectedly when 'setWarningCallback' is used Bug: 175459 - [SQLDBC] - error message improvement for numeric overflow Bug: 178841 - [node] - Resultset.getValues returns incorrect data for double/real/float Bug: 178680 - [SQLDBC] - Access violation while batch-inserting BLOB-placeholder in expression Bug: 180561 - [SQLDBC] - BasisClient lacks CRASH_ASSERT_* macros Bug: 178819 - [node] - Cannot fetch spatial types using stream","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underling-sqldbc-changes_1","text":"Bug: 175459 - [SQLDBC] - error message improvement for numeric overflow Bug: 178680 - [SQLDBC] - Access violation while batch-inserting BLOB-placeholder in expression Bug: 180561 - [SQLDBC] - BasisClient lacks CRASH_ASSERT_* macros","title":"Underling SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-2257","text":"","title":"Version 2.2.57"},{"location":"apis/hana-client/CHANGELOG/#changes_44","text":"Bug: 175712 - [node] - Intermittent failures when inserting blobs into HANA through streams Bug: 173705 - [node] - garbage collector causes sporadic crashes Bug: 175368 - [node] - Authentication fails if password contains a semicolon (;) Bug: 176053 - [node] - instanceNumber connection property not supported Bug: 169885 - [node] - Connection pooling","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underling-sqldbc-changes_2","text":"Bug: 174651 - [SQLDBC] - Network compression assertions on non-rel builds on distributed system Bug: 168750 - [SQLDBC] - Many transactions were blocked by record locks right after secondary replication was registered, and record locks were never released Bug: 176544 - [SQLDBC] - testJtClientsDistributed table placement should be default","title":"Underling SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-2253","text":"","title":"Version 2.2.53"},{"location":"apis/hana-client/CHANGELOG/#changes_45","text":"Bug: 170723 - [node] - crash in dbcapi_get_function_code Bug: 169885 - [node] - Connection pooling","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#underling-sqldbc-changes_3","text":"Bug: 170954 - [SQLDBC] - The second part can be off by a second for the timestamp output param in a procedure call Bug: 171387 - [SQLDBC] - Trace content removal too aggressive Bug: 174788 - [SQLDBC] - Statement routing not working for batch updates if 1-level part. key in the set-clause Bug: 168697 - [SQLDBC] - DLL Autocommit setting will get lost on reconnect Bug: 163336 - [SQLDBC] - General error;600 failed routed execution: anchor is switched in runtime: line 0 col 0 (at pos 0) after topology changed on SDA source site Bug: 171093 - [SQLDBC] - SQL level tracing should imply DISTRIBUTION tracing but does not Bug: 174161 - [SQLDBC] - DBCAPI reuses previous ResultSet bindings when fetching more results for a multi-resultset query","title":"Underling SQLDBC changes"},{"location":"apis/hana-client/CHANGELOG/#version-2239-included-in-rev-24-200024","text":"","title":"Version 2.2.39 (included in Rev 24 ; 2.00.024)"},{"location":"apis/hana-client/CHANGELOG/#changes_46","text":"Bug: 169668 - wrong value returned from ResultSet.getValue(N) Bug: 169674 - Main thread blocks when destroying a statement through garbage collector Bug: 168663 - Cannot unset client info","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2237","text":"","title":"Version 2.2.37"},{"location":"apis/hana-client/CHANGELOG/#changes_47","text":"Bug: 160073 - Cannot create TLS-encrypted connection using certificate string Bug: 167516 - Crash if integer input parameter is given an empty string Bug: 167524 - Crash when iterating an empty result set or a result set is not fully consumed Bug: 167504 - No way to specify multiple hosts for connection Bug: 167517 - Data type 53 incorrect in TypeCode.js Bug: 167531 - Cannot determine if a Connection is connected Bug: 160073 - Cannot create TLS-encrypted connection using certificate string Bug: 167112 - Streaming API -- insert statement returns \"undefined\" result","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2235-included-in-rev-23-200023","text":"","title":"Version 2.2.35 (included in Rev 23 ; 2.00.023)"},{"location":"apis/hana-client/CHANGELOG/#changes_48","text":"Bug: 162268 - statement options are not supported in statement.exec Bug: 165051 - Coverity CID 140729 - Dereference before null check Bug: 163582 - MDX SELECT is not handled properly Bug: 163070 - clientsBarrier.seq fails - node4 test crashes Bug: 163236 - Failed Client Conti: NodeJS crashing on master","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2234","text":"","title":"Version 2.2.34"},{"location":"apis/hana-client/CHANGELOG/#changes_49","text":"Bug: 163374 - node driver returns incorrect numbers for large BIGINT Bug: 163375 - node driver returns incorrect unicode strings for NCLOB Bug: 160968 - Failed Client Conti: ADO.NET - ColumnMapping tests fail sporadically but often","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2231","text":"","title":"Version 2.2.31"},{"location":"apis/hana-client/CHANGELOG/#changes_50","text":"Bug: 162924 - dbcapi crashes when fetching multiple resultsets","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2228-included-in-200022","text":"","title":"Version 2.2.28 (included in 2.00.022)"},{"location":"apis/hana-client/CHANGELOG/#changes_51","text":"Bug: 162265 - end() is not available out-of-the-box Bug: 160083 - Writing a stream from an HTTP IncomingMessage hangs Bug: 160422 - Writing a stream that is not an instance of Readable crashes Bug: 156392 - crash in ResultSet.getValues() Bug: 159735 - Need to know total number of rows returned without fetching each one Bug: 159649 - crash in getInputParameters Bug: 160416 - Need a way to close a stream early","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2227","text":"","title":"Version 2.2.27"},{"location":"apis/hana-client/CHANGELOG/#changes_52","text":"Bug: 154982 - clients.seq fails - node tests on Windows fail with RC = 65280 Bug: 156105 - executing procedure call with CLOB output parameter very slow Bug: 156119 - How to insert data from a stream Bug: 150587 - cannot call stored procedures with named parameters","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2225-included-in-200021","text":"","title":"Version 2.2.25 (included in 2.00.021)"},{"location":"apis/hana-client/CHANGELOG/#changes_53","text":"Bug: 156388 - Readable streams are not implemented correctly Bug: 156389 - ResultSet.close() is not available as an async method Bug: 156133 - Cannot determine if a statement was dropped Bug: 156146 - INOUT parameter gets wrong value and type, depending on input parameter type Bug: 155535 - If no parameters passed to stmt.execQuery, cannot get output parameter values Bug: 156386 - ResultSet.getValues() crashes if connection was closed Bug: 153647 - wrong number of arguments in callback from exec for DDL Bug: 153657 - passing too many parameters should return an error Bug: 153674 - getParameterValue for boolean type returns invalid value","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2224","text":"","title":"Version 2.2.24"},{"location":"apis/hana-client/CHANGELOG/#changes_54","text":"Bug: 153503 - params for statement.exec (and connection.exec) should not include output parameters Bug: 153506 - Cannot get value for output parameter if no input param provided Bug: 153656 - cannot get value from inout parameter Bug: 153683 - setClientInfo() doesn't work as expected","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2222-included-in-200020","text":"","title":"Version 2.2.22 (included in 2.00.020)"},{"location":"apis/hana-client/CHANGELOG/#changes_55","text":"Bug: 152564 - Error doesn't have stack trace","title":"Changes"},{"location":"apis/hana-client/CHANGELOG/#version-2220-initial-version","text":"","title":"Version 2.2.20 (initial version)"},{"location":"apis/hana-client/CHANGELOG/#changes_56","text":"Bug: 152218 - wrong number of arguments in callback of connect Bug: 150564 - \"No more result\" error Bug: 150561 - wrong number of arguments in callback from commit and rollback Bug: 150546 - crash in Connection::setClientInfo() Bug: 150165 - getParameterValue doesn't work Bug: 148776 - node.js client crashes when used in generic-pool with connections in parallel Bug: 148128 - Exception from ExecuteReader when executing select with long case block Bug: 145975 - warnings are (sometimes) fatal Bug: 145953 - APIs are too picky Bug: 145974 - Column metadata unavailable outside of the streaming interface Bug: 145971 - Need isClosed() function on a streaming ResultSet Bug: 145970 - need access to parameter metadata Bug: 145976 - data type codes do not align with protocol/node-hdb","title":"Changes"},{"location":"apis/hdbext/","text":"@sap/hdbext \u00b6 This package provides convenient functions on top of the @sap/hana-client module. The change log describes notable changes in this package. Usage \u00b6 var hdbext = require ( '@sap/hdbext' ); API \u00b6 createConnection(hanaConfig, callback) \u00b6 Creates a connection to a HANA database: var hanaConfig = { host : 'hostname' , port : 30015 , user : 'user' , password : 'secret' }; hdbext . createConnection ( hanaConfig , function ( error , client ) { if ( error ) { return console . error ( error ); } client . exec (...); }); The hanaConfig argument contains database connection options and additional options . The callback provides a connected client object. If the application will be deployed on Cloud Foundry or XS Advanced, you can use @sap/xsenv package to lookup the bound HANA service, like this: var xsenv = require ( '@sap/xsenv' ); var hanaConfig = xsenv . cfServiceCredentials ({ tag : 'hana' }); hdbext . createConnection ( hanaConfig , function ( error , client ) { //... }); Database connection options \u00b6 The HANA options provided to @sap/hdbext should be in the same format as expected by the @sap/hana-client package. For convenience these properties set by the HANA service broker are also accepted: * schema - can be used instead of the currentSchema property of @sap/hana-client . * db_hosts - can be used instead of the hosts property of @sap/hana-client . * certificate - can be used instead of ca property of @sap/hana-client . Note: certificate is a string containing one certificate, while ca is an array of certificates. * hostname_in_certificate - can be used instead of sslHostNameInCertificate property of @sap/hana-client . * validate_certificate - can be used instead of sslValidateCertificate property of @sap/hana-client . The default value is true . * client_authentication_certificate - can be used instead of cert property of @sap/hana-client . * client_authentication_private_key - can be used instead of key property of @sap/hana-client . Additional options \u00b6 A connection created with @sap/hdbext can be further configured with the following options: Option Type Description autoCommit boolean Sets the autoCommit flag. If no option is specified it defaults to true . Note : the @sap/hana-client package also accepts other configurations like isolationLevel (one can use the isolation level constants in require('@sap/hana-client/extension/Enums') ), locale and sessionVariable:<name-of-the-session-variable> . Special session variables \u00b6 Some session variables are handled in a special way. XS_APPLICATIONUSER - can be set to a user token (SAML/JWT) to associate the application user with the database connection SAP_PASSPORT - used to propagate SAP passport to SAP HANA, used for end-to-end tracing APPLICATION - the name of the application initiating the database connection Note : If providing the SAP_PASSPORT session variable, the SAP Passport in it should have already been updated with data, specific to the component that consumes @sap/hdbext . For more information, see the documentation of the @sap/e2e-trace package. Example \u00b6 Sample configuration with both database connection options and additional options : var enums = require ( '@sap/hana-client/extension/Enums' ); { host : 'my.host' , port : 30015 , user : 'my_user' , password : 'secret' , schema : 'name_of_the_schema' , isolationLevel : enums . SERIALIZABLE , locale : 'en_US' , autoCommit : false , 'sessionVariable:APPLICATION' : 'myapp' , 'sessionVariable:SAP_PASSPORT' : 'passport' } connectionOptions.getGlobalOptions() \u00b6 Returns an object with the following properties: * sessionVariable:APPLICATION - extracted from VCAP_APPLICATION, fallbacks to process's pid and machine's hostname. * sessionVariable:APPLICATIONVERSION - extracted from package.json in current directory. May not be present if the file is not present or not in valid JSON format. connectionOptions.getRequestOptions(req) \u00b6 Returns an object with the following properties, based on the given HTTP request ( req ): * sessionVariable:SAP_PASSPORT - may not be present if the SAP Passport header is not present. The passport is updated with default component data. * sessionVariable:XS_APPLICATIONUSER - only present for authenticated requests that do not use client credentials token. * locale - only present if req has either a x-sap-request-language or accept-language header. loadProcedure(client, schemaName, procedureName, callback) \u00b6 @sap/hdbext provides functionalities to simplify stored procedure calls. For example, if you have the following stored procedure: create procedure PROC_DUMMY ( in a int , in b int , out c int , out d DUMMY , out e TABLES ) language sqlscript reads sql data as begin c : = : a + : b ; d = select * from DUMMY ; e = select TOP 3 * from TABLES ; end you can call it via the @sap/hana-client package in the following way: var dbStream = require ( '@sap/hana-client/extension/Stream' ); dbStream . createProcStatement ( client , 'CALL PROC_DUMMY (?, ?, ?, ?, ?)' , function ( err , stmt ) { if ( err ) { return console . error ( 'createProcStatement error:' , err ); } stmt . exec ({ A : 3 , B : 4 }, function ( err , params , dummyRows , tablesRows ) { if ( err ) { return console . error ( 'exec error:' , err ); } stmt . drop ( function ( err ) { if ( err ) { return console . error ( 'drop error:' , err ); } console . log ( 'C:' , params . C ); console . log ( 'Dummy rows:' , dummyRows ); console . log ( 'Tables rows:' , tablesRows ); }); }); }); With @sap/hdbext you don't need to construct a CALL statement. The procedure can be loaded by its name. The code can look like this: hdbext . loadProcedure ( client , null , 'PROC_DUMMY' , function ( err , sp ) { sp ({ A : 3 , B : 4 }, function ( err , parameters , dummyRows , tablesRows ) { if ( err ) { return console . error ( err ); } console . log ( 'C:' , parameters . C ); console . log ( 'Dummy rows:' , dummyRows ); console . log ( 'Tables rows:' , tablesRows ); }); }); To use the current schema, pass an empty string '' , null or undefined for schema. loadProcedure(client, schemaName, procedureName, callback) returns a JavaScript function which you can call directly. The function has the paramsMetadata property containing metadata for all parameters of the stored procedure. This could be useful if you need to implement generic stored procedures calling. You can also pass the input parameters directly in the proper order: sp ( 3 , 4 , function ( err , parameters , dummyRows , tableRows ) { // ... }); or as an array: sp ([ 3 , 4 ], function ( err , parameters , dummyRows , tableRows ) { // ... }); Where the big advantage comes in is with table parameters. You can pass an array of objects and @sap/hdbext will automatically convert it into a table parameter. Say we have a customer table with ID and NAME columns and a procedure: create table \"customer\" ( ID integer , NAME VARCHAR ( 100 ), primary key ( ID )); create procedure \"getCustomers\" ( in in_table_1 \"customer\" ) language sqlscript reads sql data as begin select * from : in_table_1 ; end ; You can call it like this: hdbext . loadProcedure ( client , null , 'getCustomers' , function ( err , sp ) { if ( err ) { return console . error ( err ); } sp ([ { ID : 1 , NAME : 'Alex' }, { ID : 2 , NAME : 'Peter' } ], function ( err , parameters , tableRows ) { if ( err ) { return console . error ( err ); } console . log ( parameters ); console . log ( tableRows ); }); }); In this example each array element represents a table row. Property names should case-sensitively match the corresponding column names. Internally @sap/hdbext creates a local temporary table in the current schema for each table parameter. Thus, the current user needs the respective permissions. It is also possible to explicitly state an existing table to be used as input table parameter: sp ({ schema : 'my-schema' , table : 'my-table' }, function ( err , parameters , tableRows ) { // ... }); The schema property is optional. Every output table has a columnInfo property which contains info about each of the table's columns. Input arguments for parameters that have default values can be skipped in order to use the defined defaults. It is recommended to pass the input as an object in those cases. In this way the application code would be independent from the order in which parameters with default values are defined in the procedure. When the parameters are passed in a sequence (i.e. as an array or are passed directly in the proper order), input arguments can be skipped only for the parameters which are after the last mandatory parameter in the procedure's list. Middleware \u00b6 @sap/hdbext provides a middleware which allows easy database connection creation in a middleware-based application. The close method of the database client is invoked when the request is closed or finished. var hdbext = require ( '@sap/hdbext' ); var express = require ( 'express' ); var app = express (); app . use ( hdbext . middleware ( hanaConfig )); app . get ( '/execute-query' , function ( req , res ) { var client = req . db ; client . exec ( 'SELECT * FROM DUMMY' , function ( err , rs ) { if ( err ) { return res . end ( 'Error: ' + err . message ); } res . end ( JSON . stringify ( rs )); }); }); The argument hanaConfig may contain both database connection options and additional options . The middleware uses connectionOptions.getGlobalOptions() and connectionOptions.getRequestOptions(req) for extracting options. It is possible for applications to override the default global options by setting them explicitly in hanaConfig . SQL Parameter Utilities \u00b6 The hdbext.sqlInjectionUtils object contains several synchronous utility functions that can be used to prevent SQL injections. isAcceptableParameter(value, maxToken) \u00b6 Returns true if value can be used to construct SQL statements. The number of tokens a value is allowed to contain is set via the optional maxToken argument. Defaults to 1. isAcceptableQuotedParameter(value) \u00b6 Returns true if the provided value is quoted correctly and can be used in an SQL statement. escapeDoubleQuotes(value) \u00b6 Returns the value parameter with all double quotation marks escaped (i. e. doubled). escapeSingleQuotes(value) \u00b6 Returns the value parameter with all single quotation marks escaped (i. e. doubled). Troubleshooting \u00b6 To enable tracing, you should set the environment variable DEBUG to hdbext:* . Migration guide \u00b6 Guide on how to adopt new major versions of the library can be found here .","title":"Index"},{"location":"apis/hdbext/#saphdbext","text":"This package provides convenient functions on top of the @sap/hana-client module. The change log describes notable changes in this package.","title":"@sap/hdbext"},{"location":"apis/hdbext/#usage","text":"var hdbext = require ( '@sap/hdbext' );","title":"Usage"},{"location":"apis/hdbext/#api","text":"","title":"API"},{"location":"apis/hdbext/#createconnectionhanaconfig-callback","text":"Creates a connection to a HANA database: var hanaConfig = { host : 'hostname' , port : 30015 , user : 'user' , password : 'secret' }; hdbext . createConnection ( hanaConfig , function ( error , client ) { if ( error ) { return console . error ( error ); } client . exec (...); }); The hanaConfig argument contains database connection options and additional options . The callback provides a connected client object. If the application will be deployed on Cloud Foundry or XS Advanced, you can use @sap/xsenv package to lookup the bound HANA service, like this: var xsenv = require ( '@sap/xsenv' ); var hanaConfig = xsenv . cfServiceCredentials ({ tag : 'hana' }); hdbext . createConnection ( hanaConfig , function ( error , client ) { //... });","title":"createConnection(hanaConfig, callback)"},{"location":"apis/hdbext/#database-connection-options","text":"The HANA options provided to @sap/hdbext should be in the same format as expected by the @sap/hana-client package. For convenience these properties set by the HANA service broker are also accepted: * schema - can be used instead of the currentSchema property of @sap/hana-client . * db_hosts - can be used instead of the hosts property of @sap/hana-client . * certificate - can be used instead of ca property of @sap/hana-client . Note: certificate is a string containing one certificate, while ca is an array of certificates. * hostname_in_certificate - can be used instead of sslHostNameInCertificate property of @sap/hana-client . * validate_certificate - can be used instead of sslValidateCertificate property of @sap/hana-client . The default value is true . * client_authentication_certificate - can be used instead of cert property of @sap/hana-client . * client_authentication_private_key - can be used instead of key property of @sap/hana-client .","title":"Database connection options"},{"location":"apis/hdbext/#additional-options","text":"A connection created with @sap/hdbext can be further configured with the following options: Option Type Description autoCommit boolean Sets the autoCommit flag. If no option is specified it defaults to true . Note : the @sap/hana-client package also accepts other configurations like isolationLevel (one can use the isolation level constants in require('@sap/hana-client/extension/Enums') ), locale and sessionVariable:<name-of-the-session-variable> .","title":"Additional options"},{"location":"apis/hdbext/#special-session-variables","text":"Some session variables are handled in a special way. XS_APPLICATIONUSER - can be set to a user token (SAML/JWT) to associate the application user with the database connection SAP_PASSPORT - used to propagate SAP passport to SAP HANA, used for end-to-end tracing APPLICATION - the name of the application initiating the database connection Note : If providing the SAP_PASSPORT session variable, the SAP Passport in it should have already been updated with data, specific to the component that consumes @sap/hdbext . For more information, see the documentation of the @sap/e2e-trace package.","title":"Special session variables"},{"location":"apis/hdbext/#example","text":"Sample configuration with both database connection options and additional options : var enums = require ( '@sap/hana-client/extension/Enums' ); { host : 'my.host' , port : 30015 , user : 'my_user' , password : 'secret' , schema : 'name_of_the_schema' , isolationLevel : enums . SERIALIZABLE , locale : 'en_US' , autoCommit : false , 'sessionVariable:APPLICATION' : 'myapp' , 'sessionVariable:SAP_PASSPORT' : 'passport' }","title":"Example"},{"location":"apis/hdbext/#connectionoptionsgetglobaloptions","text":"Returns an object with the following properties: * sessionVariable:APPLICATION - extracted from VCAP_APPLICATION, fallbacks to process's pid and machine's hostname. * sessionVariable:APPLICATIONVERSION - extracted from package.json in current directory. May not be present if the file is not present or not in valid JSON format.","title":"connectionOptions.getGlobalOptions()"},{"location":"apis/hdbext/#connectionoptionsgetrequestoptionsreq","text":"Returns an object with the following properties, based on the given HTTP request ( req ): * sessionVariable:SAP_PASSPORT - may not be present if the SAP Passport header is not present. The passport is updated with default component data. * sessionVariable:XS_APPLICATIONUSER - only present for authenticated requests that do not use client credentials token. * locale - only present if req has either a x-sap-request-language or accept-language header.","title":"connectionOptions.getRequestOptions(req)"},{"location":"apis/hdbext/#loadprocedureclient-schemaname-procedurename-callback","text":"@sap/hdbext provides functionalities to simplify stored procedure calls. For example, if you have the following stored procedure: create procedure PROC_DUMMY ( in a int , in b int , out c int , out d DUMMY , out e TABLES ) language sqlscript reads sql data as begin c : = : a + : b ; d = select * from DUMMY ; e = select TOP 3 * from TABLES ; end you can call it via the @sap/hana-client package in the following way: var dbStream = require ( '@sap/hana-client/extension/Stream' ); dbStream . createProcStatement ( client , 'CALL PROC_DUMMY (?, ?, ?, ?, ?)' , function ( err , stmt ) { if ( err ) { return console . error ( 'createProcStatement error:' , err ); } stmt . exec ({ A : 3 , B : 4 }, function ( err , params , dummyRows , tablesRows ) { if ( err ) { return console . error ( 'exec error:' , err ); } stmt . drop ( function ( err ) { if ( err ) { return console . error ( 'drop error:' , err ); } console . log ( 'C:' , params . C ); console . log ( 'Dummy rows:' , dummyRows ); console . log ( 'Tables rows:' , tablesRows ); }); }); }); With @sap/hdbext you don't need to construct a CALL statement. The procedure can be loaded by its name. The code can look like this: hdbext . loadProcedure ( client , null , 'PROC_DUMMY' , function ( err , sp ) { sp ({ A : 3 , B : 4 }, function ( err , parameters , dummyRows , tablesRows ) { if ( err ) { return console . error ( err ); } console . log ( 'C:' , parameters . C ); console . log ( 'Dummy rows:' , dummyRows ); console . log ( 'Tables rows:' , tablesRows ); }); }); To use the current schema, pass an empty string '' , null or undefined for schema. loadProcedure(client, schemaName, procedureName, callback) returns a JavaScript function which you can call directly. The function has the paramsMetadata property containing metadata for all parameters of the stored procedure. This could be useful if you need to implement generic stored procedures calling. You can also pass the input parameters directly in the proper order: sp ( 3 , 4 , function ( err , parameters , dummyRows , tableRows ) { // ... }); or as an array: sp ([ 3 , 4 ], function ( err , parameters , dummyRows , tableRows ) { // ... }); Where the big advantage comes in is with table parameters. You can pass an array of objects and @sap/hdbext will automatically convert it into a table parameter. Say we have a customer table with ID and NAME columns and a procedure: create table \"customer\" ( ID integer , NAME VARCHAR ( 100 ), primary key ( ID )); create procedure \"getCustomers\" ( in in_table_1 \"customer\" ) language sqlscript reads sql data as begin select * from : in_table_1 ; end ; You can call it like this: hdbext . loadProcedure ( client , null , 'getCustomers' , function ( err , sp ) { if ( err ) { return console . error ( err ); } sp ([ { ID : 1 , NAME : 'Alex' }, { ID : 2 , NAME : 'Peter' } ], function ( err , parameters , tableRows ) { if ( err ) { return console . error ( err ); } console . log ( parameters ); console . log ( tableRows ); }); }); In this example each array element represents a table row. Property names should case-sensitively match the corresponding column names. Internally @sap/hdbext creates a local temporary table in the current schema for each table parameter. Thus, the current user needs the respective permissions. It is also possible to explicitly state an existing table to be used as input table parameter: sp ({ schema : 'my-schema' , table : 'my-table' }, function ( err , parameters , tableRows ) { // ... }); The schema property is optional. Every output table has a columnInfo property which contains info about each of the table's columns. Input arguments for parameters that have default values can be skipped in order to use the defined defaults. It is recommended to pass the input as an object in those cases. In this way the application code would be independent from the order in which parameters with default values are defined in the procedure. When the parameters are passed in a sequence (i.e. as an array or are passed directly in the proper order), input arguments can be skipped only for the parameters which are after the last mandatory parameter in the procedure's list.","title":"loadProcedure(client, schemaName, procedureName, callback)"},{"location":"apis/hdbext/#middleware","text":"@sap/hdbext provides a middleware which allows easy database connection creation in a middleware-based application. The close method of the database client is invoked when the request is closed or finished. var hdbext = require ( '@sap/hdbext' ); var express = require ( 'express' ); var app = express (); app . use ( hdbext . middleware ( hanaConfig )); app . get ( '/execute-query' , function ( req , res ) { var client = req . db ; client . exec ( 'SELECT * FROM DUMMY' , function ( err , rs ) { if ( err ) { return res . end ( 'Error: ' + err . message ); } res . end ( JSON . stringify ( rs )); }); }); The argument hanaConfig may contain both database connection options and additional options . The middleware uses connectionOptions.getGlobalOptions() and connectionOptions.getRequestOptions(req) for extracting options. It is possible for applications to override the default global options by setting them explicitly in hanaConfig .","title":"Middleware"},{"location":"apis/hdbext/#sql-parameter-utilities","text":"The hdbext.sqlInjectionUtils object contains several synchronous utility functions that can be used to prevent SQL injections.","title":"SQL Parameter Utilities"},{"location":"apis/hdbext/#isacceptableparametervalue-maxtoken","text":"Returns true if value can be used to construct SQL statements. The number of tokens a value is allowed to contain is set via the optional maxToken argument. Defaults to 1.","title":"isAcceptableParameter(value, maxToken)"},{"location":"apis/hdbext/#isacceptablequotedparametervalue","text":"Returns true if the provided value is quoted correctly and can be used in an SQL statement.","title":"isAcceptableQuotedParameter(value)"},{"location":"apis/hdbext/#escapedoublequotesvalue","text":"Returns the value parameter with all double quotation marks escaped (i. e. doubled).","title":"escapeDoubleQuotes(value)"},{"location":"apis/hdbext/#escapesinglequotesvalue","text":"Returns the value parameter with all single quotation marks escaped (i. e. doubled).","title":"escapeSingleQuotes(value)"},{"location":"apis/hdbext/#troubleshooting","text":"To enable tracing, you should set the environment variable DEBUG to hdbext:* .","title":"Troubleshooting"},{"location":"apis/hdbext/#migration-guide","text":"Guide on how to adopt new major versions of the library can be found here .","title":"Migration guide"},{"location":"apis/hdbext/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 6.2.2 - 2020-04-29 \u00b6 Fixed \u00b6 Update @sap/hana-client to v2.4.196 6.2.1 - 2020-04-15 \u00b6 Fixed \u00b6 Do not drop statement objects in the background in order to prevent IsGlobalEmpty crash 6.2.0 - 2020-03-06 \u00b6 Added \u00b6 Node.js 12.x support. 6.1.1 - 2019-11-19 \u00b6 Fixed \u00b6 Update @sap/hana-client to v2.4.167 6.1.0 - 2019-10-25 \u00b6 Added \u00b6 Support for synonyms as table parameters in procedures 6.0.1 - 2019-07-10 \u00b6 Fixed \u00b6 Update lodash package to 4.17.13 6.0.0 - 2019-05-20 \u00b6 Removed \u00b6 Node 4 support Stored procedures: caching of prepared CALL statements for simple procedures Fixed \u00b6 Statement leak due to caching of prepared CALL statements for simple procedures Update @sap/hana-client to v2.4.139 Added \u00b6 Node.js 10 support 5.1.0 - 2019-01-11 \u00b6 Added \u00b6 Support for hostname_in_certificate , validate_certificate , client_authentication_certificate , client_authentication_private_key properties from HANA service binding Fixed \u00b6 Check for non-existing procedure 5.0.0 - 2018-09-27 \u00b6 Removed \u00b6 Node 0.12 support. The constants property. The getPool property. The createPool property. The updateConnectionOptions property. The session property is no longer considered for setting session variables. Changed \u00b6 Now the package provides convenient functions on top of the @sap/hana-client package instead of the hdb package. The package expects schema and table names to be provided unescaped everywhere, e.g. my\"TABLE instead of \"my\"\"Table\" . A string containing a table name and optionally a schema name is no longer accepted for input table parameters. An object with table property (mandatory) and schema property (optional) should be provided instead, e.g. { schema: 'my\"Schema', table: 'my\"Table' } hdbext.createConnection throws if the input is not an object. hdbext.createConnection throws if provided value for autoCommit is not a boolean. Format of the object returned from hdbext.connectionOptions.getGlobalOptions , from { session: { APPLICATION: '', APPLICATIONVERSION: '' } } to { 'sessionVariable:APPLICATION': '', 'sessionVariable:APPLICATIONVERSION': '' } hdbext.connectionOptions.getGlobalOptions may return an object without a 'sessionVariable:APPLICATIONVERSION' property if an appropriate value cannot be determined. Format of the object returned from hdbext.connectionOptions.getRequestOptions from { session: { XS_APPLICATIONUSER: '', SAP_PASSPORT: '', locale: '' } } to { 'sessionVariable:XS_APPLICATIONUSER': '', 'sessionVariable:SAP_PASSPORT': '', locale: '' } hdbext.connectionOptions.getRequestOptions may return an object without a locale property if an appropriate value cannot be determined. hdbext.middleware no longer takes pool options as second argument. hdbext.middleware does not work with pooled connections by default. 4.7.5 - 2018-09-18 \u00b6 Fixed \u00b6 Update lodash package to 4.17.11 4.7.4 - 2018-07-27 \u00b6 Fixed \u00b6 Passing a Buffer as a single input argument for a procedure 4.7.3 - 2018-06-29 \u00b6 Fixed \u00b6 Updated hdb package to 0.16.0 4.7.2 - 2018-04-03 \u00b6 Fixed \u00b6 Do not call setImmediate when invoking stored procedures 4.7.1 - 2018-03-30 \u00b6 Fixed \u00b6 Update dependencies Implicit commit when procedure with input table parameters is executed Cleanup of global temporary tables when a connection is returned to a pool Local temporary tables are now dropped without CASCADE Names of temporary tables are now properly escaped during cleanup of connections returned to a pool Prepared statement leak when calling a procedure without input table parameters and without parameters having a default value 4.7.0 - 2018-01-19 \u00b6 Added \u00b6 npm-shrinkwrap.json 4.6.0 - 2018-01-12 \u00b6 Added \u00b6 Support for servername option on connect Fixed \u00b6 Error when authInfo is missing getGrantType property Minimum idle connections is now 0 4.5.0 - 2017-11-23 \u00b6 Added \u00b6 Stored procedures: support for default parameters Fixed \u00b6 Update dependencies 4.4.3 - 2017-10-12 \u00b6 Added \u00b6 Support for Node.js 8 Fixed \u00b6 Prevent using a client object that has been returned to the pool Update dependencies 4.4.2 - 2017-07-17 \u00b6 Fixed \u00b6 Client credentials token now doesn't throw error 4.4.1 - 2017-07-04 \u00b6 Fixed \u00b6 Allow pool release to be called only once 4.4.0 - 2017-06-30 \u00b6 Added \u00b6 Support for synonyms for procedures Expose generic-pool object Fixed \u00b6 Return only non-busy connections to pool Additional options leaks in getPool Fixes in passing input arguments as Array Fixed passing null as single input argument 4.3.4 - 2017-05-02 \u00b6 Fixed \u00b6 Close connection if authentication fails Handle null for procedures with input table parameters 4.3.3 - 2017-04-04 \u00b6 Fixed \u00b6 Support for INOUT parameters in stored procedures 4.3.2 - 2017-03-10 \u00b6 Fixed \u00b6 Report error if temp table delete fails Updated hdb module to 0.12.1 4.3.1 - 2017-02-23 \u00b6 Fixed \u00b6 The locale property in the object returned by connOptions.getRequestOptions now defaults to undefined instead of to an empty string when there is no language info in the provided request 4.3.0 - 2017-01-26 \u00b6 Added \u00b6 Introduce pool.drain - a function to dispose of idle connections Fixed \u00b6 Log on level 'debug' in case of 'insufficient privilege' error during clean-up of temporary tables 4.2.3 - 2017-01-24 \u00b6 Changed \u00b6 Rename package to use @sap scope 4.2.2 - 2017-01-24 \u00b6 Fixed \u00b6 Clean-up temporary tables on connection release Fixes in procedures and inplace table parameters 4.2.1 - 2016-12-07 \u00b6 Fixed \u00b6 middleware and connOptions.getRequestOptions now update SAP-Passports automatically with default component data 4.2.0 - 2016-11-16 \u00b6 Added \u00b6 Make options optional in pool.acquire Fixed \u00b6 Quote name in set schema statement Rollback transaction before isolation level restore Support for multiple middlewares Allow calling a procedure with inplace table parameter Fix crash on connect 4.1.3 - 2016-10-14 \u00b6 Fixed \u00b6 Fixes in database connectivity 4.1.2 - 2016-09-28 \u00b6 Fixed \u00b6 Handle websocket connection end. Set DB connection locale from HTTP request in middleware. 4.1.1 - 2016-09-15 \u00b6 Added \u00b6 Rollback of uncommitted changes when a connection is returned to a connection pool. 4.1.0 - 2016-09-14 \u00b6 Added \u00b6 autoCommit connection option Set APPLICATION and APPLICATIONVERSION session variables in the middleware connectionOptions.getGlobalOptions() and connectionOptions.getRequestOptions(req) functions 4.0.0 - 2016-09-09 \u00b6 Added \u00b6 session property in database connection options certificate property in database connection options Removed \u00b6 sapPassport property in database connection options, use session.SAP_PASSPORT instead. userTokens property in database connection options, use session.XS_APPLICATIONUSER instead. Now a single token is expected. 3.0.0 - 2016-08-05 \u00b6 Changed \u00b6 Removed additional functions attached to the returned HDB connection object (incompatible change). In previous versions the returned connection object was enriched with the following functions: setSchema setApplicationUser unsetApplicationUser Those functions have been removed and we have provided a new function updateConnectionOptions instead, to be used as utility for setting the supported connection options. Read HANA service properties from environment as fallback if no HANA config provided has been removed. HANA config object no longer supports setting userTokens as string, it must be an object. Connection pooling API was changed incompatibly to fix issues with connection cleanup.","title":"Change Log"},{"location":"apis/hdbext/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/hdbext/CHANGELOG/#622-2020-04-29","text":"","title":"6.2.2 - 2020-04-29"},{"location":"apis/hdbext/CHANGELOG/#fixed","text":"Update @sap/hana-client to v2.4.196","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#621-2020-04-15","text":"","title":"6.2.1 - 2020-04-15"},{"location":"apis/hdbext/CHANGELOG/#fixed_1","text":"Do not drop statement objects in the background in order to prevent IsGlobalEmpty crash","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#620-2020-03-06","text":"","title":"6.2.0 - 2020-03-06"},{"location":"apis/hdbext/CHANGELOG/#added","text":"Node.js 12.x support.","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#611-2019-11-19","text":"","title":"6.1.1 - 2019-11-19"},{"location":"apis/hdbext/CHANGELOG/#fixed_2","text":"Update @sap/hana-client to v2.4.167","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#610-2019-10-25","text":"","title":"6.1.0 - 2019-10-25"},{"location":"apis/hdbext/CHANGELOG/#added_1","text":"Support for synonyms as table parameters in procedures","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#601-2019-07-10","text":"","title":"6.0.1 - 2019-07-10"},{"location":"apis/hdbext/CHANGELOG/#fixed_3","text":"Update lodash package to 4.17.13","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#600-2019-05-20","text":"","title":"6.0.0 - 2019-05-20"},{"location":"apis/hdbext/CHANGELOG/#removed","text":"Node 4 support Stored procedures: caching of prepared CALL statements for simple procedures","title":"Removed"},{"location":"apis/hdbext/CHANGELOG/#fixed_4","text":"Statement leak due to caching of prepared CALL statements for simple procedures Update @sap/hana-client to v2.4.139","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#added_2","text":"Node.js 10 support","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#510-2019-01-11","text":"","title":"5.1.0 - 2019-01-11"},{"location":"apis/hdbext/CHANGELOG/#added_3","text":"Support for hostname_in_certificate , validate_certificate , client_authentication_certificate , client_authentication_private_key properties from HANA service binding","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#fixed_5","text":"Check for non-existing procedure","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#500-2018-09-27","text":"","title":"5.0.0 - 2018-09-27"},{"location":"apis/hdbext/CHANGELOG/#removed_1","text":"Node 0.12 support. The constants property. The getPool property. The createPool property. The updateConnectionOptions property. The session property is no longer considered for setting session variables.","title":"Removed"},{"location":"apis/hdbext/CHANGELOG/#changed","text":"Now the package provides convenient functions on top of the @sap/hana-client package instead of the hdb package. The package expects schema and table names to be provided unescaped everywhere, e.g. my\"TABLE instead of \"my\"\"Table\" . A string containing a table name and optionally a schema name is no longer accepted for input table parameters. An object with table property (mandatory) and schema property (optional) should be provided instead, e.g. { schema: 'my\"Schema', table: 'my\"Table' } hdbext.createConnection throws if the input is not an object. hdbext.createConnection throws if provided value for autoCommit is not a boolean. Format of the object returned from hdbext.connectionOptions.getGlobalOptions , from { session: { APPLICATION: '', APPLICATIONVERSION: '' } } to { 'sessionVariable:APPLICATION': '', 'sessionVariable:APPLICATIONVERSION': '' } hdbext.connectionOptions.getGlobalOptions may return an object without a 'sessionVariable:APPLICATIONVERSION' property if an appropriate value cannot be determined. Format of the object returned from hdbext.connectionOptions.getRequestOptions from { session: { XS_APPLICATIONUSER: '', SAP_PASSPORT: '', locale: '' } } to { 'sessionVariable:XS_APPLICATIONUSER': '', 'sessionVariable:SAP_PASSPORT': '', locale: '' } hdbext.connectionOptions.getRequestOptions may return an object without a locale property if an appropriate value cannot be determined. hdbext.middleware no longer takes pool options as second argument. hdbext.middleware does not work with pooled connections by default.","title":"Changed"},{"location":"apis/hdbext/CHANGELOG/#475-2018-09-18","text":"","title":"4.7.5 - 2018-09-18"},{"location":"apis/hdbext/CHANGELOG/#fixed_6","text":"Update lodash package to 4.17.11","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#474-2018-07-27","text":"","title":"4.7.4 - 2018-07-27"},{"location":"apis/hdbext/CHANGELOG/#fixed_7","text":"Passing a Buffer as a single input argument for a procedure","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#473-2018-06-29","text":"","title":"4.7.3 - 2018-06-29"},{"location":"apis/hdbext/CHANGELOG/#fixed_8","text":"Updated hdb package to 0.16.0","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#472-2018-04-03","text":"","title":"4.7.2 - 2018-04-03"},{"location":"apis/hdbext/CHANGELOG/#fixed_9","text":"Do not call setImmediate when invoking stored procedures","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#471-2018-03-30","text":"","title":"4.7.1 - 2018-03-30"},{"location":"apis/hdbext/CHANGELOG/#fixed_10","text":"Update dependencies Implicit commit when procedure with input table parameters is executed Cleanup of global temporary tables when a connection is returned to a pool Local temporary tables are now dropped without CASCADE Names of temporary tables are now properly escaped during cleanup of connections returned to a pool Prepared statement leak when calling a procedure without input table parameters and without parameters having a default value","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#470-2018-01-19","text":"","title":"4.7.0 - 2018-01-19"},{"location":"apis/hdbext/CHANGELOG/#added_4","text":"npm-shrinkwrap.json","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#460-2018-01-12","text":"","title":"4.6.0 - 2018-01-12"},{"location":"apis/hdbext/CHANGELOG/#added_5","text":"Support for servername option on connect","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#fixed_11","text":"Error when authInfo is missing getGrantType property Minimum idle connections is now 0","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#450-2017-11-23","text":"","title":"4.5.0 - 2017-11-23"},{"location":"apis/hdbext/CHANGELOG/#added_6","text":"Stored procedures: support for default parameters","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#fixed_12","text":"Update dependencies","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#443-2017-10-12","text":"","title":"4.4.3 - 2017-10-12"},{"location":"apis/hdbext/CHANGELOG/#added_7","text":"Support for Node.js 8","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#fixed_13","text":"Prevent using a client object that has been returned to the pool Update dependencies","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#442-2017-07-17","text":"","title":"4.4.2 - 2017-07-17"},{"location":"apis/hdbext/CHANGELOG/#fixed_14","text":"Client credentials token now doesn't throw error","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#441-2017-07-04","text":"","title":"4.4.1 - 2017-07-04"},{"location":"apis/hdbext/CHANGELOG/#fixed_15","text":"Allow pool release to be called only once","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#440-2017-06-30","text":"","title":"4.4.0 - 2017-06-30"},{"location":"apis/hdbext/CHANGELOG/#added_8","text":"Support for synonyms for procedures Expose generic-pool object","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#fixed_16","text":"Return only non-busy connections to pool Additional options leaks in getPool Fixes in passing input arguments as Array Fixed passing null as single input argument","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#434-2017-05-02","text":"","title":"4.3.4 - 2017-05-02"},{"location":"apis/hdbext/CHANGELOG/#fixed_17","text":"Close connection if authentication fails Handle null for procedures with input table parameters","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#433-2017-04-04","text":"","title":"4.3.3 - 2017-04-04"},{"location":"apis/hdbext/CHANGELOG/#fixed_18","text":"Support for INOUT parameters in stored procedures","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#432-2017-03-10","text":"","title":"4.3.2 - 2017-03-10"},{"location":"apis/hdbext/CHANGELOG/#fixed_19","text":"Report error if temp table delete fails Updated hdb module to 0.12.1","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#431-2017-02-23","text":"","title":"4.3.1 - 2017-02-23"},{"location":"apis/hdbext/CHANGELOG/#fixed_20","text":"The locale property in the object returned by connOptions.getRequestOptions now defaults to undefined instead of to an empty string when there is no language info in the provided request","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#430-2017-01-26","text":"","title":"4.3.0 - 2017-01-26"},{"location":"apis/hdbext/CHANGELOG/#added_9","text":"Introduce pool.drain - a function to dispose of idle connections","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#fixed_21","text":"Log on level 'debug' in case of 'insufficient privilege' error during clean-up of temporary tables","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#423-2017-01-24","text":"","title":"4.2.3 - 2017-01-24"},{"location":"apis/hdbext/CHANGELOG/#changed_1","text":"Rename package to use @sap scope","title":"Changed"},{"location":"apis/hdbext/CHANGELOG/#422-2017-01-24","text":"","title":"4.2.2 - 2017-01-24"},{"location":"apis/hdbext/CHANGELOG/#fixed_22","text":"Clean-up temporary tables on connection release Fixes in procedures and inplace table parameters","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#421-2016-12-07","text":"","title":"4.2.1 - 2016-12-07"},{"location":"apis/hdbext/CHANGELOG/#fixed_23","text":"middleware and connOptions.getRequestOptions now update SAP-Passports automatically with default component data","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#420-2016-11-16","text":"","title":"4.2.0 - 2016-11-16"},{"location":"apis/hdbext/CHANGELOG/#added_10","text":"Make options optional in pool.acquire","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#fixed_24","text":"Quote name in set schema statement Rollback transaction before isolation level restore Support for multiple middlewares Allow calling a procedure with inplace table parameter Fix crash on connect","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#413-2016-10-14","text":"","title":"4.1.3 - 2016-10-14"},{"location":"apis/hdbext/CHANGELOG/#fixed_25","text":"Fixes in database connectivity","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#412-2016-09-28","text":"","title":"4.1.2 - 2016-09-28"},{"location":"apis/hdbext/CHANGELOG/#fixed_26","text":"Handle websocket connection end. Set DB connection locale from HTTP request in middleware.","title":"Fixed"},{"location":"apis/hdbext/CHANGELOG/#411-2016-09-15","text":"","title":"4.1.1 - 2016-09-15"},{"location":"apis/hdbext/CHANGELOG/#added_11","text":"Rollback of uncommitted changes when a connection is returned to a connection pool.","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#410-2016-09-14","text":"","title":"4.1.0 - 2016-09-14"},{"location":"apis/hdbext/CHANGELOG/#added_12","text":"autoCommit connection option Set APPLICATION and APPLICATIONVERSION session variables in the middleware connectionOptions.getGlobalOptions() and connectionOptions.getRequestOptions(req) functions","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#400-2016-09-09","text":"","title":"4.0.0 - 2016-09-09"},{"location":"apis/hdbext/CHANGELOG/#added_13","text":"session property in database connection options certificate property in database connection options","title":"Added"},{"location":"apis/hdbext/CHANGELOG/#removed_2","text":"sapPassport property in database connection options, use session.SAP_PASSPORT instead. userTokens property in database connection options, use session.XS_APPLICATIONUSER instead. Now a single token is expected.","title":"Removed"},{"location":"apis/hdbext/CHANGELOG/#300-2016-08-05","text":"","title":"3.0.0 - 2016-08-05"},{"location":"apis/hdbext/CHANGELOG/#changed_2","text":"Removed additional functions attached to the returned HDB connection object (incompatible change). In previous versions the returned connection object was enriched with the following functions: setSchema setApplicationUser unsetApplicationUser Those functions have been removed and we have provided a new function updateConnectionOptions instead, to be used as utility for setting the supported connection options. Read HANA service properties from environment as fallback if no HANA config provided has been removed. HANA config object no longer supports setting userTokens as string, it must be an object. Connection pooling API was changed incompatibly to fix issues with connection cleanup.","title":"Changed"},{"location":"apis/hdbext/migration/","text":"Migration Guide \u00b6 Version 5 ==> Version 6 \u00b6 Support for Node.js 4 has been droppped, @sap/hdbext APIs have not been changed. Version 4 ==> Version 5 \u00b6 Changes to application code \u00b6 Creating connections \u00b6 Code like: hdbext . createConnection ({ host : 'my.host' , port : 30015 , user : 'my_user' , password : 'secret' , schema : 'name_of_the_schema' , isolationLevel : hdbext . constants . isolation . SERIALIZABLE , locale : 'en_US' , session : { APPLICATION : 'myapp' , SAP_PASSPORT : 'passport' } }, function ( err , client ) { }); should be transformed to: var enums = require ( '@sap/hana-client/extension/Enums' ); hdbext . createConnection ({ host : 'my.host' , port : 30015 , user : 'my_user' , password : 'secret' , schema : 'name_of_the_schema' , isolationLevel : enums . SERIALIZABLE , locale : 'en_US' , autoCommit : false , 'sessionVariable:APPLICATION' : 'myapp' , 'sessionVariable:SAP_PASSPORT' : 'passport' }, function ( err , client ) { }); Connection pooling \u00b6 var pool = hdbext . getPool ({ /* database options */ }, { /* pool options */ }); // or var pool = hdbext . createPool ({ /* database options */ }, { /* pool options */ }); pool . acquire ({ /* options */ }, function ( err , client ) { }); should be transformed to: hdbext . createConnection ({ // database options pooling : true }, function ( err , client ) { }); In that way the connection pooling functionality of @sap/hana-client will be used. Connection pooling in the middleware \u00b6 To enable connection pooling in hdbext.middleware add the option pooling: true to the database options. Passing table name as input table parameter to a procedure \u00b6 Code like: hdbext . loadProcedure ( client , schema , name , function ( err , sp ) { sp ({ MY_INPUT_TABLE_PARAM : '\"my\"\"Schema\".\"my\"\"Table\"' }, function ( err , outParams ) { }); }); should be transofmed to: hdbext . loadProcedure ( client , schema , name , function ( err , sp ) { sp ({ MY_INPUT_TABLE_PARAM : { schema : 'my\"Schema' , table : 'my\"Table' } }, function ( err , outParams ) { }); }); The table property is mandatory and the schema property is optional if using the current schema. Constants \u00b6 @sap/hdbext no longer exposes constants, use those provided by @sap/hana-client instead: var types = require ( '@sap/hana-client/extension/TypeCode' ); var enums = require ( '@sap/hana-client/extension/Enums' );","title":"Migration Guide"},{"location":"apis/hdbext/migration/#migration-guide","text":"","title":"Migration Guide"},{"location":"apis/hdbext/migration/#version-5-version-6","text":"Support for Node.js 4 has been droppped, @sap/hdbext APIs have not been changed.","title":"Version 5 ==&gt; Version 6"},{"location":"apis/hdbext/migration/#version-4-version-5","text":"","title":"Version 4 ==&gt; Version 5"},{"location":"apis/hdbext/migration/#changes-to-application-code","text":"","title":"Changes to application code"},{"location":"apis/hdbext/migration/#creating-connections","text":"Code like: hdbext . createConnection ({ host : 'my.host' , port : 30015 , user : 'my_user' , password : 'secret' , schema : 'name_of_the_schema' , isolationLevel : hdbext . constants . isolation . SERIALIZABLE , locale : 'en_US' , session : { APPLICATION : 'myapp' , SAP_PASSPORT : 'passport' } }, function ( err , client ) { }); should be transformed to: var enums = require ( '@sap/hana-client/extension/Enums' ); hdbext . createConnection ({ host : 'my.host' , port : 30015 , user : 'my_user' , password : 'secret' , schema : 'name_of_the_schema' , isolationLevel : enums . SERIALIZABLE , locale : 'en_US' , autoCommit : false , 'sessionVariable:APPLICATION' : 'myapp' , 'sessionVariable:SAP_PASSPORT' : 'passport' }, function ( err , client ) { });","title":"Creating connections"},{"location":"apis/hdbext/migration/#connection-pooling","text":"var pool = hdbext . getPool ({ /* database options */ }, { /* pool options */ }); // or var pool = hdbext . createPool ({ /* database options */ }, { /* pool options */ }); pool . acquire ({ /* options */ }, function ( err , client ) { }); should be transformed to: hdbext . createConnection ({ // database options pooling : true }, function ( err , client ) { }); In that way the connection pooling functionality of @sap/hana-client will be used.","title":"Connection pooling"},{"location":"apis/hdbext/migration/#connection-pooling-in-the-middleware","text":"To enable connection pooling in hdbext.middleware add the option pooling: true to the database options.","title":"Connection pooling in the middleware"},{"location":"apis/hdbext/migration/#passing-table-name-as-input-table-parameter-to-a-procedure","text":"Code like: hdbext . loadProcedure ( client , schema , name , function ( err , sp ) { sp ({ MY_INPUT_TABLE_PARAM : '\"my\"\"Schema\".\"my\"\"Table\"' }, function ( err , outParams ) { }); }); should be transofmed to: hdbext . loadProcedure ( client , schema , name , function ( err , sp ) { sp ({ MY_INPUT_TABLE_PARAM : { schema : 'my\"Schema' , table : 'my\"Table' } }, function ( err , outParams ) { }); }); The table property is mandatory and the schema property is optional if using the current schema.","title":"Passing table name as input table parameter to a procedure"},{"location":"apis/hdbext/migration/#constants","text":"@sap/hdbext no longer exposes constants, use those provided by @sap/hana-client instead: var types = require ( '@sap/hana-client/extension/TypeCode' ); var enums = require ( '@sap/hana-client/extension/Enums' );","title":"Constants"},{"location":"apis/hdi/","text":"@sap/hdi \u00b6 This is the node.js-based client library for HANA DI (HDI). Currently, the module provides the following asynchronous methods to access HDI functionality: connect disconnect configureDI configureDIParameters createContainer dropContainer configureContainer configureContainerParameters listLibraries configureLibraries listConfiguredLibraries status read listDeployed readDeployed write delete make makeAsync grantContainerApiPrivileges grantContainerApiPrivilegesWithGrantOption revokeContainerApiPrivileges grantContainerSchemaPrivileges revokeContainerSchemaPrivileges grantContainerSchemaRoles revokeContainerSchemaRoles After installing the module via npm, an application needs to create an instance of the client: hdi = new HDI(container, logger, credentials); where container is the name of an existing container, logger is a callback function used to write logging information, and credentials is an object containing the host name, port, user and password that shall be used for the DB connection: { host : 'hostname', port : 30015, user : 'user', password : 'secret' } The connection to the database is established with the connect method, which takes only a callback function as parameter. When the application finishes, it should call hdi.disconnect(); configureDI (Deprecated) Configures HDI with the given parameters. - call_params : an object with key/value pairs configuring HDI and controlling the HDI behaviour - externCB : a callback function used to return errors or results configureDIParameters Configures HDI with the given configuration parameters and the given parameters. - di_params : an object with key/value pairs configuring HDI - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results createContainer Creates a container with the given container id. - container : the container id/name - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results dropContainer Drops the container with the given container id, incl. all corresponding technical users, schemata, tables, etc. - container : the container id/name - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results configureContainer (Deprecated) Configures the container with the given parameters. - call_params : an object with key/value pairs configuring the container and controlling the HDI behaviour - externCB : a callback function used to return errors or results configureContainerParameters Configures the container with the given configuration parameters and the given parameters. - container_params : an object with key/value pairs configuring the container - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results listLibraries List all available plugin libraries that can be installed into a container. - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results configureLibraries (Re)configures the set of plugin libraries which are installed in the given container. - libconfig : an array of [action, library_name] tuples. action could be ADD or REMOVE - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results listConfiguredLibraries List the set of plugin libraries which are installed in the given container. - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results status Shows the status of files and folders in the container. It takes the following parameters: - paths : an array of path names (strings) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results read Reads files/folders from the containers work file system . It takes the same parameters as status readDeployed Like read , but reads files/folders from the containers deployed file system . listDeployed Like readDeployed , but reads only metadata for files/folders from the containers deployed file system . write Writes files/folders to the containers work file system . It takes the following parameters: - paths_content : an array of arrays, containing the path names and the corresponding file content - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results delete Deletes files/folders from the containers work file system . It takes the same parameters as read . make / makeAsync Triggers a synchronous resp. asynchronous make with the given sets of files/folders. - deploy_paths : an array of path names, listing the files/folders to deploy - undeploy_paths : an array of path names, listing the files/folders to undeploy - path_parameters : an object with path names as keys and file specific parameters (like call_params) for each such path - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results grantContainerApiPrivileges / grantContainerApiPrivilegesWithGrantOption Grants the given privileges on the containers API objects to the given users. - privileges : an array of arrays (4-tuples: privilege name, object name, principal schema name, principal name) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results revokeContainerApiPrivileges Revokes the given privileges on the containers API objects from the given users. It takes the same parameters as grantContainerApiPrivileges. grantContainerSchemaPrivileges Grants the given privileges on the containers target schema to the given users. - privileges : array of arrays (3-tuples: privilege name, principal schema name, principal name) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results revokeContainerSchemaPrivileges Revokes the given privileges on the containers target schema from the given users. It takes the same parameters as grantContainerSchemaPrivileges. grantContainerSchemaRoles Grants the given roles (which are deployed inside the container) to the given users. - roles : array of arrays (3-tuples: role name, principal schema name, principal name) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results revokeContainerSchemaRoles Revokes the given roles (which are deployed inside the container) from the given users. It takes the same parameters as grantContainerSchemaRoles.","title":"Index"},{"location":"apis/hdi/#saphdi","text":"This is the node.js-based client library for HANA DI (HDI). Currently, the module provides the following asynchronous methods to access HDI functionality: connect disconnect configureDI configureDIParameters createContainer dropContainer configureContainer configureContainerParameters listLibraries configureLibraries listConfiguredLibraries status read listDeployed readDeployed write delete make makeAsync grantContainerApiPrivileges grantContainerApiPrivilegesWithGrantOption revokeContainerApiPrivileges grantContainerSchemaPrivileges revokeContainerSchemaPrivileges grantContainerSchemaRoles revokeContainerSchemaRoles After installing the module via npm, an application needs to create an instance of the client: hdi = new HDI(container, logger, credentials); where container is the name of an existing container, logger is a callback function used to write logging information, and credentials is an object containing the host name, port, user and password that shall be used for the DB connection: { host : 'hostname', port : 30015, user : 'user', password : 'secret' } The connection to the database is established with the connect method, which takes only a callback function as parameter. When the application finishes, it should call hdi.disconnect(); configureDI (Deprecated) Configures HDI with the given parameters. - call_params : an object with key/value pairs configuring HDI and controlling the HDI behaviour - externCB : a callback function used to return errors or results configureDIParameters Configures HDI with the given configuration parameters and the given parameters. - di_params : an object with key/value pairs configuring HDI - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results createContainer Creates a container with the given container id. - container : the container id/name - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results dropContainer Drops the container with the given container id, incl. all corresponding technical users, schemata, tables, etc. - container : the container id/name - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results configureContainer (Deprecated) Configures the container with the given parameters. - call_params : an object with key/value pairs configuring the container and controlling the HDI behaviour - externCB : a callback function used to return errors or results configureContainerParameters Configures the container with the given configuration parameters and the given parameters. - container_params : an object with key/value pairs configuring the container - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results listLibraries List all available plugin libraries that can be installed into a container. - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results configureLibraries (Re)configures the set of plugin libraries which are installed in the given container. - libconfig : an array of [action, library_name] tuples. action could be ADD or REMOVE - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results listConfiguredLibraries List the set of plugin libraries which are installed in the given container. - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results status Shows the status of files and folders in the container. It takes the following parameters: - paths : an array of path names (strings) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results read Reads files/folders from the containers work file system . It takes the same parameters as status readDeployed Like read , but reads files/folders from the containers deployed file system . listDeployed Like readDeployed , but reads only metadata for files/folders from the containers deployed file system . write Writes files/folders to the containers work file system . It takes the following parameters: - paths_content : an array of arrays, containing the path names and the corresponding file content - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results delete Deletes files/folders from the containers work file system . It takes the same parameters as read . make / makeAsync Triggers a synchronous resp. asynchronous make with the given sets of files/folders. - deploy_paths : an array of path names, listing the files/folders to deploy - undeploy_paths : an array of path names, listing the files/folders to undeploy - path_parameters : an object with path names as keys and file specific parameters (like call_params) for each such path - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results grantContainerApiPrivileges / grantContainerApiPrivilegesWithGrantOption Grants the given privileges on the containers API objects to the given users. - privileges : an array of arrays (4-tuples: privilege name, object name, principal schema name, principal name) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results revokeContainerApiPrivileges Revokes the given privileges on the containers API objects from the given users. It takes the same parameters as grantContainerApiPrivileges. grantContainerSchemaPrivileges Grants the given privileges on the containers target schema to the given users. - privileges : array of arrays (3-tuples: privilege name, principal schema name, principal name) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results revokeContainerSchemaPrivileges Revokes the given privileges on the containers target schema from the given users. It takes the same parameters as grantContainerSchemaPrivileges. grantContainerSchemaRoles Grants the given roles (which are deployed inside the container) to the given users. - roles : array of arrays (3-tuples: role name, principal schema name, principal name) - call_params : an object with key/value pairs controlling the HDI behaviour - externCB : a callback function used to return errors or results revokeContainerSchemaRoles Revokes the given roles (which are deployed inside the container) from the given users. It takes the same parameters as grantContainerSchemaRoles.","title":"@sap/hdi"},{"location":"apis/hdi/CHANGELOG/","text":"1.1.4 \u00b6 Features: - Updated dependencies 1.1.3 \u00b6 Features: - Updated dependencies 1.1.2 \u00b6 Features: - Added npm-shrinkwrap.json 1.1.1 \u00b6 Features: - Updated dependencies - Added README.md - Added CHANGELOG.md","title":"CHANGELOG"},{"location":"apis/hdi/CHANGELOG/#114","text":"Features: - Updated dependencies","title":"1.1.4"},{"location":"apis/hdi/CHANGELOG/#113","text":"Features: - Updated dependencies","title":"1.1.3"},{"location":"apis/hdi/CHANGELOG/#112","text":"Features: - Added npm-shrinkwrap.json","title":"1.1.2"},{"location":"apis/hdi/CHANGELOG/#111","text":"Features: - Updated dependencies - Added README.md - Added CHANGELOG.md","title":"1.1.1"},{"location":"apis/hdi-deploy/","text":"@sap/hdi-deploy \u00b6 @sap/hdi-deploy is a Node.js -based deployment module for SAP HANA DI (HDI)-based persistence models, HDI Deployer for short. The HDI Deployer can be used in XS Advanced (XSA) and in SAP Cloud Platform (SAP CP)/Cloud Foundry (CF), and it is also used by the SAP Web IDE for interactive development scenarios. It can also be used in scenarios without XSA (or SAP CP), e.g. for deploying HDI persistence models into a HANA database where no XSA is installed. For more information about HANA DI, please check the SAP HANA Developer Guide and the SAP HANA Administration Guide . Usually, the HDI Deployer is packaged into a database module, a db module, as part of a Multi-Target Application (MTA) and is used to deploy HDI design-time artifacts of the db module to the respective HDI container. When an MTA is deployed via the Deploy Service, the db module is pushed first so that it can \"prepare\" the SAP HANA persistence; by the time defined services are started, the HDI container is ready for use. The HDI Deployer can also be used without the Deploy Service and MTAs, without XSA, and also for interactive scenarios or automation scripts. For an MTA with different modules, e.g. a db module, a Node.js module, etc., this looks as follows: + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | | | | | \\ / deploy persistence \\ / read / write / extend persistence | | | | | | + ---------------------------------------------------------------+ | HDI container | | | + ---------------------------------------------------------------+ In a HANA-Service-Broker-based HDI setup, each module of the MTA is equipped with it's own technical database user for accessing the runtime schema of the HDI container. The following diagram illustrates the different users who are involved in this setup with regard to privileges: the application users user1 and user2 who are bound to one of the modules each, and the HDI container's object owner (the #OO user) who is the owner of the objects in the database persistence of the MTA which are managed by HDI: + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | o | --------------------------------- X application user user1 | | o | | ----- X application user user2 | | + ---------------------------------------------------------------+ | HDI container | | db object 1 db object 2 | + -------------------------------------\\-------------/-----------+ \\ / o \\ / X object owner ( # OO user ) The HDI Deployer is packaged into the db module of the MTA. So, in order to use a new HDI Deployer, you need to reference a new version of the HDI Deployer in the db module's package.json file. The HDI Deployer supports HANA 1 SPS11/SPS12 and HANA 2. The HDI Deployer assumes that for newer versions of HANA, a corresponding version of the HANA Service Broker is used to create the CF/XSA service bindings. Note: The HDI Deployer assumes ownership of the src/ , cfg/ , and lib/ folders in the bound target HDI container. Binding more than 1 instance of the HDI Deployer to the same HDI container as the target container, e.g. the db modules of 2 MTAs or 2 applications are bound to the same HDI container as the target container, is not supported and results in undefined behavior. README.md \u00b6 Installation : - Integration into a Database Module - Database Connection Details - Deployment via Push and Tasks - Deployment via Local Run The Database Module : - A Database Module's File System Structure - Delta Deployment and Undeploy Whitelist - The default_access_role Role - The development_debug_role Role - Reusable Database Modules - Configuration File Templating - Permissions to Container-External Objects Configuration and Reconfiguration : - Environment Variables for Applications - Environment Variables for Infrastructure / Development Tools - Options for Interactive Scenarios - Ignore List - Supported Features Dynamic Deployment : - Deployment via hdi-dynamic-deploy Library Usage : - Using hdi-deploy as a Node.js library Integration into a Database Module \u00b6 Usually, @sap/hdi-deploy gets installed via a package.json -based dependency inside your application's db module: db/package.json : { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-deploy\": \"3.11.5\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-deploy/\" } } Database Connection Details \u00b6 Connection details for the database, e.g. host, port, credentials, certificates, hostname_in_certificate, encrypt and validate_certificate, are looked up by the HDI Deployer from the standard CF/XSA VCAP_SERVICES environment variable which contains the bound services. In order to use mutual authentication, client_authentication_private_key and client_authentication_certificate can be supplied via the service binding. For local testing, the HDI Deployer supports default configurations via the following configuration files: default-env.json : a JSON file which contains a set of environment variables and their values default-services.json : a JSON file which contains a set of service bindings Details of a bound service from a HANA-Service-Broker-based service binding in CF/XSA usually look as follows: { \"name\" : \"foo\" , \"label\" : \"hana\" , \"tags\" : [ \"hana\" , \"database\" , \"relational\" ], \"plan\" : \"hdi-shared\" , \"credentials\" : { \"schema\" : \"FOO\" , \"user\" : \"FOO_345999596729_RT\" , \"password\" : \"<password>\" , \"hdi_user\" : \"FOO_645927945801_DT\" , \"hdi_password\" : \"<password>\" , \"host\" : \"srv1234567.host.name\" , \"port\" : \"30115\" , \"db_hosts\" : [ { \"port\" : 30115 , \"host\" : \"srv1234567.host.name\" } ], \"url\" : \"jdbc:sap://srv1234567.host.name:30115/?currentschema=FOO\" , \"driver\" : \"com.sap.db.jdbc.Driver\" } } Here, the credentials section contains all the data which is needed by the HDI Deployer for connecting to the database. The HDI Deployer uses the hdi_user / hdi_password credentials from a direct service binding. The hdi_user should be minimal, i.e. only have the privileges required to fulfill the deployment. In most cases, access to a container FOO's API in the FOO#DI schema is sufficient. Splitting passwords across services \u00b6 The password property and the hdi_password property can also be specified as a combination of passwords from other bound services. Consider the following service binding: { \"hana\" : [], \"user-provided\" : [ { \"name\" : \"split_password_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"user\" : \"user\" , \"schema\" : \"schema\" , \"password\" : [ \"password_and_hdi_password_service\" , \"password_only_service\" ], \"hdi_password\" : [ \"password_and_hdi_password_service\" , \"hdi_password_only_service\" ], \"tags\" : [ \"hana\" ] } }, { \"name\" : \"password_and_hdi_password_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"password\" : \"PASSWORD\" , \"hdi_password\" : \"HDI_PASSWORD\" , \"tags\" : [ \"password\" ] } }, { \"name\" : \"hdi_password_only_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"hdi_password\" : \"123\" , \"tags\" : [ \"password\" ] } }, { \"name\" : \"password_only_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"password\" : \"456\" , \"tags\" : [ \"password\" ] } } ] } When the service shared_password_service is used, the services specified in password and/or hdi_password will be checked and their password and/or hdi_password will be concatenated. The services will be accessed in the order they are defined. The resulting shared_password_service would have the password \"PASSWORD456\" and the hdi_password \"HDI_PASSWORD123\". 0 to n services can be specified, specifying 0 services results in the password / hdi_password ''. VCAP_SERVICES \u00b6 Connection details for the database are stored in the following format in the VCAP_SERVICES environment variable: VCAP_SERVICES : { \"hana\" : [ <hana-service-binding-1>, <hana-service-binding-2>, ... <hana-service-binding-n> ], \"user-provided\" : [ <user-provided-service-binding-1>, <user-provided-service-binding-2>, ... <user-provided-service-binding-m> ] } ' default-env.json \u00b6 A default-env.json file can contain a set of environment variables and their values. The HDI Deployer will pick up these settings on startup: default-env.json: { \"TARGET_CONTAINER\" : \"<name-of-the-service-instance-to-use-as-deployment-target>\", \"VCAP_SERVICES\" : { \"hana\" : [ <hana-service-binding-1>, <hana-service-binding-2>, ... <hana-service-binding-n> ], \"user-provided\" : [ <user-provided-service-binding-1>, <user-provided-service-binding-2>, ... <user-provided-service-binding-m> ] } } default-env.json example file with a target container binding and a user-provided service: { \"TARGET_CONTAINER\" : \"target-service\", \"VCAP_SERVICES\" : { \"hana\" : [ { \"name\" : \"target-service\", \"label\" : \"hana\", \"tags\" : [ \"hana\", \"database\", \"relational\" ], \"plan\" : \"hdi-shared\", \"credentials\" : { \"schema\" : \"SCHEMA\", \"hdi_user\" : \"USER_DT\", \"hdi_password\" : \"PASSWORD_DT\", \"certificate\" : \"-----BEGIN CERTIFICATE-----\\nABCD...1234\\n-----END CERTIFICATE-----\\n\", \"host\" : \"host\", \"port\" : \"30015\" } } ], \"user-provided\" : [ { \"name\" : \"GRANTING_SERVICE\", \"label\" : \"user-provided\", \"tags\" : [ ], \"credentials\" : { \"schema\" : \"SYS\", \"user\" : \"GRANT_USER\", \"password\" : \"PASSWORD\", \"procedure_schema\" : \"PRIVILEGE_PROCEDURE_GRANTOR_DEFINER\", \"procedure\" : \"GRANT\", \"type\" : \"procedure\", \"tags\" : [ \"hana\" ] } } ] } } Deployment via Push and Tasks \u00b6 There are two ways of using the HDI Deployer as an application: Push the application with one instance. The application will then start and do the HDI deployment of the data model. After a successful deployment, the application will enter an idle loop and can be stopped. Push the application with zero instances and then trigger a task on the application which does the HDI deployment of the data model. After deployment of the data model, the task will be completed. An instance of the application is only running while the task is being executed. For both scenarios, ensure that the health-check-type in the manifest is set to process , instead of the default, port -based health check. In order to push the application with zero instances, the application can either be pushed with the --no-start option or the number of instances can be set to zero in the manifest.yml file via instances: 0 . The deployment task can be started via xs run-task <app> deployment-task \"npm run start -- --exit\" --wait-for-completion on XSA. The task will run and the call will propagate the success/failure of the deployment task. On CF, the --wait-for-completion option is not available and the status of the task needs to be checked periodically. Deployment via Local Run \u00b6 An HDI deployment can also be triggered without using an application. In this case, the HDI Deployer will be run locally and directly connects to the database. This is possible in the following scenarios: the database is accessible locally from a network point of view or a network tunnel with a local endpoint was established, e.g. a cf ssh -based tunnel is set up in CF. Apply the following steps to run the HDI Deployer locally: run npm install in the db module's folder to install the HDI Deployer module, then create a default-env.json file in the db module's folder which contains the required service bindings and the TARGET_CONTAINER setting, then run npm run start -- --exit in the db module's folder to trigger the deployment of the data model. If the database uses SSL/TLS encryption, please ensure that the hostname_in_certificate value is set up correctly in the service bindings, because the network tunnel's local endpoint (e.g. localhost:9000) doesn't match the hostname in the SSL/TLS certificate. A Database Module's File System Structure \u00b6 The HDI Deployer expects the following file system structure for the HDI content in your db module: src/ : folder which contains your HDI source artifacts cfg/ : optional folder with HDI configuration artifacts package.json : this file is used by npm (the Node.js package manager) to bootstrap and start the application Other files in the root directory will be ignored by @sap/hdi-deploy . Please note that the cfg/ folder also might need a .hdiconfig file, e.g. in case .hdbsynonymconfig files are placed there. In combination with reusable database modules, the HDI Deployer will also consider database modules which are located in the node_modules/ folder and which will be mapped to a corresponding sub-folder hierarchy in the container's lib/ folder. Note: The design-time files should be protected against unauthorized modifications to guard against unwanted undeployments or deployment of foreign objects. For applications running on XSA or Cloud Foundry, this is taken care of by the platform. Delta Deployment and Undeploy Whitelist \u00b6 The HDI Deployer implements a delta-based deployment strategy: On startup, the HDI Deployer recursively scans the local src/ and cfg/ folders, processes config templates, looks at the HDI container at the server-side and calculates the set of added, modified, and deleted files based on the difference between the local file system state and the deployed file system state of the server-side HDI container. In normal operation, the HDI Deployer will schedule only the set of added and modified files for deployment. The set of deleted files is not scheduled for undeployment. In order to undeploy deleted files, an application needs to include an undeploy whitelist via an undeploy.json file in the root directory of the db module (right beside the src/ and cfg/ folders). The undeploy whitelist undeploy.json file is a JSON document with a top-level array of file names: undeploy.json : [ \"src/Table.hdbcds\", \"src/Procedure.hdbprocedure\" ] The file must list all artifacts which should be undeployed. The file path of the artifacts must be relative to the root directory of the db module, must use the HDI file path delimiter '/', and must be based on the HDI server-side folder structure. In case of reusable database modules, the server-side top-level folder lib/ needs to be used instead of the local folder node_modules/ . For interactive scenarios, it's possible to pass the auto-undeploy option to the HDI Deployer, e.g. node deploy --auto-undeploy In this case, the HDI Deployer will ignore the undeploy whitelist undeploy.json file and will schedule all deleted files in the src/ and cfg/ folders for undeployment. The default_access_role Role \u00b6 When an HDI container service instance is created by the HANA Service Broker, e.g. service instance foo with schema name FOO , the broker creates an HDI container FOO (consisting of the runtime schema FOO , the HDI metadata and API schema FOO#DI , and the object owner FOO#OO ) and a global access role FOO::access_role for the runtime schema. This access role is equipped with a default permission set for the runtime schema which consists of SELECT , INSERT , UPDATE , DELETE , EXECUTE , CREATE TEMPORARY TABLE , and SELECT CDS METADATA on the runtime schema FOO . Every time the service instance is bound to an application, the broker creates 2 new users which are specific to this binding. The first user is the application user who is named user in the instance's credentials. This user is used by the application to access the HDI container's runtime schema FOO . This user is equipped with the service instance's global access role FOO::access_role . The second user is the HDI API user who is named hdi_user in the credentials. This user is equipped with privileges for the container's APIs in the FOO#DI schema. The following diagram illustrates the binding-specific application users and the role of the global access role (the HDI API users and the bindings for the HDI Deployer are not shown for simplicity): + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | o | --------------------------------- X application user user1 | | o \\ | | ----- X application user user2 \\ | | \\ \\ \\ \\ + ---------------------------------------------------------------+ role FOO::access_role | HDI container FOO | / | | SELECT / INSERT / ... on schema FOO + ---------------------------------------------------------------+ Exemplary service binding: { \"hana\" : [ { \"name\" : \"foo\", \"label\" : \"hana\", \"tags\" : [ \"hana\", \"database\", \"relational\" ], \"plan\" : \"hdi-shared\", \"credentials\" : { \"schema\" : \"FOO\", \"user\" : \"FOO_345999596729_RT\", \"password\" : \"<password>\", \"hdi_user\" : \"FOO_645927945801_DT, \"hdi_password\" : \"<password>\", \"host\" : \"srv1234567.host.name\", \"port\" : \"30115\", \"db_hosts\" : [ { \"port\" : 30115, \"host\" : \"srv1234567.host.name\" } ], \"url\" : \"jdbc:sap://srv1234567.host.name:30115/?currentschema=FOO\", \"driver\" : \"com.sap.db.jdbc.Driver\" } } ] } In order to assign roles from the HDI content to the application binding users (the user users), the HDI Deployer implements an automatic assignment of the default_access_role role if it is present in the deployed content: If a role definition file exists at the path src/defaults/default_access_role.hdbrole , and this file defines a role named default_access_role , and this file is included in the deployment (e.g. not excluded via include-filter ), then the HDI Deployer grants the deployed default_access_role role to the service instance's global access role (e.g. FOO::access_role ). In addition, the HDI Deployer revokes all default permissions (e.g. SELECT , INSERT , UPDATE , DELETE , EXECUTE , CREATE TEMPORARY TABLE , and SELECT CDS METADATA on the runtime schema FOO ) from the global access role. If the default_access_role is undeployed, the default permission set for the runtime schema will be restored. Note: If you use a .hdinamespace file in src/ which defines a real namespace prefix for subfolders, then you need to put a .hdinamespace file with the empty namespace \"name\" : \"\" at src/defaults/ to ensure that the role can be named default_access_role . The following diagram illustrates the binding-specific application users, the role of the global access role, and the container-specific default access role: + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | o | --------------------------------- X application user user1 | | o \\ | | ----- X application user user2 \\ | | \\ \\ \\ \\ + ---------------------------------------------------------------+ role FOO::access_role | HDI container FOO | / | role default_access_role ----------------------------+ | / \\ | | role role1 role role2 | | / / \\ | | structured privileges DCL role 1 / 2 | + ---------------------------------------------------------------+ Note: The default_access_role is assumed to be an \"umbrella\" role which aggregates other roles. A role with the default permission set which is granted by the HANA Service Broker on container creation looks as follows: default_permissions_role.hdbrole : { \"role\":{ \"name\":\"default_permissions_role\", \"schema_privileges\":[ { \"privileges\":[ \"SELECT\", \"INSERT\", \"UPDATE\", \"DELETE\", \"EXECUTE\", \"CREATE TEMPORARY TABLE\", \"SELECT CDS METADATA\" ] } ] } } The development_debug_role Role \u00b6 Similarly to the default_access_role, a development_debug_role can be used to add additional privileges to the access role. This is only intended for development and debugging, not for productive use! If a role definition file exists at the path src/defaults/development_debug_role.hdbrole , and this file defines a role named development_debug_role , and this file is explicitly included in the deployment via the --deploy option, then the HDI Deployer grants the deployed development_debug_role role to the service instance's global access role (e.g. FOO::access_role ). In order to remove the privileges granted this way, the file has to be undeployed. Reusable Database Modules \u00b6 In order to allow that an application uses (parts of) the database persistence of a reusable component inside its own persistence model, the HDI Deployer allows to link/include the design-time files of reusable components in a consuming application in an automated way. This mechanism is based on the Node.js package management mechanism for defining, publishing, and consuming reusable database modules which also supports versioning based on the semantic versioning concepts (cf. http://semver.org). A reusable database module is considered to have the same src/ and cfg/ folder structure as a normal database module. The src/.hdiconfig file is mandatory and used by the module mechanism as an indicator that the src/ and cfg/ folders belong to a consumable, reusable database module. In addition, the reusable database module needs to have a package.json file which defines the module's name, the module's version, etc. A complete reusable database module looks as follows: / +-- src/ | +-- .hdiconfig | +-- <source files ...> +-- cfg/ | +-- <optional configuration files ...> +-- package.json The package.json file contains the module\u2019s name, description, version, repository URL, and the set of files which belong to the module: package.json : { \"name\": \"module1\", \"description\": \"A set of reusable database objects\", \"version\": \"1.3.1\", \"repository\": { \"url\": \"git@your.gitserver:modules/module1.git\" }, \"files\": [ \"src\", \"cfg\", \"package.json\" ] } The reusable database module should be published to a Node.js package management compliant object repository. Consumption of a reusable database module is done by adding a dependency in the consuming module's package.json file, right beside the dependency to @sap/hdi-deploy : { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-deploy\": \"3.11.5\", \"module1\": \"1.3.1\", \"module2\": \"1.7.0\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-deploy/\" } } Here, the consuming module requires module1 in version 1.3.1 and module2 in version 1.7.0 . When running npm install to download and install the dependencies which are listed in the dependencies section of the package.json file, npm will also download the reusable database modules and places them into the node_modules/ folder of the consuming module. For each module a separate subfolder is created with the name of the module. When the HDI Deployer is triggered to do the actual deployment of the (consuming) database module, it scans the node_modules/ folder and virtually integrates the src/ and cfg/ folders of found reusable database modules into the (consuming) database module\u2019s lib/ folder. Reusable database modules are identified by the mandatory src/.hdiconfig file. On successful deployment, the HDI container will contain the consumed modules below the root-level lib/ folder, e.g. / +-- src/ +-- cfg/ +-- lib/ | +-- module1/ | | +-- src/ | | +-- cfg/ | +-- module2/ | +-- src/ | +-- cfg/ For the time being, it\u2019s not allowed to recursively include reusable database modules. The cfg/ folders of reusable database modules are also subject to configuration file templating. Configuration File Templating \u00b6 The HDI Deployer implements a templating mechanism for HDI configuration files, e.g. configuration files for synonyms, projection views, etc., based on services which are bound to the db module application. By means of this templating mechanism, it is possible to configure synonyms, projection views, etc. to point to the right database schema without knowing the schema name at development time. On startup, the HDI Deployer recursively scans the local cfg/ folder and picks up all files with a .*config suffix, e.g. all .hdbsynonymconfig , .hdbvirtualtableconfig , etc. files. For all collected files which contain .configure markers in their content, it applies the configuration templating and creates transient configuration files which are then deployed to the HDI container. For a synonym configuration file cfg/LOCAL_TARGET.hdbsynonymconfig { \"LOCAL_TARGET\" : { \"target\" : { \"schema.configure\" : \"logical-external-service/schema\", \"database.configure\" : \"logical-external-service/database\", \"object\" : \"TARGET\" } } } the section \"schema.configure\" : \"logical-external-service/schema\", \"database.configure\" : \"logical-external-service/database\", \"object\" : \"TARGET\" will be transformed by the templating mechanism into \"schema\" : \"THE_SCHEMA\", \"database\" : \"THE_DATABASE\", \"object\" : \"TARGET\" where THE_SCHEMA and THE_DATABASE are the values for the schema and database fields of the bound service logical-external-service , which are denoted by the path expressions logical-external-service/schema and logical-external-service/database . If a field in the service is missing, it will not be configured and will be removed instead, e.g. database might be optional. The names of the services are subject to the service replacements mechanism, which can be used to map a real service, e.g. real-external-service , to a logical service name which is used in the configuration files, e.g. logical-external-service . It's not always applicable to use schema.configure , database.configure , etc. in the configuration template files. Therefore, the HDI Deployer provides a generic way of copying a set of properties from the bound service, e.g. schema, database, remote source, etc. if they are present, although the template file doesn't mention them. For the configuration file cfg/LOCAL_TARGET.hdbsynonymconfig this could looks as follows: { \"LOCAL_TARGET\" : { \"target\" : { \"*.configure\" : \"logical-external-service\", \"object\" : \"TARGET\" } } } When the HDI Deployer encounters a *.configure entry, it simply copies all well-known fields which are present in the bound service into the configuration file. The well-known fields are currently remote , database , and schema . The HDI Deployer also supports old-style .hdbsynonymtemplate template files: If a .hdbsynonymtemplate file is found in the cfg/ or src/ folder, then it is processed as a configuration template file and a transient file with the suffix .hdbsynonymconfig is created. A field grantor is replaced with the schema value from the referenced service; so, a grantor field is equivalent to a \"schema.configure\" : \"the-service/schema\" entry in a configuration template file. Permissions to Container-External Objects \u00b6 An HDI container is by default equipped with nearly zero database privileges, e.g. the object owner ( #OO user) is mainly equipped with the CREATE ANY privilege on the container's runtime schema (e.g. schema FOO for an HDI container FOO ). Since HANA 2 SPS00, the object owner is equipped with an additional restricted set of privileges for system views in the database's SYS schema, e.g. SYS.VIEWS or SYS.TABLES . These system views apply an additional row-level filter based on the object owner's other privileges, e.g. the object owner can only see metadata in SYS.VIEWS for views he has privileges on. So, without additional privileges, the object owner can only see metadata for the objects in his container schema. In order to access database objects inside other database schemata or other HDI containers, and in order to deploy synonyms into the HDI container which point to these container-external objects, at least the object owner needs additional privileges, e.g. for an object object in schema X SELECT privileges on X.object : +---------------------------------------------------------------+ +------------------------+ | HDI container FOO | | other schema X | | synonym ------------------------> object | +---------------------------------------------------/-----------+ +-------------\\----------+ / \\ o / \\ X object owner FOO#OO -------------------- SELECT on X.object Please also refer to the official Using Synonyms to Access External Schemas and Objects in XS Advanced guide. .hdbrevokes Files \u00b6 Starting with version 3.8, the deployer now allows revoking rights. Anything that can be granted via .hdbgrants can be revoked via .hdbrevokes. Both files, .hdbgrants and .hdbrevokes use the same structure. For more information on the structure of these files, see the section about .hdbgrants Files . The .hdbrevokes file will be processed before the .hdbgrants file. .hdbgrants Files \u00b6 In order to automatically assign privileges to the object owner and/or the application binding users, the HDI Deployer provides .hdbgrants files with a syntax similar to .hdbrole files: An .hdbgrants file has the following structure: granting-service.hdbgrants : { \"granting-service\": { \"object_owner\": { <privileges> }, \"application_user\": { <privileges> } } } The top-level keys define the names of the bound services which \"grant\" the privileges, these are the \"grantors\", e.g. granting-service in the example. The next level defines to which users the privileges will be granted, these are the \"grantees\": object_owner is used for the HDI container's object owner, and application_user marks the application users which are bound to the application modules, e.g. the Node.js module. The third level defines the set of privileges in a .hdbrole -like structure. On startup, the HDI Deployer looks for .hdbgrants files and processes them as follows: For each grantor in the file, the HDI Deployer looks up a bound service with the name (subject to service replacements), connects to the database with the service's credentials, and grants the specified privileges to the grantees. If the schema field is omitted for a privilege, then the grantor's schema property is used. If the name field in a global_object_privileges element of type REMOTE SOURCE is omitted, then the grantor's remote property is used. For backwards compatibility, also the suffix .hdbsynonymgrantor is supported. Example of a cfg/external-access.hdbgrants file with some privileges for the object owner: { \"external-access\": { \"object_owner\": { \"system_privileges\" : [ { \"privileges\" : [ \"SYSTEM_PRIVILEGE_1\" ], \"privileges_with_admin_option\" : [ \"SYSTEM_PRIVILEGE_2\", \"SYSTEM_PRIVILEGE_3\" ] } ], \"global_roles\" : [ { \"roles\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ], \"roles_with_admin_option\" : [ \"GLOBAL_ROLE_3\", \"GLOBAL_ROLE_4\" ] } ], \"schema_privileges\" : [ { \"privileges\" : [ \"INSERT\", \"UPDATE\" ], \"privileges_with_grant_option\" : [ \"SELECT\" ] } ], \"schema_roles\" : [ { \"roles\" : [ \"SCHEMA_ROLE_1\", \"SCHEMA_ROLE_2\" ], \"roles_with_admin_option\" : [ \"SCHEMA_ROLE_3\", \"SCHEMA_ROLE_4\" ] } ], \"object_privileges\" : [ { \"name\": \"AN_OBJECT\", \"privileges\": [ \"INSERT\", \"UPDATE\" ], \"privileges_with_grant_option\" : [ \"SELECT\" ] } ], \"global_object_privileges\" : [ { \"name\" : \"A_REMOTE_SOURCE\", \"type\" : \"REMOTE SOURCE\", \"privileges\" : [ \"CREATE VIRTUAL TABLE\" ], \"privileges_with_grant_option\" : [ \"CREATE VIRTUAL PROCEDURE\" ] } ] } } } The following elements and keys are supported for backwards compatibility or for compatibility with .hdbrole : container_roles : grant roles from an HDI container; superseded by schema_roles which works for normal schemas and HDI containers \"container_roles\" : [ \"SCHEMA_ROLE_1\", \"SCHEMA_ROLE_2\" ] roles : grant global roles; superseded by global_roles : \"roles\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ] string-array-style roles and names key (maps to the non-grant/admin-option variant): \"global_roles\" : [ \"GLOBAL_ROLE_1\", { \"roles\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ] }, { \"names\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ] }, { \"roles_with_admin_option\" : [ \"GLOBAL_ROLE_3\", \"GLOBAL_ROLE_4\" ] }, \"GLOBAL_ROLE_2\" ] If any non-container privileges are used, then the object owner ( #OO user) will need to be given these privileges WITH GRANT option by a user-defined granting-service. Otherwise it won't be able to grant these privileges to e.g. a role in the container. Creating a Granting Service \u00b6 The HDI Deployer supports the following types of granting-services: hdi : an HDI container with access to the container's GRANT APIs sql : a technical database user with GRANT privileges for the required object privileges, roles, system privileges, etc. procedure : a technical database user with EXECUTE privileges on a stored procedure which has GRANT privileges for the required object privileges, roles, system privileges, etc. ignore : grants were already given at the database-level and the HDI Deployer will ignore the content of the .hdbgrants file. For the HDI container case, the corresponding service can simply be bound to the db module application. The HDI Deployer recognizes the bound service by its hdi_user value in the credentials section and calls the container's API procedures to grant the privileges from the .hdbgrants file. In case a technical database user is used, a 'user-defined service' must be created for this purpose in the same space as the container. The service needs to be set up with the permissions of a specified database user to connect to the database and to grant the privileges specified in the .hdbgrants files during application deployment. Such a user-provided service can be created as follows: Open a command shell and log on to XSA: xs login Change to the target space where you want to create the user-defined service: xs target -s <SPACE> Create the user-defined service (e.g. grantor-service ): xs cups grantor-service -p '{ \"host\": \"host.acme.com\", \"port\": \"30015\", \"certificate\": \"<myCertificate>\", \"user\": \"TARGET_USER\", \"password\": \"Grant_123\", \"schema\": \"TARGET_SCHEMA\", \"tags\": [ \"hana\" ] }' \"host\"/\"port\" : Required for the connection to the database: port is the SQL port of the index server. \"certificate\" : If the database is configured to only accept secure connections, then the granting-service requires an SSL certificate that must be included in the user-provided service, for example, using the \"certificate\":\" \" parameter. \"user\"/\"password\" : Connection details for a database user that has grant permissions for the objects in the schema. \"schema\" : The database schema that contains the objects to which access is to be granted. \"type\" : The type of the grantor mechanism; valid values are \"hdi\" , \"sql\" , or \"procedure\" . If the type is not specified, then the type is auto-sensed (see details below). Use the command xs services to display a list of services available in the current space; the 'grantor-service' service should be visible. For Cloud Foundry, use the corresponding cf commands. Note: Starting with version 3.0.0 of the HDI Deployer, the \"host\" , \"port\" , and \"certificate\" parameters are no longer required since they can be obtained from the target container binding. In this case, you must only specify the \"user\" , \"password\" , and \"schema\" when creating the user-provided service, e.g. xs cups grantor-service -p '{ \"user\": \"TARGET_USER\", \"password\": \"Grant_123\", \"schema\": \"TARGET_SCHEMA\", \"tags\": [ \"hana\" ] }' . If the \"type\" is not specified, then the type is selected based on the following rule: if the field hdi_user is present, then the type is auto-sensed as hdi ; otherwise, the type is set to sql . If the technical database user does not have GRANT privileges by its own, but only EXECUTE privileges on a stored procedure which can grant the privileges, then the following settings are required: At the database, a GRANT procedure must exist (or be visible) in the schema which is used in the user-provided service; an example is shown below. The technical database user must have EXECUTE privileges on the GRANT procedure. The name of the GRANT procedure must be specified in the user-provided service in the \"procedure\" field, e.g. \"procedure\": \"GRANT\" . The scheme name of the GRANT procedure can be specified in the user-provided service in the \"procedure_schema\" field, e.g. \"procedure_schema\": \"A_SCHEMA\" . The user-provided service must contain a \"type\" field with the value \"procedure\" . For the different types of privileges, the following fields are passed to the GRANT procedure: PRIVILEGE_TYPE PRIVILEGE_NAME OBJECT_SCHEMA OBJECT_NAME OBJECT_TYPE GRANTEE_SCHEMA GRANTEE_NAME GRANTABLE SCHEMA_OBJECT_PRIVILEGE privilege schema object NULL NULL grantee TRUE/FALSE GLOBAL_OBJECT_PRIVILEGE privilege NULL object type NULL grantee TRUE/FALSE SCHEMA_ROLE NULL schema role NULL NULL grantee TRUE/FALSE GLOBAL_ROLE NULL NULL role NULL NULL grantee TRUE/FALSE SCHEMA_PRIVILEGE privilege NULL schema NULL NULL grantee TRUE/FALSE SYSTEM_PRIVILEGE privilege NULL NULL NULL NULL grantee TRUE/FALSE Note: This procedure does not work for HANA1 SPS11, since REPLACE_REGEXPR is not supported. Please use the sample procedure provided with older releases of the deployer. The old sample procedure does not correctly handle component names of system privileges in .hdbgrants files. Example of a GRANT procedure: CREATE PROCEDURE GRANT ( IN PRIVILEGES TABLE ( PRIVILEGE_TYPE NVARCHAR ( 128 ), -- 'SCHEMA_OBJECT_PRIVILEGE' -- 'GLOBAL_OBJECT_PRIVILEGE' -- 'SCHEMA_ROLE' -- 'GLOBAL_ROLE' -- 'SCHEMA_PRIVILEGE' -- 'SYSTEM_PRIVILEGE' PRIVILEGE_NAME NVARCHAR ( 256 ), -- cf. SYS.PRIVILEGES OBJECT_SCHEMA NVARCHAR ( 256 ), -- NULL or schema OBJECT_NAME NVARCHAR ( 256 ), OBJECT_TYPE NVARCHAR ( 128 ), -- NULL or 'REMOTE SOURCE' GRANTEE_SCHEMA NVARCHAR ( 256 ), -- NULL or schema GRANTEE_NAME NVARCHAR ( 256 ), GRANTABLE NVARCHAR ( 5 ) -- 'TRUE' or 'FALSE' ) ) LANGUAGE SQLSCRIPT SQL SECURITY DEFINER AS BEGIN DECLARE ERROR CONDITION FOR SQL_ERROR_CODE 10000 ; DECLARE CURSOR PRIVILEGES_CURSOR FOR SELECT * FROM : PRIVILEGES ; -- TODO: add checks for valid grantees, e.g. check with _SYS_DI#<group>.M_CONTAINER_SCHEMAS -- or with SYS.USERS and creator and grantee like '%#OO' -- TODO: keep only functionality that should be allowed, e.g. only allow to grant schema-local -- roles, but no object privileges, etc. FOR PRIVILEGE AS PRIVILEGES_CURSOR DO DECLARE TO_GRANTEE_CLAUSE NVARCHAR ( 512 ); DECLARE GRANTABLE_CLAUSE NVARCHAR ( 512 ) = '' ; IF PRIVILEGE . GRANTEE_SCHEMA IS NULL THEN TO_GRANTEE_CLAUSE = ' TO \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . GRANTEE_NAME ) || '\"' ; ELSE TO_GRANTEE_CLAUSE = ' TO \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . GRANTEE_SCHEMA ) || '\".\"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . GRANTEE_NAME ) || '\"' ; END IF ; IF PRIVILEGE . GRANTABLE = 'TRUE' THEN IF PRIVILEGE . PRIVILEGE_TYPE = 'SYSTEM_PRIVILEGE' OR PRIVILEGE . PRIVILEGE_TYPE = 'GLOBAL_ROLE' OR PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_ROLE' THEN GRANTABLE_CLAUSE = ' WITH ADMIN OPTION' ; ELSE GRANTABLE_CLAUSE = ' WITH GRANT OPTION' ; END IF ; ELSEIF PRIVILEGE . GRANTABLE != 'FALSE' THEN SIGNAL ERROR SET MESSAGE_TEXT = 'unsupported value for GRANTABLE: ' || PRIVILEGE . GRANTABLE ; END IF ; IF PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_OBJECT_PRIVILEGE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) || '\"' || ' ON \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_SCHEMA ) || '\".\"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'GLOBAL_OBJECT_PRIVILEGE' THEN IF PRIVILEGE . OBJECT_TYPE = 'REMOTE SOURCE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) || '\"' || ' ON ' || PRIVILEGE . OBJECT_TYPE || ' \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSE SIGNAL ERROR SET MESSAGE_TEXT = 'unsupported value for OBJECT_TYPE for GLOBAL_OBJECT_PRIVILEGE: ' || PRIVILEGE . OBJECT_TYPE ; END IF ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_ROLE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_SCHEMA ) || '\".\"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'GLOBAL_ROLE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_PRIVILEGE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) || '\"' || ' ON SCHEMA \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'SYSTEM_PRIVILEGE' THEN EXEC 'GRANT \"' || REPLACE_REGEXPR ( '\\.' IN ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) WITH '\".\"' ) || '\"' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSE SIGNAL ERROR SET MESSAGE_TEXT = 'unsupported value for PRIVILEGE_TYPE: ' || PRIVILEGE . PRIVILEGE_TYPE ; END IF ; END FOR ; END ; Defining the Granting Service in the mta[d].yaml \u00b6 If the container needs a granting-service, then besides the service itself, the Application Development Descriptor mta.yaml needs to be adjusted for the deployer to be able to find the service. The mta.yaml must be modified to: The container of the db module needs to get a TARGET_CONTAINER property to mark the service that corresponds to the container A new entry in requires is added for the granting-service A new entry in resources is added for the granting-service Example: mta.yaml : schema-version: '2.0' ID: granting-service-example version: 0.0.1 modules: - name: db type: hdb path: db requires: - name: hdi-container properties: # 1. TARGET_CONTAINER: ~{hdi-container-service} # 1. - name: granting-service # 2. resources: - name: hdi-container type: com.sap.xs.hdi-container properties: hdi-container-service: ${ service - name } - name: granting-service # 3. type: org.cloudfoundry.existing-service # 3. Environment Variables for Applications \u00b6 @sap/hdi-deploy supports (re-)configuration via the following environment variables which are exposed to applications, e.g. via the CF/XSA manifest.yml or the MTA descriptor mta.yaml : TARGET_CONTAINER : (optional) service name that specifies the HDI target container (needed, if more than one HDI service is bound to the HDI Deployer) SERVICE_REPLACEMENTS : (optional) JSON-structured list of service replacements, e.g. [ { \"key\": \"logical-service-name-1\", \"service\":\"real-service-name-1\"}, { \"key\": \"logical-service-name-2\", \"service\":\"real-service-name-2\"} ] , where the logical service names refer to the names in the HDI content and the real service names refer to the services which are bound to the HDI Deployer via VCAP_SERVICES ; if the HDI content references a service name which is not listed in the replacements, then this name is used as a real service name The structure of the SERVICE_REPLACEMENTS environment variable is based on the MTA specification in order to enable MTA group assignments. Example manifest.yml : applications: - name: app-db path: db health-check-type: process services: - app-database - real-grantor-service - real-external-service env: TARGET_CONTAINER: app-database SERVICE_REPLACEMENTS: > [ { \"key\" : \"logical-grantor-service\", \"service\" : \"real-grantor-service\" }, { \"key\" : \"logical-external-service\", \"service\" : \"real-external-service\" } ] Environment Variables for Infrastructure / Development Tools \u00b6 @sap/hdi-deploy supports (re-)configuration via the following environment variables for infrastructure / development tools like the Deploy Service or internal build tools of the WEB IDE EXIT : (optional) if set, the HDI Deployer will exit when the deployment is done; using the environment variable is equivalent to passing a --exit on the command line DEPLOY_ID : (optional) if set, the given id will be written to the final application log entry (custom id, to support processes in parsing log output HDI_DEPLOY_OPTIONS : (optional) JSON-structured set of options for the HDI Deployer, e.g. { \"auto_undeploy\" : true, \"exit\" : true, \"root\" : \"/volumes/A/workspaces/B/db/\", \"include_filter\" : [ \"src/\", \"cfg/\" ] } ; command line options can be translated to HDI_DEPLOY_OPTIONS options by replacing the - s in the option names with _ s; options which can accept multiple values require a JSON array with the values, e.g. path options like the include-filter option. APPLICATION_ID : (optional, fallback SAP_HDI ) this will be used, in conjunction with the space_name and the organization_name of the VCAP_APPLICATION to set the session variable APPLICATION for all connections to the database. This setting may only be used by applications from SAP. APPLICATION_VERSION_INFO : (optional) this will be logged to the command line, to allow logging of some additional information about the application. Options from HDI_DEPLOY_OPTIONS override options which are passed on the command line. Ignore List \u00b6 The hdi deployer supports ignoring certain files via an .hdiignore file. The file has to be placed at the root of the project folder, just like the undeploy.json . The file has a structure similar to a .gitignore file, simply lines of texts specifying the paths to exclude. Both \"real\" paths and path patterns are supported. src/table_1.hdbtable src/*_2.hdbtable The file works just like the --exclude-filter option and they can be used at the same time. Options for Interactive Scenarios \u00b6 @sap/hdi-deploy supports the following options for interactive deployment scenarios, e.g. for orchestration via the WEB IDE or for CI scripts: --[no-]verbose : [don't] print detailed log messages to the console --structured-log <file> : write log messages as JSON objects into the given file; messages are appended if the file already exists --[no-]exit : [don't] exit after deployment of artifacts --[no-]lock-container : [don't] acquire the container lock while working with the container --root <path> : use the given root path for artifacts --working-set [<path> ..] : define the given paths (directories and files) as the working set; a non-default working set applies additional restrictions, e.g. other options might be disallowed --include-filter [<path> ..] : only include the given paths (directories and files) during delta detection --deploy [<file> ..] : explicitly schedule the given files for deploy; extends the include-filter for collecting local files. Instead of a real path, a path pattern like src/* / .hdbtable can be used as well. --[no-]treat-unmodified-as-modified : [don't] treat unmodified files during delta detection as modified files --undeploy [<file> ..] : explicitly schedule the given files for undeploy --parameter [<key>=<value> ..] : pass the given list of key-value parameters to the deployment --path-parameter [<path>:<key>=<value> ..] : pass the given list of path-key-value parameters to the deployment --[no-]auto-undeploy : [don't] undeploy artifacts automatically based on delta detection and ignore the undeploy.json file --[no-]treat-warnings-as-errors : [don't] treat warnings as errors --[no-]simulate-make : [don't] simulate the make and skip post-make activities; pre-make activities still take effect, e.g. grants --connection-timeout <ms> : number of milliseconds to wait for the database connection(s) --lock-container-timeout <ms> : number of milliseconds to wait for the container lock --exclude-filter [<path> ..] : exclude the given paths during: file walk, delta detection and when explicitly scheduled via --(un)deploy --[no-]treat-wrong-ownership-as-errors : [don't] treat wrong ownership of objects as errors, not enabled by default --[no-]migrationtable-development-mode : [don't] pass the development mode flag for migration tables to HDI, if the parameter is supported by the server, not enabled by default --[no-]liveness-ping : [don't] send a sign of life from time to time, by default, a sign of life will be sent --[no-]live-messages : [don't] display the make messages while the make is still in progress, by default, the messages will be displayed while the make is in progress See --help for details and defaults. Options can also be passed to @sap/hdi-deploy via the HDI_DEPLOY_OPTIONS environment variable. Supported Features \u00b6 @sap/hdi-deploy exposes its set of features via the info option, which can be passed as --option or via HDI_DEPLOY_OPTIONS , e.g. node deploy --info [<component> [<component> [...]]] where a list of components can be specified. The info option allows to pass multiple components. The info request for these components is optional, e.g. if the HDI Deployer doesn't support the component, then it will not throw an error, but simply not return information for that component. The special component all will return the information for all known components; all is the default if no component is specified. For certain future components, e.g. server , the HDI Deployer might need to connect to the HDI container in the database and retrieve feature information from there. Examples: node deploy --info all node deploy --info client server The result of an info call is a JSON document where the top-level objects correspond to the requested components. Each component should at least report its name, its version, and the set of supported features with name and version number (version numbers are simple numbers (no dots, no double-dots)). If a version number is negative, then the feature is supported by the client, but not supported by the server. For a --info client call, the document looks as follows: { \"client\": { \"name\": \"@sap/hdi-deploy\", \"version\": \"3.11.5\", \"features\": { \"info\": 2, \"verbose\": 1, \"structured-log\": 1, \"lock-container\": 1, \"default-access-role\": 1, \"grants\": 4, \"working-set\": 1, \"include-filter\": 1, \"deploy\": 1, \"treat-unmodified-as-modified\": 1, \"undeploy\": 1, \"parameter\": 1, \"path-parameter\": 1, \"treat-warnings-as-errors\": 1, \"simulate-make\": 1, \"service-replacements\": 1, \"modules\": 2, \"config-templates\": 2, \"environment-options\": 1, \"undeploy-whitelist\": 1 } } } For the server component, the document would also contain the following data: { ... \"server\": { \"name\": \"sap-hana-database\", \"version\": \"1.00.120.04.0000000000\", \"features\": {} } } Deployment via hdi-dynamic-deploy \u00b6 The standard XSA/CF way for deploying HDI content at runtime is to make use of @sap/hdi-dynamic-deploy instead of @sap/hdi-deploy directly. The @sap/hdi-dynamic-deploy app is an http server that calls @sap/hdi-deploy when it receives a corresponding HTTP POST request. See the @sap/hdi-dynamic-deploy module for more information. Using hdi-deploy as a Node.js library \u00b6 Since version 3.3.0 of @sap/hdi-deploy it is also possible to use it as a Node.js library. By requiring the library.js file from the project root it is possible to start the deployer app from within another Node.js app. The module exports the function function deploy ( contentDir, deployerEnv, callback, io ) with the following parameters: contentDir : string containing a path pointing to the root of the db module to be deployed deployerEnv : javascript object containing the OS environment for the call to the deployer (e.g. containing VCAP_SERVICES) callback : a standard callback of the form (errors, result), where result is the result of the call to the deployer of the form: { messages: [<list of result messages from the di server>], exitCode: <exit code of the call to the deployer app, one of -1, 0, 1.>, signal: <signal that the child process was closed with> } io (optional): javascript object containing two callback functions io.stdoutCB and io.stderrCB of the form function(data) for streaming stdout and stderr of the call to the deployer, defaults to piping stdout and stderr of the deployer to stdout and stderr of the calling Node.js app The exit codes have different meanings: -1: The child process was most likely killed externally, check the signal property for details. 0: Deployment done succesfully. 1: Deployment failed, errors occurred. The signal property is only set, if exitCode is -1.","title":"Index"},{"location":"apis/hdi-deploy/#saphdi-deploy","text":"@sap/hdi-deploy is a Node.js -based deployment module for SAP HANA DI (HDI)-based persistence models, HDI Deployer for short. The HDI Deployer can be used in XS Advanced (XSA) and in SAP Cloud Platform (SAP CP)/Cloud Foundry (CF), and it is also used by the SAP Web IDE for interactive development scenarios. It can also be used in scenarios without XSA (or SAP CP), e.g. for deploying HDI persistence models into a HANA database where no XSA is installed. For more information about HANA DI, please check the SAP HANA Developer Guide and the SAP HANA Administration Guide . Usually, the HDI Deployer is packaged into a database module, a db module, as part of a Multi-Target Application (MTA) and is used to deploy HDI design-time artifacts of the db module to the respective HDI container. When an MTA is deployed via the Deploy Service, the db module is pushed first so that it can \"prepare\" the SAP HANA persistence; by the time defined services are started, the HDI container is ready for use. The HDI Deployer can also be used without the Deploy Service and MTAs, without XSA, and also for interactive scenarios or automation scripts. For an MTA with different modules, e.g. a db module, a Node.js module, etc., this looks as follows: + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | | | | | \\ / deploy persistence \\ / read / write / extend persistence | | | | | | + ---------------------------------------------------------------+ | HDI container | | | + ---------------------------------------------------------------+ In a HANA-Service-Broker-based HDI setup, each module of the MTA is equipped with it's own technical database user for accessing the runtime schema of the HDI container. The following diagram illustrates the different users who are involved in this setup with regard to privileges: the application users user1 and user2 who are bound to one of the modules each, and the HDI container's object owner (the #OO user) who is the owner of the objects in the database persistence of the MTA which are managed by HDI: + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | o | --------------------------------- X application user user1 | | o | | ----- X application user user2 | | + ---------------------------------------------------------------+ | HDI container | | db object 1 db object 2 | + -------------------------------------\\-------------/-----------+ \\ / o \\ / X object owner ( # OO user ) The HDI Deployer is packaged into the db module of the MTA. So, in order to use a new HDI Deployer, you need to reference a new version of the HDI Deployer in the db module's package.json file. The HDI Deployer supports HANA 1 SPS11/SPS12 and HANA 2. The HDI Deployer assumes that for newer versions of HANA, a corresponding version of the HANA Service Broker is used to create the CF/XSA service bindings. Note: The HDI Deployer assumes ownership of the src/ , cfg/ , and lib/ folders in the bound target HDI container. Binding more than 1 instance of the HDI Deployer to the same HDI container as the target container, e.g. the db modules of 2 MTAs or 2 applications are bound to the same HDI container as the target container, is not supported and results in undefined behavior.","title":"@sap/hdi-deploy"},{"location":"apis/hdi-deploy/#readmemd","text":"Installation : - Integration into a Database Module - Database Connection Details - Deployment via Push and Tasks - Deployment via Local Run The Database Module : - A Database Module's File System Structure - Delta Deployment and Undeploy Whitelist - The default_access_role Role - The development_debug_role Role - Reusable Database Modules - Configuration File Templating - Permissions to Container-External Objects Configuration and Reconfiguration : - Environment Variables for Applications - Environment Variables for Infrastructure / Development Tools - Options for Interactive Scenarios - Ignore List - Supported Features Dynamic Deployment : - Deployment via hdi-dynamic-deploy Library Usage : - Using hdi-deploy as a Node.js library","title":"README.md"},{"location":"apis/hdi-deploy/#integration-into-a-database-module","text":"Usually, @sap/hdi-deploy gets installed via a package.json -based dependency inside your application's db module: db/package.json : { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-deploy\": \"3.11.5\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-deploy/\" } }","title":"Integration into a Database Module"},{"location":"apis/hdi-deploy/#database-connection-details","text":"Connection details for the database, e.g. host, port, credentials, certificates, hostname_in_certificate, encrypt and validate_certificate, are looked up by the HDI Deployer from the standard CF/XSA VCAP_SERVICES environment variable which contains the bound services. In order to use mutual authentication, client_authentication_private_key and client_authentication_certificate can be supplied via the service binding. For local testing, the HDI Deployer supports default configurations via the following configuration files: default-env.json : a JSON file which contains a set of environment variables and their values default-services.json : a JSON file which contains a set of service bindings Details of a bound service from a HANA-Service-Broker-based service binding in CF/XSA usually look as follows: { \"name\" : \"foo\" , \"label\" : \"hana\" , \"tags\" : [ \"hana\" , \"database\" , \"relational\" ], \"plan\" : \"hdi-shared\" , \"credentials\" : { \"schema\" : \"FOO\" , \"user\" : \"FOO_345999596729_RT\" , \"password\" : \"<password>\" , \"hdi_user\" : \"FOO_645927945801_DT\" , \"hdi_password\" : \"<password>\" , \"host\" : \"srv1234567.host.name\" , \"port\" : \"30115\" , \"db_hosts\" : [ { \"port\" : 30115 , \"host\" : \"srv1234567.host.name\" } ], \"url\" : \"jdbc:sap://srv1234567.host.name:30115/?currentschema=FOO\" , \"driver\" : \"com.sap.db.jdbc.Driver\" } } Here, the credentials section contains all the data which is needed by the HDI Deployer for connecting to the database. The HDI Deployer uses the hdi_user / hdi_password credentials from a direct service binding. The hdi_user should be minimal, i.e. only have the privileges required to fulfill the deployment. In most cases, access to a container FOO's API in the FOO#DI schema is sufficient.","title":"Database Connection Details"},{"location":"apis/hdi-deploy/#splitting-passwords-across-services","text":"The password property and the hdi_password property can also be specified as a combination of passwords from other bound services. Consider the following service binding: { \"hana\" : [], \"user-provided\" : [ { \"name\" : \"split_password_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"user\" : \"user\" , \"schema\" : \"schema\" , \"password\" : [ \"password_and_hdi_password_service\" , \"password_only_service\" ], \"hdi_password\" : [ \"password_and_hdi_password_service\" , \"hdi_password_only_service\" ], \"tags\" : [ \"hana\" ] } }, { \"name\" : \"password_and_hdi_password_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"password\" : \"PASSWORD\" , \"hdi_password\" : \"HDI_PASSWORD\" , \"tags\" : [ \"password\" ] } }, { \"name\" : \"hdi_password_only_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"hdi_password\" : \"123\" , \"tags\" : [ \"password\" ] } }, { \"name\" : \"password_only_service\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"password\" : \"456\" , \"tags\" : [ \"password\" ] } } ] } When the service shared_password_service is used, the services specified in password and/or hdi_password will be checked and their password and/or hdi_password will be concatenated. The services will be accessed in the order they are defined. The resulting shared_password_service would have the password \"PASSWORD456\" and the hdi_password \"HDI_PASSWORD123\". 0 to n services can be specified, specifying 0 services results in the password / hdi_password ''.","title":"Splitting passwords across services"},{"location":"apis/hdi-deploy/#vcap_services","text":"Connection details for the database are stored in the following format in the VCAP_SERVICES environment variable: VCAP_SERVICES : { \"hana\" : [ <hana-service-binding-1>, <hana-service-binding-2>, ... <hana-service-binding-n> ], \"user-provided\" : [ <user-provided-service-binding-1>, <user-provided-service-binding-2>, ... <user-provided-service-binding-m> ] } '","title":"VCAP_SERVICES"},{"location":"apis/hdi-deploy/#default-envjson","text":"A default-env.json file can contain a set of environment variables and their values. The HDI Deployer will pick up these settings on startup: default-env.json: { \"TARGET_CONTAINER\" : \"<name-of-the-service-instance-to-use-as-deployment-target>\", \"VCAP_SERVICES\" : { \"hana\" : [ <hana-service-binding-1>, <hana-service-binding-2>, ... <hana-service-binding-n> ], \"user-provided\" : [ <user-provided-service-binding-1>, <user-provided-service-binding-2>, ... <user-provided-service-binding-m> ] } } default-env.json example file with a target container binding and a user-provided service: { \"TARGET_CONTAINER\" : \"target-service\", \"VCAP_SERVICES\" : { \"hana\" : [ { \"name\" : \"target-service\", \"label\" : \"hana\", \"tags\" : [ \"hana\", \"database\", \"relational\" ], \"plan\" : \"hdi-shared\", \"credentials\" : { \"schema\" : \"SCHEMA\", \"hdi_user\" : \"USER_DT\", \"hdi_password\" : \"PASSWORD_DT\", \"certificate\" : \"-----BEGIN CERTIFICATE-----\\nABCD...1234\\n-----END CERTIFICATE-----\\n\", \"host\" : \"host\", \"port\" : \"30015\" } } ], \"user-provided\" : [ { \"name\" : \"GRANTING_SERVICE\", \"label\" : \"user-provided\", \"tags\" : [ ], \"credentials\" : { \"schema\" : \"SYS\", \"user\" : \"GRANT_USER\", \"password\" : \"PASSWORD\", \"procedure_schema\" : \"PRIVILEGE_PROCEDURE_GRANTOR_DEFINER\", \"procedure\" : \"GRANT\", \"type\" : \"procedure\", \"tags\" : [ \"hana\" ] } } ] } }","title":"default-env.json"},{"location":"apis/hdi-deploy/#deployment-via-push-and-tasks","text":"There are two ways of using the HDI Deployer as an application: Push the application with one instance. The application will then start and do the HDI deployment of the data model. After a successful deployment, the application will enter an idle loop and can be stopped. Push the application with zero instances and then trigger a task on the application which does the HDI deployment of the data model. After deployment of the data model, the task will be completed. An instance of the application is only running while the task is being executed. For both scenarios, ensure that the health-check-type in the manifest is set to process , instead of the default, port -based health check. In order to push the application with zero instances, the application can either be pushed with the --no-start option or the number of instances can be set to zero in the manifest.yml file via instances: 0 . The deployment task can be started via xs run-task <app> deployment-task \"npm run start -- --exit\" --wait-for-completion on XSA. The task will run and the call will propagate the success/failure of the deployment task. On CF, the --wait-for-completion option is not available and the status of the task needs to be checked periodically.","title":"Deployment via Push and Tasks"},{"location":"apis/hdi-deploy/#deployment-via-local-run","text":"An HDI deployment can also be triggered without using an application. In this case, the HDI Deployer will be run locally and directly connects to the database. This is possible in the following scenarios: the database is accessible locally from a network point of view or a network tunnel with a local endpoint was established, e.g. a cf ssh -based tunnel is set up in CF. Apply the following steps to run the HDI Deployer locally: run npm install in the db module's folder to install the HDI Deployer module, then create a default-env.json file in the db module's folder which contains the required service bindings and the TARGET_CONTAINER setting, then run npm run start -- --exit in the db module's folder to trigger the deployment of the data model. If the database uses SSL/TLS encryption, please ensure that the hostname_in_certificate value is set up correctly in the service bindings, because the network tunnel's local endpoint (e.g. localhost:9000) doesn't match the hostname in the SSL/TLS certificate.","title":"Deployment via Local Run"},{"location":"apis/hdi-deploy/#a-database-modules-file-system-structure","text":"The HDI Deployer expects the following file system structure for the HDI content in your db module: src/ : folder which contains your HDI source artifacts cfg/ : optional folder with HDI configuration artifacts package.json : this file is used by npm (the Node.js package manager) to bootstrap and start the application Other files in the root directory will be ignored by @sap/hdi-deploy . Please note that the cfg/ folder also might need a .hdiconfig file, e.g. in case .hdbsynonymconfig files are placed there. In combination with reusable database modules, the HDI Deployer will also consider database modules which are located in the node_modules/ folder and which will be mapped to a corresponding sub-folder hierarchy in the container's lib/ folder. Note: The design-time files should be protected against unauthorized modifications to guard against unwanted undeployments or deployment of foreign objects. For applications running on XSA or Cloud Foundry, this is taken care of by the platform.","title":"A Database Module's File System Structure"},{"location":"apis/hdi-deploy/#delta-deployment-and-undeploy-whitelist","text":"The HDI Deployer implements a delta-based deployment strategy: On startup, the HDI Deployer recursively scans the local src/ and cfg/ folders, processes config templates, looks at the HDI container at the server-side and calculates the set of added, modified, and deleted files based on the difference between the local file system state and the deployed file system state of the server-side HDI container. In normal operation, the HDI Deployer will schedule only the set of added and modified files for deployment. The set of deleted files is not scheduled for undeployment. In order to undeploy deleted files, an application needs to include an undeploy whitelist via an undeploy.json file in the root directory of the db module (right beside the src/ and cfg/ folders). The undeploy whitelist undeploy.json file is a JSON document with a top-level array of file names: undeploy.json : [ \"src/Table.hdbcds\", \"src/Procedure.hdbprocedure\" ] The file must list all artifacts which should be undeployed. The file path of the artifacts must be relative to the root directory of the db module, must use the HDI file path delimiter '/', and must be based on the HDI server-side folder structure. In case of reusable database modules, the server-side top-level folder lib/ needs to be used instead of the local folder node_modules/ . For interactive scenarios, it's possible to pass the auto-undeploy option to the HDI Deployer, e.g. node deploy --auto-undeploy In this case, the HDI Deployer will ignore the undeploy whitelist undeploy.json file and will schedule all deleted files in the src/ and cfg/ folders for undeployment.","title":"Delta Deployment and Undeploy Whitelist"},{"location":"apis/hdi-deploy/#the-default_access_role-role","text":"When an HDI container service instance is created by the HANA Service Broker, e.g. service instance foo with schema name FOO , the broker creates an HDI container FOO (consisting of the runtime schema FOO , the HDI metadata and API schema FOO#DI , and the object owner FOO#OO ) and a global access role FOO::access_role for the runtime schema. This access role is equipped with a default permission set for the runtime schema which consists of SELECT , INSERT , UPDATE , DELETE , EXECUTE , CREATE TEMPORARY TABLE , and SELECT CDS METADATA on the runtime schema FOO . Every time the service instance is bound to an application, the broker creates 2 new users which are specific to this binding. The first user is the application user who is named user in the instance's credentials. This user is used by the application to access the HDI container's runtime schema FOO . This user is equipped with the service instance's global access role FOO::access_role . The second user is the HDI API user who is named hdi_user in the credentials. This user is equipped with privileges for the container's APIs in the FOO#DI schema. The following diagram illustrates the binding-specific application users and the role of the global access role (the HDI API users and the bindings for the HDI Deployer are not shown for simplicity): + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | o | --------------------------------- X application user user1 | | o \\ | | ----- X application user user2 \\ | | \\ \\ \\ \\ + ---------------------------------------------------------------+ role FOO::access_role | HDI container FOO | / | | SELECT / INSERT / ... on schema FOO + ---------------------------------------------------------------+ Exemplary service binding: { \"hana\" : [ { \"name\" : \"foo\", \"label\" : \"hana\", \"tags\" : [ \"hana\", \"database\", \"relational\" ], \"plan\" : \"hdi-shared\", \"credentials\" : { \"schema\" : \"FOO\", \"user\" : \"FOO_345999596729_RT\", \"password\" : \"<password>\", \"hdi_user\" : \"FOO_645927945801_DT, \"hdi_password\" : \"<password>\", \"host\" : \"srv1234567.host.name\", \"port\" : \"30115\", \"db_hosts\" : [ { \"port\" : 30115, \"host\" : \"srv1234567.host.name\" } ], \"url\" : \"jdbc:sap://srv1234567.host.name:30115/?currentschema=FOO\", \"driver\" : \"com.sap.db.jdbc.Driver\" } } ] } In order to assign roles from the HDI content to the application binding users (the user users), the HDI Deployer implements an automatic assignment of the default_access_role role if it is present in the deployed content: If a role definition file exists at the path src/defaults/default_access_role.hdbrole , and this file defines a role named default_access_role , and this file is included in the deployment (e.g. not excluded via include-filter ), then the HDI Deployer grants the deployed default_access_role role to the service instance's global access role (e.g. FOO::access_role ). In addition, the HDI Deployer revokes all default permissions (e.g. SELECT , INSERT , UPDATE , DELETE , EXECUTE , CREATE TEMPORARY TABLE , and SELECT CDS METADATA on the runtime schema FOO ) from the global access role. If the default_access_role is undeployed, the default permission set for the runtime schema will be restored. Note: If you use a .hdinamespace file in src/ which defines a real namespace prefix for subfolders, then you need to put a .hdinamespace file with the empty namespace \"name\" : \"\" at src/defaults/ to ensure that the role can be named default_access_role . The following diagram illustrates the binding-specific application users, the role of the global access role, and the container-specific default access role: + -----------------+ +-----------------+ +-----------------+ | db module | | Node . js module | | ... module | | w / HDI Deployer | | | | | + -----------------+ +-----------------+ +-----------------+ | | o | --------------------------------- X application user user1 | | o \\ | | ----- X application user user2 \\ | | \\ \\ \\ \\ + ---------------------------------------------------------------+ role FOO::access_role | HDI container FOO | / | role default_access_role ----------------------------+ | / \\ | | role role1 role role2 | | / / \\ | | structured privileges DCL role 1 / 2 | + ---------------------------------------------------------------+ Note: The default_access_role is assumed to be an \"umbrella\" role which aggregates other roles. A role with the default permission set which is granted by the HANA Service Broker on container creation looks as follows: default_permissions_role.hdbrole : { \"role\":{ \"name\":\"default_permissions_role\", \"schema_privileges\":[ { \"privileges\":[ \"SELECT\", \"INSERT\", \"UPDATE\", \"DELETE\", \"EXECUTE\", \"CREATE TEMPORARY TABLE\", \"SELECT CDS METADATA\" ] } ] } }","title":"The default_access_role Role"},{"location":"apis/hdi-deploy/#the-development_debug_role-role","text":"Similarly to the default_access_role, a development_debug_role can be used to add additional privileges to the access role. This is only intended for development and debugging, not for productive use! If a role definition file exists at the path src/defaults/development_debug_role.hdbrole , and this file defines a role named development_debug_role , and this file is explicitly included in the deployment via the --deploy option, then the HDI Deployer grants the deployed development_debug_role role to the service instance's global access role (e.g. FOO::access_role ). In order to remove the privileges granted this way, the file has to be undeployed.","title":"The development_debug_role Role"},{"location":"apis/hdi-deploy/#reusable-database-modules","text":"In order to allow that an application uses (parts of) the database persistence of a reusable component inside its own persistence model, the HDI Deployer allows to link/include the design-time files of reusable components in a consuming application in an automated way. This mechanism is based on the Node.js package management mechanism for defining, publishing, and consuming reusable database modules which also supports versioning based on the semantic versioning concepts (cf. http://semver.org). A reusable database module is considered to have the same src/ and cfg/ folder structure as a normal database module. The src/.hdiconfig file is mandatory and used by the module mechanism as an indicator that the src/ and cfg/ folders belong to a consumable, reusable database module. In addition, the reusable database module needs to have a package.json file which defines the module's name, the module's version, etc. A complete reusable database module looks as follows: / +-- src/ | +-- .hdiconfig | +-- <source files ...> +-- cfg/ | +-- <optional configuration files ...> +-- package.json The package.json file contains the module\u2019s name, description, version, repository URL, and the set of files which belong to the module: package.json : { \"name\": \"module1\", \"description\": \"A set of reusable database objects\", \"version\": \"1.3.1\", \"repository\": { \"url\": \"git@your.gitserver:modules/module1.git\" }, \"files\": [ \"src\", \"cfg\", \"package.json\" ] } The reusable database module should be published to a Node.js package management compliant object repository. Consumption of a reusable database module is done by adding a dependency in the consuming module's package.json file, right beside the dependency to @sap/hdi-deploy : { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-deploy\": \"3.11.5\", \"module1\": \"1.3.1\", \"module2\": \"1.7.0\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-deploy/\" } } Here, the consuming module requires module1 in version 1.3.1 and module2 in version 1.7.0 . When running npm install to download and install the dependencies which are listed in the dependencies section of the package.json file, npm will also download the reusable database modules and places them into the node_modules/ folder of the consuming module. For each module a separate subfolder is created with the name of the module. When the HDI Deployer is triggered to do the actual deployment of the (consuming) database module, it scans the node_modules/ folder and virtually integrates the src/ and cfg/ folders of found reusable database modules into the (consuming) database module\u2019s lib/ folder. Reusable database modules are identified by the mandatory src/.hdiconfig file. On successful deployment, the HDI container will contain the consumed modules below the root-level lib/ folder, e.g. / +-- src/ +-- cfg/ +-- lib/ | +-- module1/ | | +-- src/ | | +-- cfg/ | +-- module2/ | +-- src/ | +-- cfg/ For the time being, it\u2019s not allowed to recursively include reusable database modules. The cfg/ folders of reusable database modules are also subject to configuration file templating.","title":"Reusable Database Modules"},{"location":"apis/hdi-deploy/#configuration-file-templating","text":"The HDI Deployer implements a templating mechanism for HDI configuration files, e.g. configuration files for synonyms, projection views, etc., based on services which are bound to the db module application. By means of this templating mechanism, it is possible to configure synonyms, projection views, etc. to point to the right database schema without knowing the schema name at development time. On startup, the HDI Deployer recursively scans the local cfg/ folder and picks up all files with a .*config suffix, e.g. all .hdbsynonymconfig , .hdbvirtualtableconfig , etc. files. For all collected files which contain .configure markers in their content, it applies the configuration templating and creates transient configuration files which are then deployed to the HDI container. For a synonym configuration file cfg/LOCAL_TARGET.hdbsynonymconfig { \"LOCAL_TARGET\" : { \"target\" : { \"schema.configure\" : \"logical-external-service/schema\", \"database.configure\" : \"logical-external-service/database\", \"object\" : \"TARGET\" } } } the section \"schema.configure\" : \"logical-external-service/schema\", \"database.configure\" : \"logical-external-service/database\", \"object\" : \"TARGET\" will be transformed by the templating mechanism into \"schema\" : \"THE_SCHEMA\", \"database\" : \"THE_DATABASE\", \"object\" : \"TARGET\" where THE_SCHEMA and THE_DATABASE are the values for the schema and database fields of the bound service logical-external-service , which are denoted by the path expressions logical-external-service/schema and logical-external-service/database . If a field in the service is missing, it will not be configured and will be removed instead, e.g. database might be optional. The names of the services are subject to the service replacements mechanism, which can be used to map a real service, e.g. real-external-service , to a logical service name which is used in the configuration files, e.g. logical-external-service . It's not always applicable to use schema.configure , database.configure , etc. in the configuration template files. Therefore, the HDI Deployer provides a generic way of copying a set of properties from the bound service, e.g. schema, database, remote source, etc. if they are present, although the template file doesn't mention them. For the configuration file cfg/LOCAL_TARGET.hdbsynonymconfig this could looks as follows: { \"LOCAL_TARGET\" : { \"target\" : { \"*.configure\" : \"logical-external-service\", \"object\" : \"TARGET\" } } } When the HDI Deployer encounters a *.configure entry, it simply copies all well-known fields which are present in the bound service into the configuration file. The well-known fields are currently remote , database , and schema . The HDI Deployer also supports old-style .hdbsynonymtemplate template files: If a .hdbsynonymtemplate file is found in the cfg/ or src/ folder, then it is processed as a configuration template file and a transient file with the suffix .hdbsynonymconfig is created. A field grantor is replaced with the schema value from the referenced service; so, a grantor field is equivalent to a \"schema.configure\" : \"the-service/schema\" entry in a configuration template file.","title":"Configuration File Templating"},{"location":"apis/hdi-deploy/#permissions-to-container-external-objects","text":"An HDI container is by default equipped with nearly zero database privileges, e.g. the object owner ( #OO user) is mainly equipped with the CREATE ANY privilege on the container's runtime schema (e.g. schema FOO for an HDI container FOO ). Since HANA 2 SPS00, the object owner is equipped with an additional restricted set of privileges for system views in the database's SYS schema, e.g. SYS.VIEWS or SYS.TABLES . These system views apply an additional row-level filter based on the object owner's other privileges, e.g. the object owner can only see metadata in SYS.VIEWS for views he has privileges on. So, without additional privileges, the object owner can only see metadata for the objects in his container schema. In order to access database objects inside other database schemata or other HDI containers, and in order to deploy synonyms into the HDI container which point to these container-external objects, at least the object owner needs additional privileges, e.g. for an object object in schema X SELECT privileges on X.object : +---------------------------------------------------------------+ +------------------------+ | HDI container FOO | | other schema X | | synonym ------------------------> object | +---------------------------------------------------/-----------+ +-------------\\----------+ / \\ o / \\ X object owner FOO#OO -------------------- SELECT on X.object Please also refer to the official Using Synonyms to Access External Schemas and Objects in XS Advanced guide.","title":"Permissions to Container-External Objects"},{"location":"apis/hdi-deploy/#hdbrevokes-files","text":"Starting with version 3.8, the deployer now allows revoking rights. Anything that can be granted via .hdbgrants can be revoked via .hdbrevokes. Both files, .hdbgrants and .hdbrevokes use the same structure. For more information on the structure of these files, see the section about .hdbgrants Files . The .hdbrevokes file will be processed before the .hdbgrants file.","title":".hdbrevokes Files"},{"location":"apis/hdi-deploy/#hdbgrants-files","text":"In order to automatically assign privileges to the object owner and/or the application binding users, the HDI Deployer provides .hdbgrants files with a syntax similar to .hdbrole files: An .hdbgrants file has the following structure: granting-service.hdbgrants : { \"granting-service\": { \"object_owner\": { <privileges> }, \"application_user\": { <privileges> } } } The top-level keys define the names of the bound services which \"grant\" the privileges, these are the \"grantors\", e.g. granting-service in the example. The next level defines to which users the privileges will be granted, these are the \"grantees\": object_owner is used for the HDI container's object owner, and application_user marks the application users which are bound to the application modules, e.g. the Node.js module. The third level defines the set of privileges in a .hdbrole -like structure. On startup, the HDI Deployer looks for .hdbgrants files and processes them as follows: For each grantor in the file, the HDI Deployer looks up a bound service with the name (subject to service replacements), connects to the database with the service's credentials, and grants the specified privileges to the grantees. If the schema field is omitted for a privilege, then the grantor's schema property is used. If the name field in a global_object_privileges element of type REMOTE SOURCE is omitted, then the grantor's remote property is used. For backwards compatibility, also the suffix .hdbsynonymgrantor is supported. Example of a cfg/external-access.hdbgrants file with some privileges for the object owner: { \"external-access\": { \"object_owner\": { \"system_privileges\" : [ { \"privileges\" : [ \"SYSTEM_PRIVILEGE_1\" ], \"privileges_with_admin_option\" : [ \"SYSTEM_PRIVILEGE_2\", \"SYSTEM_PRIVILEGE_3\" ] } ], \"global_roles\" : [ { \"roles\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ], \"roles_with_admin_option\" : [ \"GLOBAL_ROLE_3\", \"GLOBAL_ROLE_4\" ] } ], \"schema_privileges\" : [ { \"privileges\" : [ \"INSERT\", \"UPDATE\" ], \"privileges_with_grant_option\" : [ \"SELECT\" ] } ], \"schema_roles\" : [ { \"roles\" : [ \"SCHEMA_ROLE_1\", \"SCHEMA_ROLE_2\" ], \"roles_with_admin_option\" : [ \"SCHEMA_ROLE_3\", \"SCHEMA_ROLE_4\" ] } ], \"object_privileges\" : [ { \"name\": \"AN_OBJECT\", \"privileges\": [ \"INSERT\", \"UPDATE\" ], \"privileges_with_grant_option\" : [ \"SELECT\" ] } ], \"global_object_privileges\" : [ { \"name\" : \"A_REMOTE_SOURCE\", \"type\" : \"REMOTE SOURCE\", \"privileges\" : [ \"CREATE VIRTUAL TABLE\" ], \"privileges_with_grant_option\" : [ \"CREATE VIRTUAL PROCEDURE\" ] } ] } } } The following elements and keys are supported for backwards compatibility or for compatibility with .hdbrole : container_roles : grant roles from an HDI container; superseded by schema_roles which works for normal schemas and HDI containers \"container_roles\" : [ \"SCHEMA_ROLE_1\", \"SCHEMA_ROLE_2\" ] roles : grant global roles; superseded by global_roles : \"roles\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ] string-array-style roles and names key (maps to the non-grant/admin-option variant): \"global_roles\" : [ \"GLOBAL_ROLE_1\", { \"roles\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ] }, { \"names\" : [ \"GLOBAL_ROLE_1\", \"GLOBAL_ROLE_2\" ] }, { \"roles_with_admin_option\" : [ \"GLOBAL_ROLE_3\", \"GLOBAL_ROLE_4\" ] }, \"GLOBAL_ROLE_2\" ] If any non-container privileges are used, then the object owner ( #OO user) will need to be given these privileges WITH GRANT option by a user-defined granting-service. Otherwise it won't be able to grant these privileges to e.g. a role in the container.","title":".hdbgrants Files"},{"location":"apis/hdi-deploy/#creating-a-granting-service","text":"The HDI Deployer supports the following types of granting-services: hdi : an HDI container with access to the container's GRANT APIs sql : a technical database user with GRANT privileges for the required object privileges, roles, system privileges, etc. procedure : a technical database user with EXECUTE privileges on a stored procedure which has GRANT privileges for the required object privileges, roles, system privileges, etc. ignore : grants were already given at the database-level and the HDI Deployer will ignore the content of the .hdbgrants file. For the HDI container case, the corresponding service can simply be bound to the db module application. The HDI Deployer recognizes the bound service by its hdi_user value in the credentials section and calls the container's API procedures to grant the privileges from the .hdbgrants file. In case a technical database user is used, a 'user-defined service' must be created for this purpose in the same space as the container. The service needs to be set up with the permissions of a specified database user to connect to the database and to grant the privileges specified in the .hdbgrants files during application deployment. Such a user-provided service can be created as follows: Open a command shell and log on to XSA: xs login Change to the target space where you want to create the user-defined service: xs target -s <SPACE> Create the user-defined service (e.g. grantor-service ): xs cups grantor-service -p '{ \"host\": \"host.acme.com\", \"port\": \"30015\", \"certificate\": \"<myCertificate>\", \"user\": \"TARGET_USER\", \"password\": \"Grant_123\", \"schema\": \"TARGET_SCHEMA\", \"tags\": [ \"hana\" ] }' \"host\"/\"port\" : Required for the connection to the database: port is the SQL port of the index server. \"certificate\" : If the database is configured to only accept secure connections, then the granting-service requires an SSL certificate that must be included in the user-provided service, for example, using the \"certificate\":\" \" parameter. \"user\"/\"password\" : Connection details for a database user that has grant permissions for the objects in the schema. \"schema\" : The database schema that contains the objects to which access is to be granted. \"type\" : The type of the grantor mechanism; valid values are \"hdi\" , \"sql\" , or \"procedure\" . If the type is not specified, then the type is auto-sensed (see details below). Use the command xs services to display a list of services available in the current space; the 'grantor-service' service should be visible. For Cloud Foundry, use the corresponding cf commands. Note: Starting with version 3.0.0 of the HDI Deployer, the \"host\" , \"port\" , and \"certificate\" parameters are no longer required since they can be obtained from the target container binding. In this case, you must only specify the \"user\" , \"password\" , and \"schema\" when creating the user-provided service, e.g. xs cups grantor-service -p '{ \"user\": \"TARGET_USER\", \"password\": \"Grant_123\", \"schema\": \"TARGET_SCHEMA\", \"tags\": [ \"hana\" ] }' . If the \"type\" is not specified, then the type is selected based on the following rule: if the field hdi_user is present, then the type is auto-sensed as hdi ; otherwise, the type is set to sql . If the technical database user does not have GRANT privileges by its own, but only EXECUTE privileges on a stored procedure which can grant the privileges, then the following settings are required: At the database, a GRANT procedure must exist (or be visible) in the schema which is used in the user-provided service; an example is shown below. The technical database user must have EXECUTE privileges on the GRANT procedure. The name of the GRANT procedure must be specified in the user-provided service in the \"procedure\" field, e.g. \"procedure\": \"GRANT\" . The scheme name of the GRANT procedure can be specified in the user-provided service in the \"procedure_schema\" field, e.g. \"procedure_schema\": \"A_SCHEMA\" . The user-provided service must contain a \"type\" field with the value \"procedure\" . For the different types of privileges, the following fields are passed to the GRANT procedure: PRIVILEGE_TYPE PRIVILEGE_NAME OBJECT_SCHEMA OBJECT_NAME OBJECT_TYPE GRANTEE_SCHEMA GRANTEE_NAME GRANTABLE SCHEMA_OBJECT_PRIVILEGE privilege schema object NULL NULL grantee TRUE/FALSE GLOBAL_OBJECT_PRIVILEGE privilege NULL object type NULL grantee TRUE/FALSE SCHEMA_ROLE NULL schema role NULL NULL grantee TRUE/FALSE GLOBAL_ROLE NULL NULL role NULL NULL grantee TRUE/FALSE SCHEMA_PRIVILEGE privilege NULL schema NULL NULL grantee TRUE/FALSE SYSTEM_PRIVILEGE privilege NULL NULL NULL NULL grantee TRUE/FALSE Note: This procedure does not work for HANA1 SPS11, since REPLACE_REGEXPR is not supported. Please use the sample procedure provided with older releases of the deployer. The old sample procedure does not correctly handle component names of system privileges in .hdbgrants files. Example of a GRANT procedure: CREATE PROCEDURE GRANT ( IN PRIVILEGES TABLE ( PRIVILEGE_TYPE NVARCHAR ( 128 ), -- 'SCHEMA_OBJECT_PRIVILEGE' -- 'GLOBAL_OBJECT_PRIVILEGE' -- 'SCHEMA_ROLE' -- 'GLOBAL_ROLE' -- 'SCHEMA_PRIVILEGE' -- 'SYSTEM_PRIVILEGE' PRIVILEGE_NAME NVARCHAR ( 256 ), -- cf. SYS.PRIVILEGES OBJECT_SCHEMA NVARCHAR ( 256 ), -- NULL or schema OBJECT_NAME NVARCHAR ( 256 ), OBJECT_TYPE NVARCHAR ( 128 ), -- NULL or 'REMOTE SOURCE' GRANTEE_SCHEMA NVARCHAR ( 256 ), -- NULL or schema GRANTEE_NAME NVARCHAR ( 256 ), GRANTABLE NVARCHAR ( 5 ) -- 'TRUE' or 'FALSE' ) ) LANGUAGE SQLSCRIPT SQL SECURITY DEFINER AS BEGIN DECLARE ERROR CONDITION FOR SQL_ERROR_CODE 10000 ; DECLARE CURSOR PRIVILEGES_CURSOR FOR SELECT * FROM : PRIVILEGES ; -- TODO: add checks for valid grantees, e.g. check with _SYS_DI#<group>.M_CONTAINER_SCHEMAS -- or with SYS.USERS and creator and grantee like '%#OO' -- TODO: keep only functionality that should be allowed, e.g. only allow to grant schema-local -- roles, but no object privileges, etc. FOR PRIVILEGE AS PRIVILEGES_CURSOR DO DECLARE TO_GRANTEE_CLAUSE NVARCHAR ( 512 ); DECLARE GRANTABLE_CLAUSE NVARCHAR ( 512 ) = '' ; IF PRIVILEGE . GRANTEE_SCHEMA IS NULL THEN TO_GRANTEE_CLAUSE = ' TO \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . GRANTEE_NAME ) || '\"' ; ELSE TO_GRANTEE_CLAUSE = ' TO \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . GRANTEE_SCHEMA ) || '\".\"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . GRANTEE_NAME ) || '\"' ; END IF ; IF PRIVILEGE . GRANTABLE = 'TRUE' THEN IF PRIVILEGE . PRIVILEGE_TYPE = 'SYSTEM_PRIVILEGE' OR PRIVILEGE . PRIVILEGE_TYPE = 'GLOBAL_ROLE' OR PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_ROLE' THEN GRANTABLE_CLAUSE = ' WITH ADMIN OPTION' ; ELSE GRANTABLE_CLAUSE = ' WITH GRANT OPTION' ; END IF ; ELSEIF PRIVILEGE . GRANTABLE != 'FALSE' THEN SIGNAL ERROR SET MESSAGE_TEXT = 'unsupported value for GRANTABLE: ' || PRIVILEGE . GRANTABLE ; END IF ; IF PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_OBJECT_PRIVILEGE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) || '\"' || ' ON \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_SCHEMA ) || '\".\"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'GLOBAL_OBJECT_PRIVILEGE' THEN IF PRIVILEGE . OBJECT_TYPE = 'REMOTE SOURCE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) || '\"' || ' ON ' || PRIVILEGE . OBJECT_TYPE || ' \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSE SIGNAL ERROR SET MESSAGE_TEXT = 'unsupported value for OBJECT_TYPE for GLOBAL_OBJECT_PRIVILEGE: ' || PRIVILEGE . OBJECT_TYPE ; END IF ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_ROLE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_SCHEMA ) || '\".\"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'GLOBAL_ROLE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'SCHEMA_PRIVILEGE' THEN EXEC 'GRANT \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) || '\"' || ' ON SCHEMA \"' || ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . OBJECT_NAME ) || '\" ' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSEIF PRIVILEGE . PRIVILEGE_TYPE = 'SYSTEM_PRIVILEGE' THEN EXEC 'GRANT \"' || REPLACE_REGEXPR ( '\\.' IN ESCAPE_DOUBLE_QUOTES ( PRIVILEGE . PRIVILEGE_NAME ) WITH '\".\"' ) || '\"' || TO_GRANTEE_CLAUSE || GRANTABLE_CLAUSE ; ELSE SIGNAL ERROR SET MESSAGE_TEXT = 'unsupported value for PRIVILEGE_TYPE: ' || PRIVILEGE . PRIVILEGE_TYPE ; END IF ; END FOR ; END ;","title":"Creating a Granting Service"},{"location":"apis/hdi-deploy/#defining-the-granting-service-in-the-mtadyaml","text":"If the container needs a granting-service, then besides the service itself, the Application Development Descriptor mta.yaml needs to be adjusted for the deployer to be able to find the service. The mta.yaml must be modified to: The container of the db module needs to get a TARGET_CONTAINER property to mark the service that corresponds to the container A new entry in requires is added for the granting-service A new entry in resources is added for the granting-service Example: mta.yaml : schema-version: '2.0' ID: granting-service-example version: 0.0.1 modules: - name: db type: hdb path: db requires: - name: hdi-container properties: # 1. TARGET_CONTAINER: ~{hdi-container-service} # 1. - name: granting-service # 2. resources: - name: hdi-container type: com.sap.xs.hdi-container properties: hdi-container-service: ${ service - name } - name: granting-service # 3. type: org.cloudfoundry.existing-service # 3.","title":"Defining the Granting Service in the mta[d].yaml"},{"location":"apis/hdi-deploy/#environment-variables-for-applications","text":"@sap/hdi-deploy supports (re-)configuration via the following environment variables which are exposed to applications, e.g. via the CF/XSA manifest.yml or the MTA descriptor mta.yaml : TARGET_CONTAINER : (optional) service name that specifies the HDI target container (needed, if more than one HDI service is bound to the HDI Deployer) SERVICE_REPLACEMENTS : (optional) JSON-structured list of service replacements, e.g. [ { \"key\": \"logical-service-name-1\", \"service\":\"real-service-name-1\"}, { \"key\": \"logical-service-name-2\", \"service\":\"real-service-name-2\"} ] , where the logical service names refer to the names in the HDI content and the real service names refer to the services which are bound to the HDI Deployer via VCAP_SERVICES ; if the HDI content references a service name which is not listed in the replacements, then this name is used as a real service name The structure of the SERVICE_REPLACEMENTS environment variable is based on the MTA specification in order to enable MTA group assignments. Example manifest.yml : applications: - name: app-db path: db health-check-type: process services: - app-database - real-grantor-service - real-external-service env: TARGET_CONTAINER: app-database SERVICE_REPLACEMENTS: > [ { \"key\" : \"logical-grantor-service\", \"service\" : \"real-grantor-service\" }, { \"key\" : \"logical-external-service\", \"service\" : \"real-external-service\" } ]","title":"Environment Variables for Applications"},{"location":"apis/hdi-deploy/#environment-variables-for-infrastructure-development-tools","text":"@sap/hdi-deploy supports (re-)configuration via the following environment variables for infrastructure / development tools like the Deploy Service or internal build tools of the WEB IDE EXIT : (optional) if set, the HDI Deployer will exit when the deployment is done; using the environment variable is equivalent to passing a --exit on the command line DEPLOY_ID : (optional) if set, the given id will be written to the final application log entry (custom id, to support processes in parsing log output HDI_DEPLOY_OPTIONS : (optional) JSON-structured set of options for the HDI Deployer, e.g. { \"auto_undeploy\" : true, \"exit\" : true, \"root\" : \"/volumes/A/workspaces/B/db/\", \"include_filter\" : [ \"src/\", \"cfg/\" ] } ; command line options can be translated to HDI_DEPLOY_OPTIONS options by replacing the - s in the option names with _ s; options which can accept multiple values require a JSON array with the values, e.g. path options like the include-filter option. APPLICATION_ID : (optional, fallback SAP_HDI ) this will be used, in conjunction with the space_name and the organization_name of the VCAP_APPLICATION to set the session variable APPLICATION for all connections to the database. This setting may only be used by applications from SAP. APPLICATION_VERSION_INFO : (optional) this will be logged to the command line, to allow logging of some additional information about the application. Options from HDI_DEPLOY_OPTIONS override options which are passed on the command line.","title":"Environment Variables for Infrastructure / Development Tools"},{"location":"apis/hdi-deploy/#ignore-list","text":"The hdi deployer supports ignoring certain files via an .hdiignore file. The file has to be placed at the root of the project folder, just like the undeploy.json . The file has a structure similar to a .gitignore file, simply lines of texts specifying the paths to exclude. Both \"real\" paths and path patterns are supported. src/table_1.hdbtable src/*_2.hdbtable The file works just like the --exclude-filter option and they can be used at the same time.","title":"Ignore List"},{"location":"apis/hdi-deploy/#options-for-interactive-scenarios","text":"@sap/hdi-deploy supports the following options for interactive deployment scenarios, e.g. for orchestration via the WEB IDE or for CI scripts: --[no-]verbose : [don't] print detailed log messages to the console --structured-log <file> : write log messages as JSON objects into the given file; messages are appended if the file already exists --[no-]exit : [don't] exit after deployment of artifacts --[no-]lock-container : [don't] acquire the container lock while working with the container --root <path> : use the given root path for artifacts --working-set [<path> ..] : define the given paths (directories and files) as the working set; a non-default working set applies additional restrictions, e.g. other options might be disallowed --include-filter [<path> ..] : only include the given paths (directories and files) during delta detection --deploy [<file> ..] : explicitly schedule the given files for deploy; extends the include-filter for collecting local files. Instead of a real path, a path pattern like src/* / .hdbtable can be used as well. --[no-]treat-unmodified-as-modified : [don't] treat unmodified files during delta detection as modified files --undeploy [<file> ..] : explicitly schedule the given files for undeploy --parameter [<key>=<value> ..] : pass the given list of key-value parameters to the deployment --path-parameter [<path>:<key>=<value> ..] : pass the given list of path-key-value parameters to the deployment --[no-]auto-undeploy : [don't] undeploy artifacts automatically based on delta detection and ignore the undeploy.json file --[no-]treat-warnings-as-errors : [don't] treat warnings as errors --[no-]simulate-make : [don't] simulate the make and skip post-make activities; pre-make activities still take effect, e.g. grants --connection-timeout <ms> : number of milliseconds to wait for the database connection(s) --lock-container-timeout <ms> : number of milliseconds to wait for the container lock --exclude-filter [<path> ..] : exclude the given paths during: file walk, delta detection and when explicitly scheduled via --(un)deploy --[no-]treat-wrong-ownership-as-errors : [don't] treat wrong ownership of objects as errors, not enabled by default --[no-]migrationtable-development-mode : [don't] pass the development mode flag for migration tables to HDI, if the parameter is supported by the server, not enabled by default --[no-]liveness-ping : [don't] send a sign of life from time to time, by default, a sign of life will be sent --[no-]live-messages : [don't] display the make messages while the make is still in progress, by default, the messages will be displayed while the make is in progress See --help for details and defaults. Options can also be passed to @sap/hdi-deploy via the HDI_DEPLOY_OPTIONS environment variable.","title":"Options for Interactive Scenarios"},{"location":"apis/hdi-deploy/#supported-features","text":"@sap/hdi-deploy exposes its set of features via the info option, which can be passed as --option or via HDI_DEPLOY_OPTIONS , e.g. node deploy --info [<component> [<component> [...]]] where a list of components can be specified. The info option allows to pass multiple components. The info request for these components is optional, e.g. if the HDI Deployer doesn't support the component, then it will not throw an error, but simply not return information for that component. The special component all will return the information for all known components; all is the default if no component is specified. For certain future components, e.g. server , the HDI Deployer might need to connect to the HDI container in the database and retrieve feature information from there. Examples: node deploy --info all node deploy --info client server The result of an info call is a JSON document where the top-level objects correspond to the requested components. Each component should at least report its name, its version, and the set of supported features with name and version number (version numbers are simple numbers (no dots, no double-dots)). If a version number is negative, then the feature is supported by the client, but not supported by the server. For a --info client call, the document looks as follows: { \"client\": { \"name\": \"@sap/hdi-deploy\", \"version\": \"3.11.5\", \"features\": { \"info\": 2, \"verbose\": 1, \"structured-log\": 1, \"lock-container\": 1, \"default-access-role\": 1, \"grants\": 4, \"working-set\": 1, \"include-filter\": 1, \"deploy\": 1, \"treat-unmodified-as-modified\": 1, \"undeploy\": 1, \"parameter\": 1, \"path-parameter\": 1, \"treat-warnings-as-errors\": 1, \"simulate-make\": 1, \"service-replacements\": 1, \"modules\": 2, \"config-templates\": 2, \"environment-options\": 1, \"undeploy-whitelist\": 1 } } } For the server component, the document would also contain the following data: { ... \"server\": { \"name\": \"sap-hana-database\", \"version\": \"1.00.120.04.0000000000\", \"features\": {} } }","title":"Supported Features"},{"location":"apis/hdi-deploy/#deployment-via-hdi-dynamic-deploy","text":"The standard XSA/CF way for deploying HDI content at runtime is to make use of @sap/hdi-dynamic-deploy instead of @sap/hdi-deploy directly. The @sap/hdi-dynamic-deploy app is an http server that calls @sap/hdi-deploy when it receives a corresponding HTTP POST request. See the @sap/hdi-dynamic-deploy module for more information.","title":"Deployment via hdi-dynamic-deploy"},{"location":"apis/hdi-deploy/#using-hdi-deploy-as-a-nodejs-library","text":"Since version 3.3.0 of @sap/hdi-deploy it is also possible to use it as a Node.js library. By requiring the library.js file from the project root it is possible to start the deployer app from within another Node.js app. The module exports the function function deploy ( contentDir, deployerEnv, callback, io ) with the following parameters: contentDir : string containing a path pointing to the root of the db module to be deployed deployerEnv : javascript object containing the OS environment for the call to the deployer (e.g. containing VCAP_SERVICES) callback : a standard callback of the form (errors, result), where result is the result of the call to the deployer of the form: { messages: [<list of result messages from the di server>], exitCode: <exit code of the call to the deployer app, one of -1, 0, 1.>, signal: <signal that the child process was closed with> } io (optional): javascript object containing two callback functions io.stdoutCB and io.stderrCB of the form function(data) for streaming stdout and stderr of the call to the deployer, defaults to piping stdout and stderr of the deployer to stdout and stderr of the calling Node.js app The exit codes have different meanings: -1: The child process was most likely killed externally, check the signal property for details. 0: Deployment done succesfully. 1: Deployment failed, errors occurred. The signal property is only set, if exitCode is -1.","title":"Using hdi-deploy as a Node.js library"},{"location":"apis/hdi-deploy/CHANGELOG/","text":"3.11.5 \u00b6 Fixes: - when used as a library, do not exit until all messages have been sent to the parent process Features: - use hana-client 2.4.162 3.11.4 \u00b6 Fixes: - update handlebars 3.11.3 \u00b6 Features: - update dependencies Fixes: - correctly handle SQL grantors 3.11.2 \u00b6 Features: - update dependencies 3.11.1 \u00b6 Features: - node 10 support - updated dependencies 3.11.0 \u00b6 Features: - added option --liveness-ping to periodically send a signal that notifies the user that the deployer is still working - added option --live-messages to display the make messages while the make is still in progress - added function clean-env to library.js to allow cleaning a passed environment of all deployer-related variables Fixes: - library.js would sometimes return with exitCode null because of unexpected closing of the child process - update dependencies - add missing options to HDI_DEPLOY_OPTIONS 3.10.0 \u00b6 Features: - passwords can be split over multiple services 3.9.4 \u00b6 Fixes: - update handlebars 3.9.3 \u00b6 Fixes: - add full support for .hdbmigrationtable files by adding the --[no-]migrationtable-development-mode flag 3.9.2 \u00b6 Fixes: - the private key used for mutual authentication was logged if tracing is enabled - mutual auth was missing on some database connections - some database connections were not closed correctly 3.9.1 \u00b6 Fixes: - revert changes to hdi actions that could possibly cause a behavior change 3.9.0 \u00b6 Features: - allow passing ssl connection parameters in service binding - allow mutual auth via parameters in service binding - set session variable APPLICATION on all HANA connections - support path parameters for HDI - allow development debug role similar to the default access role - update @sap/hdi dependency - better handling of invalid undeploy.json files - improved timestamps in logging output - check ownership of objects in the container via --treat-wrong-ownership-as-errors - allow logging of additional application data Fixes: - issue with schema privileges and global roles in the same .hdbgrants file 3.8.2 \u00b6 Features: - introduced .hdbrevokes as a counterpart to .hdbgrants - automatically find target service: if only one HDI service is bound, TARGET_CONTAINER does not have to be set - print timestamp of HDI messages - print the status of the last build - fallback to the .hdiconfig in src/ if it is missing in cfg/ - switch to @sap/hdi 2.1.2 - switch from hdb to @sap/hana-client - check if the container supports locking and skip it if not Fixes: - support \\n and \\r\\n as line endings in .hdiignore files - correctly process grantor files in ZDM mode - fix 'Maximum call stack size exceeded' in ZDM mode - don't escape schema names in .hdbgrants 3.7.0 \u00b6 Features: - warning messages will now be prepended with \"WARNING:\" - error messages in case of a bad service binding now offer more detail on what caused the error - now supports comments in JSON files like default services file - allow file patterns in --deploy option - added new options --exclude-filter and .hdiignore file that basically work like .gitignore - improved error reporting when using the deployer as a library Fixes: - correctly handle component names of system privileges in .hdbgrants files - handle empty privilege objects - filter client files like .hdbgrants before deploying 3.6.0 \u00b6 Features: - support ZDM deployment of HDI artifacts modeled in data/ and access/ folders inside db module - support ZDM deployment of .hdbrole files in access schema - target service is logged during deployment 3.5.1 \u00b6 Features: - support ZDM deployment - added warning message when using .hdbsysnonymtemplate or .hdbsynonymgrantor 3.4.1 \u00b6 Features: - update dependencies 3.4.0 \u00b6 Features: - provide --treat-unmodified-as-modified option to schedule also unmodified for deploy - support procedure-type granting services - improve Readme Fixes: - fix handling of grantor services which have a db_hosts value, but no host value - fix occasional 'Callback was already called' error in case of deployment failures 3.3.0 \u00b6 Features: - provide library.js to fork the deployer from a node.js app for a given content directory including support for stdio callbacks Fixes: - don't look at server folders outside cfg/, src/, and lib/ 3.2.0 \u00b6 Features: - support for @sap/hdi-dynamic-deploy 3.1.2 \u00b6 Fixes: - use db_hosts from VCAP_SERVICES if it exists - transform paths from --include-filter , --deploy , --undeploy , --working-set to the server format where reusable modules are located at lib/ instead of node_modules/ 3.1.1 \u00b6 Fixes: - support @-scoped reusable modules 3.1.0 \u00b6 Features: - support --parameter option to pass key-value parameters to the deployment Fixes: - use non-sync write to stdout (and stderr), and on exit, wait until stdout is drained to avoid loss of log output in case of crashes, etc. - container locking is available since server version 2.0.1.0, not 2.0.0.0 3.0.0 \u00b6 Features: - check src/defaults/default_access_role.hdbrole file against the working set - check .hdbgrants files against the working set - show the processing of individual .hdbgrants files - on newer server versions, acquire the container lock while working with the container - support --lock-container-timeout <ms> option for setting the number of milliseconds to wait for the container lock, defaults to 120.000 ms - also support grantor services with only \"user\" , \"password\" , \"schema\" ; and take \"host\" , \"port\" , \"certificate\" from the target container - in .hdbgrants files, use the first non-undefined schema value ( \"schema\" , \"reference\" , \"schema\" from grantor service); \"reference\" is only used for \"schema_privileges\" - support schema roles in .hdbgrants files - reject explicit delta detection of files outside the working set - switch to Node.js 6.9.1 as minimal Node.js version - provide --working-set option to restrict the set of files which can be modified in the container - support global roles with admin option in .hdbgrants files - support system privileges with admin option in .hdbgrants files - support --connection-timeout <ms> option for setting the number of milliseconds to wait for the database connection(s) Fixes: - lock the container before showing the synchronizing message - support .hdbgrants files without a name ( folder/.hdbgrants ) - support the string-array style in schema_roles, too - support typed global object privileges in .hdbgrants files - correctly pass certificate to hdi client 2.3.0 \u00b6 Features: - rename module to @sap/hdi-deploy 2.2.0 \u00b6 Fixes: - fix schema name handling to allow schema names with special characters - fix handling of more than 1 privilege in a single element in .hdbgrants files - fix trace handling for VCAP_SERVICES and connection data 2.1.0 \u00b6 Features: - detect server version; provide --[no-]detect-server-version option - invert client feature version numbers if they are not available due to the detected server version - support server in --info - generalize handling of configuration file templating for cfg/**/*config files - provide --structured-log option to send messages in a JSON-structured format into a log file - provide --[no-]verbose option to suppress detailed messages at the console output - allow consumption of reusable database modules via package.json and npm install - provide --simulate-make option to enable server-side feature for simulating the make activities - provide --treat-warnings-as-errors option to enable server-side feature for treating warnings as errors - provide --deploy option to explicitly include a set of files in the deploy set - provide --undeploy option to explicitly include a set of files in the undeploy set Fixes: - reject --simulate-make and --treat-warnings-as-errors if the server doesn't support these features - consider the root path when looking for reuse modules - throw an error if we find a nested node_modules folder inside a reuse module 2.0.1 \u00b6 Fixes: - pass the certificate from the service binding down to the database ( certificate field in the binding, ca field in the database connection) - fix handling of file templating in cfg/ folder and include-filter handling on Windows - fix handling of multiple roles in container_roles elements in .hdbgrants files - fix handling of .hdbgrants files with more than 1 grantors inside 2.0.0 \u00b6 Features: - allow .hdbgrants as suffix for privilege grants / grantor mechanism files - apply consistency check on file src/defaults/default_access_role.hdbrole - show information about used service replacements - reworked reporting of hdideploy.js errors and HDI errors/warnings - refactored JSON parser handling - automatic assignment of the deployed role default_access_role if the file src/defaults/default_access_role.hdbrole is in the processing file set - provide --info option to show supported features - provide timing information for certain actions, e.g. time spent for collecting files, time spent for synchronizing files with the server, etc. - provide --include-filter option to define a filter for restricting the set of files which are processed by the deployer app for deploy/undeploy - allow the indirection of service names via a SERVICE_REPLACEMENTS environment variables - provide a generic templating mechanism for cfg/**/*config files, replacing the hdbsynonymtemplate files - support default-services.json and default-env.json for local development - show information about the effects of the undeploy.json file - always show application name plus version number; for support cases - always consider all deploy directories, even if they do not exist locally - write the log message Application can be stopped. only once - ignore errors when deleting non-existing directories - show information about the steps that are performed - provide --[no-]strip-cr-from-csv option to [not] strip carriage return characters from CSV files; not enabled by default anymore Fixes: - don't report a missing undeploy.json file as an error 1.1.0 \u00b6 Features: - replace --autoUndeploy with --auto-undeploy ; keep --autoUndeploy for backwards compatibility - provide --no-auto-undeploy option to revert --auto-undeploy - provide --root option - provide --exit and --no-exit options - allow to pass options via JSON structured HDI_DEPLOY_OPTIONS environment variable","title":"CHANGELOG"},{"location":"apis/hdi-deploy/CHANGELOG/#3115","text":"Fixes: - when used as a library, do not exit until all messages have been sent to the parent process Features: - use hana-client 2.4.162","title":"3.11.5"},{"location":"apis/hdi-deploy/CHANGELOG/#3114","text":"Fixes: - update handlebars","title":"3.11.4"},{"location":"apis/hdi-deploy/CHANGELOG/#3113","text":"Features: - update dependencies Fixes: - correctly handle SQL grantors","title":"3.11.3"},{"location":"apis/hdi-deploy/CHANGELOG/#3112","text":"Features: - update dependencies","title":"3.11.2"},{"location":"apis/hdi-deploy/CHANGELOG/#3111","text":"Features: - node 10 support - updated dependencies","title":"3.11.1"},{"location":"apis/hdi-deploy/CHANGELOG/#3110","text":"Features: - added option --liveness-ping to periodically send a signal that notifies the user that the deployer is still working - added option --live-messages to display the make messages while the make is still in progress - added function clean-env to library.js to allow cleaning a passed environment of all deployer-related variables Fixes: - library.js would sometimes return with exitCode null because of unexpected closing of the child process - update dependencies - add missing options to HDI_DEPLOY_OPTIONS","title":"3.11.0"},{"location":"apis/hdi-deploy/CHANGELOG/#3100","text":"Features: - passwords can be split over multiple services","title":"3.10.0"},{"location":"apis/hdi-deploy/CHANGELOG/#394","text":"Fixes: - update handlebars","title":"3.9.4"},{"location":"apis/hdi-deploy/CHANGELOG/#393","text":"Fixes: - add full support for .hdbmigrationtable files by adding the --[no-]migrationtable-development-mode flag","title":"3.9.3"},{"location":"apis/hdi-deploy/CHANGELOG/#392","text":"Fixes: - the private key used for mutual authentication was logged if tracing is enabled - mutual auth was missing on some database connections - some database connections were not closed correctly","title":"3.9.2"},{"location":"apis/hdi-deploy/CHANGELOG/#391","text":"Fixes: - revert changes to hdi actions that could possibly cause a behavior change","title":"3.9.1"},{"location":"apis/hdi-deploy/CHANGELOG/#390","text":"Features: - allow passing ssl connection parameters in service binding - allow mutual auth via parameters in service binding - set session variable APPLICATION on all HANA connections - support path parameters for HDI - allow development debug role similar to the default access role - update @sap/hdi dependency - better handling of invalid undeploy.json files - improved timestamps in logging output - check ownership of objects in the container via --treat-wrong-ownership-as-errors - allow logging of additional application data Fixes: - issue with schema privileges and global roles in the same .hdbgrants file","title":"3.9.0"},{"location":"apis/hdi-deploy/CHANGELOG/#382","text":"Features: - introduced .hdbrevokes as a counterpart to .hdbgrants - automatically find target service: if only one HDI service is bound, TARGET_CONTAINER does not have to be set - print timestamp of HDI messages - print the status of the last build - fallback to the .hdiconfig in src/ if it is missing in cfg/ - switch to @sap/hdi 2.1.2 - switch from hdb to @sap/hana-client - check if the container supports locking and skip it if not Fixes: - support \\n and \\r\\n as line endings in .hdiignore files - correctly process grantor files in ZDM mode - fix 'Maximum call stack size exceeded' in ZDM mode - don't escape schema names in .hdbgrants","title":"3.8.2"},{"location":"apis/hdi-deploy/CHANGELOG/#370","text":"Features: - warning messages will now be prepended with \"WARNING:\" - error messages in case of a bad service binding now offer more detail on what caused the error - now supports comments in JSON files like default services file - allow file patterns in --deploy option - added new options --exclude-filter and .hdiignore file that basically work like .gitignore - improved error reporting when using the deployer as a library Fixes: - correctly handle component names of system privileges in .hdbgrants files - handle empty privilege objects - filter client files like .hdbgrants before deploying","title":"3.7.0"},{"location":"apis/hdi-deploy/CHANGELOG/#360","text":"Features: - support ZDM deployment of HDI artifacts modeled in data/ and access/ folders inside db module - support ZDM deployment of .hdbrole files in access schema - target service is logged during deployment","title":"3.6.0"},{"location":"apis/hdi-deploy/CHANGELOG/#351","text":"Features: - support ZDM deployment - added warning message when using .hdbsysnonymtemplate or .hdbsynonymgrantor","title":"3.5.1"},{"location":"apis/hdi-deploy/CHANGELOG/#341","text":"Features: - update dependencies","title":"3.4.1"},{"location":"apis/hdi-deploy/CHANGELOG/#340","text":"Features: - provide --treat-unmodified-as-modified option to schedule also unmodified for deploy - support procedure-type granting services - improve Readme Fixes: - fix handling of grantor services which have a db_hosts value, but no host value - fix occasional 'Callback was already called' error in case of deployment failures","title":"3.4.0"},{"location":"apis/hdi-deploy/CHANGELOG/#330","text":"Features: - provide library.js to fork the deployer from a node.js app for a given content directory including support for stdio callbacks Fixes: - don't look at server folders outside cfg/, src/, and lib/","title":"3.3.0"},{"location":"apis/hdi-deploy/CHANGELOG/#320","text":"Features: - support for @sap/hdi-dynamic-deploy","title":"3.2.0"},{"location":"apis/hdi-deploy/CHANGELOG/#312","text":"Fixes: - use db_hosts from VCAP_SERVICES if it exists - transform paths from --include-filter , --deploy , --undeploy , --working-set to the server format where reusable modules are located at lib/ instead of node_modules/","title":"3.1.2"},{"location":"apis/hdi-deploy/CHANGELOG/#311","text":"Fixes: - support @-scoped reusable modules","title":"3.1.1"},{"location":"apis/hdi-deploy/CHANGELOG/#310","text":"Features: - support --parameter option to pass key-value parameters to the deployment Fixes: - use non-sync write to stdout (and stderr), and on exit, wait until stdout is drained to avoid loss of log output in case of crashes, etc. - container locking is available since server version 2.0.1.0, not 2.0.0.0","title":"3.1.0"},{"location":"apis/hdi-deploy/CHANGELOG/#300","text":"Features: - check src/defaults/default_access_role.hdbrole file against the working set - check .hdbgrants files against the working set - show the processing of individual .hdbgrants files - on newer server versions, acquire the container lock while working with the container - support --lock-container-timeout <ms> option for setting the number of milliseconds to wait for the container lock, defaults to 120.000 ms - also support grantor services with only \"user\" , \"password\" , \"schema\" ; and take \"host\" , \"port\" , \"certificate\" from the target container - in .hdbgrants files, use the first non-undefined schema value ( \"schema\" , \"reference\" , \"schema\" from grantor service); \"reference\" is only used for \"schema_privileges\" - support schema roles in .hdbgrants files - reject explicit delta detection of files outside the working set - switch to Node.js 6.9.1 as minimal Node.js version - provide --working-set option to restrict the set of files which can be modified in the container - support global roles with admin option in .hdbgrants files - support system privileges with admin option in .hdbgrants files - support --connection-timeout <ms> option for setting the number of milliseconds to wait for the database connection(s) Fixes: - lock the container before showing the synchronizing message - support .hdbgrants files without a name ( folder/.hdbgrants ) - support the string-array style in schema_roles, too - support typed global object privileges in .hdbgrants files - correctly pass certificate to hdi client","title":"3.0.0"},{"location":"apis/hdi-deploy/CHANGELOG/#230","text":"Features: - rename module to @sap/hdi-deploy","title":"2.3.0"},{"location":"apis/hdi-deploy/CHANGELOG/#220","text":"Fixes: - fix schema name handling to allow schema names with special characters - fix handling of more than 1 privilege in a single element in .hdbgrants files - fix trace handling for VCAP_SERVICES and connection data","title":"2.2.0"},{"location":"apis/hdi-deploy/CHANGELOG/#210","text":"Features: - detect server version; provide --[no-]detect-server-version option - invert client feature version numbers if they are not available due to the detected server version - support server in --info - generalize handling of configuration file templating for cfg/**/*config files - provide --structured-log option to send messages in a JSON-structured format into a log file - provide --[no-]verbose option to suppress detailed messages at the console output - allow consumption of reusable database modules via package.json and npm install - provide --simulate-make option to enable server-side feature for simulating the make activities - provide --treat-warnings-as-errors option to enable server-side feature for treating warnings as errors - provide --deploy option to explicitly include a set of files in the deploy set - provide --undeploy option to explicitly include a set of files in the undeploy set Fixes: - reject --simulate-make and --treat-warnings-as-errors if the server doesn't support these features - consider the root path when looking for reuse modules - throw an error if we find a nested node_modules folder inside a reuse module","title":"2.1.0"},{"location":"apis/hdi-deploy/CHANGELOG/#201","text":"Fixes: - pass the certificate from the service binding down to the database ( certificate field in the binding, ca field in the database connection) - fix handling of file templating in cfg/ folder and include-filter handling on Windows - fix handling of multiple roles in container_roles elements in .hdbgrants files - fix handling of .hdbgrants files with more than 1 grantors inside","title":"2.0.1"},{"location":"apis/hdi-deploy/CHANGELOG/#200","text":"Features: - allow .hdbgrants as suffix for privilege grants / grantor mechanism files - apply consistency check on file src/defaults/default_access_role.hdbrole - show information about used service replacements - reworked reporting of hdideploy.js errors and HDI errors/warnings - refactored JSON parser handling - automatic assignment of the deployed role default_access_role if the file src/defaults/default_access_role.hdbrole is in the processing file set - provide --info option to show supported features - provide timing information for certain actions, e.g. time spent for collecting files, time spent for synchronizing files with the server, etc. - provide --include-filter option to define a filter for restricting the set of files which are processed by the deployer app for deploy/undeploy - allow the indirection of service names via a SERVICE_REPLACEMENTS environment variables - provide a generic templating mechanism for cfg/**/*config files, replacing the hdbsynonymtemplate files - support default-services.json and default-env.json for local development - show information about the effects of the undeploy.json file - always show application name plus version number; for support cases - always consider all deploy directories, even if they do not exist locally - write the log message Application can be stopped. only once - ignore errors when deleting non-existing directories - show information about the steps that are performed - provide --[no-]strip-cr-from-csv option to [not] strip carriage return characters from CSV files; not enabled by default anymore Fixes: - don't report a missing undeploy.json file as an error","title":"2.0.0"},{"location":"apis/hdi-deploy/CHANGELOG/#110","text":"Features: - replace --autoUndeploy with --auto-undeploy ; keep --autoUndeploy for backwards compatibility - provide --no-auto-undeploy option to revert --auto-undeploy - provide --root option - provide --exit and --no-exit options - allow to pass options via JSON structured HDI_DEPLOY_OPTIONS environment variable","title":"1.1.0"},{"location":"apis/hdi-dynamic-deploy/","text":"@sap/hdi-dynamic-deploy \u00b6 @sap/hdi-dynamic-deploy is a Node.js -based http server for dynamic deployment to SAP HANA DI (HDI) containers, HDI Dynamic Deployer for short. The HDI Dynamic Deployer can be used in XS Advanced (XSA) and in SAP Cloud Platform (SAP CP)/Cloud Foundry (CF) to deploy database content to dynamically created containers (e.g. created via the Instance Manager). The dynamic deployer is built upon @sap/hdi-deploy which should be used directly if a static deployment at deploytime is sufficient. README.md \u00b6 Installation : - Integration into a Database Module - Configuration of the dynamic deployer Dynamic deployment : - Triggering a dynamic deployment by a HTTP POST request - How to use it in a multi-target application - Accessing the underlying HTTP server - Accessing the underlying HTTP server Integration into a Database Module \u00b6 Usually, @sap/hdi-dynamic-deploy gets installed via a package.json -based dependency inside your application's db module: db/package.json : { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-dynamic-deploy\": \"1.7.1\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-dynamic-deploy/\" } } Configuration of the dynamic deployer \u00b6 The dynamic deployer needs to be configured via the following environment variables: PORT : port the HTTP server listens to hdi_dynamic_deploy_user : username for HTTP basic authentication hdi_dynamic_deploy_password : password for HTTP basic authentication ENFORCE_AUDITING : force usage of audit logging. If audit logging cannot be enabled, the server will throw an error and stop. ENFORCE_V2 : force usage of the V2 audit logging API. If audit logging V2 cannot be enabled, the server will throw an error and stop. AUDIT_LOG_TENANT : specifies the tenant to use for audit logging. Likely this will be the subaccount-id where your app is deployed. If this is not specified you may be unable to view the logs. Note: Any client that knows the hdi_dynamic_deploy_user and the corresponding password will indirectly be able to read the database artifacts contained in the dynamic deploy server. If an auditlog service is bound to the dynamic deployer, invalid authentication attempts will be logger accordingly. The PORT variable is automatically set by XSA. ENFORCE_AUDITING , ENFORCE_V2 , username and password have to be given e.g. via the mta.yaml file (see example below). When using the XSA deploy-service, a strong generated password will be used. In other use cases, sufficient password strength has to be ensured! modules: - name: db type: com.sap.xs.hdi-dynamic path: db properties: hdi_dynamic_deploy_user: ${ generated - user } hdi_dynamic_deploy_password: ${ generated - password } provides: - name: db_deployment properties: url: ${ default - url } user: ${ generated - user } password: ${ generated - password } Triggering a dynamic deployment by a HTTP POST request \u00b6 The dynamic deployer is a http server started for a specific db module. When the module is pushed to XSA or CF, the dynamic deployer starts listening for requests and eventually starts the (non-dynamic) deployer to deploy the content of the db module to a given container. To trigger the deployment one has to send a HTTP POST request with basic authentication and content type application/json to the dynamic deployer. The api offers three urls for deployment, http(s)://<hostname>:<port>/v1/deploy , http(s)://<hostname>:<port>/v1/deploy/to/instance and http(s)://<hostname>:<port>/v1/deploy/to/instance/async . Synchronous deployment \u00b6 Deployment via http(s)://<hostname>:<port>/v1/deploy (VCAP_SERVICES style) \u00b6 The first way to trigger a deployment is to send a HTTP POST request to the url http(s)://<hostname>:<port>/v1/deploy . The body simply consists of a JSON object containing replacements for several of the HDI deployer's environment variables. Supported are replacements for: HDI_DEPLOY_OPTIONS DEPLOY_ID TARGET_CONTAINER SERVICE_REPLACEMENTS VCAP_SERVICES In addition to providing VCAP_SERVICES for replacing the corresponding environment variable it is also possible to provide ADDITIONAL_VCAP_SERVICES . The deployer is then called with service bindings created from the VCAP_SERVICES of the dynamic deployer by adding the service definitions given by ADDITIONAL_VCAP_SERVICES . The ADDITIONAL_VCAP_SERVICES object has the same structure as the original VCAP_SERVICES , i.e. it contains lists of service bindings. If the request contains ADDITIONAL_VCAP_SERVICES , the server scans through all of its services and either adds the list of bindings to the VCAP_SERVICES environment variable or merges the two lists in case bindings for the given service already exist. Existing bindings with the same name are replaced with the bindings from ADDITIONAL_VCAP_SERVICES . Example: { \"TARGET_CONTAINER\": \"hdi_container_service_name\", \"ADDITIONAL_VCAP_SERVICES\": { \"hana\" : [ { \"name\" : \"hdi_container_service_name\", \"label\" : \"hana\", \"tags\" : [ \"hana\", \"database\", \"relational\" ], \"plan\" : \"hdi-shared\", \"credentials\" : { \"schema\" : \"DB_EXAMPLE\", \"hdi_password\" : \"hdi_password\", \"password\" : \"password\", \"driver\" : \"com.sap.db.jdbc.Driver\", \"port\" : \"30015\", \"host\" : \"srv1234567.host.name\", \"db_hosts\" : [ { \"port\" : 30015, \"host\" : \"srv7654321.host.name\" } ], \"hdi_user\" : \"hdi_user\", \"user\" : \"user\", \"url\" : \"jdbc:sap://srv1234567.host.name:30015/?currentschema=DB_EXAMPLE\" } } ] } } Deployment via http(s)://<hostname>:<port>/v1/deploy/to/instance (Instance Manager style) \u00b6 Since version 1.2.0 of the dynamic deployer there is a second way to trigger a deployment by sending a HTTP POST request to the url http(s)://<hostname>:<port>/v1/deploy/to/instance . The request body is simply a managed service instance as retrieved from the Instance Manager with a HTTP GET. Example: { \"tenant_id\": \"1\", \"id\": \"da7ff475-fd3f-4a86-a3e7-cd3e41e3653d\", \"binding_id\": \"3bb96cab-0bec-4088-9991-244b750e53b3\", \"instance_id\": \"d9cc0aef-16f7-40d2-8e10-1816b9214f2e\", \"managed_service_id\": \"79d9e11a-95c2-4771-ae2d-8ba703bd8fda\", \"managed_plan_id\": \"bebaad3e-352b-4928-bc6b-8783d754ac3b\", \"managed_instance_id\": \"0a4d365a-eec5-4083-85ae-677f77bb6f5d\", \"managed_binding_id\": \"a5cba4c8-95a3-42c8-982d-e075d0a6b941\", \"status\": \"CREATION_SUCCEEDED\", \"updated_on\": 1494322225942, \"credentials\": { \"host\": \"srv1234567.host.name\", \"port\": \"30015\", \"driver\": \"com.sap.db.jdbc.Driver\", \"url\": \"jdbc:sap://srv1234567.host.name:30015/?currentschema=55D392C7232649E8A2F08993645B28B5\", \"schema\": \"55D392C7232649E8A2F08993645B28B5\", \"hdi_user\": \"SBSS_78283957013891283645150604040575244555286482237534978212872169092\", \"hdi_password\": \"password\", \"user\": \"SBSS_92380540949443696814788249184554628165227387555319796659663474608\", \"password\": \"password\" } } The response from the dynamic deployer \u00b6 If there was no problem with the basic authentication and the request reaches the dynamic deployer, it usually responds with status code 200 and a json body containing the result of the deployment. The response body has the following form: { messages: [<list of result messages from the di server>], exitCode: <exit code of the call to the deployer app> } IMPORTANT: A status code of 200 does not mean that the deployment was successful. It just means that the dynamic deployer was able to call the (non-dynamic) deployer. If the deployer finished with no errors the exitCode attribute of the response is 0 , otherwise it is 1 . More detailed information about the deployment can be retrieved from the messages attribute of the response. Asynchronous deployment \u00b6 Since version 1.7.0 of the dynamic deployer there is a third way to trigger a deployment by sending a HTTP POST request to the url http(s)://<hostname>:<port>/v1/deploy/to/instance/async . The request body is simply a managed service instance as retrieved from the Instance Manager with a HTTP GET, i.e. the same as for http(s)://<hostname>:<port>/v1/deploy/to/instance . But instead of waiting until the deployment is done and then returning the results, a GUID is returned. This GUID can be used to query the status of the deployment by sending a GET request to http(s)://<hostname>:<port>/v1/status/:guid - if the deployment is still running, the response just contains a status property. If the deployment is finished, the usual response is returned - in conjunction with the status property. How to use it in a multi-target application \u00b6 A multi-target application (MTA) for multi-tenancy scenarios with the instance manager typically includes multiple db modules: - N static db modules ( type: com.sap.xs.hdi ), e.g. for configuration or shared data. A static module depends on @sap/hdi-deploy ; it does not depend on @sap/hdi-dynamic-deploy . - M dynamic db modules ( type: com.sap.xs.hdi-dynamic ) where the business data for a certain type of tenant is contained. A dynamic module depends on @sap/hdi-dynamic-deploy , which internally depends on @sap/hdi-deploy for deployment to the correct tenant. Example: modules: - name: db-static-1 type: com . sap . xs . hdi path: db-static-1 - name: db-static-2 type: com . sap . xs . hdi path: db-static-2 - name: db-dynamic-1 type: com . sap . xs . hdi-dynamic path: db-dynamic-1 - name: db-dynamic-2 type: com . sap . xs . hdi-dynamic path: db-dynamic-2 - name: db-dynamic-3 type: com . sap . xs . hdi-dynamic path: db-dynamic-3 Accessing the underlying HTTP server \u00b6 By requiring the dynamic deploy package, you can access the internal HTTP server. This way, you can decide when to start/stop the server. The exported object offers two methods: /** * Start the HTTP server on this.port. * * @param {any} cb Callback function (error, result). * @returns {undefined} */ function start ( cb ){ < .. > }; /** * Stop the HTTP server. * * @param {any} cb Callback function (error, result). * @returns {undefined} */ function stop ( cb ){ < .. > }; Furthermore, the object has the property port . This has to be set to the port that you want the server to listen on. Example: 'use strict' ; const { server } = require ( '@sap/hdi-dynamic-deploy/index' ); server . port = process . env . PORT ; server . start ( function (){ console . log ( `@sap/hdi-dynamic-deploy HTTP server up and running, listening on port ${ server . port } ` ); }); Accessing the router functions \u00b6 By requiring the dynamic deploy package, you can access the functions used for the API endpoints and can use them in your own router. Both functions expect two parameters: - A HTTP request object - A HTTP response object Example: 'use strict' ; const { deploy_to_instance , deploy } = require ( '@sap/hdi-dynamic-deploy/index' ); /** * Now the functions can be added to a router. * * deploy_to_instance is the function used for the /v1/deploy/to/instance route * deploy is the function used for the /v1/deploy route * */","title":"Index"},{"location":"apis/hdi-dynamic-deploy/#saphdi-dynamic-deploy","text":"@sap/hdi-dynamic-deploy is a Node.js -based http server for dynamic deployment to SAP HANA DI (HDI) containers, HDI Dynamic Deployer for short. The HDI Dynamic Deployer can be used in XS Advanced (XSA) and in SAP Cloud Platform (SAP CP)/Cloud Foundry (CF) to deploy database content to dynamically created containers (e.g. created via the Instance Manager). The dynamic deployer is built upon @sap/hdi-deploy which should be used directly if a static deployment at deploytime is sufficient.","title":"@sap/hdi-dynamic-deploy"},{"location":"apis/hdi-dynamic-deploy/#readmemd","text":"Installation : - Integration into a Database Module - Configuration of the dynamic deployer Dynamic deployment : - Triggering a dynamic deployment by a HTTP POST request - How to use it in a multi-target application - Accessing the underlying HTTP server - Accessing the underlying HTTP server","title":"README.md"},{"location":"apis/hdi-dynamic-deploy/#integration-into-a-database-module","text":"Usually, @sap/hdi-dynamic-deploy gets installed via a package.json -based dependency inside your application's db module: db/package.json : { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-dynamic-deploy\": \"1.7.1\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-dynamic-deploy/\" } }","title":"Integration into a Database Module"},{"location":"apis/hdi-dynamic-deploy/#configuration-of-the-dynamic-deployer","text":"The dynamic deployer needs to be configured via the following environment variables: PORT : port the HTTP server listens to hdi_dynamic_deploy_user : username for HTTP basic authentication hdi_dynamic_deploy_password : password for HTTP basic authentication ENFORCE_AUDITING : force usage of audit logging. If audit logging cannot be enabled, the server will throw an error and stop. ENFORCE_V2 : force usage of the V2 audit logging API. If audit logging V2 cannot be enabled, the server will throw an error and stop. AUDIT_LOG_TENANT : specifies the tenant to use for audit logging. Likely this will be the subaccount-id where your app is deployed. If this is not specified you may be unable to view the logs. Note: Any client that knows the hdi_dynamic_deploy_user and the corresponding password will indirectly be able to read the database artifacts contained in the dynamic deploy server. If an auditlog service is bound to the dynamic deployer, invalid authentication attempts will be logger accordingly. The PORT variable is automatically set by XSA. ENFORCE_AUDITING , ENFORCE_V2 , username and password have to be given e.g. via the mta.yaml file (see example below). When using the XSA deploy-service, a strong generated password will be used. In other use cases, sufficient password strength has to be ensured! modules: - name: db type: com.sap.xs.hdi-dynamic path: db properties: hdi_dynamic_deploy_user: ${ generated - user } hdi_dynamic_deploy_password: ${ generated - password } provides: - name: db_deployment properties: url: ${ default - url } user: ${ generated - user } password: ${ generated - password }","title":"Configuration of the dynamic deployer"},{"location":"apis/hdi-dynamic-deploy/#triggering-a-dynamic-deployment-by-a-http-post-request","text":"The dynamic deployer is a http server started for a specific db module. When the module is pushed to XSA or CF, the dynamic deployer starts listening for requests and eventually starts the (non-dynamic) deployer to deploy the content of the db module to a given container. To trigger the deployment one has to send a HTTP POST request with basic authentication and content type application/json to the dynamic deployer. The api offers three urls for deployment, http(s)://<hostname>:<port>/v1/deploy , http(s)://<hostname>:<port>/v1/deploy/to/instance and http(s)://<hostname>:<port>/v1/deploy/to/instance/async .","title":"Triggering a dynamic deployment by a HTTP POST request"},{"location":"apis/hdi-dynamic-deploy/#synchronous-deployment","text":"","title":"Synchronous deployment"},{"location":"apis/hdi-dynamic-deploy/#deployment-via-httpslthostnamegtltportgtv1deploy-vcap_services-style","text":"The first way to trigger a deployment is to send a HTTP POST request to the url http(s)://<hostname>:<port>/v1/deploy . The body simply consists of a JSON object containing replacements for several of the HDI deployer's environment variables. Supported are replacements for: HDI_DEPLOY_OPTIONS DEPLOY_ID TARGET_CONTAINER SERVICE_REPLACEMENTS VCAP_SERVICES In addition to providing VCAP_SERVICES for replacing the corresponding environment variable it is also possible to provide ADDITIONAL_VCAP_SERVICES . The deployer is then called with service bindings created from the VCAP_SERVICES of the dynamic deployer by adding the service definitions given by ADDITIONAL_VCAP_SERVICES . The ADDITIONAL_VCAP_SERVICES object has the same structure as the original VCAP_SERVICES , i.e. it contains lists of service bindings. If the request contains ADDITIONAL_VCAP_SERVICES , the server scans through all of its services and either adds the list of bindings to the VCAP_SERVICES environment variable or merges the two lists in case bindings for the given service already exist. Existing bindings with the same name are replaced with the bindings from ADDITIONAL_VCAP_SERVICES . Example: { \"TARGET_CONTAINER\": \"hdi_container_service_name\", \"ADDITIONAL_VCAP_SERVICES\": { \"hana\" : [ { \"name\" : \"hdi_container_service_name\", \"label\" : \"hana\", \"tags\" : [ \"hana\", \"database\", \"relational\" ], \"plan\" : \"hdi-shared\", \"credentials\" : { \"schema\" : \"DB_EXAMPLE\", \"hdi_password\" : \"hdi_password\", \"password\" : \"password\", \"driver\" : \"com.sap.db.jdbc.Driver\", \"port\" : \"30015\", \"host\" : \"srv1234567.host.name\", \"db_hosts\" : [ { \"port\" : 30015, \"host\" : \"srv7654321.host.name\" } ], \"hdi_user\" : \"hdi_user\", \"user\" : \"user\", \"url\" : \"jdbc:sap://srv1234567.host.name:30015/?currentschema=DB_EXAMPLE\" } } ] } }","title":"Deployment via http(s)://&amp;lt;hostname&amp;gt;:&amp;lt;port&amp;gt;/v1/deploy (VCAP_SERVICES style)"},{"location":"apis/hdi-dynamic-deploy/#deployment-via-httpslthostnamegtltportgtv1deploytoinstance-instance-manager-style","text":"Since version 1.2.0 of the dynamic deployer there is a second way to trigger a deployment by sending a HTTP POST request to the url http(s)://<hostname>:<port>/v1/deploy/to/instance . The request body is simply a managed service instance as retrieved from the Instance Manager with a HTTP GET. Example: { \"tenant_id\": \"1\", \"id\": \"da7ff475-fd3f-4a86-a3e7-cd3e41e3653d\", \"binding_id\": \"3bb96cab-0bec-4088-9991-244b750e53b3\", \"instance_id\": \"d9cc0aef-16f7-40d2-8e10-1816b9214f2e\", \"managed_service_id\": \"79d9e11a-95c2-4771-ae2d-8ba703bd8fda\", \"managed_plan_id\": \"bebaad3e-352b-4928-bc6b-8783d754ac3b\", \"managed_instance_id\": \"0a4d365a-eec5-4083-85ae-677f77bb6f5d\", \"managed_binding_id\": \"a5cba4c8-95a3-42c8-982d-e075d0a6b941\", \"status\": \"CREATION_SUCCEEDED\", \"updated_on\": 1494322225942, \"credentials\": { \"host\": \"srv1234567.host.name\", \"port\": \"30015\", \"driver\": \"com.sap.db.jdbc.Driver\", \"url\": \"jdbc:sap://srv1234567.host.name:30015/?currentschema=55D392C7232649E8A2F08993645B28B5\", \"schema\": \"55D392C7232649E8A2F08993645B28B5\", \"hdi_user\": \"SBSS_78283957013891283645150604040575244555286482237534978212872169092\", \"hdi_password\": \"password\", \"user\": \"SBSS_92380540949443696814788249184554628165227387555319796659663474608\", \"password\": \"password\" } }","title":"Deployment via http(s)://&amp;lt;hostname&amp;gt;:&amp;lt;port&amp;gt;/v1/deploy/to/instance (Instance Manager style)"},{"location":"apis/hdi-dynamic-deploy/#the-response-from-the-dynamic-deployer","text":"If there was no problem with the basic authentication and the request reaches the dynamic deployer, it usually responds with status code 200 and a json body containing the result of the deployment. The response body has the following form: { messages: [<list of result messages from the di server>], exitCode: <exit code of the call to the deployer app> } IMPORTANT: A status code of 200 does not mean that the deployment was successful. It just means that the dynamic deployer was able to call the (non-dynamic) deployer. If the deployer finished with no errors the exitCode attribute of the response is 0 , otherwise it is 1 . More detailed information about the deployment can be retrieved from the messages attribute of the response.","title":"The response from the dynamic deployer"},{"location":"apis/hdi-dynamic-deploy/#asynchronous-deployment","text":"Since version 1.7.0 of the dynamic deployer there is a third way to trigger a deployment by sending a HTTP POST request to the url http(s)://<hostname>:<port>/v1/deploy/to/instance/async . The request body is simply a managed service instance as retrieved from the Instance Manager with a HTTP GET, i.e. the same as for http(s)://<hostname>:<port>/v1/deploy/to/instance . But instead of waiting until the deployment is done and then returning the results, a GUID is returned. This GUID can be used to query the status of the deployment by sending a GET request to http(s)://<hostname>:<port>/v1/status/:guid - if the deployment is still running, the response just contains a status property. If the deployment is finished, the usual response is returned - in conjunction with the status property.","title":"Asynchronous deployment"},{"location":"apis/hdi-dynamic-deploy/#how-to-use-it-in-a-multi-target-application","text":"A multi-target application (MTA) for multi-tenancy scenarios with the instance manager typically includes multiple db modules: - N static db modules ( type: com.sap.xs.hdi ), e.g. for configuration or shared data. A static module depends on @sap/hdi-deploy ; it does not depend on @sap/hdi-dynamic-deploy . - M dynamic db modules ( type: com.sap.xs.hdi-dynamic ) where the business data for a certain type of tenant is contained. A dynamic module depends on @sap/hdi-dynamic-deploy , which internally depends on @sap/hdi-deploy for deployment to the correct tenant. Example: modules: - name: db-static-1 type: com . sap . xs . hdi path: db-static-1 - name: db-static-2 type: com . sap . xs . hdi path: db-static-2 - name: db-dynamic-1 type: com . sap . xs . hdi-dynamic path: db-dynamic-1 - name: db-dynamic-2 type: com . sap . xs . hdi-dynamic path: db-dynamic-2 - name: db-dynamic-3 type: com . sap . xs . hdi-dynamic path: db-dynamic-3","title":"How to use it in a multi-target application"},{"location":"apis/hdi-dynamic-deploy/#accessing-the-underlying-http-server","text":"By requiring the dynamic deploy package, you can access the internal HTTP server. This way, you can decide when to start/stop the server. The exported object offers two methods: /** * Start the HTTP server on this.port. * * @param {any} cb Callback function (error, result). * @returns {undefined} */ function start ( cb ){ < .. > }; /** * Stop the HTTP server. * * @param {any} cb Callback function (error, result). * @returns {undefined} */ function stop ( cb ){ < .. > }; Furthermore, the object has the property port . This has to be set to the port that you want the server to listen on. Example: 'use strict' ; const { server } = require ( '@sap/hdi-dynamic-deploy/index' ); server . port = process . env . PORT ; server . start ( function (){ console . log ( `@sap/hdi-dynamic-deploy HTTP server up and running, listening on port ${ server . port } ` ); });","title":"Accessing the underlying HTTP server"},{"location":"apis/hdi-dynamic-deploy/#accessing-the-router-functions","text":"By requiring the dynamic deploy package, you can access the functions used for the API endpoints and can use them in your own router. Both functions expect two parameters: - A HTTP request object - A HTTP response object Example: 'use strict' ; const { deploy_to_instance , deploy } = require ( '@sap/hdi-dynamic-deploy/index' ); /** * Now the functions can be added to a router. * * deploy_to_instance is the function used for the /v1/deploy/to/instance route * deploy is the function used for the /v1/deploy route * */","title":"Accessing the router functions"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/","text":"1.7.1 \u00b6 Features: - use hdi-deploy version 3.11.11 - prefix log lines relating to the same deployment with an identifier 1.7.0 \u00b6 Features: - added a new route /v1/deploy/to/instance/async that implements an asynchronous deployment with status polling via /v1/status/:guid . - log the server version on start-up 1.6.0 \u00b6 Features: - node 12 support - use hdi-deploy version 3.11.9 - updated dependencies - allow specifying the tenant for audit logging via env variable \"AUDIT_LOG_TENANT\" Fixes: - previously, a simple get request (in combination with audit logging) caused an internal server error 1.5.9 \u00b6 Fixes: - use hdi-deploy version 3.11.6 - don't send duplicate messages as part of response 1.5.8 \u00b6 Fixes: - use hdi-deploy version 3.11.5 - send all deployer messages as part of response 1.5.7 \u00b6 Fixes: - use hdi-deploy version 3.11.4 1.5.6 \u00b6 Features: - use hdi-deploy version 3.11.2 - Node 10 support 1.5.5 \u00b6 Features: - use hdi-deploy version 3.11.0 - update dependencies Fixes: - fix issue with audit logging: IP determination would sometimes return multiple IPs, causing audit logging to crash 1.5.4 \u00b6 Features: - use hdi-deploy version 3.10.0 1.5.3 \u00b6 Features: - update dependencies Fixes: - full support for .hdbmigrationtable files by using hdi-deploy version 3.9.4 1.5.2 \u00b6 Fixes: - solved issue with long running deployments 1.5.1 \u00b6 Features: - use hdi-deploy version 3.9.2 1.5.0 \u00b6 Features: - logging of parameters passed via the request - optional audit logging of failed login attempts - export API endpoint functions - use hdi-deploy version 3.9.1 1.4.2 \u00b6 Features: - export the internal HTTP server - use hdi-deploy version 3.8.2 1.2.2 \u00b6 Fixes: - switch from res.send back to res.end to fix problems with the content type 1.2.1 \u00b6 Features: - update dependencies 1.2.0 \u00b6 Features: - additional route /v1/deploy/to/instance accepting the response of a instance manager GET - use hdi-deploy version 3.4.0 1.1.0 \u00b6 Features: - use hdi-deploy version 3.3.0 - move forking of hdi-deploy into hdi-deploy itself 1.0.0 \u00b6 initial release","title":"1.7.1"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#171","text":"Features: - use hdi-deploy version 3.11.11 - prefix log lines relating to the same deployment with an identifier","title":"1.7.1"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#170","text":"Features: - added a new route /v1/deploy/to/instance/async that implements an asynchronous deployment with status polling via /v1/status/:guid . - log the server version on start-up","title":"1.7.0"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#160","text":"Features: - node 12 support - use hdi-deploy version 3.11.9 - updated dependencies - allow specifying the tenant for audit logging via env variable \"AUDIT_LOG_TENANT\" Fixes: - previously, a simple get request (in combination with audit logging) caused an internal server error","title":"1.6.0"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#159","text":"Fixes: - use hdi-deploy version 3.11.6 - don't send duplicate messages as part of response","title":"1.5.9"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#158","text":"Fixes: - use hdi-deploy version 3.11.5 - send all deployer messages as part of response","title":"1.5.8"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#157","text":"Fixes: - use hdi-deploy version 3.11.4","title":"1.5.7"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#156","text":"Features: - use hdi-deploy version 3.11.2 - Node 10 support","title":"1.5.6"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#155","text":"Features: - use hdi-deploy version 3.11.0 - update dependencies Fixes: - fix issue with audit logging: IP determination would sometimes return multiple IPs, causing audit logging to crash","title":"1.5.5"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#154","text":"Features: - use hdi-deploy version 3.10.0","title":"1.5.4"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#153","text":"Features: - update dependencies Fixes: - full support for .hdbmigrationtable files by using hdi-deploy version 3.9.4","title":"1.5.3"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#152","text":"Fixes: - solved issue with long running deployments","title":"1.5.2"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#151","text":"Features: - use hdi-deploy version 3.9.2","title":"1.5.1"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#150","text":"Features: - logging of parameters passed via the request - optional audit logging of failed login attempts - export API endpoint functions - use hdi-deploy version 3.9.1","title":"1.5.0"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#142","text":"Features: - export the internal HTTP server - use hdi-deploy version 3.8.2","title":"1.4.2"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#122","text":"Fixes: - switch from res.send back to res.end to fix problems with the content type","title":"1.2.2"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#121","text":"Features: - update dependencies","title":"1.2.1"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#120","text":"Features: - additional route /v1/deploy/to/instance accepting the response of a instance manager GET - use hdi-deploy version 3.4.0","title":"1.2.0"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#110","text":"Features: - use hdi-deploy version 3.3.0 - move forking of hdi-deploy into hdi-deploy itself","title":"1.1.0"},{"location":"apis/hdi-dynamic-deploy/CHANGELOG/#100","text":"initial release","title":"1.0.0"},{"location":"apis/html5-app-deployer/","text":"@sap/html5-app-deployer \u00b6 Overview Deploying HTML5 Application Deployer App Deploying HTML5 Application Deployer App Using cf push Deploying HTML5 Application Deployer App using cf deploy Undeploy HTML5 Application Deployer Apps Delete HTML5 Application Deployer App Using cf delete Undeploy HTML5 Application Deployer App Using cf undeploy Redeploy HTML5 Application Deployer App Overview \u00b6 HTML5 application deployer handles the upload of the HTML5 applications content to the HTML5 application repository. The @sap/html5-app-deployer module is consumed as a dependency in a node.js CF application. For example: { \"name\": \"myAppDeployer\", \"engines\": { \"node\": \">=6.0.0\" }, \"dependencies\": { \"@sap/html5-app-deployer\": \"2.0.1\" }, \"scripts\": { \"start\": \"node node_modules/@sap/html5-app-deployer/index.js\" } } Below the root folder, the HTML5 applications deployer app can contain a \"resources\" folder for the static files of the HTML5 application. For example: cf create-service html5-apps-repo app-host myApps-app-host If no \"resources=\" tag is provided HTML5 application deployer will still try to upload files from resources folder. If no resources folder is found,the upload will fail.In the resources folder there should be one folder or one zip archive for each application that should be uploaded. In each application folder/zip archive there should be two files at root level: manifest.json and xs-app.json. For example: ``` myAppsDeployer + node_modules - resources - app1 index.html manifest.json xs-app.json - app2 ... package.json manifest.yaml ``` The manifest.json file should contain at least sap.app.id and sap.app.applicationVersion.version. Note that sap.app.id and sap.app.applicationVersion.version are used in the HTML5 application repository as applicationName and applicationVersion. If sap.app.id contains dots or dashes, they will be removed in the applicationName. The version format must be xx.xx.xx, whereas x is a digit. For example: 1.0.10 Note that different app-host service instances cannot be used to upload applications with the same application id/name. For example: manifest.json { \"_version\": \"1.7.0\", \"sap.app\": { \"id\": \"app1\", \"type\": \"application\", \"i18n\": \"i18n/i18n.properties\", \"applicationVersion\": { \"version\": \"1.0.0\" } } } The xs-app.json file that can be used by the application router to support application routing. For example: xs-app.json \"welcomeFile\": \"index.html\", \"authenticationMethod\": \"route\", \"routes\": [ { \"source\": \"^/be(.*)\", \"target\": \"$1\", \"destination\": \"mybackend\" }, { \"source\": \"^(/.*)\", \"target\": \"$1\", \"service\": \"html5-apps-repo-rt\" } ] } The @sap/html5-app-deployer consumer application should be bound to a single html5-apps-repo service instance of the app-host service plan. When the @sap/html5-app-deployer consumer application is started, the @sap/html5-app-deployer module creates a zip archive for each folder in the \u201cresources\u201d folder - if it is not zipped already - and triggers the upload of all zip archives to the HTML5 application repository via multi-part request. Deploying HTML5 Application Deployer App \u00b6 To deploy an sap/html5-app-deployer consumer application in the Cloud Foundry environment you can choose one of the following procedures: Deploying HTML5 Application Deployer App Using cf push \u00b6 1. Create a manifest.yaml file in the following format: \u00b6 applications : - name : myAppsDeployer no - route : true memory : 128 M services : - myApps - app - host 2. Create an html5-apps-repo service instance of the app-host plan using CF CLI \u00b6 cf create-service html5-apps-repo app-host myApps-app-host 3. Push to CF \u00b6 cf push -f manifest.yaml 4. Stop sap/html5-app-deployer consumer application \u00b6 After @sap/html5-app-deployer consumer application has uploaded the content successfully, stop the application to avoid using up CF container resources. cf stop myAppsDeployer Deploying HTML5 Application Deployer App using cf deploy \u00b6 To use cf deploy the installation of the deploy plugin is required, see deploy plugin documentation In addition, create an *.mtar archive using WebIDE or MTA Build Tool. 1. Create an mtad.yaml file. \u00b6 The MTA project should have an mtad.yaml file in the following format: ID : myApps . deployer //MTA ID _schema - version : '2.0' version : 0.0 . 3 modules : - name : myAppsDeployer type : com . sap . html5 . application - content path : deployer / requires : - name : myApps - app - host resources : - name : myApps - app - host //Resource name type : org . cloudfoundry . managed - service parameters : service : html5 - apps - repo //Service name service - plan : app - host //Service plan service - name : myApps - app - host //Service instance name 2. Generate *.mtar file. \u00b6 Use the WebIDE build or the MTA Build Tool to generate a valid myAppDeployer.mtar file. 3. Deploy *.mtar file. \u00b6 cf deploy myAppsDeployer.mtar After deploying the *.mtar file, an application called myAppsDeployer (stopped) is shown in cf apps. Undeploy HTML5 Application Deployer Apps \u00b6 When you undeploy the HTML5 application deployer app using MTA ID, the related HTML5 application repository content should be deleted too. Delete HTML5 Application Deployer App Using cf delete \u00b6 If you have used the cf push command to deploy the app, delete the HTML5 application deployer app manually: 1. Unbind html5-apps-repo app-host service instance. \u00b6 For example: cf unbind-service myAppsDeployer myApps-app-host 2. Delete html5-apps-repo app-host service instance \u00b6 This step deletes the HTML5 application respository content. For example cf delete-service myApps-app-host This step deletes the HTML5 application repository content. 3. Delete the HTML5 application deployer app. \u00b6 For example: cf delete myAppsDeployer Undeploy HTML5 Application Deployer App Using cf undeploy \u00b6 When you undeploy the HTML5 application deployer app, the HTML5 application deployer app is deleted and you can - in the same step - delete the app-host service instance of the html5-apps-repo. To delete the app-host service instance of the html5-apps-repo, the --delete-service parameter should be passed. Note that the undeploy requires the mta id, which can be obtained by calling cf mtas or from the mtad.yaml ID. 1. Undeploy HTML5 Application Deployer App and delete the service instance \u00b6 For example: cf undeploy myApps.deployer --delete-services Redeploy HTML5 Application Deployer App \u00b6 After making changes to the static content files of HTML5 applications, the new content can be redeployed to the HTML5 application repository. All content referenced by the app-host service instance id is replaced by the new content.","title":"Index"},{"location":"apis/html5-app-deployer/#saphtml5-app-deployer","text":"Overview Deploying HTML5 Application Deployer App Deploying HTML5 Application Deployer App Using cf push Deploying HTML5 Application Deployer App using cf deploy Undeploy HTML5 Application Deployer Apps Delete HTML5 Application Deployer App Using cf delete Undeploy HTML5 Application Deployer App Using cf undeploy Redeploy HTML5 Application Deployer App","title":"@sap/html5-app-deployer"},{"location":"apis/html5-app-deployer/#overview","text":"HTML5 application deployer handles the upload of the HTML5 applications content to the HTML5 application repository. The @sap/html5-app-deployer module is consumed as a dependency in a node.js CF application. For example: { \"name\": \"myAppDeployer\", \"engines\": { \"node\": \">=6.0.0\" }, \"dependencies\": { \"@sap/html5-app-deployer\": \"2.0.1\" }, \"scripts\": { \"start\": \"node node_modules/@sap/html5-app-deployer/index.js\" } } Below the root folder, the HTML5 applications deployer app can contain a \"resources\" folder for the static files of the HTML5 application. For example: cf create-service html5-apps-repo app-host myApps-app-host If no \"resources=\" tag is provided HTML5 application deployer will still try to upload files from resources folder. If no resources folder is found,the upload will fail.In the resources folder there should be one folder or one zip archive for each application that should be uploaded. In each application folder/zip archive there should be two files at root level: manifest.json and xs-app.json. For example: ``` myAppsDeployer + node_modules - resources - app1 index.html manifest.json xs-app.json - app2 ... package.json manifest.yaml ``` The manifest.json file should contain at least sap.app.id and sap.app.applicationVersion.version. Note that sap.app.id and sap.app.applicationVersion.version are used in the HTML5 application repository as applicationName and applicationVersion. If sap.app.id contains dots or dashes, they will be removed in the applicationName. The version format must be xx.xx.xx, whereas x is a digit. For example: 1.0.10 Note that different app-host service instances cannot be used to upload applications with the same application id/name. For example: manifest.json { \"_version\": \"1.7.0\", \"sap.app\": { \"id\": \"app1\", \"type\": \"application\", \"i18n\": \"i18n/i18n.properties\", \"applicationVersion\": { \"version\": \"1.0.0\" } } } The xs-app.json file that can be used by the application router to support application routing. For example: xs-app.json \"welcomeFile\": \"index.html\", \"authenticationMethod\": \"route\", \"routes\": [ { \"source\": \"^/be(.*)\", \"target\": \"$1\", \"destination\": \"mybackend\" }, { \"source\": \"^(/.*)\", \"target\": \"$1\", \"service\": \"html5-apps-repo-rt\" } ] } The @sap/html5-app-deployer consumer application should be bound to a single html5-apps-repo service instance of the app-host service plan. When the @sap/html5-app-deployer consumer application is started, the @sap/html5-app-deployer module creates a zip archive for each folder in the \u201cresources\u201d folder - if it is not zipped already - and triggers the upload of all zip archives to the HTML5 application repository via multi-part request.","title":"Overview"},{"location":"apis/html5-app-deployer/#deploying-html5-application-deployer-app","text":"To deploy an sap/html5-app-deployer consumer application in the Cloud Foundry environment you can choose one of the following procedures:","title":"Deploying HTML5 Application Deployer App"},{"location":"apis/html5-app-deployer/#deploying-html5-application-deployer-app-using-cf-push","text":"","title":"Deploying HTML5 Application Deployer App Using cf push"},{"location":"apis/html5-app-deployer/#1-create-a-manifestyaml-file-in-the-following-format","text":"applications : - name : myAppsDeployer no - route : true memory : 128 M services : - myApps - app - host","title":"1. Create a manifest.yaml file in the following format:"},{"location":"apis/html5-app-deployer/#2-create-an-html5-apps-repo-service-instance-of-the-app-host-plan-using-cf-cli","text":"cf create-service html5-apps-repo app-host myApps-app-host","title":"2. Create an html5-apps-repo service instance of the app-host plan using CF CLI"},{"location":"apis/html5-app-deployer/#3-push-to-cf","text":"cf push -f manifest.yaml","title":"3. Push to CF"},{"location":"apis/html5-app-deployer/#4-stop-saphtml5-app-deployer-consumer-application","text":"After @sap/html5-app-deployer consumer application has uploaded the content successfully, stop the application to avoid using up CF container resources. cf stop myAppsDeployer","title":"4. Stop sap/html5-app-deployer consumer application"},{"location":"apis/html5-app-deployer/#deploying-html5-application-deployer-app-using-cf-deploy","text":"To use cf deploy the installation of the deploy plugin is required, see deploy plugin documentation In addition, create an *.mtar archive using WebIDE or MTA Build Tool.","title":"Deploying HTML5 Application Deployer App using cf deploy"},{"location":"apis/html5-app-deployer/#1-create-an-mtadyaml-file","text":"The MTA project should have an mtad.yaml file in the following format: ID : myApps . deployer //MTA ID _schema - version : '2.0' version : 0.0 . 3 modules : - name : myAppsDeployer type : com . sap . html5 . application - content path : deployer / requires : - name : myApps - app - host resources : - name : myApps - app - host //Resource name type : org . cloudfoundry . managed - service parameters : service : html5 - apps - repo //Service name service - plan : app - host //Service plan service - name : myApps - app - host //Service instance name","title":"1. Create an mtad.yaml file."},{"location":"apis/html5-app-deployer/#2-generate-mtar-file","text":"Use the WebIDE build or the MTA Build Tool to generate a valid myAppDeployer.mtar file.","title":"2. Generate *.mtar file."},{"location":"apis/html5-app-deployer/#3-deploy-mtar-file","text":"cf deploy myAppsDeployer.mtar After deploying the *.mtar file, an application called myAppsDeployer (stopped) is shown in cf apps.","title":"3. Deploy *.mtar file."},{"location":"apis/html5-app-deployer/#undeploy-html5-application-deployer-apps","text":"When you undeploy the HTML5 application deployer app using MTA ID, the related HTML5 application repository content should be deleted too.","title":"Undeploy HTML5 Application Deployer Apps"},{"location":"apis/html5-app-deployer/#delete-html5-application-deployer-app-using-cf-delete","text":"If you have used the cf push command to deploy the app, delete the HTML5 application deployer app manually:","title":"Delete HTML5 Application Deployer App Using cf delete"},{"location":"apis/html5-app-deployer/#1-unbind-html5-apps-repo-app-host-service-instance","text":"For example: cf unbind-service myAppsDeployer myApps-app-host","title":"1. Unbind html5-apps-repo app-host service instance."},{"location":"apis/html5-app-deployer/#2-delete-html5-apps-repo-app-host-service-instance","text":"This step deletes the HTML5 application respository content. For example cf delete-service myApps-app-host This step deletes the HTML5 application repository content.","title":"2. Delete html5-apps-repo app-host service instance"},{"location":"apis/html5-app-deployer/#3-delete-the-html5-application-deployer-app","text":"For example: cf delete myAppsDeployer","title":"3. Delete the HTML5 application deployer app."},{"location":"apis/html5-app-deployer/#undeploy-html5-application-deployer-app-using-cf-undeploy","text":"When you undeploy the HTML5 application deployer app, the HTML5 application deployer app is deleted and you can - in the same step - delete the app-host service instance of the html5-apps-repo. To delete the app-host service instance of the html5-apps-repo, the --delete-service parameter should be passed. Note that the undeploy requires the mta id, which can be obtained by calling cf mtas or from the mtad.yaml ID.","title":"Undeploy HTML5 Application Deployer App Using cf undeploy"},{"location":"apis/html5-app-deployer/#1-undeploy-html5-application-deployer-app-and-delete-the-service-instance","text":"For example: cf undeploy myApps.deployer --delete-services","title":"1. Undeploy HTML5 Application Deployer App and delete the service instance"},{"location":"apis/html5-app-deployer/#redeploy-html5-application-deployer-app","text":"After making changes to the static content files of HTML5 applications, the new content can be redeployed to the HTML5 application repository. All content referenced by the app-host service instance id is replaced by the new content.","title":"Redeploy HTML5 Application Deployer App"},{"location":"apis/html5-app-deployer/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 2.0.1 - 2018-06-07 \u00b6 Fixed \u00b6 Validation of binding for app-host 2.0.0 - 2018-03-01 \u00b6 Added \u00b6 Single Deployer to serve multiple applications 1.1.8 - 2018-02-14 \u00b6 Added \u00b6 Initial release as NPM 1.1.0 - 2017-11-12 \u00b6 Added \u00b6 Initial release","title":"Change Log"},{"location":"apis/html5-app-deployer/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/html5-app-deployer/CHANGELOG/#201-2018-06-07","text":"","title":"2.0.1 - 2018-06-07"},{"location":"apis/html5-app-deployer/CHANGELOG/#fixed","text":"Validation of binding for app-host","title":"Fixed"},{"location":"apis/html5-app-deployer/CHANGELOG/#200-2018-03-01","text":"","title":"2.0.0 - 2018-03-01"},{"location":"apis/html5-app-deployer/CHANGELOG/#added","text":"Single Deployer to serve multiple applications","title":"Added"},{"location":"apis/html5-app-deployer/CHANGELOG/#118-2018-02-14","text":"","title":"1.1.8 - 2018-02-14"},{"location":"apis/html5-app-deployer/CHANGELOG/#added_1","text":"Initial release as NPM","title":"Added"},{"location":"apis/html5-app-deployer/CHANGELOG/#110-2017-11-12","text":"","title":"1.1.0 - 2017-11-12"},{"location":"apis/html5-app-deployer/CHANGELOG/#added_2","text":"Initial release","title":"Added"},{"location":"apis/instance-manager/","text":"@sap/instance-manager \u00b6 Node.js package for creating and deleting service instances per tenant within an application at runtime. Overview \u00b6 This package provides a client for the Instance Manager - a component that creates and deletes service instances (via REST API) for a specified key. Instance Manager can be used in the context of multitenant applications where the tenant id is the key an instance is associated with. Multitenancy is a concept for sharing resources between several different and unrelated to each other groups of users called tenants . Example: subscriptions to a commercial cloud application can be sold to two different companies each of which should use the application in isolation from the other one. Customizations are also applied (e.g. different branding, identity providers, database schemas etc.). A typical application has access to external resources (e.g. a database or messaging) via services . If an application is used by different tenants, then using a separate service instance for each one will improve isolation since service binding provides access to a particular resource. With this package a Node.js application can dynamically create and delete service instances per tenant at runtime. An instance of a managed service of the desired type is created first and is then bound to the application. For a HANA database the managed service is called 'managed-hana' . This service binding only provides parameters (HTTP endpoints and credentials) which can later be used by the application for creating and deleting service instances of the desired type for each tenant. API \u00b6 var createInstanceManager = require ( '@sap/instance-manager' ). create ; var options = { /* properties from service binding */ }; createInstanceManager ( options , function ( err , instanceManager ) { if ( err ) { return console . log ( 'Create instance manager error:' , err . message ); } var optionalParameters = { /* Optional JSON object containing service-specific configuration parameters */ }; instanceManager . create ( 'my-tenant' , optionalParameters , function ( err , instance ) { if ( err ) { return console . log ( 'Create error:' , err . message ); } // consume instance.credentials console . log ( instance ); instanceManager . get ( 'my-tenant' , function ( err , instance ) { if ( err ) { return console . log ( 'Get error:' , err . message ); } // same instance console . log ( instance ); instanceManager . delete ( 'my-tenant' , function ( err ) { if ( err ) { return console . log ( 'Delete error:' , err . message ); } console . log ( 'Instance deleted' ); }); }); }); }); Options \u00b6 The managed service bound to the application (for example managed-hana ) provides credentials as well as REST endpoints of the Instance Manager - the component that handles creation and deletion of services. These credentials and endpoints are mandatory. The create and delete operations are executed asynchronously on server side. To provide an easier interface, this library also implements polling until an operation is finished. Developers can tune polling via some optional properties. Since operations involve network activity (thus, can be considered relatively slower) the package also caches the created instances. Cache options can also be provided by developers. Property Mandatory Details user x User for authentication. password x Password for the user. post_managed_instance_url x REST endpoint used for creating a new service instance for a tenant. get_managed_instance_url x REST endpoint used for getting the details about a specific tenant service instance. get_all_managed_instances_url x REST endpoint used for getting the details about all instances (for all tenants). delete_managed_instance_url x REST endpoint used for deletion of a service instance. polling_interval_millis Defaults to 300. States how many milliseconds to wait between requests in the polling phase. polling_timeout_seconds Defaults to 120. Sets a limit for the amount of time (in seconds) that can be spent in polling. cache_max_items Default value is 500. States the capacity of the cache. cache_item_expire_seconds Defaults to 600 (10 minutes). Number of seconds after which a cache entry expires. Note : - A managed service binding contains all of the mandatory properties mentioned above. - It is recommended to have a single instance manager JavaScript object per managed service bound to the application. Methods \u00b6 create(tenant, optionalParameters, callback) - creates a service instance for the provided tenant. The method polls until the instance is successfully created and then invokes the callback. Reports error if an instance for this tenant already exists. tenant | String | Tenant name. optionalParameters | Object | ( optional ) JSON object with parameters for provisioning or binding, as would be done with the -c options of the CLI commands create-service and bind-service for unmanaged services. E.g. json { \"provisioning_parameters\": { \"database_id\" : \"<HANA Tenant DB Guid or Name>\" }, \"binding_parameters\": {\"<key>\" : \"<value>\"} } callback | function(err, instance) | Callback function with the newly created instance as second argument. get(tenant, callback) - gets the corresponding instance for the provided tenant either from cache or from server. Value of null means that a service instance for this tenant does not exist. Note : this method only polls if the instance is in status CREATION_IN_PROGRESS . In all other cases it returns the service instance as it is on server. Thus, having the credentials property on the instance object in the callback is not guaranteed. tenant | String | Tenant name. callback | function(err, instance) | Callback function with the instance as second argument. getAll(callback) - gets the instances for all tenants as array of objects. Filtering of the instances according to their status (e.g. CREATION_SUCCEEDED , CREATION_IN_PROGRESS ) does not take place. Thus, having the credentials property on each of the instances provided in the callback is not guaranteed. This method updates the cache. callback | function(err, instances) | Callback function with all instances as second argument. delete(tenant, callback) - deletes service instance for the provided tenant. The method polls until the instance is successfully deleted and then invokes the callback. Reports error if an instance for this tenant does not exists. tenant | String | Tenant name. callback | function(err) | Callback function called when the instance is deleted or an error has occured. When the callback of a method is invoked with an error and this error is caused by an unexpected HTTP response code received from the server, then this error object will have a statusCode property with the status code of the received HTTP response. Debug logs \u00b6 One can enable debug logs of this package via adding instance-manager to the DEBUG environment variable.","title":"@sap/instance-manager"},{"location":"apis/instance-manager/#sapinstance-manager","text":"Node.js package for creating and deleting service instances per tenant within an application at runtime.","title":"@sap/instance-manager"},{"location":"apis/instance-manager/#overview","text":"This package provides a client for the Instance Manager - a component that creates and deletes service instances (via REST API) for a specified key. Instance Manager can be used in the context of multitenant applications where the tenant id is the key an instance is associated with. Multitenancy is a concept for sharing resources between several different and unrelated to each other groups of users called tenants . Example: subscriptions to a commercial cloud application can be sold to two different companies each of which should use the application in isolation from the other one. Customizations are also applied (e.g. different branding, identity providers, database schemas etc.). A typical application has access to external resources (e.g. a database or messaging) via services . If an application is used by different tenants, then using a separate service instance for each one will improve isolation since service binding provides access to a particular resource. With this package a Node.js application can dynamically create and delete service instances per tenant at runtime. An instance of a managed service of the desired type is created first and is then bound to the application. For a HANA database the managed service is called 'managed-hana' . This service binding only provides parameters (HTTP endpoints and credentials) which can later be used by the application for creating and deleting service instances of the desired type for each tenant.","title":"Overview"},{"location":"apis/instance-manager/#api","text":"var createInstanceManager = require ( '@sap/instance-manager' ). create ; var options = { /* properties from service binding */ }; createInstanceManager ( options , function ( err , instanceManager ) { if ( err ) { return console . log ( 'Create instance manager error:' , err . message ); } var optionalParameters = { /* Optional JSON object containing service-specific configuration parameters */ }; instanceManager . create ( 'my-tenant' , optionalParameters , function ( err , instance ) { if ( err ) { return console . log ( 'Create error:' , err . message ); } // consume instance.credentials console . log ( instance ); instanceManager . get ( 'my-tenant' , function ( err , instance ) { if ( err ) { return console . log ( 'Get error:' , err . message ); } // same instance console . log ( instance ); instanceManager . delete ( 'my-tenant' , function ( err ) { if ( err ) { return console . log ( 'Delete error:' , err . message ); } console . log ( 'Instance deleted' ); }); }); }); });","title":"API"},{"location":"apis/instance-manager/#options","text":"The managed service bound to the application (for example managed-hana ) provides credentials as well as REST endpoints of the Instance Manager - the component that handles creation and deletion of services. These credentials and endpoints are mandatory. The create and delete operations are executed asynchronously on server side. To provide an easier interface, this library also implements polling until an operation is finished. Developers can tune polling via some optional properties. Since operations involve network activity (thus, can be considered relatively slower) the package also caches the created instances. Cache options can also be provided by developers. Property Mandatory Details user x User for authentication. password x Password for the user. post_managed_instance_url x REST endpoint used for creating a new service instance for a tenant. get_managed_instance_url x REST endpoint used for getting the details about a specific tenant service instance. get_all_managed_instances_url x REST endpoint used for getting the details about all instances (for all tenants). delete_managed_instance_url x REST endpoint used for deletion of a service instance. polling_interval_millis Defaults to 300. States how many milliseconds to wait between requests in the polling phase. polling_timeout_seconds Defaults to 120. Sets a limit for the amount of time (in seconds) that can be spent in polling. cache_max_items Default value is 500. States the capacity of the cache. cache_item_expire_seconds Defaults to 600 (10 minutes). Number of seconds after which a cache entry expires. Note : - A managed service binding contains all of the mandatory properties mentioned above. - It is recommended to have a single instance manager JavaScript object per managed service bound to the application.","title":"Options"},{"location":"apis/instance-manager/#methods","text":"create(tenant, optionalParameters, callback) - creates a service instance for the provided tenant. The method polls until the instance is successfully created and then invokes the callback. Reports error if an instance for this tenant already exists. tenant | String | Tenant name. optionalParameters | Object | ( optional ) JSON object with parameters for provisioning or binding, as would be done with the -c options of the CLI commands create-service and bind-service for unmanaged services. E.g. json { \"provisioning_parameters\": { \"database_id\" : \"<HANA Tenant DB Guid or Name>\" }, \"binding_parameters\": {\"<key>\" : \"<value>\"} } callback | function(err, instance) | Callback function with the newly created instance as second argument. get(tenant, callback) - gets the corresponding instance for the provided tenant either from cache or from server. Value of null means that a service instance for this tenant does not exist. Note : this method only polls if the instance is in status CREATION_IN_PROGRESS . In all other cases it returns the service instance as it is on server. Thus, having the credentials property on the instance object in the callback is not guaranteed. tenant | String | Tenant name. callback | function(err, instance) | Callback function with the instance as second argument. getAll(callback) - gets the instances for all tenants as array of objects. Filtering of the instances according to their status (e.g. CREATION_SUCCEEDED , CREATION_IN_PROGRESS ) does not take place. Thus, having the credentials property on each of the instances provided in the callback is not guaranteed. This method updates the cache. callback | function(err, instances) | Callback function with all instances as second argument. delete(tenant, callback) - deletes service instance for the provided tenant. The method polls until the instance is successfully deleted and then invokes the callback. Reports error if an instance for this tenant does not exists. tenant | String | Tenant name. callback | function(err) | Callback function called when the instance is deleted or an error has occured. When the callback of a method is invoked with an error and this error is caused by an unexpected HTTP response code received from the server, then this error object will have a statusCode property with the status code of the received HTTP response.","title":"Methods"},{"location":"apis/instance-manager/#debug-logs","text":"One can enable debug logs of this package via adding instance-manager to the DEBUG environment variable.","title":"Debug logs"},{"location":"apis/instance-manager/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 1.4.0 - 2018-12-18 \u00b6 Added \u00b6 Node.js version 10 support 1.3.4 - 2018-08-14 \u00b6 Fixed \u00b6 Update dependencies 1.3.3 - 2018-07-17 \u00b6 Fixed \u00b6 Update request package to v2.87.0 1.3.2 - 2018-05-28 \u00b6 Fixed \u00b6 Update request package to v2.86.0 1.3.1 - 2018-04-05 \u00b6 Fixed \u00b6 Update npm-shrinkwrap.json 1.3.0 - 2018-01-19 \u00b6 Added \u00b6 npm-shrinkwrap.json 1.2.0 - 2017-10-13 \u00b6 Added \u00b6 Support for Node.js 8 Optional argument to instanceManager.create - an object with parameters for provisioning or binding Changed \u00b6 Dependencies' versions 1.1.0 - 2017-06-01 \u00b6 Added \u00b6 instanceManager.getAll function 1.0.1 - 2017-02-10 \u00b6 Fixed \u00b6 Update dependencies 1.0.0 - 2017-02-02 \u00b6 Added \u00b6 Initial implementation","title":"Change Log"},{"location":"apis/instance-manager/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/instance-manager/CHANGELOG/#140-2018-12-18","text":"","title":"1.4.0 - 2018-12-18"},{"location":"apis/instance-manager/CHANGELOG/#added","text":"Node.js version 10 support","title":"Added"},{"location":"apis/instance-manager/CHANGELOG/#134-2018-08-14","text":"","title":"1.3.4 - 2018-08-14"},{"location":"apis/instance-manager/CHANGELOG/#fixed","text":"Update dependencies","title":"Fixed"},{"location":"apis/instance-manager/CHANGELOG/#133-2018-07-17","text":"","title":"1.3.3 - 2018-07-17"},{"location":"apis/instance-manager/CHANGELOG/#fixed_1","text":"Update request package to v2.87.0","title":"Fixed"},{"location":"apis/instance-manager/CHANGELOG/#132-2018-05-28","text":"","title":"1.3.2 - 2018-05-28"},{"location":"apis/instance-manager/CHANGELOG/#fixed_2","text":"Update request package to v2.86.0","title":"Fixed"},{"location":"apis/instance-manager/CHANGELOG/#131-2018-04-05","text":"","title":"1.3.1 - 2018-04-05"},{"location":"apis/instance-manager/CHANGELOG/#fixed_3","text":"Update npm-shrinkwrap.json","title":"Fixed"},{"location":"apis/instance-manager/CHANGELOG/#130-2018-01-19","text":"","title":"1.3.0 - 2018-01-19"},{"location":"apis/instance-manager/CHANGELOG/#added_1","text":"npm-shrinkwrap.json","title":"Added"},{"location":"apis/instance-manager/CHANGELOG/#120-2017-10-13","text":"","title":"1.2.0 - 2017-10-13"},{"location":"apis/instance-manager/CHANGELOG/#added_2","text":"Support for Node.js 8 Optional argument to instanceManager.create - an object with parameters for provisioning or binding","title":"Added"},{"location":"apis/instance-manager/CHANGELOG/#changed","text":"Dependencies' versions","title":"Changed"},{"location":"apis/instance-manager/CHANGELOG/#110-2017-06-01","text":"","title":"1.1.0 - 2017-06-01"},{"location":"apis/instance-manager/CHANGELOG/#added_3","text":"instanceManager.getAll function","title":"Added"},{"location":"apis/instance-manager/CHANGELOG/#101-2017-02-10","text":"","title":"1.0.1 - 2017-02-10"},{"location":"apis/instance-manager/CHANGELOG/#fixed_4","text":"Update dependencies","title":"Fixed"},{"location":"apis/instance-manager/CHANGELOG/#100-2017-02-02","text":"","title":"1.0.0 - 2017-02-02"},{"location":"apis/instance-manager/CHANGELOG/#added_4","text":"Initial implementation","title":"Added"},{"location":"apis/jobs-client/","text":"@sap/jobs-client \u00b6 Node.js client for XS Advanced Job Scheduler service This is a small Node.js module to integrate jobs in your Node.js application. The module contains utilities to create REST calls according to expected by job scheduler service request format used to register/unregister jobs in job scheduler service, update job schedules and job status. Usage \u00b6 This module works with job descriptor objects, having the properties as the expected by the respective service in JobScheduler. Example usage: var jobsc = require ( '@sap/jobs-client' ); var options = { host : 'localhost' , port : 4242 , timeout : 15000 , user : 'username' , password : 'password' , baseURL : 'http://apphost:port/' }; var myJob = { /* according to job scheduler documentation */ }; var scheduler = new jobsc . Scheduler ( options ); var scJob = { job : myJob }; scheduler . createJob ( scJob , function ( error , body ) { if ( error ) { return console . log ( 'Error registering new job %s' , error ); } // job was created successfully job . id = body . _id ; }); ... Update job, var req = { jobId : 33 , job : { user : 'John' , password : 'secret' , active : 1 } }; scheduler . updateJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error updating job: %s' , err ); } //job was updated successfully }); Delete job, var req = { jobId : 33 }; scheduler . deleteJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deleting job: %s' , err ); } //job was deleted successfully }); Get job Details, var req = { //by Id jobId : 33 }; scheduler . fetchJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving job: %s' , err ); } //job details retrieved successfully }); var req = { //by name name : 'my job' }; scheduler . fetchJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving job: %s' , err ); } //job details retrieved successfully }); Create job schedule, var mySchedule = { /* according to job scheduler documentation */ } var req = { jobId : 33 , schedule : mySchedule }; scheduler . createJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error creating job schedule: %s' , err ); } //Schedule created successfully }); Update job schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , schedule : { cron : \"* * * * 4\" } }; scheduler . updateJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error updating job schedule: %s' , err ); } //Schedule updated successfully }); Delete job schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' }; scheduler . deleteJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deleting schedule: %s' , err ); } //Schedule deleted successfully }); Get all jobs, var req = {}; scheduler . fetchAllJobs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving jobs: %s' , err ); } //Jobs retrieved successfully }); Get job schedule details, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , displayLogs : false }; scheduler . fetchJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving schedule: %s' , err ); } //Schedule retrieved successfully }); Get schedules of job, var req = { jobId : 33 }; scheduler . fetchJobSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving all schedules: %s' , err ); } //All schedules retrieved successfully }); Update run log of schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , runId : 1 , data : data }; scheduler . updateJobRunLog ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error updating run log: %s' , err ); } //Run log updated successfully }); Get run logs of schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , page_size : 15 , offset : 0 }; scheduler . getRunLogs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving run logs: %s' , err ); } //Run log retrieved successfully }); Delete all schedules of job, var req = { jobId : 3 }; scheduler . deleteAllJobSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deleting schedules: %s' , err ); } //All schedules deleted successfully }); Bulk activation of schedules of job, var req = { jobId : 3 }; scheduler . activateAllSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error activating bulk schedules: %s' , err ); } //All schedules activated successfully }); Bulk deactivation of schedules of job, var req = { jobId : 3 }; scheduler . deactivateAllSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deactivating bulk schedules: %s' , err ); } //All schedules deactivated successfully }); Get action logs of job, var req = { jobId : 3 }; scheduler . getJobActionLogs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving action logs: %s' , err ); } //All actionlogs logs retrieved successfully }); Get action logs of schedule, var req = { jobId : 3 , scheduleId : \"ABC-DEF\" }; scheduler . getScheduleActionLogs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving action logs: %s' , err ); } //All actionlogs logs retrieved successfully }); Get active and inactive jobcount var req = { activeStatus : true // true- for getting active number of jobs and false- for getting inactive number of jobs }; scheduler . getJobCount ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving jobcount: %s' , err ); } //Active Job count retrieved successfully }); Search API : \u00b6 Search can be done in both job and schedule entities. Here in the client 'q' contains the query parameter, you need to provide the query in decoded format, the client will decode the query. And filtering parameters can be provided as shown below: ```js var searchToken = { q : 'job startTime:>2011-02-18 active:false', displaySchedules : 'false', offset : 0, page_size : 5 }; scheduler.searchJobs(searchToken,function(error,result){ if(error){ return console.log('Error during Job search: %s',error); } console.log(JSON.stringify(result)); }); For schedule search: js var searchScheduleToken = { q : 'startTime:>2011-02-18 active:false', offset : 0, page_size : 5 }; scheduler.searchSchedules(searchScheduleToken,function(error,result){ if(error){ return console.log('Error during Schedule search %s',error); } console.log(JSON.stringify(result)); }); ```","title":"Index"},{"location":"apis/jobs-client/#sapjobs-client","text":"Node.js client for XS Advanced Job Scheduler service This is a small Node.js module to integrate jobs in your Node.js application. The module contains utilities to create REST calls according to expected by job scheduler service request format used to register/unregister jobs in job scheduler service, update job schedules and job status.","title":"@sap/jobs-client"},{"location":"apis/jobs-client/#usage","text":"This module works with job descriptor objects, having the properties as the expected by the respective service in JobScheduler. Example usage: var jobsc = require ( '@sap/jobs-client' ); var options = { host : 'localhost' , port : 4242 , timeout : 15000 , user : 'username' , password : 'password' , baseURL : 'http://apphost:port/' }; var myJob = { /* according to job scheduler documentation */ }; var scheduler = new jobsc . Scheduler ( options ); var scJob = { job : myJob }; scheduler . createJob ( scJob , function ( error , body ) { if ( error ) { return console . log ( 'Error registering new job %s' , error ); } // job was created successfully job . id = body . _id ; }); ... Update job, var req = { jobId : 33 , job : { user : 'John' , password : 'secret' , active : 1 } }; scheduler . updateJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error updating job: %s' , err ); } //job was updated successfully }); Delete job, var req = { jobId : 33 }; scheduler . deleteJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deleting job: %s' , err ); } //job was deleted successfully }); Get job Details, var req = { //by Id jobId : 33 }; scheduler . fetchJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving job: %s' , err ); } //job details retrieved successfully }); var req = { //by name name : 'my job' }; scheduler . fetchJob ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving job: %s' , err ); } //job details retrieved successfully }); Create job schedule, var mySchedule = { /* according to job scheduler documentation */ } var req = { jobId : 33 , schedule : mySchedule }; scheduler . createJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error creating job schedule: %s' , err ); } //Schedule created successfully }); Update job schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , schedule : { cron : \"* * * * 4\" } }; scheduler . updateJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error updating job schedule: %s' , err ); } //Schedule updated successfully }); Delete job schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' }; scheduler . deleteJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deleting schedule: %s' , err ); } //Schedule deleted successfully }); Get all jobs, var req = {}; scheduler . fetchAllJobs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving jobs: %s' , err ); } //Jobs retrieved successfully }); Get job schedule details, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , displayLogs : false }; scheduler . fetchJobSchedule ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving schedule: %s' , err ); } //Schedule retrieved successfully }); Get schedules of job, var req = { jobId : 33 }; scheduler . fetchJobSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving all schedules: %s' , err ); } //All schedules retrieved successfully }); Update run log of schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , runId : 1 , data : data }; scheduler . updateJobRunLog ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error updating run log: %s' , err ); } //Run log updated successfully }); Get run logs of schedule, var req = { jobId : 33 , scheduleId : 'ABC-DEF' , page_size : 15 , offset : 0 }; scheduler . getRunLogs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving run logs: %s' , err ); } //Run log retrieved successfully }); Delete all schedules of job, var req = { jobId : 3 }; scheduler . deleteAllJobSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deleting schedules: %s' , err ); } //All schedules deleted successfully }); Bulk activation of schedules of job, var req = { jobId : 3 }; scheduler . activateAllSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error activating bulk schedules: %s' , err ); } //All schedules activated successfully }); Bulk deactivation of schedules of job, var req = { jobId : 3 }; scheduler . deactivateAllSchedules ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error deactivating bulk schedules: %s' , err ); } //All schedules deactivated successfully }); Get action logs of job, var req = { jobId : 3 }; scheduler . getJobActionLogs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving action logs: %s' , err ); } //All actionlogs logs retrieved successfully }); Get action logs of schedule, var req = { jobId : 3 , scheduleId : \"ABC-DEF\" }; scheduler . getScheduleActionLogs ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving action logs: %s' , err ); } //All actionlogs logs retrieved successfully }); Get active and inactive jobcount var req = { activeStatus : true // true- for getting active number of jobs and false- for getting inactive number of jobs }; scheduler . getJobCount ( req , function ( err , result ) { if ( err ){ return console . log ( 'Error retrieving jobcount: %s' , err ); } //Active Job count retrieved successfully });","title":"Usage"},{"location":"apis/jobs-client/#search-api","text":"Search can be done in both job and schedule entities. Here in the client 'q' contains the query parameter, you need to provide the query in decoded format, the client will decode the query. And filtering parameters can be provided as shown below: ```js var searchToken = { q : 'job startTime:>2011-02-18 active:false', displaySchedules : 'false', offset : 0, page_size : 5 }; scheduler.searchJobs(searchToken,function(error,result){ if(error){ return console.log('Error during Job search: %s',error); } console.log(JSON.stringify(result)); }); For schedule search: js var searchScheduleToken = { q : 'startTime:>2011-02-18 active:false', offset : 0, page_size : 5 }; scheduler.searchSchedules(searchScheduleToken,function(error,result){ if(error){ return console.log('Error during Schedule search %s',error); } console.log(JSON.stringify(result)); }); ```","title":"Search API :"},{"location":"apis/jobs-client/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 1.3.4 - 2018-08-14 \u00b6 Fixed \u00b6 Update request package to v2.88.0 1.3.3 - 2018-08-08 \u00b6 Fixed \u00b6 Update request package to v2.87.0 1.3.2 - 2018-05-18 \u00b6 Fixed \u00b6 Update request package to v2.86.0 1.3.1 - 2018-04-05 \u00b6 Fixed \u00b6 Update npm-shrikwrap.json 1.3.0 - 2018-01-19 \u00b6 Added \u00b6 npm-shrikwrap.json Fixed \u00b6 Update request to 2.83.0 1.2.0 - 2017-11-16 \u00b6 Added \u00b6 Node.js 8 support Improvements in the input validation messages Support for page_size and offset parameters in getRunLogs 1.1.1 - 2017-05-30 \u00b6 Fixed \u00b6 Dependencies updates 1.1.0 - 2017-03-30 \u00b6 Added \u00b6 Delete Job Bulk schedule activation/deactivation Get active/inactive job count Get job/schedule action logs Bulk schedule deletion Fetch all jobs Search API","title":"Change Log"},{"location":"apis/jobs-client/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/jobs-client/CHANGELOG/#134-2018-08-14","text":"","title":"1.3.4 - 2018-08-14"},{"location":"apis/jobs-client/CHANGELOG/#fixed","text":"Update request package to v2.88.0","title":"Fixed"},{"location":"apis/jobs-client/CHANGELOG/#133-2018-08-08","text":"","title":"1.3.3 - 2018-08-08"},{"location":"apis/jobs-client/CHANGELOG/#fixed_1","text":"Update request package to v2.87.0","title":"Fixed"},{"location":"apis/jobs-client/CHANGELOG/#132-2018-05-18","text":"","title":"1.3.2 - 2018-05-18"},{"location":"apis/jobs-client/CHANGELOG/#fixed_2","text":"Update request package to v2.86.0","title":"Fixed"},{"location":"apis/jobs-client/CHANGELOG/#131-2018-04-05","text":"","title":"1.3.1 - 2018-04-05"},{"location":"apis/jobs-client/CHANGELOG/#fixed_3","text":"Update npm-shrikwrap.json","title":"Fixed"},{"location":"apis/jobs-client/CHANGELOG/#130-2018-01-19","text":"","title":"1.3.0 - 2018-01-19"},{"location":"apis/jobs-client/CHANGELOG/#added","text":"npm-shrikwrap.json","title":"Added"},{"location":"apis/jobs-client/CHANGELOG/#fixed_4","text":"Update request to 2.83.0","title":"Fixed"},{"location":"apis/jobs-client/CHANGELOG/#120-2017-11-16","text":"","title":"1.2.0 - 2017-11-16"},{"location":"apis/jobs-client/CHANGELOG/#added_1","text":"Node.js 8 support Improvements in the input validation messages Support for page_size and offset parameters in getRunLogs","title":"Added"},{"location":"apis/jobs-client/CHANGELOG/#111-2017-05-30","text":"","title":"1.1.1 - 2017-05-30"},{"location":"apis/jobs-client/CHANGELOG/#fixed_5","text":"Dependencies updates","title":"Fixed"},{"location":"apis/jobs-client/CHANGELOG/#110-2017-03-30","text":"","title":"1.1.0 - 2017-03-30"},{"location":"apis/jobs-client/CHANGELOG/#added_2","text":"Delete Job Bulk schedule activation/deactivation Get active/inactive job count Get job/schedule action logs Bulk schedule deletion Fetch all jobs Search API","title":"Added"},{"location":"apis/logging/","text":"@sap/logging \u00b6 A package that provides logging and tracing functionalities for Node.js applications. Example Logging & Tracing Categories & Locations Location values Wildcard support Formats Severity Levels XS_APP_LOG_LEVEL environment variable Changing severity levels for an application XS Advanced Cloud Foundry Logging sensitive data API Application context Log context Log context id Middleware Loggers Tracers Custom fields (in CF) Convenient tracing methods Other Migration guide Example \u00b6 Following is an example of how to consume the package using express : var logging = require ( '@sap/logging' ); var express = require ( 'express' ); var app = express (); var appContext = logging . createAppContext (); app . use ( logging . middleware ({ appContext : appContext , logNetwork : true })); app . get ( '/demo' , function ( req , res ) { var logger = req . loggingContext . getLogger ( '/Application/Network' ); var tracer = req . loggingContext . getTracer ( __filename ); logger . info ( 'Retrieving demo greeting ...' ); tracer . info ( 'Processing GET request to /demo' ); res . send ( 'Hello World!' ); }); app . listen ( 3000 , function () { console . log ( 'Server started' ); }); In general, you just need to: - Initialize the logging library with some application-wide options. - Use the provided middleware that will extract request specific information. It is recommended that this middleware is the first one to be called in order to have the logging context available as early as possible. It is also recommended to have the middleware that sets the user of the request (if the application intends to log the current user) right after the one provided by this library. - Instantiate a logger and a tracer via the loggingContext property of the request. - Log and trace whatever you need. See more details below. Logging & Tracing \u00b6 Logs are addressed to an administrator of an application. Traces - to a developer or support staff. - Events that need to be logged are related to how the app operates - e.g. the app cannot display some results taken from a remote HTTP service because the remote server is down. An administrator of an app does not need to know how it is implemented, he/she should just be able to determine the state of the app itself. - Traces are mainly used when a problem has occurred and further investigation on code level has to take place. The logging library writes log entries to standard output and trace entries - to standard error. Categories & Locations \u00b6 Categories - represent a feature area in an application. For example, different layers - Network layer, Database layer etc. The concept of categories is used in logging. Locations - represent a location in the source code - e.g. a path to a file. Used in the context of tracing. Getting a tracer object requires explicitly providing a location. It is recommended to pass as argument the location of the current script - __filename . Location values \u00b6 The path to the application root is removed from the source file paths in the trace output to reduce duplication. The application root directory is taken from the HOME environment variable. If it is not defined, absolute file paths are used in the trace output. Example: Let's assume the structure of your application looks like the following: +-- demo-app | +-- package.json | +-- lib | | +-- index.js | | +-- services | | | +-- customer-service.js | | | +-- sales-service.js Here is how the location of a script (path to a file) will look like in the trace entries (having in mind __filename has been passed as location to the tracer): Script HOME environment variable is set HOME environment variable is not set index.js /lib/index.js /path/from/root/demo-app/lib/index.js customer-service.js /lib/services/customer-service.js /path/from/root/demo-app/lib/services/customer-service.js The same applies to Windows systems as well. Note : The path separator in the trace entries is always a forward slash, no matter the platform. Wildcard support \u00b6 The asterisk (*) is the only wildcard character supported by the library. It corresponds to zero or more characters (no matter what they are). Let's illustrate the wildcard usage using the example application structure from the previous section, assuming the HOME environment variable is set to the root of the application (as it would be on XS Advanced or Cloud Foundry): Pattern Result /Application/Network Match a certain Category /Application/Network/* Match all subcategories /lib/services/users-service.js Match a specific file /lib/services/* Match all files in all subdirectories of services Formats \u00b6 ListLog format is used for logs in XS Advanced and during local development Trace format is used for traces in XS Advanced and during local development CF Log format is used for logs and traces in Cloud Foundry Note : Instead of thread-name (in ListLog and Trace formats), a context id is used. This is an identifier that helps to distinguish which entries are logged/traced because of which requests/events. More info on that is available in this section . Severity Levels \u00b6 The following table shows which severity levels are available for loggers and tracers: Logging Tracing debug path info info warning warning error error fatal fatal Here you can find when to use which level: Level When to use debug Used to output the internal status of a program. path Used to analyze the execution flow of a program. info Used for events that do not need any follow up activity. They show the normal operations within an app. warning Used for events that need follow up activity in order to prevent errors in the future. error Used when the desired tasks cannot be completed and the application is still usable. fatal Used in case of errors, because of which the application is no longer usable. The default severity level for loggers is info and the default one for tracers is error . XS_APP_LOG_LEVEL environment variable \u00b6 The XS_APP_LOG_LEVEL environment variable can be used to configure severity levels for logging and tracing. Valid values are severity levels from debug to fatal . The level specified in this environment variable will be used instead of all already set levels. none is also a valid value for XS_APP_LOG_LEVEL . In that case all logging and tracing is disabled (useful for automated tests). The library throws an error if the value of XS_APP_LOG_LEVEL is not a valid severity level or none . Changing severity levels for an application \u00b6 XS Advanced \u00b6 You can enable debug logs and traces for an application deployed on XS Advanced via the command: xs set-logging-level <application-name> \"*\" debug This can be reverted via the command: xs unset-logging-level <application-name> \"*\" Restart of the application is not required for those commands to take effect. The example above shows how to enable debug level for all loggers and tracers. It is possible to use the command for setting levels for a single category or location (e.g. xs set-logging-level <application-name> \"/index.js\" debug ), or multiple by using the asterisk wildcard (e.g. xs set-logging-level <application-name> \"/Application/Network/*\" debug ). The comparison with the actual category/location of a logger/tracer is executed in a case insensitive manner. Cloud Foundry \u00b6 You can enable debug logs and traces for an application deployed on Cloud Foundry via setting the environment variable XS_APP_LOG_LEVEL : cf set-env <application-name> XS_APP_LOG_LEVEL debug This can be reverted via the command: cf unset-env <application-name> XS_APP_LOG_LEVEL Note : Application restart is required after each of the commands above in order the changes to the environment to take effect. Logging sensitive data \u00b6 Logging sensitive data is not enabled by default. The following table shows which environment variable enables (when set to true ) which fields and for which formats: Environment Variable Field Taken from Format XS_LOG_USER user/remote_user req.user.id property ListLog, CF Log XS_LOG_REFERER referer referer request header CF Log XS_LOG_CONNECTION_DATA remote_ip, remote_host, remote_port, x_forwarded_for req.connection.remoteAddress property, req.connection.remotePort property, x-forwarded-for header CF Log API \u00b6 To consume the logging package, an application context needs to be created. It contains information that is valid for the whole application. Next a log context needs to be created. It contains information that is valid for the current context. A separate log context should be created for each new event (HTTP request received, job execution started, message from messaging service received). Because of the asynchronous nature of Node.js, entries produced during the processing of different events can be mixed. All entries contain information specific to the log context they are associated with, which helps to distinguish between entries produced during the processing of different events. Loggers and tracers are obtained from the log context. Application context \u00b6 var logging = require ( '@sap/logging' ); var appContext = logging . createAppContext ({ // options }); To create the application context, pass some application-wide options. Here is a list of the properties you may optionally pass: Property Description csnComponent String Only applicable to SAP applications. You may use the application context to change severity levels (with wildcards for flexibility): appContext . setLevel ( '/Application/*' , 'warning' ); // for a logger appContext . setLevel ( pathToFile , 'debug' ); // for a tracer The method throws an error in case of an incorrect level. Severity levels can be unset with: appContext . unsetLevel ( '/Application/*' ); // for a logger appContext . unsetLevel ( pathToFile ); // for a tracer To set custom fields, you could do: appContext . setCustomFields ([ \"abc\" ]); Log context \u00b6 appContext . createLogContext ({ // options }); A log context needs to be created in order to obtain a logger or a tracer. Here is a list of the options that can be provided to the log context (all are optional): Option Description id String Included in all logs and traces, should be unique. Used to distinguish entries from different log contexts. Defaults to an auto-generated value. If req is provided, the value is taken from the request headers x-request-id and x-vcap-request-id if present. It is recommended to explicitly pass an empty string for log contexts used during application startup. If req is present, then this id can be thought of as a request id, because all log/trace entries for that request will have the same id. See this section for more information. correlationId String Used to correlate entries for a logical transaction which involves processing within different applications. If the value is not set explicitly, then it is taken from the x-correlationid header (if req is provided and the header is present) or from the id of the log context. req Object Represents an HTTP request. The log context exposes the following functions: | Function | Description | | --------------- | ----------- | | getAppContext | AppConext object associated with this log context | The log context exposes the following read-only properties: Property Description id The id of the log context. correlationId The correlation id of the log context. This property is useful when the value needs to be sent to another application. Loggers and tracers can be obtained from the log context as follows: let logger = logContext . getLogger ( '/Application/Network' ); let tracer = logContext . getTracer ( __filename ); It is possible to log request metrics for an HTTP request using the enableNetworkLog method: logContext . enableNetworkLog ( res ); It takes a response object as argument. A req object needs to be passed in advance as option when creating the log context. This method registers a handler for the finish event of the HTTP response. An entry (of info severity level), containing request metrics will be logged when the event is emitted. enableNetworkLog should be called once for a request-response pair: http . createServer ( function ( req , res ) { var reqContext = appContext . createLogContext ({ req : req }); reqContext . enableNetworkLog ( res ); res . end ( 'Hello World' ); }); The log entry uses category /LoggingLibrary/NetworkLog . It can be used to turn off the network log at runtime with xs set-logging-level or with appContext.setLevel . Log context id \u00b6 Let's take HTTP requests as an example: Because of the single-threaded nature and the event loop mechanism in Node.js, you may: - receive a request - start some async I/O operation - in the meantime start processing another request before returning a response to the first one This means that the log entries for the two requests will be mixed a bit. To overcome this issue, each request (and the corresponding log context) is associated with a unique id which is present in the logs and traces for that request. In that way one can distinguish between the logs from the first request and the logs from the second request. The same concept applies to messages received from a messaging service and to job runs triggered according to a schedule. Middleware \u00b6 There is a utility middleware that can be used (see this example ). It automatically attaches a property named \"loggingContext\" to the request object. It accepts an object with properties: Property Description appContext Mandatory An application context object. logNetwork Optional Defaults to false , boolean specifying whether an entry containing request metrics will be logged for every finished HTTP request. The middleware sets the x-request-id response header to the context id for the current request, so in case of any troubles you may see the value in the response header and then filter the logs to see what the entries for that request are. Loggers \u00b6 You may create a logger in the following way: var logger = req . loggingContext . getLogger ( '/Application/Network' ); The log context has got the \"getLogger\" function that takes 1 string argument - the category. Categories are names of functional areas in an application. We recommend your categories to always begin with \"/Application\" . The categories form a hierarchy with forward slash as a separator. Using back slashes in categories is not allowed. You may always get the severity level (a string) of a logger with such code: var level = logger . getLevel (); It is also possible to check whether an entry with a specific severity level will be logged with the current level configuration: var willItBeLogged = logger . isEnabled ( 'info' ); Logging entries: logger . info ( 'Successful login of user %s - ' , user , new Date ()); logger . warning ( 'Job could not finish successfully. An app admin should retrigger it.' ); logger . error ( new Error ( 'Uups, an error has occurred' )); logger . fatal ( 'We are in trouble' ); You may use the same string interpolation mechanism as with util.format Logging errors: function callback ( err , result ) { if ( err ) { logger . error ( err , 'Error during operation X' ); } // ... } If the first argument is an error, its message is appended to the log message. Also, the error stack is written to the trace. This works for all severity levels and also with tracers. Tracers \u00b6 All you need to do to obtain a tracer instance is: var tracer = req . loggingContext . getTracer ( __filename ); Methods regarding level getting and checking are provided (similarly to loggers): var level = tracer . getLevel (); var willItBeTraced = tracer . isEnabled ( 'path' ); // etc. Custom Fields \u00b6 Note: This feature is available in Cloud Foundry and not in XS Advanced. \u00b6 If you want to use custom fields, you need to set them to the application context. The expected format is a string based array: appContext . setCustomFields ([ \"custom1\" , \"custom2\" ]); When logging, if the last argument is an object with a custom field, the custom field will be included in the log output as a custom field and not as part of the message: app . get ( '/' , function ( req , res ) { logger . info ( 'Let me say hi ...' ,{ \"abc\" : \"data\" }); // ... \"custom_fields\": {\"abc\": \"data\"} ... Convenient tracing methods \u00b6 Note : The first argument to all of these methods should be a string with the name of the function in which entries are being traced. There are several methods that the API provides for convenience (they use severity level path ): - entering - used to record that a function has been entered in the program flow. You may pass all of the arguments of your function to the entering function and they will be traced. - exiting - typically used in pair with the entering method. You may pass the return value of your function to the exiting function. function myFunction ( tracer , a , b , c ) { tracer . entering ( 'myFunction' , a , b , c ); var result = // some logic here ... tracer . exiting ( 'myFunction' , result ); return result ; } throwing - used when you would like to trace when the code is about to throw an error. You may pass the error that is about to be thrown as an argument. catching - used in catch blocks. You may pass the caught error as an argument. function func1 ( tracer ) { var error = new Error ( 'An error has occurred' ); tracer . throwing ( 'func1' , error ); throw err ; } function func2 ( tracer ) { try { func1 ( tracer ); } catch ( err ) { tracer . catching ( 'func2' , err ); // logic for processing the error } } Other \u00b6 The library supports SAP Passports. When a log context is created with a request object that has the sap-passport header, the unique identifiers of the received SAP Passport will be part of the log entries for ListLog format. Migration guide \u00b6 Guide on how to adopt new major versions of the library can be found here .","title":"Index"},{"location":"apis/logging/#saplogging","text":"A package that provides logging and tracing functionalities for Node.js applications. Example Logging & Tracing Categories & Locations Location values Wildcard support Formats Severity Levels XS_APP_LOG_LEVEL environment variable Changing severity levels for an application XS Advanced Cloud Foundry Logging sensitive data API Application context Log context Log context id Middleware Loggers Tracers Custom fields (in CF) Convenient tracing methods Other Migration guide","title":"@sap/logging"},{"location":"apis/logging/#example","text":"Following is an example of how to consume the package using express : var logging = require ( '@sap/logging' ); var express = require ( 'express' ); var app = express (); var appContext = logging . createAppContext (); app . use ( logging . middleware ({ appContext : appContext , logNetwork : true })); app . get ( '/demo' , function ( req , res ) { var logger = req . loggingContext . getLogger ( '/Application/Network' ); var tracer = req . loggingContext . getTracer ( __filename ); logger . info ( 'Retrieving demo greeting ...' ); tracer . info ( 'Processing GET request to /demo' ); res . send ( 'Hello World!' ); }); app . listen ( 3000 , function () { console . log ( 'Server started' ); }); In general, you just need to: - Initialize the logging library with some application-wide options. - Use the provided middleware that will extract request specific information. It is recommended that this middleware is the first one to be called in order to have the logging context available as early as possible. It is also recommended to have the middleware that sets the user of the request (if the application intends to log the current user) right after the one provided by this library. - Instantiate a logger and a tracer via the loggingContext property of the request. - Log and trace whatever you need. See more details below.","title":"Example"},{"location":"apis/logging/#logging-tracing","text":"Logs are addressed to an administrator of an application. Traces - to a developer or support staff. - Events that need to be logged are related to how the app operates - e.g. the app cannot display some results taken from a remote HTTP service because the remote server is down. An administrator of an app does not need to know how it is implemented, he/she should just be able to determine the state of the app itself. - Traces are mainly used when a problem has occurred and further investigation on code level has to take place. The logging library writes log entries to standard output and trace entries - to standard error.","title":"Logging &amp; Tracing"},{"location":"apis/logging/#categories-locations","text":"Categories - represent a feature area in an application. For example, different layers - Network layer, Database layer etc. The concept of categories is used in logging. Locations - represent a location in the source code - e.g. a path to a file. Used in the context of tracing. Getting a tracer object requires explicitly providing a location. It is recommended to pass as argument the location of the current script - __filename .","title":"Categories &amp; Locations"},{"location":"apis/logging/#location-values","text":"The path to the application root is removed from the source file paths in the trace output to reduce duplication. The application root directory is taken from the HOME environment variable. If it is not defined, absolute file paths are used in the trace output. Example: Let's assume the structure of your application looks like the following: +-- demo-app | +-- package.json | +-- lib | | +-- index.js | | +-- services | | | +-- customer-service.js | | | +-- sales-service.js Here is how the location of a script (path to a file) will look like in the trace entries (having in mind __filename has been passed as location to the tracer): Script HOME environment variable is set HOME environment variable is not set index.js /lib/index.js /path/from/root/demo-app/lib/index.js customer-service.js /lib/services/customer-service.js /path/from/root/demo-app/lib/services/customer-service.js The same applies to Windows systems as well. Note : The path separator in the trace entries is always a forward slash, no matter the platform.","title":"Location values"},{"location":"apis/logging/#wildcard-support","text":"The asterisk (*) is the only wildcard character supported by the library. It corresponds to zero or more characters (no matter what they are). Let's illustrate the wildcard usage using the example application structure from the previous section, assuming the HOME environment variable is set to the root of the application (as it would be on XS Advanced or Cloud Foundry): Pattern Result /Application/Network Match a certain Category /Application/Network/* Match all subcategories /lib/services/users-service.js Match a specific file /lib/services/* Match all files in all subdirectories of services","title":"Wildcard support"},{"location":"apis/logging/#formats","text":"ListLog format is used for logs in XS Advanced and during local development Trace format is used for traces in XS Advanced and during local development CF Log format is used for logs and traces in Cloud Foundry Note : Instead of thread-name (in ListLog and Trace formats), a context id is used. This is an identifier that helps to distinguish which entries are logged/traced because of which requests/events. More info on that is available in this section .","title":"Formats"},{"location":"apis/logging/#severity-levels","text":"The following table shows which severity levels are available for loggers and tracers: Logging Tracing debug path info info warning warning error error fatal fatal Here you can find when to use which level: Level When to use debug Used to output the internal status of a program. path Used to analyze the execution flow of a program. info Used for events that do not need any follow up activity. They show the normal operations within an app. warning Used for events that need follow up activity in order to prevent errors in the future. error Used when the desired tasks cannot be completed and the application is still usable. fatal Used in case of errors, because of which the application is no longer usable. The default severity level for loggers is info and the default one for tracers is error .","title":"Severity Levels"},{"location":"apis/logging/#xs_app_log_level-environment-variable","text":"The XS_APP_LOG_LEVEL environment variable can be used to configure severity levels for logging and tracing. Valid values are severity levels from debug to fatal . The level specified in this environment variable will be used instead of all already set levels. none is also a valid value for XS_APP_LOG_LEVEL . In that case all logging and tracing is disabled (useful for automated tests). The library throws an error if the value of XS_APP_LOG_LEVEL is not a valid severity level or none .","title":"XS_APP_LOG_LEVEL environment variable"},{"location":"apis/logging/#changing-severity-levels-for-an-application","text":"","title":"Changing severity levels for an application"},{"location":"apis/logging/#xs-advanced","text":"You can enable debug logs and traces for an application deployed on XS Advanced via the command: xs set-logging-level <application-name> \"*\" debug This can be reverted via the command: xs unset-logging-level <application-name> \"*\" Restart of the application is not required for those commands to take effect. The example above shows how to enable debug level for all loggers and tracers. It is possible to use the command for setting levels for a single category or location (e.g. xs set-logging-level <application-name> \"/index.js\" debug ), or multiple by using the asterisk wildcard (e.g. xs set-logging-level <application-name> \"/Application/Network/*\" debug ). The comparison with the actual category/location of a logger/tracer is executed in a case insensitive manner.","title":"XS Advanced"},{"location":"apis/logging/#cloud-foundry","text":"You can enable debug logs and traces for an application deployed on Cloud Foundry via setting the environment variable XS_APP_LOG_LEVEL : cf set-env <application-name> XS_APP_LOG_LEVEL debug This can be reverted via the command: cf unset-env <application-name> XS_APP_LOG_LEVEL Note : Application restart is required after each of the commands above in order the changes to the environment to take effect.","title":"Cloud Foundry"},{"location":"apis/logging/#logging-sensitive-data","text":"Logging sensitive data is not enabled by default. The following table shows which environment variable enables (when set to true ) which fields and for which formats: Environment Variable Field Taken from Format XS_LOG_USER user/remote_user req.user.id property ListLog, CF Log XS_LOG_REFERER referer referer request header CF Log XS_LOG_CONNECTION_DATA remote_ip, remote_host, remote_port, x_forwarded_for req.connection.remoteAddress property, req.connection.remotePort property, x-forwarded-for header CF Log","title":"Logging sensitive data"},{"location":"apis/logging/#api","text":"To consume the logging package, an application context needs to be created. It contains information that is valid for the whole application. Next a log context needs to be created. It contains information that is valid for the current context. A separate log context should be created for each new event (HTTP request received, job execution started, message from messaging service received). Because of the asynchronous nature of Node.js, entries produced during the processing of different events can be mixed. All entries contain information specific to the log context they are associated with, which helps to distinguish between entries produced during the processing of different events. Loggers and tracers are obtained from the log context.","title":"API"},{"location":"apis/logging/#application-context","text":"var logging = require ( '@sap/logging' ); var appContext = logging . createAppContext ({ // options }); To create the application context, pass some application-wide options. Here is a list of the properties you may optionally pass: Property Description csnComponent String Only applicable to SAP applications. You may use the application context to change severity levels (with wildcards for flexibility): appContext . setLevel ( '/Application/*' , 'warning' ); // for a logger appContext . setLevel ( pathToFile , 'debug' ); // for a tracer The method throws an error in case of an incorrect level. Severity levels can be unset with: appContext . unsetLevel ( '/Application/*' ); // for a logger appContext . unsetLevel ( pathToFile ); // for a tracer To set custom fields, you could do: appContext . setCustomFields ([ \"abc\" ]);","title":"Application context"},{"location":"apis/logging/#log-context","text":"appContext . createLogContext ({ // options }); A log context needs to be created in order to obtain a logger or a tracer. Here is a list of the options that can be provided to the log context (all are optional): Option Description id String Included in all logs and traces, should be unique. Used to distinguish entries from different log contexts. Defaults to an auto-generated value. If req is provided, the value is taken from the request headers x-request-id and x-vcap-request-id if present. It is recommended to explicitly pass an empty string for log contexts used during application startup. If req is present, then this id can be thought of as a request id, because all log/trace entries for that request will have the same id. See this section for more information. correlationId String Used to correlate entries for a logical transaction which involves processing within different applications. If the value is not set explicitly, then it is taken from the x-correlationid header (if req is provided and the header is present) or from the id of the log context. req Object Represents an HTTP request. The log context exposes the following functions: | Function | Description | | --------------- | ----------- | | getAppContext | AppConext object associated with this log context | The log context exposes the following read-only properties: Property Description id The id of the log context. correlationId The correlation id of the log context. This property is useful when the value needs to be sent to another application. Loggers and tracers can be obtained from the log context as follows: let logger = logContext . getLogger ( '/Application/Network' ); let tracer = logContext . getTracer ( __filename ); It is possible to log request metrics for an HTTP request using the enableNetworkLog method: logContext . enableNetworkLog ( res ); It takes a response object as argument. A req object needs to be passed in advance as option when creating the log context. This method registers a handler for the finish event of the HTTP response. An entry (of info severity level), containing request metrics will be logged when the event is emitted. enableNetworkLog should be called once for a request-response pair: http . createServer ( function ( req , res ) { var reqContext = appContext . createLogContext ({ req : req }); reqContext . enableNetworkLog ( res ); res . end ( 'Hello World' ); }); The log entry uses category /LoggingLibrary/NetworkLog . It can be used to turn off the network log at runtime with xs set-logging-level or with appContext.setLevel .","title":"Log context"},{"location":"apis/logging/#log-context-id","text":"Let's take HTTP requests as an example: Because of the single-threaded nature and the event loop mechanism in Node.js, you may: - receive a request - start some async I/O operation - in the meantime start processing another request before returning a response to the first one This means that the log entries for the two requests will be mixed a bit. To overcome this issue, each request (and the corresponding log context) is associated with a unique id which is present in the logs and traces for that request. In that way one can distinguish between the logs from the first request and the logs from the second request. The same concept applies to messages received from a messaging service and to job runs triggered according to a schedule.","title":"Log context id"},{"location":"apis/logging/#middleware","text":"There is a utility middleware that can be used (see this example ). It automatically attaches a property named \"loggingContext\" to the request object. It accepts an object with properties: Property Description appContext Mandatory An application context object. logNetwork Optional Defaults to false , boolean specifying whether an entry containing request metrics will be logged for every finished HTTP request. The middleware sets the x-request-id response header to the context id for the current request, so in case of any troubles you may see the value in the response header and then filter the logs to see what the entries for that request are.","title":"Middleware"},{"location":"apis/logging/#loggers","text":"You may create a logger in the following way: var logger = req . loggingContext . getLogger ( '/Application/Network' ); The log context has got the \"getLogger\" function that takes 1 string argument - the category. Categories are names of functional areas in an application. We recommend your categories to always begin with \"/Application\" . The categories form a hierarchy with forward slash as a separator. Using back slashes in categories is not allowed. You may always get the severity level (a string) of a logger with such code: var level = logger . getLevel (); It is also possible to check whether an entry with a specific severity level will be logged with the current level configuration: var willItBeLogged = logger . isEnabled ( 'info' ); Logging entries: logger . info ( 'Successful login of user %s - ' , user , new Date ()); logger . warning ( 'Job could not finish successfully. An app admin should retrigger it.' ); logger . error ( new Error ( 'Uups, an error has occurred' )); logger . fatal ( 'We are in trouble' ); You may use the same string interpolation mechanism as with util.format Logging errors: function callback ( err , result ) { if ( err ) { logger . error ( err , 'Error during operation X' ); } // ... } If the first argument is an error, its message is appended to the log message. Also, the error stack is written to the trace. This works for all severity levels and also with tracers.","title":"Loggers"},{"location":"apis/logging/#tracers","text":"All you need to do to obtain a tracer instance is: var tracer = req . loggingContext . getTracer ( __filename ); Methods regarding level getting and checking are provided (similarly to loggers): var level = tracer . getLevel (); var willItBeTraced = tracer . isEnabled ( 'path' ); // etc.","title":"Tracers"},{"location":"apis/logging/#custom-fields","text":"","title":"Custom Fields"},{"location":"apis/logging/#note-this-feature-is-available-in-cloud-foundry-and-not-in-xs-advanced","text":"If you want to use custom fields, you need to set them to the application context. The expected format is a string based array: appContext . setCustomFields ([ \"custom1\" , \"custom2\" ]); When logging, if the last argument is an object with a custom field, the custom field will be included in the log output as a custom field and not as part of the message: app . get ( '/' , function ( req , res ) { logger . info ( 'Let me say hi ...' ,{ \"abc\" : \"data\" }); // ... \"custom_fields\": {\"abc\": \"data\"} ...","title":"Note: This feature is available in Cloud Foundry and not in XS Advanced."},{"location":"apis/logging/#convenient-tracing-methods","text":"Note : The first argument to all of these methods should be a string with the name of the function in which entries are being traced. There are several methods that the API provides for convenience (they use severity level path ): - entering - used to record that a function has been entered in the program flow. You may pass all of the arguments of your function to the entering function and they will be traced. - exiting - typically used in pair with the entering method. You may pass the return value of your function to the exiting function. function myFunction ( tracer , a , b , c ) { tracer . entering ( 'myFunction' , a , b , c ); var result = // some logic here ... tracer . exiting ( 'myFunction' , result ); return result ; } throwing - used when you would like to trace when the code is about to throw an error. You may pass the error that is about to be thrown as an argument. catching - used in catch blocks. You may pass the caught error as an argument. function func1 ( tracer ) { var error = new Error ( 'An error has occurred' ); tracer . throwing ( 'func1' , error ); throw err ; } function func2 ( tracer ) { try { func1 ( tracer ); } catch ( err ) { tracer . catching ( 'func2' , err ); // logic for processing the error } }","title":"Convenient tracing methods"},{"location":"apis/logging/#other","text":"The library supports SAP Passports. When a log context is created with a request object that has the sap-passport header, the unique identifiers of the received SAP Passport will be part of the log entries for ListLog format.","title":"Other"},{"location":"apis/logging/#migration-guide","text":"Guide on how to adopt new major versions of the library can be found here .","title":"Migration guide"},{"location":"apis/logging/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 5.3.0 - 2020-04-14 \u00b6 Added \u00b6 Support for custom fields on Cloud Foundry platform 5.2.0 - 2020-01-08 \u00b6 Added \u00b6 Added organization_id and organization_name to the log output 5.1.0 - 2019-12-02 \u00b6 Added \u00b6 Node.js 12.x support. 5.0.2 - 2019-07-10 \u00b6 Fixed \u00b6 Update lodash dependency to v4.17.13. 5.0.1 - 2019-05-13 \u00b6 Fixed \u00b6 Update @sap/e2e-trace dependency to v2.0.0. 5.0.0 - 2019-05-02 \u00b6 Removed \u00b6 Node.js v4 support 4.1.0 - 2019-01-16 \u00b6 Added \u00b6 Support for Node.js 10 4.0.2 - 2018-09-16 \u00b6 Fixed \u00b6 Update lodash dependency to v4.17.11. 4.0.1 - 2018-09-04 \u00b6 Fixed \u00b6 logContext.id is used as a fallback value for correlation id if no other value is available. 4.0.0 - 2018-08-20 \u00b6 Removed \u00b6 Support for writing entries to files (the logLocation and traceLocation options are no longer taken into account). The STORAGE property exposed by the library. Node 0.12 support. Coloring when writing to console. ApplicationContext.prototype.createRequestContext . Changed \u00b6 The exposed middleware can be consumed via the middleware property instead of expressMiddleware . Back slashes cannot be used in category names. middleware does not take an application context, but an object with an appContext property and optionally - a logNetwork property. x-correlationid header is no longer taken into account when resolving request id. An error is thrown if the level set through the XS_APP_LOG_LEVEL environment variable is not valid. Added \u00b6 Performance improvements. Support for CF Log format. Possibility to explicitly set correlation id via JavaScript API. Correlation id (if present) will be set to ListLog entries as well. AppContext.prototype.createLogContext . LogContext.prototype.enableNetworkLog . 3.4.0 - 2018-04-26 \u00b6 Added \u00b6 Possibility to enable logging of the current user via the XS_LOG_USER environment variable. From this version onwards the user is not being logged by default. 3.3.2 - 2018-04-05 \u00b6 Fixed \u00b6 Update dependencies. Unsetting tracer locations. tracer.exiting when the argument for the return value of the function is falsy. 3.3.1 - 2018-02-05 \u00b6 Fixed \u00b6 Replace new lines in traces when running on XS Advanced. Replace new lines in logs when running on XS Advanced. 3.3.0 - 2018-01-19 \u00b6 Added \u00b6 npm-shrinkwrap.json 3.2.1 - 2017-12-01 \u00b6 Fixed \u00b6 Update momentjs to 2.19.3 3.2.0 - 2017-11-23 \u00b6 Added \u00b6 The request id can be taken from the request headers 'x-request-id', 'x-correlationid', 'x-vcap-request-id' (if available). The request id is exposed through the requestId property of the request context. Improvements to the documentation. Fixed \u00b6 Handling of tracer locations. Process does not exit even if there is no other activity keeping the event loop running. 3.1.0 - 2017-08-14 \u00b6 Added \u00b6 Support for Node.js v8. Performance improvements in tracing. 3.0.0 - 2017-04-12 \u00b6 Changed \u00b6 Automatic location tracking for tracers has been removed due to severe performance impact. This affects application code as follows: A location (path to a file) needs to be explicitly passed to the getTracer functions as first argument. Passing __filename as a location is recommended. A tracer is no longer associated with the script it is currently being used in, but with the location provided for its instantiation. A function name (a string) should be passed as a first argument to the entering , exiting , throwing and catching methods of tracers. 2.2.0 - 2017-02-07 \u00b6 Fixed \u00b6 support for the 'xs unset-logging-level' command Added \u00b6 'unsetLevel' method on application level contexts 2.1.2 - 2017-01-24 \u00b6 Fixed \u00b6 Minor improvements 2.1.1 - 2017-01-24 \u00b6 Changed \u00b6 Rename package to use @sap scope 2.1.0 - 2017-01-09 \u00b6 Added \u00b6 Log session id when available. 2.0.3 - 2016-12-01 \u00b6 Fixed \u00b6 Minor fixes. 2.0.2 - 2016-11-08 \u00b6 Fixed \u00b6 Minor fixes. 2.0.1 - 2016-11-08 \u00b6 Fixed \u00b6 Minor fixes. 2.0.0 - 2016-10-25 \u00b6 Changed \u00b6 By default logs and traces are written to standard output and standard error respectively. Fixed \u00b6 Replace new lines in logs. Removed \u00b6 The package no longer fallbacks to the environment variables XS_APPLICATION_LOG_FILE and XS_TRACE_FILE .","title":"Change Log"},{"location":"apis/logging/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/logging/CHANGELOG/#530-2020-04-14","text":"","title":"5.3.0 - 2020-04-14"},{"location":"apis/logging/CHANGELOG/#added","text":"Support for custom fields on Cloud Foundry platform","title":"Added"},{"location":"apis/logging/CHANGELOG/#520-2020-01-08","text":"","title":"5.2.0 - 2020-01-08"},{"location":"apis/logging/CHANGELOG/#added_1","text":"Added organization_id and organization_name to the log output","title":"Added"},{"location":"apis/logging/CHANGELOG/#510-2019-12-02","text":"","title":"5.1.0 - 2019-12-02"},{"location":"apis/logging/CHANGELOG/#added_2","text":"Node.js 12.x support.","title":"Added"},{"location":"apis/logging/CHANGELOG/#502-2019-07-10","text":"","title":"5.0.2 - 2019-07-10"},{"location":"apis/logging/CHANGELOG/#fixed","text":"Update lodash dependency to v4.17.13.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#501-2019-05-13","text":"","title":"5.0.1 - 2019-05-13"},{"location":"apis/logging/CHANGELOG/#fixed_1","text":"Update @sap/e2e-trace dependency to v2.0.0.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#500-2019-05-02","text":"","title":"5.0.0 - 2019-05-02"},{"location":"apis/logging/CHANGELOG/#removed","text":"Node.js v4 support","title":"Removed"},{"location":"apis/logging/CHANGELOG/#410-2019-01-16","text":"","title":"4.1.0 - 2019-01-16"},{"location":"apis/logging/CHANGELOG/#added_3","text":"Support for Node.js 10","title":"Added"},{"location":"apis/logging/CHANGELOG/#402-2018-09-16","text":"","title":"4.0.2 - 2018-09-16"},{"location":"apis/logging/CHANGELOG/#fixed_2","text":"Update lodash dependency to v4.17.11.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#401-2018-09-04","text":"","title":"4.0.1 - 2018-09-04"},{"location":"apis/logging/CHANGELOG/#fixed_3","text":"logContext.id is used as a fallback value for correlation id if no other value is available.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#400-2018-08-20","text":"","title":"4.0.0 - 2018-08-20"},{"location":"apis/logging/CHANGELOG/#removed_1","text":"Support for writing entries to files (the logLocation and traceLocation options are no longer taken into account). The STORAGE property exposed by the library. Node 0.12 support. Coloring when writing to console. ApplicationContext.prototype.createRequestContext .","title":"Removed"},{"location":"apis/logging/CHANGELOG/#changed","text":"The exposed middleware can be consumed via the middleware property instead of expressMiddleware . Back slashes cannot be used in category names. middleware does not take an application context, but an object with an appContext property and optionally - a logNetwork property. x-correlationid header is no longer taken into account when resolving request id. An error is thrown if the level set through the XS_APP_LOG_LEVEL environment variable is not valid.","title":"Changed"},{"location":"apis/logging/CHANGELOG/#added_4","text":"Performance improvements. Support for CF Log format. Possibility to explicitly set correlation id via JavaScript API. Correlation id (if present) will be set to ListLog entries as well. AppContext.prototype.createLogContext . LogContext.prototype.enableNetworkLog .","title":"Added"},{"location":"apis/logging/CHANGELOG/#340-2018-04-26","text":"","title":"3.4.0 - 2018-04-26"},{"location":"apis/logging/CHANGELOG/#added_5","text":"Possibility to enable logging of the current user via the XS_LOG_USER environment variable. From this version onwards the user is not being logged by default.","title":"Added"},{"location":"apis/logging/CHANGELOG/#332-2018-04-05","text":"","title":"3.3.2 - 2018-04-05"},{"location":"apis/logging/CHANGELOG/#fixed_4","text":"Update dependencies. Unsetting tracer locations. tracer.exiting when the argument for the return value of the function is falsy.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#331-2018-02-05","text":"","title":"3.3.1 - 2018-02-05"},{"location":"apis/logging/CHANGELOG/#fixed_5","text":"Replace new lines in traces when running on XS Advanced. Replace new lines in logs when running on XS Advanced.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#330-2018-01-19","text":"","title":"3.3.0 - 2018-01-19"},{"location":"apis/logging/CHANGELOG/#added_6","text":"npm-shrinkwrap.json","title":"Added"},{"location":"apis/logging/CHANGELOG/#321-2017-12-01","text":"","title":"3.2.1 - 2017-12-01"},{"location":"apis/logging/CHANGELOG/#fixed_6","text":"Update momentjs to 2.19.3","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#320-2017-11-23","text":"","title":"3.2.0 - 2017-11-23"},{"location":"apis/logging/CHANGELOG/#added_7","text":"The request id can be taken from the request headers 'x-request-id', 'x-correlationid', 'x-vcap-request-id' (if available). The request id is exposed through the requestId property of the request context. Improvements to the documentation.","title":"Added"},{"location":"apis/logging/CHANGELOG/#fixed_7","text":"Handling of tracer locations. Process does not exit even if there is no other activity keeping the event loop running.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#310-2017-08-14","text":"","title":"3.1.0 - 2017-08-14"},{"location":"apis/logging/CHANGELOG/#added_8","text":"Support for Node.js v8. Performance improvements in tracing.","title":"Added"},{"location":"apis/logging/CHANGELOG/#300-2017-04-12","text":"","title":"3.0.0 - 2017-04-12"},{"location":"apis/logging/CHANGELOG/#changed_1","text":"Automatic location tracking for tracers has been removed due to severe performance impact. This affects application code as follows: A location (path to a file) needs to be explicitly passed to the getTracer functions as first argument. Passing __filename as a location is recommended. A tracer is no longer associated with the script it is currently being used in, but with the location provided for its instantiation. A function name (a string) should be passed as a first argument to the entering , exiting , throwing and catching methods of tracers.","title":"Changed"},{"location":"apis/logging/CHANGELOG/#220-2017-02-07","text":"","title":"2.2.0 - 2017-02-07"},{"location":"apis/logging/CHANGELOG/#fixed_8","text":"support for the 'xs unset-logging-level' command","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#added_9","text":"'unsetLevel' method on application level contexts","title":"Added"},{"location":"apis/logging/CHANGELOG/#212-2017-01-24","text":"","title":"2.1.2 - 2017-01-24"},{"location":"apis/logging/CHANGELOG/#fixed_9","text":"Minor improvements","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#211-2017-01-24","text":"","title":"2.1.1 - 2017-01-24"},{"location":"apis/logging/CHANGELOG/#changed_2","text":"Rename package to use @sap scope","title":"Changed"},{"location":"apis/logging/CHANGELOG/#210-2017-01-09","text":"","title":"2.1.0 - 2017-01-09"},{"location":"apis/logging/CHANGELOG/#added_10","text":"Log session id when available.","title":"Added"},{"location":"apis/logging/CHANGELOG/#203-2016-12-01","text":"","title":"2.0.3 - 2016-12-01"},{"location":"apis/logging/CHANGELOG/#fixed_10","text":"Minor fixes.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#202-2016-11-08","text":"","title":"2.0.2 - 2016-11-08"},{"location":"apis/logging/CHANGELOG/#fixed_11","text":"Minor fixes.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#201-2016-11-08","text":"","title":"2.0.1 - 2016-11-08"},{"location":"apis/logging/CHANGELOG/#fixed_12","text":"Minor fixes.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#200-2016-10-25","text":"","title":"2.0.0 - 2016-10-25"},{"location":"apis/logging/CHANGELOG/#changed_3","text":"By default logs and traces are written to standard output and standard error respectively.","title":"Changed"},{"location":"apis/logging/CHANGELOG/#fixed_13","text":"Replace new lines in logs.","title":"Fixed"},{"location":"apis/logging/CHANGELOG/#removed_2","text":"The package no longer fallbacks to the environment variables XS_APPLICATION_LOG_FILE and XS_TRACE_FILE .","title":"Removed"},{"location":"apis/logging/migration/","text":"Migration Guide \u00b6 Version 3 ==> Version 4 \u00b6 Changes to application code \u00b6 Application context \u00b6 logLocation and traceLocation are no longer considered. The library writes entries to standard output and to standard error only. This makes providing these options unnecessary: var logging = require ( '@sap/logging' ); var appContext = logging . createAppContext ({ // these options are unnecessary in version 4 logLocation : logging . STORAGE . CONSOLE , traceLocation : 'path-to-file' }); Middleware \u00b6 Code like: var logging = require ( '@sap/logging' ); var appContext = logging . createAppContext (); // ... app . use ( logging . expressMiddleware ( appContext )); should be transformed to: const logging = require ( '@sap/logging' ); const appContext = logging . createAppContext (); // ... app . use ( logging . middleware ({ appContext : appContext })); Loggers and tracers from application context \u00b6 Code like: appContext . getLogger ( '/Application/Category' ); // or appContext . getTracer ( __filename ); should be transformed to one of the following variants: when getting a logger/tracer when a message from messaging service is received or a job run is triggered: appContext . createLogContext (). getLogger ( '/Application/Category' ); // or appContext . createLogContext (). getTracer ( __filename ); With the snippet above, the context id will be auto-generated. It is still possible to provide a custom value. when getting a logger/tracer for logging/tracing purposes during application startup: appContext . createLogContext ({ id : '' }). getLogger ( '/Application/Category' ); // or appContext . createLogContext ({ id : '' }). getTracer ( __filename ); Note : The context id defaults to an auto-generated value. Therefore, it is recommended to explicitly pass an empty string as id for the log context used on application startup to distinguish these entries from entries produced during job runs or during the processing of other events more easily. Loggers and tracers from request context \u00b6 Code like: appContext . createRequestContext ( req ). getLogger ( '/Application/Category' ); // or appContext . createRequestContext ( req ). getTracer ( __filename ); should be transformed to: appContext . createLogContext ({ req }). getLogger ( '/Application/Category' ); // or appContext . createLogContext ({ req }). getTracer ( __filename ); Request id \u00b6 Code like: appContext . createRequestContext ( req ). requestId should be transformed to: appContext . createLogContext ({ req }). id","title":"Migration Guide"},{"location":"apis/logging/migration/#migration-guide","text":"","title":"Migration Guide"},{"location":"apis/logging/migration/#version-3-version-4","text":"","title":"Version 3 ==&gt; Version 4"},{"location":"apis/logging/migration/#changes-to-application-code","text":"","title":"Changes to application code"},{"location":"apis/logging/migration/#application-context","text":"logLocation and traceLocation are no longer considered. The library writes entries to standard output and to standard error only. This makes providing these options unnecessary: var logging = require ( '@sap/logging' ); var appContext = logging . createAppContext ({ // these options are unnecessary in version 4 logLocation : logging . STORAGE . CONSOLE , traceLocation : 'path-to-file' });","title":"Application context"},{"location":"apis/logging/migration/#middleware","text":"Code like: var logging = require ( '@sap/logging' ); var appContext = logging . createAppContext (); // ... app . use ( logging . expressMiddleware ( appContext )); should be transformed to: const logging = require ( '@sap/logging' ); const appContext = logging . createAppContext (); // ... app . use ( logging . middleware ({ appContext : appContext }));","title":"Middleware"},{"location":"apis/logging/migration/#loggers-and-tracers-from-application-context","text":"Code like: appContext . getLogger ( '/Application/Category' ); // or appContext . getTracer ( __filename ); should be transformed to one of the following variants: when getting a logger/tracer when a message from messaging service is received or a job run is triggered: appContext . createLogContext (). getLogger ( '/Application/Category' ); // or appContext . createLogContext (). getTracer ( __filename ); With the snippet above, the context id will be auto-generated. It is still possible to provide a custom value. when getting a logger/tracer for logging/tracing purposes during application startup: appContext . createLogContext ({ id : '' }). getLogger ( '/Application/Category' ); // or appContext . createLogContext ({ id : '' }). getTracer ( __filename ); Note : The context id defaults to an auto-generated value. Therefore, it is recommended to explicitly pass an empty string as id for the log context used on application startup to distinguish these entries from entries produced during job runs or during the processing of other events more easily.","title":"Loggers and tracers from application context"},{"location":"apis/logging/migration/#loggers-and-tracers-from-request-context","text":"Code like: appContext . createRequestContext ( req ). getLogger ( '/Application/Category' ); // or appContext . createRequestContext ( req ). getTracer ( __filename ); should be transformed to: appContext . createLogContext ({ req }). getLogger ( '/Application/Category' ); // or appContext . createLogContext ({ req }). getTracer ( __filename );","title":"Loggers and tracers from request context"},{"location":"apis/logging/migration/#request-id","text":"Code like: appContext . createRequestContext ( req ). requestId should be transformed to: appContext . createLogContext ({ req }). id","title":"Request id"},{"location":"apis/node-jwt/","text":"@sap/node-jwt \u00b6 JSON Web Token (JWT) offline validation for Node with current binaries This project contains the JWT binding for Node.js. It also includes the native libraries to run on Windows/Linux. If you need another platforms, please write to the author. Platforms \u00b6 Supported platforms: Windows | Linux | MacOS Supported architectures: x64 on supported platforms. Please see also section dependencies for Node.js version. Hello world \u00b6 This standard example is from http://jwt.io // you can either load a HMAC key for signatures with HSxxx v . setSecret ( \"secret\" ); // load HMAC key v . setBase64Secret ( \"c2VjcmV0\" ); // load a Base64 encoded HMAC key // or you can load a PEM encoded X509 certificate for signatures with RSxxx v . loadPEM ( \"MIICozCCAYsCCAogFQcmCUcJMA0GCSqGSIb3DQEBCwUAMBQ....\" ); // load X509 public certificate OR public key for RSA signature validation // check the token signature and validity v . checkToken ( \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\" ); console . log ( \"Test JWT for Node.js\" ); if ( v . getErrorDescription () !== \"\" ) { // error handling console . log ( \"Error in JWT: \" + v . getErrorDescription ()); } else { // in case of success, retrieve the payload console . log ( \"JWT Payload : \" + v . getPayload ()); } Getting started \u00b6 From your project directory, run (see below for requirements): $ var jwt = require ( '@sap/node-jwt' ) ; Released versions npm config set @sap:registry=https://npm.sap.com npm install @sap/node-jwt Dependencies \u00b6 NodeJS v0.10.x is the minimum version. The maximum version is always the last LTS (long term support, https://nodejs.org/en/about/releases/) , however due to missing binaries, there might be errors in using this project You dont need node-gyp or any compiler (e.g. Visual Studio on Windows). The source code and binding.gyp is part of this project in case of errors. If you run in error with generic node exceptions, please inform the author. The root cause can be missing jwt.node modules. Error situations \u00b6 The standard error for signature operations is the situation, that the signature is not valid. This error is typical and you should handle it carefully! and not as fatal error or assert. If you think, it must work, but it does not, then you can trace the native functions. SAPSSOEXT library allows you to set the environment variables: * SAP_EXT_TRC to define a trace file in your file system * SAP_EXT_TRL an integer 0 to 3 set SAP_EXT_TRC=stdout set SAP_EXT_TRL=3 If you run your application in CloudFoundry or XSA then you can define environment variables with client command tool cf / xs, see https://docs.run.pivotal.io/devguide/deploy-apps/manifest.html#env-block In cf landscapes you can then cf logs and you will see trace from JWT validation Install via NPM \u00b6 In order to configure the sap NPM registry you need to issue the following command: npm config set @sap:registry=https://npm.sap.com npm install @sap/node-jwt","title":"Index"},{"location":"apis/node-jwt/#sapnode-jwt","text":"JSON Web Token (JWT) offline validation for Node with current binaries This project contains the JWT binding for Node.js. It also includes the native libraries to run on Windows/Linux. If you need another platforms, please write to the author.","title":"@sap/node-jwt"},{"location":"apis/node-jwt/#platforms","text":"Supported platforms: Windows | Linux | MacOS Supported architectures: x64 on supported platforms. Please see also section dependencies for Node.js version.","title":"Platforms"},{"location":"apis/node-jwt/#hello-world","text":"This standard example is from http://jwt.io // you can either load a HMAC key for signatures with HSxxx v . setSecret ( \"secret\" ); // load HMAC key v . setBase64Secret ( \"c2VjcmV0\" ); // load a Base64 encoded HMAC key // or you can load a PEM encoded X509 certificate for signatures with RSxxx v . loadPEM ( \"MIICozCCAYsCCAogFQcmCUcJMA0GCSqGSIb3DQEBCwUAMBQ....\" ); // load X509 public certificate OR public key for RSA signature validation // check the token signature and validity v . checkToken ( \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\" ); console . log ( \"Test JWT for Node.js\" ); if ( v . getErrorDescription () !== \"\" ) { // error handling console . log ( \"Error in JWT: \" + v . getErrorDescription ()); } else { // in case of success, retrieve the payload console . log ( \"JWT Payload : \" + v . getPayload ()); }","title":"Hello world"},{"location":"apis/node-jwt/#getting-started","text":"From your project directory, run (see below for requirements): $ var jwt = require ( '@sap/node-jwt' ) ; Released versions npm config set @sap:registry=https://npm.sap.com npm install @sap/node-jwt","title":"Getting started"},{"location":"apis/node-jwt/#dependencies","text":"NodeJS v0.10.x is the minimum version. The maximum version is always the last LTS (long term support, https://nodejs.org/en/about/releases/) , however due to missing binaries, there might be errors in using this project You dont need node-gyp or any compiler (e.g. Visual Studio on Windows). The source code and binding.gyp is part of this project in case of errors. If you run in error with generic node exceptions, please inform the author. The root cause can be missing jwt.node modules.","title":"Dependencies"},{"location":"apis/node-jwt/#error-situations","text":"The standard error for signature operations is the situation, that the signature is not valid. This error is typical and you should handle it carefully! and not as fatal error or assert. If you think, it must work, but it does not, then you can trace the native functions. SAPSSOEXT library allows you to set the environment variables: * SAP_EXT_TRC to define a trace file in your file system * SAP_EXT_TRL an integer 0 to 3 set SAP_EXT_TRC=stdout set SAP_EXT_TRL=3 If you run your application in CloudFoundry or XSA then you can define environment variables with client command tool cf / xs, see https://docs.run.pivotal.io/devguide/deploy-apps/manifest.html#env-block In cf landscapes you can then cf logs and you will see trace from JWT validation","title":"Error situations"},{"location":"apis/node-jwt/#install-via-npm","text":"In order to configure the sap NPM registry you need to issue the following command: npm config set @sap:registry=https://npm.sap.com npm install @sap/node-jwt","title":"Install via NPM"},{"location":"apis/node-vsi/","text":"@sap/node-vsi \u00b6 This project contains the VSI binding for node.js. It also includes the native libraries to run on Windows/Linux. If you need another platforms, please create a SAP support ticket to BC-SEC. Installation \u00b6 The module has moved to sap-internal npm registry. Ultimately all SAP modules will be there soon. Requests for opensource modules will be proxied to the official npmjs.org registry. In order to configure the sap-internal registry you need to issue the following command: npm config set @sap:registry=https://npm.sap.com npm install @sap/node-vsi Afterwards you can add the module \"sap-node-vsi\" to the dependencies section of your package.json. Platforms \u00b6 Supported platforms: Windows | Linux | MacOS Hello world \u00b6 This standard example uses the eicar from www.eicar.org which all AV scanners has to find and detect as test virus. var vsi = require ( '@sap/node-vsi' ); var vsiProfile = vsi . vsiProfile ; var v = new vsiProfile ( \"\" ); v . scanBytes ( \"eicar.txt\" , \"X5O!P%@AP[4\\\\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*\" , 68 ); console . log ( \"\\nResult of eicar scan is rc \" + v . getLastErrorCode () + \" (\" + v . getScanErrorName () + \") with error message: \\n\" + v . getLastError () + \"\\n\" ); Getting started \u00b6 From your project directory, run (see below for requirements): $ var vsi = require ( '@sap/node-vsi' ) ;","title":"Index"},{"location":"apis/node-vsi/#sapnode-vsi","text":"This project contains the VSI binding for node.js. It also includes the native libraries to run on Windows/Linux. If you need another platforms, please create a SAP support ticket to BC-SEC.","title":"@sap/node-vsi"},{"location":"apis/node-vsi/#installation","text":"The module has moved to sap-internal npm registry. Ultimately all SAP modules will be there soon. Requests for opensource modules will be proxied to the official npmjs.org registry. In order to configure the sap-internal registry you need to issue the following command: npm config set @sap:registry=https://npm.sap.com npm install @sap/node-vsi Afterwards you can add the module \"sap-node-vsi\" to the dependencies section of your package.json.","title":"Installation"},{"location":"apis/node-vsi/#platforms","text":"Supported platforms: Windows | Linux | MacOS","title":"Platforms"},{"location":"apis/node-vsi/#hello-world","text":"This standard example uses the eicar from www.eicar.org which all AV scanners has to find and detect as test virus. var vsi = require ( '@sap/node-vsi' ); var vsiProfile = vsi . vsiProfile ; var v = new vsiProfile ( \"\" ); v . scanBytes ( \"eicar.txt\" , \"X5O!P%@AP[4\\\\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*\" , 68 ); console . log ( \"\\nResult of eicar scan is rc \" + v . getLastErrorCode () + \" (\" + v . getScanErrorName () + \") with error message: \\n\" + v . getLastError () + \"\\n\" );","title":"Hello world"},{"location":"apis/node-vsi/#getting-started","text":"From your project directory, run (see below for requirements): $ var vsi = require ( '@sap/node-vsi' ) ;","title":"Getting started"},{"location":"apis/odata-server/","text":"OData V4.0 Server Library \u00b6 Table of Contents \u00b6 Overview Installation Usage Supported Requests Releases and Milestones Overview \u00b6 With the OData server library OData V4.0 services can be implemented based on the OASIS OData standard . The library can be directly used to build OData services and is also part of the SAP Fiori programming model as well the SAP Cloud Platform programming model, where the data model can be defined in CDS (Core data services) and the OData service be generated out of the model. The library leaves the freedom to build OData services with any database or persistence layer. It is also possible to create services that are calling external REST/OData services and mix up the data with your application data. The library is modular and consists of the following main components: EntityDataModel - Define your EDM in JSON format. Our provider creates the EDM out of your model and caches EDM model elements Handler Dispatcher - Maps requests to handler functions for CRUD operations URI parsers - Parse the request URI including the OData system query options (like $format, $select, $expand, ...) and validates each URI segment against the EDM model and the OData ABNF Serializers and Deserializers for the request and response payload. The deserializers validate the request payload and support type mapping between OData EDM types and JavaScript Types Automatic OData Reponse generation based on provided data ServiceFactory to create the OData service along with the CRUD handler registration Conditional request handling for optimistic concurrency control via ETags Batch handling - Batch request parsing, dispatching to single batch requests, Content-ID referencing and batch response generation Flexible API to support all backends - The service developer has the free choice of his backend system (e.g., databases, frameworks, calling additional external OData services). Installation \u00b6 npm install @sap/odata-server Usage \u00b6 Load the library: const odata = require ( '@sap/odata-server' ); Load your EDM model: const edmModel = require ( './<your_edm_model>.json' ); Create the service, set the base path, and register request handlers for CRUD operations: const service = odata . ServiceFactory . createService ( edmModel ) . setBasePath ( '/serviceroot.svc/' ) . on ( 'create' , function create ( request , response , next ) {...}) . on ( 'update' , function update ( request , response , next ) {...}) . on ( 'delete' , function delete ( request , response , next ) {...}) . on ( 'read' , function read ( request , response , next ) {...}); You can create an HTTP server locally to test your service: const http = require ( 'http' ); const port = 9000 ; const server = http . createServer (( req , res ) => service . process ( req , res )) . listen ( port , () => console . log ( 'Server listens on port ' + port + ' - ' + 'Service URL: http://localhost:' + port + '/serviceroot.svc/' )); Supported Requests \u00b6 Read Requests Using HTTP GET \u00b6 Resource Request Service root GET http://host/serviceRoot/ Metadata GET http://host/serviceRoot/metadata EntitySet GET http://host/serviceRoot/EntitySet EntitySet GET http://host/serviceRoot/EntitySet/$count Entity GET http://host/serviceRoot/EntitySet(Key) References GET http://host/serviceRoot/EntitySet/$ref Reference GET http://host/serviceRoot/EntitySet(Key)/$ref References (related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Reference (related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Related entity GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne Related entities GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany Complex property GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex property collection GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive property GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive property value GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive property collection GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Create/Insert Requests Using HTTP POST \u00b6 Resource Request Entity POST http://host/serviceRoot/EntitySet Deep insert POST http://host/serviceRoot/EntitySet Entity with bind operations POST http://host/serviceRoot/EntitySet Reference POST http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Update Requests Using HTTP PUT/PATCH \u00b6 Resource Request Entity PUT/PATCH http://host/serviceRoot/EntitySet(Key) Deep update PUT/PATCH http://host/serviceRoot/EntitySet(Key) Reference PUT http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Complex property PUT/PATCH http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex property collection PUT http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive property PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive property value PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive property collection PUT http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Delete Requests Using HTTP DELETE \u00b6 Resource Request Entity DELETE http://host/serviceRoot/EntitySet(Key) Reference DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Reference (to many) DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany(Key)/$ref Complex property DELETE http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex property collection DELETE http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive property DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive property value DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive property collection DELETE http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Functions Using HTTP GET \u00b6 Resource Request Function import GET http://host/serviceRoot/FunctionImport/[Navigation-or-Property-Path] boundFunction GET http://host/serviceRoot/EntitySet/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundFunction Actions Using HTTP POST \u00b6 Resource Request Action import POST http://host/serviceRoot/ActionImport boundAction POST http://host/serviceRoot/EntitySet/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundAction Supported System Query Options \u00b6 System Query Option OASIS OData V4.0 Errata 3 - Query Option Description $filter Supported values see OASIS specification $expand Supported values see OASIS specification $select Supported values see OASIS specification $orderby Supported values see OASIS specification $top and $skip Supported values see OASIS specification $count Supported values see OASIS specification $search Supported values see OASIS specification $format Supported values see OASIS specification Analytical Queries \u00b6 Analytical queries with $apply are described in the specification for the OData data aggregration extension. Transformation Sample Limitations aggregate GET ~/Sales?$apply=aggregate(Amount with sum as Total) Keyword 'from' is not supported topcount GET ~/Sales?$apply=topcount(2,Amount) topsum GET ~/Sales?$apply=topsum(15,Amount) toppercent GET ~/Sales?$apply=toppercent(50,Amount) bottomcount GET ~/Sales?$apply=bottomcount(2,Amount) bottomsum GET ~/Sales?$apply=bottomsum(7,Amount) bottompercent GET ~/Sales?$apply=bottompercent(50,Amount) identity GET ~/Sales?$apply=identity concat GET ~/Sales?$apply=concat(topcount(2,Amount),aggregate(Amount)) groupby GET ~/Sales?$apply=groupby((Customer/Country,Product/Name), aggregate(Amount with sum as Total)) rollup and $all is not supported compute GET ~/Customers?$apply=compute(length(Country) as Length) filter GET ~/Sales?$apply=filter(Amount gt 3) orderby GET ~/Sales?$apply=orderby(Customer/Name) expand Not supported search GET ~/Sales?$apply=search(coffee) skip GET ~/Sales?$apply=skip(5) top GET ~/Sales?$apply=top(4) Releases and Milestones \u00b6 Changelog","title":"Index"},{"location":"apis/odata-server/#odata-v40-server-library","text":"","title":"OData V4.0 Server Library"},{"location":"apis/odata-server/#table-of-contents","text":"Overview Installation Usage Supported Requests Releases and Milestones","title":"Table of Contents"},{"location":"apis/odata-server/#overview","text":"With the OData server library OData V4.0 services can be implemented based on the OASIS OData standard . The library can be directly used to build OData services and is also part of the SAP Fiori programming model as well the SAP Cloud Platform programming model, where the data model can be defined in CDS (Core data services) and the OData service be generated out of the model. The library leaves the freedom to build OData services with any database or persistence layer. It is also possible to create services that are calling external REST/OData services and mix up the data with your application data. The library is modular and consists of the following main components: EntityDataModel - Define your EDM in JSON format. Our provider creates the EDM out of your model and caches EDM model elements Handler Dispatcher - Maps requests to handler functions for CRUD operations URI parsers - Parse the request URI including the OData system query options (like $format, $select, $expand, ...) and validates each URI segment against the EDM model and the OData ABNF Serializers and Deserializers for the request and response payload. The deserializers validate the request payload and support type mapping between OData EDM types and JavaScript Types Automatic OData Reponse generation based on provided data ServiceFactory to create the OData service along with the CRUD handler registration Conditional request handling for optimistic concurrency control via ETags Batch handling - Batch request parsing, dispatching to single batch requests, Content-ID referencing and batch response generation Flexible API to support all backends - The service developer has the free choice of his backend system (e.g., databases, frameworks, calling additional external OData services).","title":"Overview"},{"location":"apis/odata-server/#installation","text":"npm install @sap/odata-server","title":"Installation"},{"location":"apis/odata-server/#usage","text":"Load the library: const odata = require ( '@sap/odata-server' ); Load your EDM model: const edmModel = require ( './<your_edm_model>.json' ); Create the service, set the base path, and register request handlers for CRUD operations: const service = odata . ServiceFactory . createService ( edmModel ) . setBasePath ( '/serviceroot.svc/' ) . on ( 'create' , function create ( request , response , next ) {...}) . on ( 'update' , function update ( request , response , next ) {...}) . on ( 'delete' , function delete ( request , response , next ) {...}) . on ( 'read' , function read ( request , response , next ) {...}); You can create an HTTP server locally to test your service: const http = require ( 'http' ); const port = 9000 ; const server = http . createServer (( req , res ) => service . process ( req , res )) . listen ( port , () => console . log ( 'Server listens on port ' + port + ' - ' + 'Service URL: http://localhost:' + port + '/serviceroot.svc/' ));","title":"Usage"},{"location":"apis/odata-server/#supported-requests","text":"","title":"Supported Requests"},{"location":"apis/odata-server/#read-requests-using-http-get","text":"Resource Request Service root GET http://host/serviceRoot/ Metadata GET http://host/serviceRoot/metadata EntitySet GET http://host/serviceRoot/EntitySet EntitySet GET http://host/serviceRoot/EntitySet/$count Entity GET http://host/serviceRoot/EntitySet(Key) References GET http://host/serviceRoot/EntitySet/$ref Reference GET http://host/serviceRoot/EntitySet(Key)/$ref References (related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Reference (related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Related entity GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne Related entities GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany Complex property GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex property collection GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive property GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive property value GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive property collection GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection","title":"Read Requests Using HTTP GET"},{"location":"apis/odata-server/#createinsert-requests-using-http-post","text":"Resource Request Entity POST http://host/serviceRoot/EntitySet Deep insert POST http://host/serviceRoot/EntitySet Entity with bind operations POST http://host/serviceRoot/EntitySet Reference POST http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref","title":"Create/Insert Requests Using HTTP POST"},{"location":"apis/odata-server/#update-requests-using-http-putpatch","text":"Resource Request Entity PUT/PATCH http://host/serviceRoot/EntitySet(Key) Deep update PUT/PATCH http://host/serviceRoot/EntitySet(Key) Reference PUT http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Complex property PUT/PATCH http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex property collection PUT http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive property PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive property value PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive property collection PUT http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection","title":"Update Requests Using HTTP PUT/PATCH"},{"location":"apis/odata-server/#delete-requests-using-http-delete","text":"Resource Request Entity DELETE http://host/serviceRoot/EntitySet(Key) Reference DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Reference (to many) DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany(Key)/$ref Complex property DELETE http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex property collection DELETE http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive property DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive property value DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive property collection DELETE http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection","title":"Delete Requests Using HTTP DELETE"},{"location":"apis/odata-server/#functions-using-http-get","text":"Resource Request Function import GET http://host/serviceRoot/FunctionImport/[Navigation-or-Property-Path] boundFunction GET http://host/serviceRoot/EntitySet/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundFunction","title":"Functions Using HTTP GET"},{"location":"apis/odata-server/#actions-using-http-post","text":"Resource Request Action import POST http://host/serviceRoot/ActionImport boundAction POST http://host/serviceRoot/EntitySet/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundAction","title":"Actions Using HTTP POST"},{"location":"apis/odata-server/#supported-system-query-options","text":"System Query Option OASIS OData V4.0 Errata 3 - Query Option Description $filter Supported values see OASIS specification $expand Supported values see OASIS specification $select Supported values see OASIS specification $orderby Supported values see OASIS specification $top and $skip Supported values see OASIS specification $count Supported values see OASIS specification $search Supported values see OASIS specification $format Supported values see OASIS specification","title":"Supported System Query Options"},{"location":"apis/odata-server/#analytical-queries","text":"Analytical queries with $apply are described in the specification for the OData data aggregration extension. Transformation Sample Limitations aggregate GET ~/Sales?$apply=aggregate(Amount with sum as Total) Keyword 'from' is not supported topcount GET ~/Sales?$apply=topcount(2,Amount) topsum GET ~/Sales?$apply=topsum(15,Amount) toppercent GET ~/Sales?$apply=toppercent(50,Amount) bottomcount GET ~/Sales?$apply=bottomcount(2,Amount) bottomsum GET ~/Sales?$apply=bottomsum(7,Amount) bottompercent GET ~/Sales?$apply=bottompercent(50,Amount) identity GET ~/Sales?$apply=identity concat GET ~/Sales?$apply=concat(topcount(2,Amount),aggregate(Amount)) groupby GET ~/Sales?$apply=groupby((Customer/Country,Product/Name), aggregate(Amount with sum as Total)) rollup and $all is not supported compute GET ~/Customers?$apply=compute(length(Country) as Length) filter GET ~/Sales?$apply=filter(Amount gt 3) orderby GET ~/Sales?$apply=orderby(Customer/Name) expand Not supported search GET ~/Sales?$apply=search(coffee) skip GET ~/Sales?$apply=skip(5) top GET ~/Sales?$apply=top(4)","title":"Analytical Queries"},{"location":"apis/odata-server/#releases-and-milestones","text":"Changelog","title":"Releases and Milestones"},{"location":"apis/odata-server/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . [1.8.0] - 2020-05-29 \u00b6 Added \u00b6 support for server-driven paging and next links in expanded navigation properties support for $count option in $expand allow doublequotes around * in If-Match and If-None-Match headers Changed \u00b6 log stacktrace for server errors with level error (#107) Fixed \u00b6 status code 200 OK instead of 304 Not Modified for GET requests without If-None-Match header (#106) $expand with complex-property path [1.7.1] - 2020-04-21 \u00b6 Fixed \u00b6 ETags are never required for transient entities from $apply queries [1.7.0] - 2020-04-16 \u00b6 Added \u00b6 support for navigation properties in complex properties Fixed \u00b6 context URL in some edge cases with keys [1.6.1] - 2020-03-31 \u00b6 Fixed \u00b6 support for JSON content in type-definition properties with underlying type Edm.Stream (#97) [1.6.0] - 2020-03-25 \u00b6 Added \u00b6 limited support for JSON content in stream properties as described in OASIS issue 1177 [1.5.5] - 2020-03-11 \u00b6 Added \u00b6 If-Match and If-None-Match headers are allowed with value * on POST requests (#86) [1.5.4] - 2020-03-06 \u00b6 Fixed \u00b6 stricter determination of related entity set [1.5.3] - 2020-03-04 \u00b6 Added \u00b6 If-Match and If-None-Match headers are allowed with value * on non-conditional DELETE requests (#86) [1.5.2] - 2020-02-21 \u00b6 Fixed \u00b6 handling of Path for navigation-property binding and EntitySetPath for bound actions and functions (#84) [1.5.1] - 2020-02-12 \u00b6 Fixed \u00b6 ensure fixed version numbers of dependencies (#79) [1.5.0] - 2020-02-11 \u00b6 Added \u00b6 support for node.js version 12 complete support of specified Unicode range in URI parsing of identifiers URI parsing of search words according to OData 4.01 CS02 Fixed \u00b6 ensure non-null field code in error responses Removed \u00b6 support for node.js version 8 due to its end of life [1.4.1] - 2020-01-31 \u00b6 Fixed \u00b6 If-Match and If-None-Match headers are allowed with value * on non-conditional PUT/PATCH requests (for upsert) (#50) If-Match header with value * is allowed for all GET requests allow annotations @odata.type in requests if they match the types specified in the metadata [1.4.0] - 2020-01-14 \u00b6 Added \u00b6 support for EDM singletons Fixed \u00b6 documentation: actions and functions are supported (#68) [1.3.9] - 2019-10-28 \u00b6 Fixed \u00b6 removed @odata.metadataEtag annotation in JSON responses (with exception of the service-document) additional notice regarding IEEE754Compatible content-type parameter in error messages if necessary [1.3.8] - 2019-10-01 \u00b6 Added \u00b6 support for annotations @odata.mediaEditLink and @odata.mediaReadLink in entity serialization [1.3.7] - 2019-09-19 \u00b6 Fixed \u00b6 npm-shrinkwrap.json remains unchanged during xmake build [1.3.6] - 2019-09-18 \u00b6 Fixed \u00b6 result type of $apply with aliases for custom aggregates (#49) [1.3.5] - 2019-09-02 \u00b6 Fixed \u00b6 serialization of navigation properties for concat transformations in $apply HEAD requests with valid if-none-match header on the ServiceDocument return 304 Not Modified [1.3.4] - 2019-06-18 \u00b6 [1.3.3] - 2019-05-08 \u00b6 Added \u00b6 support in URI resource-path parsing for key-as-segment convention [1.3.2] - 2019-04-26 \u00b6 [1.3.1] - 2019-04-23 \u00b6 [1.3.0] - 2019-04-23 \u00b6 Added \u00b6 preliminary optional switch to use non-validating serializer (not yet stable API) Fixed \u00b6 context URL for $select with same property more than once [1.2.1] - 2019-04-12 \u00b6 Added \u00b6 support for batch requests and responses in JSON format as defined in OData version 4.01 parallel processing of batch requests encoder for primitive values used in serializing made a component that can be overridden Fixed \u00b6 improved serializing performance [1.2.0] - 2019-03-29 \u00b6 Added \u00b6 advertisement for operations [1.1.0] - 2019-03-15 \u00b6 Added \u00b6 Deserialization of delta payloads and deep updates Adaption of Oasis Issue 1221: If Oasis CSDL JSON Specification version 4.01-CS02 is found, all annotations expressions based on string values will lead to an error [1.0.1] - 2019-01-21 \u00b6 [1.0.0] - 2019-01-15 \u00b6 first release version of the new odata-server module CSDL provider to provide your OData EDM model via the JSON format annotations in metadata basic cross service referencing content negotiation support for request Prefer header and response Preference-Applied header support for request Accept-Charset header URI resource-path parser parsers for the system query options $filter, $orderby, $expand (also in combination with query options for expanded entities), $select, $search, $format, and $apply dispatching of requests to handler methods support for metadata requests with automatic metadata ETag and the possibility to use a custom metadata handler for locale-specific metadata read scenarios like read EntityCollection, read Entity, read navigation between entities (including containment navigation), read EntitySet(Key)/property (primitive property, complex property, and their collections), read function imports, and read bound functions CRUD entity and property requests (primitive, complex, and collection properties), including linking with existing entities via bind operations and deep inserts upsert requests (PUT/PATCH on entity set with key and navigation to many with key) server-driven paging CRUD operations for references (also for references reached via navigation) ActionImports and bound actions $batch requests (including retrying requests for ChangeSets) HEAD requests on the service document conditional request handling with ETags $apply support for simple aggregate, groupby, filter, compute, identity, concat, bottomcount, topcount, orderby, skip, and top transformations JSON serialization and deserialization of entities, entity collections, and properties, including support for JSON format parameters IEEE754Compatible and ExponentialDecimals, built-in Context URI Builder, and automatic odata.metadataEtag annotation metadata/annotations in data structure instance annotations in JSON serializer serialization of primitive-property raw values node.js 8.x and 10.x support debug view in JSON and HTML formats logging/tracing facade","title":"Change Log"},{"location":"apis/odata-server/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/odata-server/CHANGELOG/#180-2020-05-29","text":"","title":"[1.8.0] - 2020-05-29"},{"location":"apis/odata-server/CHANGELOG/#added","text":"support for server-driven paging and next links in expanded navigation properties support for $count option in $expand allow doublequotes around * in If-Match and If-None-Match headers","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#changed","text":"log stacktrace for server errors with level error (#107)","title":"Changed"},{"location":"apis/odata-server/CHANGELOG/#fixed","text":"status code 200 OK instead of 304 Not Modified for GET requests without If-None-Match header (#106) $expand with complex-property path","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#171-2020-04-21","text":"","title":"[1.7.1] - 2020-04-21"},{"location":"apis/odata-server/CHANGELOG/#fixed_1","text":"ETags are never required for transient entities from $apply queries","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#170-2020-04-16","text":"","title":"[1.7.0] - 2020-04-16"},{"location":"apis/odata-server/CHANGELOG/#added_1","text":"support for navigation properties in complex properties","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#fixed_2","text":"context URL in some edge cases with keys","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#161-2020-03-31","text":"","title":"[1.6.1] - 2020-03-31"},{"location":"apis/odata-server/CHANGELOG/#fixed_3","text":"support for JSON content in type-definition properties with underlying type Edm.Stream (#97)","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#160-2020-03-25","text":"","title":"[1.6.0] - 2020-03-25"},{"location":"apis/odata-server/CHANGELOG/#added_2","text":"limited support for JSON content in stream properties as described in OASIS issue 1177","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#155-2020-03-11","text":"","title":"[1.5.5] - 2020-03-11"},{"location":"apis/odata-server/CHANGELOG/#added_3","text":"If-Match and If-None-Match headers are allowed with value * on POST requests (#86)","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#154-2020-03-06","text":"","title":"[1.5.4] - 2020-03-06"},{"location":"apis/odata-server/CHANGELOG/#fixed_4","text":"stricter determination of related entity set","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#153-2020-03-04","text":"","title":"[1.5.3] - 2020-03-04"},{"location":"apis/odata-server/CHANGELOG/#added_4","text":"If-Match and If-None-Match headers are allowed with value * on non-conditional DELETE requests (#86)","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#152-2020-02-21","text":"","title":"[1.5.2] - 2020-02-21"},{"location":"apis/odata-server/CHANGELOG/#fixed_5","text":"handling of Path for navigation-property binding and EntitySetPath for bound actions and functions (#84)","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#151-2020-02-12","text":"","title":"[1.5.1] - 2020-02-12"},{"location":"apis/odata-server/CHANGELOG/#fixed_6","text":"ensure fixed version numbers of dependencies (#79)","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#150-2020-02-11","text":"","title":"[1.5.0] - 2020-02-11"},{"location":"apis/odata-server/CHANGELOG/#added_5","text":"support for node.js version 12 complete support of specified Unicode range in URI parsing of identifiers URI parsing of search words according to OData 4.01 CS02","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#fixed_7","text":"ensure non-null field code in error responses","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#removed","text":"support for node.js version 8 due to its end of life","title":"Removed"},{"location":"apis/odata-server/CHANGELOG/#141-2020-01-31","text":"","title":"[1.4.1] - 2020-01-31"},{"location":"apis/odata-server/CHANGELOG/#fixed_8","text":"If-Match and If-None-Match headers are allowed with value * on non-conditional PUT/PATCH requests (for upsert) (#50) If-Match header with value * is allowed for all GET requests allow annotations @odata.type in requests if they match the types specified in the metadata","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#140-2020-01-14","text":"","title":"[1.4.0] - 2020-01-14"},{"location":"apis/odata-server/CHANGELOG/#added_6","text":"support for EDM singletons","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#fixed_9","text":"documentation: actions and functions are supported (#68)","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#139-2019-10-28","text":"","title":"[1.3.9] - 2019-10-28"},{"location":"apis/odata-server/CHANGELOG/#fixed_10","text":"removed @odata.metadataEtag annotation in JSON responses (with exception of the service-document) additional notice regarding IEEE754Compatible content-type parameter in error messages if necessary","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#138-2019-10-01","text":"","title":"[1.3.8] - 2019-10-01"},{"location":"apis/odata-server/CHANGELOG/#added_7","text":"support for annotations @odata.mediaEditLink and @odata.mediaReadLink in entity serialization","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#137-2019-09-19","text":"","title":"[1.3.7] - 2019-09-19"},{"location":"apis/odata-server/CHANGELOG/#fixed_11","text":"npm-shrinkwrap.json remains unchanged during xmake build","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#136-2019-09-18","text":"","title":"[1.3.6] - 2019-09-18"},{"location":"apis/odata-server/CHANGELOG/#fixed_12","text":"result type of $apply with aliases for custom aggregates (#49)","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#135-2019-09-02","text":"","title":"[1.3.5] - 2019-09-02"},{"location":"apis/odata-server/CHANGELOG/#fixed_13","text":"serialization of navigation properties for concat transformations in $apply HEAD requests with valid if-none-match header on the ServiceDocument return 304 Not Modified","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#134-2019-06-18","text":"","title":"[1.3.4] - 2019-06-18"},{"location":"apis/odata-server/CHANGELOG/#133-2019-05-08","text":"","title":"[1.3.3] - 2019-05-08"},{"location":"apis/odata-server/CHANGELOG/#added_8","text":"support in URI resource-path parsing for key-as-segment convention","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#132-2019-04-26","text":"","title":"[1.3.2] - 2019-04-26"},{"location":"apis/odata-server/CHANGELOG/#131-2019-04-23","text":"","title":"[1.3.1] - 2019-04-23"},{"location":"apis/odata-server/CHANGELOG/#130-2019-04-23","text":"","title":"[1.3.0] - 2019-04-23"},{"location":"apis/odata-server/CHANGELOG/#added_9","text":"preliminary optional switch to use non-validating serializer (not yet stable API)","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#fixed_14","text":"context URL for $select with same property more than once","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#121-2019-04-12","text":"","title":"[1.2.1] - 2019-04-12"},{"location":"apis/odata-server/CHANGELOG/#added_10","text":"support for batch requests and responses in JSON format as defined in OData version 4.01 parallel processing of batch requests encoder for primitive values used in serializing made a component that can be overridden","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#fixed_15","text":"improved serializing performance","title":"Fixed"},{"location":"apis/odata-server/CHANGELOG/#120-2019-03-29","text":"","title":"[1.2.0] - 2019-03-29"},{"location":"apis/odata-server/CHANGELOG/#added_11","text":"advertisement for operations","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#110-2019-03-15","text":"","title":"[1.1.0] - 2019-03-15"},{"location":"apis/odata-server/CHANGELOG/#added_12","text":"Deserialization of delta payloads and deep updates Adaption of Oasis Issue 1221: If Oasis CSDL JSON Specification version 4.01-CS02 is found, all annotations expressions based on string values will lead to an error","title":"Added"},{"location":"apis/odata-server/CHANGELOG/#101-2019-01-21","text":"","title":"[1.0.1] - 2019-01-21"},{"location":"apis/odata-server/CHANGELOG/#100-2019-01-15","text":"first release version of the new odata-server module CSDL provider to provide your OData EDM model via the JSON format annotations in metadata basic cross service referencing content negotiation support for request Prefer header and response Preference-Applied header support for request Accept-Charset header URI resource-path parser parsers for the system query options $filter, $orderby, $expand (also in combination with query options for expanded entities), $select, $search, $format, and $apply dispatching of requests to handler methods support for metadata requests with automatic metadata ETag and the possibility to use a custom metadata handler for locale-specific metadata read scenarios like read EntityCollection, read Entity, read navigation between entities (including containment navigation), read EntitySet(Key)/property (primitive property, complex property, and their collections), read function imports, and read bound functions CRUD entity and property requests (primitive, complex, and collection properties), including linking with existing entities via bind operations and deep inserts upsert requests (PUT/PATCH on entity set with key and navigation to many with key) server-driven paging CRUD operations for references (also for references reached via navigation) ActionImports and bound actions $batch requests (including retrying requests for ChangeSets) HEAD requests on the service document conditional request handling with ETags $apply support for simple aggregate, groupby, filter, compute, identity, concat, bottomcount, topcount, orderby, skip, and top transformations JSON serialization and deserialization of entities, entity collections, and properties, including support for JSON format parameters IEEE754Compatible and ExponentialDecimals, built-in Context URI Builder, and automatic odata.metadataEtag annotation metadata/annotations in data structure instance annotations in JSON serializer serialization of primitive-property raw values node.js 8.x and 10.x support debug view in JSON and HTML formats logging/tracing facade","title":"[1.0.0] - 2019-01-15"},{"location":"apis/odata-v4/","text":"OData V4.0 Server Library \u00b6 Table of Contents \u00b6 Overview Installation Usage Releases and Milestones Overview \u00b6 With the OData server library OData V4.0 services can be implemented based on the OASIS OData standard . The library can be directly used to build OData services and is also part of the SAP Fiori programming model as well the SAP Cloud Platform programming model, where the data model can be defined in CDS (Core data services) and the OData service be generated out of the model. The library leaves the freedom to build OData services with any db or persistence layer. It is also possible to create services, that are calling external REST/OData services and mix up the data with your application data. The library is modular and consists of the following main components: EntityDataModel - Define your EDM in JSON format. Our provider creates the EDM out of your model and caches EDM model elements Handler Dispatcher - Maps requests to handler functions for CRUD operations URI parsers - Parse the request URI including the OData system query options (like $format, $select, $expand,...) and validates each URI segment against the EDM model and the OData ABNF Serializers and Deserializers for the request and response payload. The deserializers validate the request payload and support type mapping between OData EDM types and JavaScript Types Automatic OData Reponse generation based on provided data ServiceFactory to create the OData service along with the CRUD handler registration Conditional request handling for optimistic concurrency control via ETAGs Batch handling - Batch request parsing, dispatching to single batch requests, Content-ID referencing and batch response generation Flexible API to support all backends - The service developer has the free choice of his backend system (e.g., databases, frameworks, calling additional external OData services). Installation \u00b6 npm install @sap/odata-v4 Usage \u00b6 const odata = require ( '@sap/odata-v4' ); // Load your edm model. const edmModel = require ( './<your_edm_model>.json' ); // Create the service const service = odata . ServiceFactory . createService ( edmModel ) // Register the request handler for CRUD operations . on ( 'create' , function create ( request , response , next ){...}) . on ( 'update' , function update ( request , response , next ){...}) . on ( 'delete' , function delete ( request , response , next ){...}) . on ( 'read' , function read ( request , response , next ){...}) //Create the server const port = 9000 ; const server = http . createServer (( req , res ) => service . process ( req , res )) . listen ( port , () => console . log ( `Server listens on port ${ port } - Service URL: http://localhost: ${ port } /serviceroot.svc/` ) ); Supported Requests \u00b6 Resource Request Read Request GET Serviceoot GET http://host/serviceRoot/ Metadata GET http://host/serviceRoot/$metadata EntitySet GET http://host/serviceRoot/EntitySet EntitySet GET http://host/serviceRoot/EntitySet/$count Entity GET http://host/serviceRoot/EntitySet(Key) References GET http://host/serviceRoot/EntitySet/$ref Reference GET http://host/serviceRoot/EntitySet(Key)/$ref References(related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Reference(related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Related Entity GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne Related Entities GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany Complex Property GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex Property Collection GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive Property GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive Property Value GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive Property Collection GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Create/Insert Requests POST Entity POST http://host/serviceRoot/EntitySet Deep Insert POST http://host/serviceRoot/EntitySet Entity with bind operations POST http://host/serviceRoot/EntitySet Reference POST http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Update Requests PUT/PATCH Entity PUT/PATCH http://host/serviceRoot/EntitySet(Key) Reference PUT http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Complex Property PUT/PATCH http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex Property Collection PUT http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive Property PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive Property Value PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive Property Collection PUT http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Delete Requests DELETE Entity DELETE http://host/serviceRoot/EntitySet(Key) Reference DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Reference(To Many) DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany(Key)/$ref Complex Property DELETE http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex Property Collection DELETE http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive Property DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive Property Value DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive Property Collection DELETE http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Actions and Functions GET/POST Function Import GET http://host/serviceRoot/FunctionImports/[Navigation- or PropertyPath] boundFunction GET http://host/serviceRoot/EntitySet/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundFunction ActionImport POST http://host/serviceRoot/ActionImport boundAction POST http://host/serviceRoot/EntitySet/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundAction Supported System Query Options \u00b6 System Query Option OASIS OData V4.0 Errata 3 - Query Option Description $filter Supported values see OASIS specification $expand Supported values see OASIS specification $select Supported values see OASIS specification $orderby Supported values see OASIS specification $top and $skip Supported values see OASIS specification $count Supported values see OASIS specification $search Supported values see OASIS specification $format Supported values see OASIS specification Analytical Queries - $apply \u00b6 Transformation Sample Limitations aggregate GET ~/Sales?$apply=aggregate(Amount with sum as Total) Keyword 'from' is not supported topcount GET ~/Sales?$apply=topcount(2,Amount) topsum GET ~/Sales?$apply=topsum(15,Amount) toppercent GET ~/Sales?$apply=toppercent(50,Amount) bottomcount GET ~/Sales?$apply=bottomcount(2,Amount) bottomsum GET ~/Sales?$apply=bottomsum(7,Amount) bottompercent GET ~/Sales?$apply=bottompercent(50,Amount) identity GET ~/Sales?$apply=identity concat GET ~/Sales?$apply=concat(topcount(2,Amount),aggregate(Amount)) groupby GET ~/Sales?$apply=groupby((Customer/Country,Product/Name), aggregate(Amount with sum as Total)) rollup and $all is not supported filter GET ~/Sales?$apply=filter(Amount gt 3) expand Not supported search GET ~/Sales?$apply=search(coffee) Releases and Milestones \u00b6 Changelog","title":"Index"},{"location":"apis/odata-v4/#odata-v40-server-library","text":"","title":"OData V4.0 Server Library"},{"location":"apis/odata-v4/#table-of-contents","text":"Overview Installation Usage Releases and Milestones","title":"Table of Contents"},{"location":"apis/odata-v4/#overview","text":"With the OData server library OData V4.0 services can be implemented based on the OASIS OData standard . The library can be directly used to build OData services and is also part of the SAP Fiori programming model as well the SAP Cloud Platform programming model, where the data model can be defined in CDS (Core data services) and the OData service be generated out of the model. The library leaves the freedom to build OData services with any db or persistence layer. It is also possible to create services, that are calling external REST/OData services and mix up the data with your application data. The library is modular and consists of the following main components: EntityDataModel - Define your EDM in JSON format. Our provider creates the EDM out of your model and caches EDM model elements Handler Dispatcher - Maps requests to handler functions for CRUD operations URI parsers - Parse the request URI including the OData system query options (like $format, $select, $expand,...) and validates each URI segment against the EDM model and the OData ABNF Serializers and Deserializers for the request and response payload. The deserializers validate the request payload and support type mapping between OData EDM types and JavaScript Types Automatic OData Reponse generation based on provided data ServiceFactory to create the OData service along with the CRUD handler registration Conditional request handling for optimistic concurrency control via ETAGs Batch handling - Batch request parsing, dispatching to single batch requests, Content-ID referencing and batch response generation Flexible API to support all backends - The service developer has the free choice of his backend system (e.g., databases, frameworks, calling additional external OData services).","title":"Overview"},{"location":"apis/odata-v4/#installation","text":"npm install @sap/odata-v4","title":"Installation"},{"location":"apis/odata-v4/#usage","text":"const odata = require ( '@sap/odata-v4' ); // Load your edm model. const edmModel = require ( './<your_edm_model>.json' ); // Create the service const service = odata . ServiceFactory . createService ( edmModel ) // Register the request handler for CRUD operations . on ( 'create' , function create ( request , response , next ){...}) . on ( 'update' , function update ( request , response , next ){...}) . on ( 'delete' , function delete ( request , response , next ){...}) . on ( 'read' , function read ( request , response , next ){...}) //Create the server const port = 9000 ; const server = http . createServer (( req , res ) => service . process ( req , res )) . listen ( port , () => console . log ( `Server listens on port ${ port } - Service URL: http://localhost: ${ port } /serviceroot.svc/` ) );","title":"Usage"},{"location":"apis/odata-v4/#supported-requests","text":"Resource Request Read Request GET Serviceoot GET http://host/serviceRoot/ Metadata GET http://host/serviceRoot/$metadata EntitySet GET http://host/serviceRoot/EntitySet EntitySet GET http://host/serviceRoot/EntitySet/$count Entity GET http://host/serviceRoot/EntitySet(Key) References GET http://host/serviceRoot/EntitySet/$ref Reference GET http://host/serviceRoot/EntitySet(Key)/$ref References(related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Reference(related) GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Related Entity GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne Related Entities GET http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany Complex Property GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex Property Collection GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive Property GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive Property Value GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive Property Collection GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Create/Insert Requests POST Entity POST http://host/serviceRoot/EntitySet Deep Insert POST http://host/serviceRoot/EntitySet Entity with bind operations POST http://host/serviceRoot/EntitySet Reference POST http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany/$ref Update Requests PUT/PATCH Entity PUT/PATCH http://host/serviceRoot/EntitySet(Key) Reference PUT http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Complex Property PUT/PATCH http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex Property Collection PUT http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive Property PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive Property Value PUT http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive Property Collection PUT http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Delete Requests DELETE Entity DELETE http://host/serviceRoot/EntitySet(Key) Reference DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToOne/$ref Reference(To Many) DELETE http://host/serviceRoot/EntitySet(Key)/NavigationPropertyToMany(Key)/$ref Complex Property DELETE http://host/serviceRoot/EntitySet(Key)/ComplexProperty Complex Property Collection DELETE http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection Primitive Property DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty Primitive Property Value DELETE http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/$value Primitive Property Collection DELETE http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection Actions and Functions GET/POST Function Import GET http://host/serviceRoot/FunctionImports/[Navigation- or PropertyPath] boundFunction GET http://host/serviceRoot/EntitySet/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundFunction boundFunction GET http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundFunction ActionImport POST http://host/serviceRoot/ActionImport boundAction POST http://host/serviceRoot/EntitySet/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/ComplexPropertyCollection/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitiveProperty/boundAction boundAction POST http://host/serviceRoot/EntitySet(Key)/PrimitivePropertyCollection/boundAction","title":"Supported Requests"},{"location":"apis/odata-v4/#supported-system-query-options","text":"System Query Option OASIS OData V4.0 Errata 3 - Query Option Description $filter Supported values see OASIS specification $expand Supported values see OASIS specification $select Supported values see OASIS specification $orderby Supported values see OASIS specification $top and $skip Supported values see OASIS specification $count Supported values see OASIS specification $search Supported values see OASIS specification $format Supported values see OASIS specification","title":"Supported System Query Options"},{"location":"apis/odata-v4/#analytical-queries-apply","text":"Transformation Sample Limitations aggregate GET ~/Sales?$apply=aggregate(Amount with sum as Total) Keyword 'from' is not supported topcount GET ~/Sales?$apply=topcount(2,Amount) topsum GET ~/Sales?$apply=topsum(15,Amount) toppercent GET ~/Sales?$apply=toppercent(50,Amount) bottomcount GET ~/Sales?$apply=bottomcount(2,Amount) bottomsum GET ~/Sales?$apply=bottomsum(7,Amount) bottompercent GET ~/Sales?$apply=bottompercent(50,Amount) identity GET ~/Sales?$apply=identity concat GET ~/Sales?$apply=concat(topcount(2,Amount),aggregate(Amount)) groupby GET ~/Sales?$apply=groupby((Customer/Country,Product/Name), aggregate(Amount with sum as Total)) rollup and $all is not supported filter GET ~/Sales?$apply=filter(Amount gt 3) expand Not supported search GET ~/Sales?$apply=search(coffee)","title":"Analytical Queries - $apply"},{"location":"apis/odata-v4/#releases-and-milestones","text":"Changelog","title":"Releases and Milestones"},{"location":"apis/odata-v4/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Unreleased \u00b6 [1.7.0] - 2018-09-19 \u00b6 Added \u00b6 Support for EDM type Edm.Stream It is now possible to create, update, and delete entities and references reached via navigation. [1.6.1] - 2018-08-07 \u00b6 Changed \u00b6 an empty JSON object is allowed as input for a create operation [1.6.0] - 2018-08-02 \u00b6 Added \u00b6 $apply support for accessing related entities in aggregation and grouping Implemented the odata.metadataEtag annotation Metadata-Etag changes, if the metadata document changes via a custom metadata handler Support for function imports and bound functions new method in ApplicationError to add an annotation Changed \u00b6 Definition of search words for $search in anticipation of OData version 4.01 Changed next() interface of ServiceHandler, MetadataHandler and localeNegotiator to behave like the other data handlers -> next (error, { value: data }) Fixed \u00b6 Context URL in case of deep inserts the check which key properties can be omitted in case of referential constraints (#426) serialization of annotations in XML error messages [1.5.0] - 2018-06-13 \u00b6 Added \u00b6 Retry Requests for ChangeSets Support for locale specific metadata-requests Support for $count as a pathsegment on expanded navigation properties Support for containment navigation Support for instance annotations in JSON serializer $apply support for orderby, skip, and top transformations Support for $expand=*, but not with the $levels option Changed \u00b6 Null property values can be omitted Updated dependencies Fixed \u00b6 Canonical URL and context URL in case of omitted key values due to referential constraints Context URL in case of bound actions that return an entityset Support for ETags in expanded entities Support for ETags in a Deep-Insert response [1.4.1] - 2018-05-03 \u00b6 Fixed \u00b6 Corrected behaviour when debug mode is not activated but requested by client [1.4.0] - 2018-04-27 \u00b6 Added \u00b6 Metadata serialization of EnumMember can use odata.type annotation if enum type is not available Support for HEAD requests on the service document Fixed \u00b6 Default status code set to 200 OK for responses to action requests Switched to more robust method of calling hasOwnProperty (#384) Added format-parameter odata.metadata to the content-type header of json responses (#351) [1.3.0] - 2018-04-04 \u00b6 Added \u00b6 Support for request Prefer header and response Preference-Applied header [1.2.0] - 2018-03-19 \u00b6 Added \u00b6 Support for Accept-Charset and the charset format-parameter in Accept and $format Changed \u00b6 Fixed \u00b6 1.1.1 - 2018-03-12 [Test] \u00b6 1.1.0 - 2018-03-12 [Okra Release for productive usage on XSA CF] \u00b6 Added \u00b6 $apply support for concat transformation Changed \u00b6 Fixed \u00b6 Context-Url for expanded entities/entity sets #366 1.0.0 - 2018-03-01 [Okra Release for productive usage on XSA/CF] \u00b6 Added \u00b6 Enumeration types Enhanced Debug HTML View $apply support for simple aggregate, groupby, filter, compute, identity, bottomcount, and topcount transformations Server-driven paging Create/Update entity and link with existing entity via bind operations CRUD operations for references ActionImports and Bound Action support Deep insert support Metadata/Annotations in data structure Annotations in expanded entities (Etags) Changed \u00b6 Refactoring of next(error, data, options) interface. Data structure of data has changed Fixed \u00b6 Debug output for batch requests #337 0.5.0 - 2017-10-18 [First Okra Release for productive usage on XSA/CF] \u00b6 Added \u00b6 Basic Cross Service Referencing Node.js 6.X and 8.X support CRUD Entity Requests CUD Property Requests (Primitive-, Complex- and Collection Properties) $batch requests EnumMemberExpression in metadata Conditional Request handling with ETAGs Logging Facade Documentation Changed \u00b6 CRUD handlers have to be registered with service.on() instead of service.use() 0.0.1-alpha.4 - 2017-05-30 [Milestone] \u00b6 Added \u00b6 Create Entity Requests Adapt JSON CSDL provider to preliminary OASIS CSDL version Adapt samples to new CSDL format Performance Test Cases 0.0.1-alpha.3 - 2017-04-24 [Milestone] \u00b6 Added \u00b6 Read EntitySet(Key)/property (Primitive Property, Complex Property and their collections) Delete Entity requests New Dispatching architecture - Usage of handlers instead of processor interfaces OData Version 4.0 in request and response Annotations in metadata Context URI Builder Enhanced Debug View support Content Negotiation $filter parser $orderby parser $expand parser $select parser $search parser $format validation $expand in combination with query options for expanded entities support for JSON format parameters IEEE754Compatible and ExponentialDecimals standalone JSON serialization of properties serialization of primitive-property raw values JSON deserialization of entities and properties 0.0.1-alpha.1 - 2016-10-28 [Milestone] \u00b6 Added \u00b6 First milestone version of the OData V4 library, that can be used for PoC's. Library supports creating your OData EDM modell as well Read scenarios like read EntityCollection, read Entity and Navigation between entities like: GET http://serviceRoot/EntitySet GET http://serviceRoot/EntitySet(key) GET http://serviceRoot/EntitySet(key)/NavigationProperty/.. The library supports the json format only. CSDL providers to provide your OData EDM model via the sap-json format or programmatically JSON Serializers for Entity and EntityCollection Serialization Dispatching of request to processor methods node.js 6.X support debug view in json and html format","title":"Change Log"},{"location":"apis/odata-v4/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/odata-v4/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"apis/odata-v4/CHANGELOG/#170-2018-09-19","text":"","title":"[1.7.0] - 2018-09-19"},{"location":"apis/odata-v4/CHANGELOG/#added","text":"Support for EDM type Edm.Stream It is now possible to create, update, and delete entities and references reached via navigation.","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#161-2018-08-07","text":"","title":"[1.6.1] - 2018-08-07"},{"location":"apis/odata-v4/CHANGELOG/#changed","text":"an empty JSON object is allowed as input for a create operation","title":"Changed"},{"location":"apis/odata-v4/CHANGELOG/#160-2018-08-02","text":"","title":"[1.6.0] - 2018-08-02"},{"location":"apis/odata-v4/CHANGELOG/#added_1","text":"$apply support for accessing related entities in aggregation and grouping Implemented the odata.metadataEtag annotation Metadata-Etag changes, if the metadata document changes via a custom metadata handler Support for function imports and bound functions new method in ApplicationError to add an annotation","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#changed_1","text":"Definition of search words for $search in anticipation of OData version 4.01 Changed next() interface of ServiceHandler, MetadataHandler and localeNegotiator to behave like the other data handlers -> next (error, { value: data })","title":"Changed"},{"location":"apis/odata-v4/CHANGELOG/#fixed","text":"Context URL in case of deep inserts the check which key properties can be omitted in case of referential constraints (#426) serialization of annotations in XML error messages","title":"Fixed"},{"location":"apis/odata-v4/CHANGELOG/#150-2018-06-13","text":"","title":"[1.5.0] - 2018-06-13"},{"location":"apis/odata-v4/CHANGELOG/#added_2","text":"Retry Requests for ChangeSets Support for locale specific metadata-requests Support for $count as a pathsegment on expanded navigation properties Support for containment navigation Support for instance annotations in JSON serializer $apply support for orderby, skip, and top transformations Support for $expand=*, but not with the $levels option","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#changed_2","text":"Null property values can be omitted Updated dependencies","title":"Changed"},{"location":"apis/odata-v4/CHANGELOG/#fixed_1","text":"Canonical URL and context URL in case of omitted key values due to referential constraints Context URL in case of bound actions that return an entityset Support for ETags in expanded entities Support for ETags in a Deep-Insert response","title":"Fixed"},{"location":"apis/odata-v4/CHANGELOG/#141-2018-05-03","text":"","title":"[1.4.1] - 2018-05-03"},{"location":"apis/odata-v4/CHANGELOG/#fixed_2","text":"Corrected behaviour when debug mode is not activated but requested by client","title":"Fixed"},{"location":"apis/odata-v4/CHANGELOG/#140-2018-04-27","text":"","title":"[1.4.0] - 2018-04-27"},{"location":"apis/odata-v4/CHANGELOG/#added_3","text":"Metadata serialization of EnumMember can use odata.type annotation if enum type is not available Support for HEAD requests on the service document","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#fixed_3","text":"Default status code set to 200 OK for responses to action requests Switched to more robust method of calling hasOwnProperty (#384) Added format-parameter odata.metadata to the content-type header of json responses (#351)","title":"Fixed"},{"location":"apis/odata-v4/CHANGELOG/#130-2018-04-04","text":"","title":"[1.3.0] - 2018-04-04"},{"location":"apis/odata-v4/CHANGELOG/#added_4","text":"Support for request Prefer header and response Preference-Applied header","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#120-2018-03-19","text":"","title":"[1.2.0] - 2018-03-19"},{"location":"apis/odata-v4/CHANGELOG/#added_5","text":"Support for Accept-Charset and the charset format-parameter in Accept and $format","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#changed_3","text":"","title":"Changed"},{"location":"apis/odata-v4/CHANGELOG/#fixed_4","text":"","title":"Fixed"},{"location":"apis/odata-v4/CHANGELOG/#111-2018-03-12-test","text":"","title":"1.1.1 - 2018-03-12 [Test]"},{"location":"apis/odata-v4/CHANGELOG/#110-2018-03-12-okra-release-for-productive-usage-on-xsa-cf","text":"","title":"1.1.0 - 2018-03-12 [Okra Release for productive usage on XSA CF]"},{"location":"apis/odata-v4/CHANGELOG/#added_6","text":"$apply support for concat transformation","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#changed_4","text":"","title":"Changed"},{"location":"apis/odata-v4/CHANGELOG/#fixed_5","text":"Context-Url for expanded entities/entity sets #366","title":"Fixed"},{"location":"apis/odata-v4/CHANGELOG/#100-2018-03-01-okra-release-for-productive-usage-on-xsacf","text":"","title":"1.0.0 - 2018-03-01 [Okra Release for productive usage on XSA/CF]"},{"location":"apis/odata-v4/CHANGELOG/#added_7","text":"Enumeration types Enhanced Debug HTML View $apply support for simple aggregate, groupby, filter, compute, identity, bottomcount, and topcount transformations Server-driven paging Create/Update entity and link with existing entity via bind operations CRUD operations for references ActionImports and Bound Action support Deep insert support Metadata/Annotations in data structure Annotations in expanded entities (Etags)","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#changed_5","text":"Refactoring of next(error, data, options) interface. Data structure of data has changed","title":"Changed"},{"location":"apis/odata-v4/CHANGELOG/#fixed_6","text":"Debug output for batch requests #337","title":"Fixed"},{"location":"apis/odata-v4/CHANGELOG/#050-2017-10-18-first-okra-release-for-productive-usage-on-xsacf","text":"","title":"0.5.0 - 2017-10-18 [First Okra Release for productive usage on XSA/CF]"},{"location":"apis/odata-v4/CHANGELOG/#added_8","text":"Basic Cross Service Referencing Node.js 6.X and 8.X support CRUD Entity Requests CUD Property Requests (Primitive-, Complex- and Collection Properties) $batch requests EnumMemberExpression in metadata Conditional Request handling with ETAGs Logging Facade Documentation","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#changed_6","text":"CRUD handlers have to be registered with service.on() instead of service.use()","title":"Changed"},{"location":"apis/odata-v4/CHANGELOG/#001-alpha4-2017-05-30-milestone","text":"","title":"0.0.1-alpha.4 - 2017-05-30 [Milestone]"},{"location":"apis/odata-v4/CHANGELOG/#added_9","text":"Create Entity Requests Adapt JSON CSDL provider to preliminary OASIS CSDL version Adapt samples to new CSDL format Performance Test Cases","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#001-alpha3-2017-04-24-milestone","text":"","title":"0.0.1-alpha.3 - 2017-04-24 [Milestone]"},{"location":"apis/odata-v4/CHANGELOG/#added_10","text":"Read EntitySet(Key)/property (Primitive Property, Complex Property and their collections) Delete Entity requests New Dispatching architecture - Usage of handlers instead of processor interfaces OData Version 4.0 in request and response Annotations in metadata Context URI Builder Enhanced Debug View support Content Negotiation $filter parser $orderby parser $expand parser $select parser $search parser $format validation $expand in combination with query options for expanded entities support for JSON format parameters IEEE754Compatible and ExponentialDecimals standalone JSON serialization of properties serialization of primitive-property raw values JSON deserialization of entities and properties","title":"Added"},{"location":"apis/odata-v4/CHANGELOG/#001-alpha1-2016-10-28-milestone","text":"","title":"0.0.1-alpha.1 - 2016-10-28 [Milestone]"},{"location":"apis/odata-v4/CHANGELOG/#added_11","text":"First milestone version of the OData V4 library, that can be used for PoC's. Library supports creating your OData EDM modell as well Read scenarios like read EntityCollection, read Entity and Navigation between entities like: GET http://serviceRoot/EntitySet GET http://serviceRoot/EntitySet(key) GET http://serviceRoot/EntitySet(key)/NavigationProperty/.. The library supports the json format only. CSDL providers to provide your OData EDM model via the sap-json format or programmatically JSON Serializers for Entity and EntityCollection Serialization Dispatching of request to processor methods node.js 6.X support debug view in json and html format","title":"Added"},{"location":"apis/portal-cf-content-deployer/","text":"Description \u00b6 portal-cf-content-deployer \u00b6 Portal CF Content Deployer This component is used to deploy the Fiori Launchpad portal site configuration (configuration of tiles, groups and catalogs) into the Cloud Foundry Environment. This component interacts with the portal service and the approuter, which in turn acts as the web entry server of the Fiori Launchpad portal site.","title":"Index"},{"location":"apis/portal-cf-content-deployer/#description","text":"","title":"Description"},{"location":"apis/portal-cf-content-deployer/#portal-cf-content-deployer","text":"Portal CF Content Deployer This component is used to deploy the Fiori Launchpad portal site configuration (configuration of tiles, groups and catalogs) into the Cloud Foundry Environment. This component interacts with the portal service and the approuter, which in turn acts as the web entry server of the Fiori Launchpad portal site.","title":"portal-cf-content-deployer"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . [4.2.0] \u00b6 Changed \u00b6 Changed jszip to version 3.4.0 Changed rimraf to version 3.0.2 Node.js engine supports only ^12.0.0 Fixed \u00b6 eslint ci support [4.1.0] \u00b6 Added \u00b6 Added PROVIDER_INFORMATION for future feature [3.32.0] \u00b6 Changed \u00b6 For external content provider take xsappname from binded uaa or from env variable SAP_CONTENT_PROVIDER_XSAPPNAME [3.30.0] \u00b6 Changed \u00b6 Add portal service data in external provider scenario [3.29.0] \u00b6 Changed \u00b6 Changed @sap/xsenv to version 2.2.0 Changed glob to version 7.1.6 Changed jszip to version 3.2.2 Changed rimraf to version 3.0.0 [3.28.0] \u00b6 Added \u00b6 Added Support of federating shell plugins in cFlp Added Support of SAP Content Provider [3.27.0] \u00b6 Changed \u00b6 Changed form-data to version 3.0.0 [3.24.0] \u00b6 Changed \u00b6 Change ID for federation, after redeployment need to add again the apps in CFLP [3.15.0] \u00b6 Added \u00b6 Added BlueBoxMetaData in deploy process [3.14.0] \u00b6 Changed \u00b6 Update to Node10 Changed axios to version 0.18.1 [3.11.0] \u00b6 Changed \u00b6 Changed axios to version 0.19.0 [3.10.0] \u00b6 Changed \u00b6 Changed buildpacks to version 1.6.50 Change @sap/xsenv version to 2.0.0 Change form-data version to 2.3.3 Change glob version to 7.1.4 Change jszip version to 3.2.1 [3.6.0] \u00b6 Added \u00b6 Added business app support [3.2.0] \u00b6 Added \u00b6 Support for one off task Changed \u00b6 Deploy message for deploy service Changed rimraf to version 2.6.3 [3.0.0] \u00b6 Changed \u00b6 Deploy CDM3 compatible site [2.11.0] \u00b6 Added \u00b6 Added shrinkwrap [2.8.0] \u00b6 Changed \u00b6 Support for multiple app host ids [2.6.0] - 2018-08-02 \u00b6 Fixed \u00b6 Show deployment errors in log when deploying from WEB-IDE [2.1.0] - 2018-06-07 \u00b6 Changed \u00b6 Expose DTS/FDC deployment errors to content deployer traces [2.0.0] - 2018-05-31 \u00b6 Added \u00b6 Initial delivery","title":"Change Log"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#420","text":"","title":"[4.2.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed","text":"Changed jszip to version 3.4.0 Changed rimraf to version 3.0.2 Node.js engine supports only ^12.0.0","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#fixed","text":"eslint ci support","title":"Fixed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#410","text":"","title":"[4.1.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#added","text":"Added PROVIDER_INFORMATION for future feature","title":"Added"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3320","text":"","title":"[3.32.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_1","text":"For external content provider take xsappname from binded uaa or from env variable SAP_CONTENT_PROVIDER_XSAPPNAME","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3300","text":"","title":"[3.30.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_2","text":"Add portal service data in external provider scenario","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3290","text":"","title":"[3.29.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_3","text":"Changed @sap/xsenv to version 2.2.0 Changed glob to version 7.1.6 Changed jszip to version 3.2.2 Changed rimraf to version 3.0.0","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3280","text":"","title":"[3.28.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#added_1","text":"Added Support of federating shell plugins in cFlp Added Support of SAP Content Provider","title":"Added"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3270","text":"","title":"[3.27.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_4","text":"Changed form-data to version 3.0.0","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3240","text":"","title":"[3.24.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_5","text":"Change ID for federation, after redeployment need to add again the apps in CFLP","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3150","text":"","title":"[3.15.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#added_2","text":"Added BlueBoxMetaData in deploy process","title":"Added"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3140","text":"","title":"[3.14.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_6","text":"Update to Node10 Changed axios to version 0.18.1","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3110","text":"","title":"[3.11.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_7","text":"Changed axios to version 0.19.0","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#3100","text":"","title":"[3.10.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_8","text":"Changed buildpacks to version 1.6.50 Change @sap/xsenv version to 2.0.0 Change form-data version to 2.3.3 Change glob version to 7.1.4 Change jszip version to 3.2.1","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#360","text":"","title":"[3.6.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#added_3","text":"Added business app support","title":"Added"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#320","text":"","title":"[3.2.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#added_4","text":"Support for one off task","title":"Added"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_9","text":"Deploy message for deploy service Changed rimraf to version 2.6.3","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#300","text":"","title":"[3.0.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_10","text":"Deploy CDM3 compatible site","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#2110","text":"","title":"[2.11.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#added_5","text":"Added shrinkwrap","title":"Added"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#280","text":"","title":"[2.8.0]"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_11","text":"Support for multiple app host ids","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#260-2018-08-02","text":"","title":"[2.6.0] - 2018-08-02"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#fixed_1","text":"Show deployment errors in log when deploying from WEB-IDE","title":"Fixed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#210-2018-06-07","text":"","title":"[2.1.0] - 2018-06-07"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#changed_12","text":"Expose DTS/FDC deployment errors to content deployer traces","title":"Changed"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#200-2018-05-31","text":"","title":"[2.0.0] - 2018-05-31"},{"location":"apis/portal-cf-content-deployer/CHANGELOG/#added_6","text":"Initial delivery","title":"Added"},{"location":"apis/sds-deploy/","text":"The deploy application can deploy SDS project consisting of CCL file and CCR file to HANA SDS option on XSA. Usage \u00b6 Create the MTA application Create the SDS module. NOTE: We invent a rule that an SDS module is mapped to an SDS project respectively. Following the rule make things simple. (1) Once the module is created, the folder 'sds_module' shall be created for it. (2) Within that folder, a sub folder 'model' shall be created for it. (3) Put the CCL file and CCR file into the folder sds_module/model (4) Create the package.json file under the folder 'sds_module'. Modify the mtad.yaml under the MTA application to provide the service instance for SDS option.","title":"Index"},{"location":"apis/sds-deploy/#usage","text":"Create the MTA application Create the SDS module. NOTE: We invent a rule that an SDS module is mapped to an SDS project respectively. Following the rule make things simple. (1) Once the module is created, the folder 'sds_module' shall be created for it. (2) Within that folder, a sub folder 'model' shall be created for it. (3) Put the CCL file and CCR file into the folder sds_module/model (4) Create the package.json file under the folder 'sds_module'. Modify the mtad.yaml under the MTA application to provide the service instance for SDS option.","title":"Usage"},{"location":"apis/sds-deploy/CHANGELOG/","text":"2.0.4 - 2018-02-28 Add npm-shrinkwrap.json 2.0.2 - 2018-02-01 Upgrade open source components 2.0.0 - 2017-02-10 Initial release","title":"CHANGELOG"},{"location":"apis/site-app-server/","text":"This component is a static resources web server for applications that run in a Fiori Launchpad portal site. During startup it persists to the portal-service all configuration (tiles, groups, routes, uaa) that is needed for this application to run in a Fiori Launchpad portal site. This component is coupled with the @sap/site-entry node module, which in turn acts as the web entry server of the Fiori Launchpad portal site. This component uses the portal-service that exists in the XSA environment. This component can be used only on HANA XSA SP1 environment.","title":"Index"},{"location":"apis/site-content-deployer/","text":"This component is used to deploy the Fiori Launchpad portal site configuration (configuration of tiles, groups and catalogs) into the XSA environment. This component is coupled with the sap-site-entry node module, which in turn acts as the web entry server of the Fiori Launchpad portal site. This component uses the portal-service that exists in the environment. This component can be used only on HANA XSA SP1 environment.","title":"Index"},{"location":"apis/site-entry/","text":"Portal Site entry - Web entry for Fiori Launchpad sites \u00b6 This component is the web entry for Fiori Launchpad portal sites. It wraps an Approuter component that serves as its web server for serving client side resources and backend calls. This componet should perform binding to the sap-portal-service that exists in the environment. This component can be used only on HANA XSA SP1 and above environment. Table of contents \u00b6 Prerequisites Configuration Supported Prerequisites \u00b6 Perform bind to portal-services with plan site-host Configuration \u00b6 Using xs-app.json file the wrapped Approuter component can be configured. Supported \u00b6 This component can be used only on HANA XSA SP1 with a compatible versions of: SAP UI5 portal-service sap-site-content-deployer","title":"Portal Site entry - Web entry for Fiori Launchpad sites"},{"location":"apis/site-entry/#portal-site-entry-web-entry-for-fiori-launchpad-sites","text":"This component is the web entry for Fiori Launchpad portal sites. It wraps an Approuter component that serves as its web server for serving client side resources and backend calls. This componet should perform binding to the sap-portal-service that exists in the environment. This component can be used only on HANA XSA SP1 and above environment.","title":"Portal Site entry - Web entry for Fiori Launchpad sites"},{"location":"apis/site-entry/#table-of-contents","text":"Prerequisites Configuration Supported","title":"Table of contents"},{"location":"apis/site-entry/#prerequisites","text":"Perform bind to portal-services with plan site-host","title":"Prerequisites"},{"location":"apis/site-entry/#configuration","text":"Using xs-app.json file the wrapped Approuter component can be configured.","title":"Configuration"},{"location":"apis/site-entry/#supported","text":"This component can be used only on HANA XSA SP1 with a compatible versions of: SAP UI5 portal-service sap-site-content-deployer","title":"Supported"},{"location":"apis/site-entry/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 1.9.29 - 2020-05-20 \u00b6 Updated dependencies \u00b6 deps: @sap/logging@5.1.0 1.9.28 - 2020-05-07 \u00b6 Added \u00b6 CHANGELOG.md Fixed \u00b6 Updated dependencies \u00b6 deps: @sap/approuter@7.1.1","title":"Change Log"},{"location":"apis/site-entry/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/site-entry/CHANGELOG/#1929-2020-05-20","text":"","title":"1.9.29 - 2020-05-20"},{"location":"apis/site-entry/CHANGELOG/#updated-dependencies","text":"deps: @sap/logging@5.1.0","title":"Updated dependencies"},{"location":"apis/site-entry/CHANGELOG/#1928-2020-05-07","text":"","title":"1.9.28 - 2020-05-07"},{"location":"apis/site-entry/CHANGELOG/#added","text":"CHANGELOG.md","title":"Added"},{"location":"apis/site-entry/CHANGELOG/#fixed","text":"","title":"Fixed"},{"location":"apis/site-entry/CHANGELOG/#updated-dependencies_1","text":"deps: @sap/approuter@7.1.1","title":"Updated dependencies"},{"location":"apis/test-nodejs-dmz-github/","text":"test-nodejs-dmz \u00b6","title":"test-nodejs-dmz"},{"location":"apis/test-nodejs-dmz-github/#test-nodejs-dmz","text":"","title":"test-nodejs-dmz"},{"location":"apis/textanalysis/","text":"@sap/textanalysis \u00b6 @sap/textanalysis is a Node.js module on the XS Advanced platform that supports text analysis. Text analysis performs linguistic analysis and entity extraction on unstructured text documents. @sap/textanalysis is implemented as an interface to the TA_ANALYZE SQL stored procedure. It provides the following single API function: - analyze() For more information on text analysis and the TA_ANALYZE stored procedure, see the Text Analysis Developer Guide . Note that TA_ANALYZE and @sap/textanalysis is only available on HANA 2.0 and later versions. Usage example \u00b6 First, a HANA database connection must be established (either with hdb or with @sap/hana-client). Then the client database object can be passed to the analyze method along with the input parameters. The input parameters set the input variables to the TA_ANALYZE stored procedure. var ta = require ( '@sap/textanalysis' ); var client ; var options = { host : process . env . HANA_HOST , port : process . env . HANA_PORT , user : process . env . HANA_USER || 'system' , password : process . env . HANA_PASSWORD || 'manager' , }; async . series ([ function connect ( callback ) { client = hdb . createClient ( options ); client . connect ( callback ); }, function analyze ( callback ) { var values = { DOCUMENT_TEXT : '<!DOCTYPE html><html><body><h1>My First Heading</h1><p>My first paragraph.</p></body></html>' , LANGUAGE_CODE : 'EN' , CONFIGURATION : 'EXTRACTION_CORE' , RETURN_PLAINTEXT : 0 }; ta . analyze ( values , client , function done ( err , parameters , rows ) { if ( err ) { return console . error ( 'error' , err ); } callback (); }); }, function end ( callback ) { client . end ( callback ); }], done );","title":"@sap/textanalysis"},{"location":"apis/textanalysis/#saptextanalysis","text":"@sap/textanalysis is a Node.js module on the XS Advanced platform that supports text analysis. Text analysis performs linguistic analysis and entity extraction on unstructured text documents. @sap/textanalysis is implemented as an interface to the TA_ANALYZE SQL stored procedure. It provides the following single API function: - analyze() For more information on text analysis and the TA_ANALYZE stored procedure, see the Text Analysis Developer Guide . Note that TA_ANALYZE and @sap/textanalysis is only available on HANA 2.0 and later versions.","title":"@sap/textanalysis"},{"location":"apis/textanalysis/#usage-example","text":"First, a HANA database connection must be established (either with hdb or with @sap/hana-client). Then the client database object can be passed to the analyze method along with the input parameters. The input parameters set the input variables to the TA_ANALYZE stored procedure. var ta = require ( '@sap/textanalysis' ); var client ; var options = { host : process . env . HANA_HOST , port : process . env . HANA_PORT , user : process . env . HANA_USER || 'system' , password : process . env . HANA_PASSWORD || 'manager' , }; async . series ([ function connect ( callback ) { client = hdb . createClient ( options ); client . connect ( callback ); }, function analyze ( callback ) { var values = { DOCUMENT_TEXT : '<!DOCTYPE html><html><body><h1>My First Heading</h1><p>My first paragraph.</p></body></html>' , LANGUAGE_CODE : 'EN' , CONFIGURATION : 'EXTRACTION_CORE' , RETURN_PLAINTEXT : 0 }; ta . analyze ( values , client , function done ( err , parameters , rows ) { if ( err ) { return console . error ( 'error' , err ); } callback (); }); }, function end ( callback ) { client . end ( callback ); }], done );","title":"Usage example"},{"location":"apis/textbundle/","text":"@sap/textbundle \u00b6 Simple tool for text internationalization in Node.js. Based on the same concept as SAP UI5, this module works with UTF-8 encoded properties files. Language defaulting is also borrowed from SAP UI5 with the idea the UI and server-side code use the same text internationalization approach. API documentation \u00b6 Usage \u00b6 Assuming you have these files in directory ./test/properties: i18n_en_EN.properties greeting = Hello {0}, you are {1} years old. i18n_de.properties greeting = Hallo {0}, Sie sind {1} Jahre alt. Creating a TextBundle \u00b6 Old API \u00b6 var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var bundle = new TextBundle ({ path : 'test/properties/i18n' , locale : 'en_EN' } ); New API \u00b6 var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var bundle = new TextBundle ( 'test/properties/i18n' , 'en_EN' ); Constructing localized messages \u00b6 var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var bundle = new TextBundle ( path . resolve ( __dirname , 'test/properties/i18n' ), 'en_EN' ); bundle . getText ( 'greeting' ); // will return 'Hello {0}, you are {1} years old.' bundle . getText ( 'greeting' , [ 'Stefan' ]); // will return 'Hello Stefan, you are undefined years old.' bundle . getText ( 'greeting' , [ 'Stefan' , '21' ]); // will return 'Hello Stefan, you are 21 years old.' // using DE locale var bundle = new TextBundle ( path . resolve ( __dirname , 'test/properties/i18n' ), 'de' ); bundle . getText ( 'greeting' , [ 'Stefan' , '21' ]); // will return 'Hallo Stefan, Sie sind 21 Jahre alt.' Loading bundles \u00b6 Bundles can be loaded by providing the absolute path to the resource bundle or relative path. If relative a path is used it will be resolved with respect to your JavaScript file. Absolute path to the resource bundle should be favored for TextBundles. Default file extension is .properties . If your file has a different extension, you just need to append it to the path you provide. The format of the file still has to be UTF-8, and the structure has to be properties-like. var TextBundle = require ( '@sap/textbundle' ); var txtBundle = new TextBundle ({ path : './test/txt/i18n.txt' }); Getting texts and language defaulting \u00b6 Getting text is straight forward - shown on the examples above already. Message retrieval from properties files is done using fall-back mechanism that searches for the provided key in a hierarchical order and returns the text associated with this key from the first occurrence in some of the files. Following order is applied when text is retrieved for specific locale: language -> country -> en -> root -> 'not-found, return the key' A simple example: locale is 'de_DE', bundle name is 'i18n', the order in which properties files are checked for key existence is following: i18n_de_DE i18n_de i18n_en i18n // if not found, the key is returned back Locale fallback \u00b6 The static function TextBundle.fallbackLocale returns the fallback of a given locale (e.g. 'fr_FR' => 'fr' => 'en' => ''). This lets you set up a locale fallback chain for your own purpose. var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var parent = TextBundle . fallbackLocale ( 'en_US' ); ResourceManager \u00b6 ResourceManager class allows managing resources for your module by caching the various TextBundle in order to avoid repeatedly loading them. var ResourceManager = require ( '@sap/textbundle' ). ResourceManager ; var rm = new ResourceManager ( path . resolve ( __dirname , 'test/properties/i18n' )); var bundle = rm . getTextBundle ( 'en_EN' ); bundle . getText ( 'greeting' ); Asynchronous resource loading \u00b6 In order to improve server scalability, resources should be loaded through asynchronous file system operations. var ResourceManager = require ( '@sap/textbundle' ). ResourceManager ; var rm = new ResourceManager ( path . resolve ( __dirname , 'test/properties/i18n' )); rm . loadTextBundle ( 'en_EN' ) . then ( function ( bundle ) { bundle . getText ( 'greeting' ); }); Resource loading middleware \u00b6 var ResourceManager = require ( '@sap/textbundle' ). ResourceManager ; var rm = new ResourceManager ( path . resolve ( __dirname , 'test/properties/i18n' )); var express = require ( 'express' ); var app = express (); function requestLocale ( req ) { var locale = req . locale = req . acceptsLanguages ([ 'en-US' , 'en' , 'de-DE' , 'de' , 'fr-FR' , 'fr' ]) || 'en' ; return locale ; } app . use ( '/' , rm . getMiddleware ( requestLocale )); app . use ( '/myHandler' , function ( req , res , next ) { // resources for request locale have been loaded at this stage var bundle = rm . getTextBundle ( req . locale ); bundle . getText ( 'greeting' ); });","title":"Index"},{"location":"apis/textbundle/#saptextbundle","text":"Simple tool for text internationalization in Node.js. Based on the same concept as SAP UI5, this module works with UTF-8 encoded properties files. Language defaulting is also borrowed from SAP UI5 with the idea the UI and server-side code use the same text internationalization approach.","title":"@sap/textbundle"},{"location":"apis/textbundle/#api-documentation","text":"","title":"API documentation"},{"location":"apis/textbundle/#usage","text":"Assuming you have these files in directory ./test/properties: i18n_en_EN.properties greeting = Hello {0}, you are {1} years old. i18n_de.properties greeting = Hallo {0}, Sie sind {1} Jahre alt.","title":"Usage"},{"location":"apis/textbundle/#creating-a-textbundle","text":"","title":"Creating a TextBundle"},{"location":"apis/textbundle/#old-api","text":"var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var bundle = new TextBundle ({ path : 'test/properties/i18n' , locale : 'en_EN' } );","title":"Old API"},{"location":"apis/textbundle/#new-api","text":"var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var bundle = new TextBundle ( 'test/properties/i18n' , 'en_EN' );","title":"New API"},{"location":"apis/textbundle/#constructing-localized-messages","text":"var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var bundle = new TextBundle ( path . resolve ( __dirname , 'test/properties/i18n' ), 'en_EN' ); bundle . getText ( 'greeting' ); // will return 'Hello {0}, you are {1} years old.' bundle . getText ( 'greeting' , [ 'Stefan' ]); // will return 'Hello Stefan, you are undefined years old.' bundle . getText ( 'greeting' , [ 'Stefan' , '21' ]); // will return 'Hello Stefan, you are 21 years old.' // using DE locale var bundle = new TextBundle ( path . resolve ( __dirname , 'test/properties/i18n' ), 'de' ); bundle . getText ( 'greeting' , [ 'Stefan' , '21' ]); // will return 'Hallo Stefan, Sie sind 21 Jahre alt.'","title":"Constructing localized messages"},{"location":"apis/textbundle/#loading-bundles","text":"Bundles can be loaded by providing the absolute path to the resource bundle or relative path. If relative a path is used it will be resolved with respect to your JavaScript file. Absolute path to the resource bundle should be favored for TextBundles. Default file extension is .properties . If your file has a different extension, you just need to append it to the path you provide. The format of the file still has to be UTF-8, and the structure has to be properties-like. var TextBundle = require ( '@sap/textbundle' ); var txtBundle = new TextBundle ({ path : './test/txt/i18n.txt' });","title":"Loading bundles"},{"location":"apis/textbundle/#getting-texts-and-language-defaulting","text":"Getting text is straight forward - shown on the examples above already. Message retrieval from properties files is done using fall-back mechanism that searches for the provided key in a hierarchical order and returns the text associated with this key from the first occurrence in some of the files. Following order is applied when text is retrieved for specific locale: language -> country -> en -> root -> 'not-found, return the key' A simple example: locale is 'de_DE', bundle name is 'i18n', the order in which properties files are checked for key existence is following: i18n_de_DE i18n_de i18n_en i18n // if not found, the key is returned back","title":"Getting texts and language defaulting"},{"location":"apis/textbundle/#locale-fallback","text":"The static function TextBundle.fallbackLocale returns the fallback of a given locale (e.g. 'fr_FR' => 'fr' => 'en' => ''). This lets you set up a locale fallback chain for your own purpose. var TextBundle = require ( '@sap/textbundle' ). TextBundle ; var parent = TextBundle . fallbackLocale ( 'en_US' );","title":"Locale fallback"},{"location":"apis/textbundle/#resourcemanager","text":"ResourceManager class allows managing resources for your module by caching the various TextBundle in order to avoid repeatedly loading them. var ResourceManager = require ( '@sap/textbundle' ). ResourceManager ; var rm = new ResourceManager ( path . resolve ( __dirname , 'test/properties/i18n' )); var bundle = rm . getTextBundle ( 'en_EN' ); bundle . getText ( 'greeting' );","title":"ResourceManager"},{"location":"apis/textbundle/#asynchronous-resource-loading","text":"In order to improve server scalability, resources should be loaded through asynchronous file system operations. var ResourceManager = require ( '@sap/textbundle' ). ResourceManager ; var rm = new ResourceManager ( path . resolve ( __dirname , 'test/properties/i18n' )); rm . loadTextBundle ( 'en_EN' ) . then ( function ( bundle ) { bundle . getText ( 'greeting' ); });","title":"Asynchronous resource loading"},{"location":"apis/textbundle/#resource-loading-middleware","text":"var ResourceManager = require ( '@sap/textbundle' ). ResourceManager ; var rm = new ResourceManager ( path . resolve ( __dirname , 'test/properties/i18n' )); var express = require ( 'express' ); var app = express (); function requestLocale ( req ) { var locale = req . locale = req . acceptsLanguages ([ 'en-US' , 'en' , 'de-DE' , 'de' , 'fr-FR' , 'fr' ]) || 'en' ; return locale ; } app . use ( '/' , rm . getMiddleware ( requestLocale )); app . use ( '/myHandler' , function ( req , res , next ) { // resources for request locale have been loaded at this stage var bundle = rm . getTextBundle ( req . locale ); bundle . getText ( 'greeting' ); });","title":"Resource loading middleware"},{"location":"apis/textbundle/API/","text":"Classes \u00b6 PropertiesParser Parse a Java .properties definition ResourceManager ResourceManager class manages a collection of localized text bundles TextBundle TextBundle classes manages text resources for a given locale. PropertiesParser \u00b6 Parse a Java .properties definition Kind : global class PropertiesParser new PropertiesParser(content) .load(propertyFile) \u21d2 Promise .loadSync(propertyFile) \u21d2 PropertiesParser new PropertiesParser(content) \u00b6 Param Type Description content string Content of the .properties file to parse PropertiesParser.load(propertyFile) \u21d2 Promise \u00b6 Loads and parses a .properties file Kind : static method of PropertiesParser Returns : Promise - Returns a promise eventually fulfilled to a newly created PropertiesParser Param Type Description propertyFile string Path to the .properties file (must be UTF-8 encoded) PropertiesParser.loadSync(propertyFile) \u21d2 PropertiesParser \u00b6 Loads and parses synchronously a .properties file Kind : static method of PropertiesParser Returns : PropertiesParser - Returns a newly created PropertiesParser Param Type Description propertyFile string Path to the .properties file (must be UTF-8 encoded) ResourceManager \u00b6 ResourceManager class manages a collection of localized text bundles Kind : global class Properties Name Type Description logger Logger Logger object which can be injected on the ResourceManager instance. It should have a bunyan/sap-json-logging compatible API. ResourceManager new ResourceManager(basePath) .getTextBundle(locale) \u21d2 TextBundle .loadTextBundle(locale) \u21d2 Promise .getMiddleware([localeAccessor]) \u21d2 function new ResourceManager(basePath) \u00b6 Param Type Description basePath string Base path of the localized text resource files resourceManager.getTextBundle(locale) \u21d2 TextBundle \u00b6 Returns a TextBundle for a given locale Kind : instance method of ResourceManager Param Type locale string resourceManager.loadTextBundle(locale) \u21d2 Promise \u00b6 Retrieves a TextBundle for a given locale. Resources for the locale are loaded if they are not yet available. Kind : instance method of ResourceManager Returns : Promise - Promise eventually fulfilled to a TextBundle for the requested locale Param Type locale string resourceManager.getMiddleware([localeAccessor]) \u21d2 function \u00b6 Returns a middleware function taking care of loading the resources for the request locale. Kind : instance method of ResourceManager Param Type Default Description [localeAccessor] string | function \"'locale'\" Accessor property of function to extract the locale from the HTTP Request. Default to 'locale' (i.e. locale is req.locale) TextBundle \u00b6 TextBundle classes manages text resources for a given locale. Kind : global class Properties Name Type Description locale string TestBundle main locale TextBundle new TextBundle([propertyFile], [locale], [options]) instance .getLocale() \u21d2 string .getText(key, [...args]) \u21d2 string .load() \u21d2 Promise .loadSync() static .fallbackLocale \u21d2 string new TextBundle([propertyFile], [locale], [options]) \u00b6 Param Type Description [propertyFile] string Path to the base text resource property file. If not provided, options.path is taken. Either propertyFile or options.path must be provided. [locale] string Bundle locale (use of standard BCP 47 locales is recommended, POSIX is supported), default to 'en'. 'propertyFile' argument is required to be able to pass locale as string argument. [options] object Bundle options (for legacy compatibility). options.locale string Bundle locale (for legacy compatibility). options.path string Path to the base text resource property file (for legacy compatibility). textBundle.getLocale() \u21d2 string \u00b6 Returns the TextBundle main locale Kind : instance method of TextBundle textBundle.getText(key, [...args]) \u21d2 string \u00b6 Returns a formatted message for the given resource key and arguments Kind : instance method of TextBundle Param Type Description key string Resoruce key [...args] object textBundle.load() \u21d2 Promise \u00b6 Asynchronously loads a bundle resources (including the full fallback chain) Kind : instance method of TextBundle Returns : Promise - Promise eventually fulfilled to the bundle. textBundle.loadSync() \u00b6 Synchronously loads a bundle resources for its main locale (without the fallback chain) Kind : instance method of TextBundle TextBundle.fallbackLocale \u21d2 string \u00b6 Returns the fallback of a given locale (e.g. 'fr_FR' => 'fr' => 'en' => '') Kind : static property of TextBundle Param Type locale string","title":"API"},{"location":"apis/textbundle/API/#classes","text":"PropertiesParser Parse a Java .properties definition ResourceManager ResourceManager class manages a collection of localized text bundles TextBundle TextBundle classes manages text resources for a given locale.","title":"Classes"},{"location":"apis/textbundle/API/#propertiesparser","text":"Parse a Java .properties definition Kind : global class PropertiesParser new PropertiesParser(content) .load(propertyFile) \u21d2 Promise .loadSync(propertyFile) \u21d2 PropertiesParser","title":"PropertiesParser"},{"location":"apis/textbundle/API/#new-propertiesparsercontent","text":"Param Type Description content string Content of the .properties file to parse","title":"new PropertiesParser(content)"},{"location":"apis/textbundle/API/#propertiesparserloadpropertyfile-promise","text":"Loads and parses a .properties file Kind : static method of PropertiesParser Returns : Promise - Returns a promise eventually fulfilled to a newly created PropertiesParser Param Type Description propertyFile string Path to the .properties file (must be UTF-8 encoded)","title":"PropertiesParser.load(propertyFile) \u21d2 Promise"},{"location":"apis/textbundle/API/#propertiesparserloadsyncpropertyfile-propertiesparser","text":"Loads and parses synchronously a .properties file Kind : static method of PropertiesParser Returns : PropertiesParser - Returns a newly created PropertiesParser Param Type Description propertyFile string Path to the .properties file (must be UTF-8 encoded)","title":"PropertiesParser.loadSync(propertyFile) \u21d2 PropertiesParser"},{"location":"apis/textbundle/API/#resourcemanager","text":"ResourceManager class manages a collection of localized text bundles Kind : global class Properties Name Type Description logger Logger Logger object which can be injected on the ResourceManager instance. It should have a bunyan/sap-json-logging compatible API. ResourceManager new ResourceManager(basePath) .getTextBundle(locale) \u21d2 TextBundle .loadTextBundle(locale) \u21d2 Promise .getMiddleware([localeAccessor]) \u21d2 function","title":"ResourceManager"},{"location":"apis/textbundle/API/#new-resourcemanagerbasepath","text":"Param Type Description basePath string Base path of the localized text resource files","title":"new ResourceManager(basePath)"},{"location":"apis/textbundle/API/#resourcemanagergettextbundlelocale-textbundle","text":"Returns a TextBundle for a given locale Kind : instance method of ResourceManager Param Type locale string","title":"resourceManager.getTextBundle(locale) \u21d2 TextBundle"},{"location":"apis/textbundle/API/#resourcemanagerloadtextbundlelocale-promise","text":"Retrieves a TextBundle for a given locale. Resources for the locale are loaded if they are not yet available. Kind : instance method of ResourceManager Returns : Promise - Promise eventually fulfilled to a TextBundle for the requested locale Param Type locale string","title":"resourceManager.loadTextBundle(locale) \u21d2 Promise"},{"location":"apis/textbundle/API/#resourcemanagergetmiddlewarelocaleaccessor-function","text":"Returns a middleware function taking care of loading the resources for the request locale. Kind : instance method of ResourceManager Param Type Default Description [localeAccessor] string | function \"'locale'\" Accessor property of function to extract the locale from the HTTP Request. Default to 'locale' (i.e. locale is req.locale)","title":"resourceManager.getMiddleware([localeAccessor]) \u21d2 function"},{"location":"apis/textbundle/API/#textbundle","text":"TextBundle classes manages text resources for a given locale. Kind : global class Properties Name Type Description locale string TestBundle main locale TextBundle new TextBundle([propertyFile], [locale], [options]) instance .getLocale() \u21d2 string .getText(key, [...args]) \u21d2 string .load() \u21d2 Promise .loadSync() static .fallbackLocale \u21d2 string","title":"TextBundle"},{"location":"apis/textbundle/API/#new-textbundlepropertyfile-locale-options","text":"Param Type Description [propertyFile] string Path to the base text resource property file. If not provided, options.path is taken. Either propertyFile or options.path must be provided. [locale] string Bundle locale (use of standard BCP 47 locales is recommended, POSIX is supported), default to 'en'. 'propertyFile' argument is required to be able to pass locale as string argument. [options] object Bundle options (for legacy compatibility). options.locale string Bundle locale (for legacy compatibility). options.path string Path to the base text resource property file (for legacy compatibility).","title":"new TextBundle([propertyFile], [locale], [options])"},{"location":"apis/textbundle/API/#textbundlegetlocale-string","text":"Returns the TextBundle main locale Kind : instance method of TextBundle","title":"textBundle.getLocale() \u21d2 string"},{"location":"apis/textbundle/API/#textbundlegettextkey-args-string","text":"Returns a formatted message for the given resource key and arguments Kind : instance method of TextBundle Param Type Description key string Resoruce key [...args] object","title":"textBundle.getText(key, [...args]) \u21d2 string"},{"location":"apis/textbundle/API/#textbundleload-promise","text":"Asynchronously loads a bundle resources (including the full fallback chain) Kind : instance method of TextBundle Returns : Promise - Promise eventually fulfilled to the bundle.","title":"textBundle.load() \u21d2 Promise"},{"location":"apis/textbundle/API/#textbundleloadsync","text":"Synchronously loads a bundle resources for its main locale (without the fallback chain) Kind : instance method of TextBundle","title":"textBundle.loadSync()"},{"location":"apis/textbundle/API/#textbundlefallbacklocale-string","text":"Returns the fallback of a given locale (e.g. 'fr_FR' => 'fr' => 'en' => '') Kind : static property of TextBundle Param Type locale string","title":"TextBundle.fallbackLocale \u21d2 string"},{"location":"apis/textbundle/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 3.1.0 - 2019-12-06 \u00b6 Added \u00b6 Node.js 12.x support. 3.0.0 - 2019-05-02 \u00b6 Removed \u00b6 Node.js v0.12 support Node.js v4 support 2.3.0 - 2018-12-18 \u00b6 Added \u00b6 Node.js version 10 support 2.2.1 - 2018-02-07 \u00b6 Fixed \u00b6 Missing typings from package 2.2.0 - 2018-01-09 \u00b6 Added \u00b6 Node.js version 8 support CHANGELOG.md Typings 2.1.0 - 2017-07-04 \u00b6 Added \u00b6 Static function TextBundle.fallbackLocale. 2.0.6 - 2017-01-25 \u00b6 Changed \u00b6 Rename package to use @sap scope.","title":"Change Log"},{"location":"apis/textbundle/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/textbundle/CHANGELOG/#310-2019-12-06","text":"","title":"3.1.0 - 2019-12-06"},{"location":"apis/textbundle/CHANGELOG/#added","text":"Node.js 12.x support.","title":"Added"},{"location":"apis/textbundle/CHANGELOG/#300-2019-05-02","text":"","title":"3.0.0 - 2019-05-02"},{"location":"apis/textbundle/CHANGELOG/#removed","text":"Node.js v0.12 support Node.js v4 support","title":"Removed"},{"location":"apis/textbundle/CHANGELOG/#230-2018-12-18","text":"","title":"2.3.0 - 2018-12-18"},{"location":"apis/textbundle/CHANGELOG/#added_1","text":"Node.js version 10 support","title":"Added"},{"location":"apis/textbundle/CHANGELOG/#221-2018-02-07","text":"","title":"2.2.1 - 2018-02-07"},{"location":"apis/textbundle/CHANGELOG/#fixed","text":"Missing typings from package","title":"Fixed"},{"location":"apis/textbundle/CHANGELOG/#220-2018-01-09","text":"","title":"2.2.0 - 2018-01-09"},{"location":"apis/textbundle/CHANGELOG/#added_2","text":"Node.js version 8 support CHANGELOG.md Typings","title":"Added"},{"location":"apis/textbundle/CHANGELOG/#210-2017-07-04","text":"","title":"2.1.0 - 2017-07-04"},{"location":"apis/textbundle/CHANGELOG/#added_3","text":"Static function TextBundle.fallbackLocale.","title":"Added"},{"location":"apis/textbundle/CHANGELOG/#206-2017-01-25","text":"","title":"2.0.6 - 2017-01-25"},{"location":"apis/textbundle/CHANGELOG/#changed","text":"Rename package to use @sap scope.","title":"Changed"},{"location":"apis/textmining/","text":"@sap/textmining \u00b6 @sap/textmining is a Node.js module on the XS Advanced platform that supports text mining. Text mining makes determinations about the content of unstructured text documents by examining the terms used within them. @sap/textmining is implemented as an interface to the Text Mining SQL API in HANA. The API functions and parameters follow the pattern of the Text Mining XS Classic API: - categorizeKNN() - getRelatedDocuments() - getRelatedTerms() - getRelevantDocuments() - getRelevantTerms() - getSuggestedTerms() - initialize() For more information on the Text Mining SQL API, see the SAP HANA SQL and System Views Reference section Advanced Data Processing . For initialize() , refer to the section ALTER FULLTEXT INDEX . For more information on the Text Mining XS Classic API, see the SAP HANA Text Mining XS JavaScript API Reference . For more information on text mining, see the SAP HANA Text Mining Developer Guide . Usage example \u00b6 var textmining = require ( '@sap/textmining' ); var hdb = require ( 'hdb' ); var db = { \"host\" : \"HOST\" , \"port\" : 3 XX15 , \"user\" : \"USERNAME\" , \"password\" : \"PASSWORD\" } var client = hdb . createClient ({ host : db . host , port : db . port , user : db . user , password : db . password }); var p = { inputTermText : \"term\" , top : 10 , threshold : 0.3 } var config = { client : client , referenceTable : 'SCHEMA.TABLE' , referenceColumn : 'COLUMN' } var tmd = new textmining ( config ); client . connect ( function ( err ){ if ( err ) { client . end (); throw err ; return ; } tmd . getSuggestedTerms ( p , function ( err , result ){ if ( err ) { client . end (); throw err ; return ; } console . log ( result ); client . end (); }); });","title":"@sap/textmining"},{"location":"apis/textmining/#saptextmining","text":"@sap/textmining is a Node.js module on the XS Advanced platform that supports text mining. Text mining makes determinations about the content of unstructured text documents by examining the terms used within them. @sap/textmining is implemented as an interface to the Text Mining SQL API in HANA. The API functions and parameters follow the pattern of the Text Mining XS Classic API: - categorizeKNN() - getRelatedDocuments() - getRelatedTerms() - getRelevantDocuments() - getRelevantTerms() - getSuggestedTerms() - initialize() For more information on the Text Mining SQL API, see the SAP HANA SQL and System Views Reference section Advanced Data Processing . For initialize() , refer to the section ALTER FULLTEXT INDEX . For more information on the Text Mining XS Classic API, see the SAP HANA Text Mining XS JavaScript API Reference . For more information on text mining, see the SAP HANA Text Mining Developer Guide .","title":"@sap/textmining"},{"location":"apis/textmining/#usage-example","text":"var textmining = require ( '@sap/textmining' ); var hdb = require ( 'hdb' ); var db = { \"host\" : \"HOST\" , \"port\" : 3 XX15 , \"user\" : \"USERNAME\" , \"password\" : \"PASSWORD\" } var client = hdb . createClient ({ host : db . host , port : db . port , user : db . user , password : db . password }); var p = { inputTermText : \"term\" , top : 10 , threshold : 0.3 } var config = { client : client , referenceTable : 'SCHEMA.TABLE' , referenceColumn : 'COLUMN' } var tmd = new textmining ( config ); client . connect ( function ( err ){ if ( err ) { client . end (); throw err ; return ; } tmd . getSuggestedTerms ( p , function ( err , result ){ if ( err ) { client . end (); throw err ; return ; } console . log ( result ); client . end (); }); });","title":"Usage example"},{"location":"apis/ui-annotations/","text":"sap-ui-annotations \u00b6 UI Annotations The purpose of this module is to provide UI Annotation Definitions required for CDS to OData exposure on XSA Plateform. How to Use this module: 1) Create package.json file under db module in an MTA project if already not present. 2) Add dependency to the sap-ui-annotations module like below: { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-deploy\": \"2.3.0\", \"@sap/ui-annotations\": \"2.0.3\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-deploy/deploy.js\" } } Please Note - The version number are subject to change for both the modules used above.","title":"sap-ui-annotations"},{"location":"apis/ui-annotations/#sap-ui-annotations","text":"UI Annotations The purpose of this module is to provide UI Annotation Definitions required for CDS to OData exposure on XSA Plateform. How to Use this module: 1) Create package.json file under db module in an MTA project if already not present. 2) Add dependency to the sap-ui-annotations module like below: { \"name\": \"deploy\", \"dependencies\": { \"@sap/hdi-deploy\": \"2.3.0\", \"@sap/ui-annotations\": \"2.0.3\" }, \"scripts\": { \"start\": \"node node_modules/@sap/hdi-deploy/deploy.js\" } } Please Note - The version number are subject to change for both the modules used above.","title":"sap-ui-annotations"},{"location":"apis/xb-msg/","text":"Stream-based Messaging \u00b6 Provides a client for stream-based messaging. Table of contents \u00b6 Prerequisites Install Overview Getting started API Examples Prerequisites \u00b6 Make sure to have an message broker available, e.g. RabbitMQ . Install \u00b6 Direct from GIT npm install @sap/xb-msg Overview \u00b6 A messaging application shall focus on its business logic. Bindings and protocol-specific settings shall move to configuration, without negative impact on performance. The package provides a solution for that, wrapping protocol-specific client implementations from separate packages. The following protocols are supported: * AMQP v0.9.1 * AMQP v1.0.0 * MQTT v3.1.1 After the client is created and connected the application can start writing to and/or reading from named stream instances. Based on the client options one or more connections will be created, each for one of the supported protocols and each providing mutiple inbound or outbound streams. All stream IDs must be unique in the scope of one client instance. In the simplest case the options are taken from environment variables (e.g. cf user-provided-service, see package @sap/xb-msg-env). Hence, switching the protocol, changing the binding to queues or topics or changing the quality of service becomes possible without changing the program code, the latter of course only if messages done/failed callbacks are already invoked at the appropriate point in time. The options start with host, port and credentials, but go optionally also down to fine-tuning of chunk sizes and high-water-marks. If more precise control on protocol-level is needed then the underlying protocol-specific clients can be used directly, accepting a direct dependency, but getting more fine-grained control. API \u00b6 Create a messaging client and start consuming messages. const msg = require ( '@sap/xb-msg' ) ; const env = require ( '@sap/xb-msg-env' ) ; /* get options from cf/xsa environment */ const options = env.msgClientOptions ( 'msg-instance-01' , [ 'MyInpA' ] , []) ; /* start messaging */ const client = new msg.Client ( options ) ; client.istream ( 'MyInpA' ) .on ( 'subscribed' , () = > { console.log ( 'subscribed' ) ; }) .on ( 'data' , ( message ) = > { console.log ( 'message: ' + message.payload.toString ()) ; message.done () ; }) ; client.connect () ; Create a messaging client and start producing messages. const msg = require ( '@sap/xb-msg' ) ; const env = require ( '@sap/xb-msg-env' ) ; /* get options from cf/xsa environment */ const options = env.msgClientOptions ( 'msg-instance-01' , [] , [ 'MyOutB' ]) ; /* start messaging */ const client = new msg.Client ( options ) ; client.ostream ( 'MyOutA' ) .on ( 'ready' , () = > { send () ; }) .on ( 'drain' , () = > { send () ; }) .on ( 'error' , ( error ) = > { console.log ( error ) ; }) ; client.connect () ; Create a messaging client and use an own transform stream as message converter. const msg = require ( '@sap/xb-msg' ) ; const env = require ( '@sap/xb-msg-env' ) ; /* get options from cf/xsa environment */ const options = env.msgClientOptions ( 'msg-instance-01' , [ 'MyInpA' ] , [ 'MyOutB' ]) ; /* start messaging */ const client = new msg.Client ( options ) ; client.istream ( 'MyInpA' ) .pipe ( new Converter ()) .pipe ( client.ostream ( 'MyOutB' )) ; client.connect () ; Connections via 'net' and 'tls' are supported for all protocols. For MQTT also WebSocket via 'https' or 'http' can be used. If multiple settings are provided the preference is as follows: preferred 'tls' then 'net' then 'wss' then finally 'ws'. Examples \u00b6 In folder 'examples' there are test programs, ready to run if a broker can be reached locally at the protocol-specific default port. Folder 'examples/cfg' provides sample configurations.","title":"Stream-based Messaging"},{"location":"apis/xb-msg/#stream-based-messaging","text":"Provides a client for stream-based messaging.","title":"Stream-based Messaging"},{"location":"apis/xb-msg/#table-of-contents","text":"Prerequisites Install Overview Getting started API Examples","title":"Table of contents"},{"location":"apis/xb-msg/#prerequisites","text":"Make sure to have an message broker available, e.g. RabbitMQ .","title":"Prerequisites"},{"location":"apis/xb-msg/#install","text":"Direct from GIT npm install @sap/xb-msg","title":"Install"},{"location":"apis/xb-msg/#overview","text":"A messaging application shall focus on its business logic. Bindings and protocol-specific settings shall move to configuration, without negative impact on performance. The package provides a solution for that, wrapping protocol-specific client implementations from separate packages. The following protocols are supported: * AMQP v0.9.1 * AMQP v1.0.0 * MQTT v3.1.1 After the client is created and connected the application can start writing to and/or reading from named stream instances. Based on the client options one or more connections will be created, each for one of the supported protocols and each providing mutiple inbound or outbound streams. All stream IDs must be unique in the scope of one client instance. In the simplest case the options are taken from environment variables (e.g. cf user-provided-service, see package @sap/xb-msg-env). Hence, switching the protocol, changing the binding to queues or topics or changing the quality of service becomes possible without changing the program code, the latter of course only if messages done/failed callbacks are already invoked at the appropriate point in time. The options start with host, port and credentials, but go optionally also down to fine-tuning of chunk sizes and high-water-marks. If more precise control on protocol-level is needed then the underlying protocol-specific clients can be used directly, accepting a direct dependency, but getting more fine-grained control.","title":"Overview"},{"location":"apis/xb-msg/#api","text":"Create a messaging client and start consuming messages. const msg = require ( '@sap/xb-msg' ) ; const env = require ( '@sap/xb-msg-env' ) ; /* get options from cf/xsa environment */ const options = env.msgClientOptions ( 'msg-instance-01' , [ 'MyInpA' ] , []) ; /* start messaging */ const client = new msg.Client ( options ) ; client.istream ( 'MyInpA' ) .on ( 'subscribed' , () = > { console.log ( 'subscribed' ) ; }) .on ( 'data' , ( message ) = > { console.log ( 'message: ' + message.payload.toString ()) ; message.done () ; }) ; client.connect () ; Create a messaging client and start producing messages. const msg = require ( '@sap/xb-msg' ) ; const env = require ( '@sap/xb-msg-env' ) ; /* get options from cf/xsa environment */ const options = env.msgClientOptions ( 'msg-instance-01' , [] , [ 'MyOutB' ]) ; /* start messaging */ const client = new msg.Client ( options ) ; client.ostream ( 'MyOutA' ) .on ( 'ready' , () = > { send () ; }) .on ( 'drain' , () = > { send () ; }) .on ( 'error' , ( error ) = > { console.log ( error ) ; }) ; client.connect () ; Create a messaging client and use an own transform stream as message converter. const msg = require ( '@sap/xb-msg' ) ; const env = require ( '@sap/xb-msg-env' ) ; /* get options from cf/xsa environment */ const options = env.msgClientOptions ( 'msg-instance-01' , [ 'MyInpA' ] , [ 'MyOutB' ]) ; /* start messaging */ const client = new msg.Client ( options ) ; client.istream ( 'MyInpA' ) .pipe ( new Converter ()) .pipe ( client.ostream ( 'MyOutB' )) ; client.connect () ; Connections via 'net' and 'tls' are supported for all protocols. For MQTT also WebSocket via 'https' or 'http' can be used. If multiple settings are provided the preference is as follows: preferred 'tls' then 'net' then 'wss' then finally 'ws'.","title":"API"},{"location":"apis/xb-msg/#examples","text":"In folder 'examples' there are test programs, ready to run if a broker can be reached locally at the protocol-specific default port. Folder 'examples/cfg' provides sample configurations.","title":"Examples"},{"location":"apis/xb-msg/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Unreleased \u00b6 Added \u00b6 support of the amqp v100 protocol with QoS at least once Changed \u00b6 Removed \u00b6","title":"Change Log"},{"location":"apis/xb-msg/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xb-msg/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"apis/xb-msg/CHANGELOG/#added","text":"support of the amqp v100 protocol with QoS at least once","title":"Added"},{"location":"apis/xb-msg/CHANGELOG/#changed","text":"","title":"Changed"},{"location":"apis/xb-msg/CHANGELOG/#removed","text":"","title":"Removed"},{"location":"apis/xb-msg-amqp-v091/","text":"AMQP 0.9.1 Client Library \u00b6 Provides a client implementation for AMQP v0.9.1 Table of contents \u00b6 Prerequisites Install Overview Getting started API Prerequisites \u00b6 Make sure to have a message broker available, e.g. RabbitMQ . Install \u00b6 Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency in applications package.json and run npm for it: npm install To generate complete API documentation run inside the library package folder npm run doc Overview \u00b6 This library provides a messaging client for AMQP v0.9.1 . A single client instance represents one connection to the broker. Either TLS or NET socket is used depending on defined client options. The API works completely asynchronous based on callbacks, often providing also done (resolve) and failed (reject) callbacks. This means it would be simple to use Promise objects in the application even if the client library so far does not use it. AMQP v0.9.1 defines classes and methods (like remote procedure calls). Unfortunately, some of them do not allow a key-based mapping of responses to requests. Hence, for those methods the client has to wait for the response before a second request can be sent. The client encapsulates this and behaves always asynchronous for the caller. Getting started \u00b6 There are examples: * How to use plain API directly publisher.js and subscriber.js * How to use unified streams producer.js and consumer.js It shall run with defaults immediately if a RabbitMQ is installed at localhost:5672 with user guest/guest. All examples support also individual settings, e.g. to use a remote host or to try different stream settings. It can be provided with a js-file given as command line parameter. The file shall export a client option object. Defaults will still be used for undefined fields. API \u00b6 Create a client instance: const options = { tls: { host: 'localhost' , port: 5671 , ca: [ fs.readFileSync ( '../truststore/cacert.pem' ) , fs.readFileSync ( '../truststore/cert.pem' ) ] } , net: { host: 'localhost' , port: 5672 , } , sasl: { user: 'guest' , password: 'guest' } , amqp: { vhost: '/' , } } ; const client = new AMQP.Client ( options ) ; Either 'tls' attributes or 'net' attributes must be provided, 'tls' will be preferred. It is also possible to provide connection data as URI : const options = { uri: 'amqp://guest:guest@localhost:5672/vhost1?heartbeat=300' } ; const client = new AMQP.Client ( options ) ; Or using 'tls' again: const options = { uri: 'amqps://guest:guest@localhost:5671?cacertfile=cacert.pem&cacertfile=cert.pem' } ; const client = new AMQP.Client ( options ) ; Finally, also an array of URIs can be provided: const options = { uri: [ 'amqp://guest:guest@localhost:5672/vh111' , 'amqp://guest:guest@localhost:5672/vh222' ] } ; const client = new AMQP.Client ( options ) ; The client will start using the first URI and will try further URIs automatically in the given sequence until the connection can be established. If the client fails with all URIs then it stops and waits for another explicit call to connect. At this point an event 'disconnected' is raised. An application that requires a permanent opened connection shall always handle the 'disconnect' event by calling client.connect() again, of course after a given delay time. Timers or other mechanisms may be used, depending on the application design. Keep in mind that NodeJS runtime does not guarantee precise timer execution, it depends on the event queue load. Finally, URIs can also be combined with all other options settings. It will just overwrite those fields that are explicitly defined in the URI. A typical example could be the following: const options = { uri: [ 'amqp://guest:guest@localhost:5672/vh111' , 'amqp://guest:guest@localhost:5672/vh222' ] istreams: { in1: { channel: 1 , exchange: 'amq.topic' , routingKey: 'a.b.c' , noAck: true } , in2: { channel: 1 , exchange: '' , routingKey: 'myQueue' , noAck : false, prefetchCount : 1000 } } ostreams: { out1: { channel: 1 , exchange: 'amq.topic' , routingKey: 'a.b.c' , confirms : true } , out2: { channel: 1 , exchange: 'amq.topic' , routingKey: 'x.y.z' , confirms : false } } } ; const client = new AMQP.Client ( options ) ;","title":"AMQP 0.9.1 Client Library"},{"location":"apis/xb-msg-amqp-v091/#amqp-091-client-library","text":"Provides a client implementation for AMQP v0.9.1","title":"AMQP 0.9.1 Client Library"},{"location":"apis/xb-msg-amqp-v091/#table-of-contents","text":"Prerequisites Install Overview Getting started API","title":"Table of contents"},{"location":"apis/xb-msg-amqp-v091/#prerequisites","text":"Make sure to have a message broker available, e.g. RabbitMQ .","title":"Prerequisites"},{"location":"apis/xb-msg-amqp-v091/#install","text":"Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency in applications package.json and run npm for it: npm install To generate complete API documentation run inside the library package folder npm run doc","title":"Install"},{"location":"apis/xb-msg-amqp-v091/#overview","text":"This library provides a messaging client for AMQP v0.9.1 . A single client instance represents one connection to the broker. Either TLS or NET socket is used depending on defined client options. The API works completely asynchronous based on callbacks, often providing also done (resolve) and failed (reject) callbacks. This means it would be simple to use Promise objects in the application even if the client library so far does not use it. AMQP v0.9.1 defines classes and methods (like remote procedure calls). Unfortunately, some of them do not allow a key-based mapping of responses to requests. Hence, for those methods the client has to wait for the response before a second request can be sent. The client encapsulates this and behaves always asynchronous for the caller.","title":"Overview"},{"location":"apis/xb-msg-amqp-v091/#getting-started","text":"There are examples: * How to use plain API directly publisher.js and subscriber.js * How to use unified streams producer.js and consumer.js It shall run with defaults immediately if a RabbitMQ is installed at localhost:5672 with user guest/guest. All examples support also individual settings, e.g. to use a remote host or to try different stream settings. It can be provided with a js-file given as command line parameter. The file shall export a client option object. Defaults will still be used for undefined fields.","title":"Getting started"},{"location":"apis/xb-msg-amqp-v091/#api","text":"Create a client instance: const options = { tls: { host: 'localhost' , port: 5671 , ca: [ fs.readFileSync ( '../truststore/cacert.pem' ) , fs.readFileSync ( '../truststore/cert.pem' ) ] } , net: { host: 'localhost' , port: 5672 , } , sasl: { user: 'guest' , password: 'guest' } , amqp: { vhost: '/' , } } ; const client = new AMQP.Client ( options ) ; Either 'tls' attributes or 'net' attributes must be provided, 'tls' will be preferred. It is also possible to provide connection data as URI : const options = { uri: 'amqp://guest:guest@localhost:5672/vhost1?heartbeat=300' } ; const client = new AMQP.Client ( options ) ; Or using 'tls' again: const options = { uri: 'amqps://guest:guest@localhost:5671?cacertfile=cacert.pem&cacertfile=cert.pem' } ; const client = new AMQP.Client ( options ) ; Finally, also an array of URIs can be provided: const options = { uri: [ 'amqp://guest:guest@localhost:5672/vh111' , 'amqp://guest:guest@localhost:5672/vh222' ] } ; const client = new AMQP.Client ( options ) ; The client will start using the first URI and will try further URIs automatically in the given sequence until the connection can be established. If the client fails with all URIs then it stops and waits for another explicit call to connect. At this point an event 'disconnected' is raised. An application that requires a permanent opened connection shall always handle the 'disconnect' event by calling client.connect() again, of course after a given delay time. Timers or other mechanisms may be used, depending on the application design. Keep in mind that NodeJS runtime does not guarantee precise timer execution, it depends on the event queue load. Finally, URIs can also be combined with all other options settings. It will just overwrite those fields that are explicitly defined in the URI. A typical example could be the following: const options = { uri: [ 'amqp://guest:guest@localhost:5672/vh111' , 'amqp://guest:guest@localhost:5672/vh222' ] istreams: { in1: { channel: 1 , exchange: 'amq.topic' , routingKey: 'a.b.c' , noAck: true } , in2: { channel: 1 , exchange: '' , routingKey: 'myQueue' , noAck : false, prefetchCount : 1000 } } ostreams: { out1: { channel: 1 , exchange: 'amq.topic' , routingKey: 'a.b.c' , confirms : true } , out2: { channel: 1 , exchange: 'amq.topic' , routingKey: 'x.y.z' , confirms : false } } } ; const client = new AMQP.Client ( options ) ;","title":"API"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Unreleased \u00b6 [0.9.9] - 2019-12-11 \u00b6 [0.9.6] - 2019-02-11 \u00b6 [0.9.5] - 2019-02-11 \u00b6 [0.9.4] - 2019-02-11 \u00b6 [0.9.2] - 2018-05-30 \u00b6 encoder /decoder refactoring, same structure like in amqp 1.0 all 'failed' callbacks will not provide an error object anymore if the pending call was discarded due to client disconnect; one can now distinguish real errors from discarded calls Added \u00b6 Changed \u00b6 Removed \u00b6","title":"Change Log"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#099-2019-12-11","text":"","title":"[0.9.9] - 2019-12-11"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#096-2019-02-11","text":"","title":"[0.9.6] - 2019-02-11"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#095-2019-02-11","text":"","title":"[0.9.5] - 2019-02-11"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#094-2019-02-11","text":"","title":"[0.9.4] - 2019-02-11"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#092-2018-05-30","text":"encoder /decoder refactoring, same structure like in amqp 1.0 all 'failed' callbacks will not provide an error object anymore if the pending call was discarded due to client disconnect; one can now distinguish real errors from discarded calls","title":"[0.9.2] - 2018-05-30"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#added","text":"","title":"Added"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#changed","text":"","title":"Changed"},{"location":"apis/xb-msg-amqp-v091/CHANGELOG/#removed","text":"","title":"Removed"},{"location":"apis/xb-msg-amqp-v100/","text":"@sap/xb-msg-amqp-v100 \u00b6 Provides a protocol implementation for AMQP 1.0 . Table of contents \u00b6 Prerequisites Install Overview Getting started API Client Options Server Options Idle Timeout Endpoints Dynamic Endpoints Common Behavior Session Sender Outgoing Stream Delivery Tags Receiver Incoming Stream Message Delivery Streams Piped Streams Message Source and Target Convert Source and Target Variable Message Routing Quality of Service Mixed Quality of Service Flow Control Payload Payload and AMQP values Message Examples Limitations Further Links Prerequisites \u00b6 Make sure to have a message broker available for testing, e.g. RabbitMQ with enabled AMQP 1.0 plugin. Install \u00b6 Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency in applications package.json and run npm for it: npm install To generate complete API documentation run inside the library package folder npm run doc Overview \u00b6 This library provides a messaging client as well as classes to realize a server for AMQP 1.0 . It has been tested successfully in combination with: * RabbitMQ, version 3.6.6 * Solace VMR, as of version 8.5.0.1008 * AMQPNetLite, version 2.1.1 * Apache Qpid Proton, version 0.23.0 (and electron go client) * Apache Qpid Proton-J, version 0.23.0 * Apache Qpid-JMS client, version 0.40.0 * Golang pack.ag/amqp, version 0.10.2 * Azure Service Bus, Queue Either TLS or NET socket is used, depending on the defined client options. Besides plain TCP/IP also WebSocket is supported, with and without OAuth 2.0 , grant flows ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . The API works completely asynchronous based on callbacks, typically providing done (resolve) and failed (reject) callbacks. Hence, it will be simple to use Promise objects in the application even if this library does not use it so far. Getting started \u00b6 There are test programs in the package folder ./examples to demonstrate: * How to use a client as producer , consumer or counter * How to realize a server, here first basics for a protocol gateway All client examples shall run with provided defaults immediately if e.g. RabbitMQ is installed at localhost:5672 with user guest/guest, having the AMQP 1.0 plugin enabled. Alternatively, the producer may run in combination with the gateway example. All examples accept individual settings, e.g. to use a remote host or to try different stream settings. It can be provided with a js-file given as command line parameter. The file shall just export the options. Run it like this if the file is stored in folder config , same level as examples . node . \\e xamples \\p roducer.js .. \\c onfig \\m y-options.js Feel free to start testing with the following file content: 'use strict' ; module.exports = { net: { host : '127.0.0.1' , port : 5672 } , sasl: { mechanism : 'PLAIN' , user : 'guest' , password : 'guest' } , data: { source : 'q001' , // a queue name, source address for a receiver target : 'q002' , // a queue name, target address for a sender payload : Buffer.allocUnsafe ( 50 ) .fill ( 'X' ) , maxCount : 10000 , logCount : 1000 } } ; The data section is ignored by the client, it is just used by the example programs. API \u00b6 First, the library provides a Client class. It represents one AMQP container and is able to manage one connection. Session , Sender and Receiver are provided as endpoints. Readable/Writable streams are used to consume/produce messages. For the server implementation a basic Server class is provided. Like Client it supports connections running plain TCP (net/tls) as well as WebSocket (http/https). Incoming connections are represented as instances of the Connection class. Connection instances can also be created by an application-specific, more specialized server class. It could for example support different connection types or WebSocket sub-protocols in parallel or could apply more strict validation rules. Client Options \u00b6 Client instances are created directly, just providing options to the constructor: const AMQP = require ( '@sap/xb-msg-amqp-v100' ) ; ... const client = new AMQP.Client ( options ) ; ... Options for a plain TCP connection, authenticating with user/password only: const options = { net: { host: 'localhost' , port: 5672 , } , sasl: { mechanism: 'PLAIN' , user: 'guest' , password: 'guest' } } ; Options for a plain TCP connection, using TLS and special trusts: const options = { tls: { host: 'localhost' , port: 5671 , ca: [ fs.readFileSync ( '../truststore/cacert.pem' ) , fs.readFileSync ( '../truststore/cert.pem' ) ] } , sasl: { mechanism: 'PLAIN' , user: 'guest' , password: 'guest' } } ; Options to run AMQP over WebSocket (HTTP): const options = { ws: { host: 'localhost' , port: 80 , path: '/' auth: 'webUser:webPass' } sasl: { mechanism: 'PLAIN' , user: 'guest' , password: 'guest' } } ; Options to run AMQP over WebSocket, using TLS (HTTPS) with well-known CA: const options = { wss: { host: 'myhost' , port: 443 , path: '/' } , sasl: { user: 'guest' , password: 'guest' } } ; Either 'tls' attributes , 'net' attributes , wss attributes or ws attributes must be provided. If more than one is defined the preference is as follows: preferred 'tls' then 'net' then 'wss' then finally 'ws'. In case of WebSocket options the client will overwrite the HTTP method (with GET) and all web-socket relevant header fields. Everything else is given to http.request() or https.request() . Hence, you could for example use a specialized https agent: const HttpsProxyAgent = require ( 'https-proxy-agent' ) ; ... const options = { wss: { host : 'my.host.behind.proxy' , port : 443 , path: '/' , agent: new HttpsProxyAgent ( 'http://proxy:8080' ) } , sasl: { user: 'guest' , password: 'guest' } } ; It is also possible to provide connection data as URI. const options = { uri: 'amqp://user:pass@localhost:5672/?container=myAMQPContainerID' } ; To use 'tls' again with own trust: const options = { uri: 'amqps://user:pass@localhost:5671?cacertfile=cacert.pem&cacertfile=cert.pem' } ; Finally, also an array of URIs can be provided: const options = { uri: [ 'amqp://user11:pass11@host11:7777/?container=ABC123' , 'amqp://user22:pass22@host22:9999/?container=XYZ789' ] } ; The client will start using the first URI and will try further URIs automatically in the given sequence until the connection can be established. If the client fails with all URIs then it stops and waits for another explicit call to connect. At this point an event 'disconnected' is raised. An application that requires a continuously opened connection shall always handle the 'disconnected' event by calling client.connect() again, of course after a given delay time. Timers or other mechanisms may be used, depending on the application design. But keep in mind that NodeJS runtime does not guarantee precise timer execution. The scheduling depends on the event queue load. Finally, URIs can also be combined with all other settings. URI data (as far as provided) will just overwrite the corresponding fields. A typical example: const options = { uri: [ 'amqp://user11:pass11@host11:7777' , 'amqp://user22:pass22@host22:9999' ] amqp: { containerID: '' , // auto-generated by client maxMessageSize: 1000000 // bytes autoDeliveryTagPrefix: 'tag-' , outgoingSessionWindow: 1000 , incomingSessionWindow: 1000 , maxReceiverLinkCredit: 255 , minReceiverLinkCredit: 200 } } ; WebSocket connections may require the use of OAuth 2.0 as well, for example a local application connecting to SAP cloud. Relevant grant flows are: ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . const options = { wss: { host: 'myapp.cfapps.sap.hana.ondemand.com' , port: 443 , path: '/' } , oa2: { endpoint: 'https://myzone.authentication.sap.hana.ondemand.com/oauth/token' , client: 'myclientid' , secret: 'myclientsecret' , } , sasl: { mechanism: 'ANONYMOUS' , identity: 'test.user@sap.com' } } ; Further settings for the OAuth token request, for example a special agent: const options = { wss: { host: 'myapp.cfapps.sap.hana.ondemand.com' , port: 443 , path: '/' agent: new HttpsProxyAgent ( 'http://proxy:8080' ) } , oa2: { endpoint: 'https://myzone.authentication.sap.hana.ondemand.com/oauth/token' , client: 'myclientid' , secret: 'myclientsecret' , request: { agent: new HttpsProxyAgent ( 'http://proxy:8080' ) } } , sasl: { mechanism: 'ANONYMOUS' , identity: 'test.user@sap.com' } } ; Server Options \u00b6 Similar to the client class new Server instances are created, using the constructor: const AMQP = require ( '@sap/xb-msg-amqp-v100' ) ; ... const server = new AMQP.Server ( options ) ; ... server.listen () ; Options for plain TCP connections, accepting two SASL mechanisms (validation triggered by event): const options = { net: { port: 9999 , } , sasl: { mechanism: 'ANONYMOUS PLAIN' , } } ; To use WebSocket with or without SASL processing, both possible in parallel: const options = { ws: { port: 8888 , } , sasl: { mechanism: 'ANONYMOUS PLAIN' , mandatory: false } } ; Secure plain TCP connections and more restrictive protocol settings: const options = { tls: { port: 5671 , } , sasl: { mechanism: 'PLAIN EXTERNAL' , } , amqp: { outgoingSessionWindow: 100 , incomingSessionWindow: 100 , maxReceiverLinkCredit: 10 , minReceiverLinkCredit: 5 maxMessageSize: 10000 // bytes } } The server will create one Connection instance for each incoming client connection. When running an own (more specialized) server similar instances can be created. The AMQP protocol is completely handled by the Connection class. It requires the same options as the Server class, but uses only the sections sasl , amqp and tune . const AMQP = require ( '@sap/xb-msg-amqp-v100' ) ; const options = { sasl: { mechanism: 'PLAIN' } , amqp: { outgoingSessionWindow: 100 , incomingSessionWindow: 100 , maxReceiverLinkCredit: 10 , minReceiverLinkCredit: 5 , maxMessageSize: 10000 // bytes } tune: { ostreamPayloadCopyLimit: 1024 // bytes } } function init ( socket ) { try { const connection = new Connection ( socket, 'net' , options ) ; ... connection .once ( 'authenticate' , ( mechanism, data, callback ) = > { ... } .once ( 'ready' , ( peerInfo ) = > { ... } .once ( 'abort' , ( hadError ) = > { ... } .once ( 'close' , ( hadError ) = > { ... } .on ( 'error' , ( error ) = > { ... } .on ( 'sender' , ( endpoint ) = > { ... } .on ( 'receiver' , ( endpoint ) = > { ... } ; ... } catch ( e ) { socket.destroy ( e ) ; // if e.g. options were not accepted } } The gateway example uses all of the defined events, you may compare it as check list. More details can also be found in JSDoc. Connection instances behave always the same, independent from the used server class. Each instance offers the expected endpoints: Session , Sender , Receiver . Idle Timeout \u00b6 While opening a new connection both peers can declare an idle timeout . It means to expect receiving any frame within this time or to close the connection otherwise. The behavior is similar for client and server. And for both sides this library supports the following options: idleTimeoutMilliseconds : specifies the timeout value in milliseconds, 0 means no timeout. The value will be provided to net.setTimeout() idleTimeoutTryKeepAlive : defines the timeout behavior, indicates whether to send an empty frame to keep the connection alive or to end the connection, sending a close frame with an appropriate error message. adjustSelfIdleTimeout : optional callback to recalculate the own timeout after peer information are available, the default implementation calculates the minimum of the own timeout and the half of peers timeout, but only if running in keep alive mode. Client defaults: const options = { amqp: { idleTimeoutMilliseconds: 90000 , idleTimeoutTryKeepAlive: true, adjustSelfIdleTimeout: adjustSelfIdleTimeout // callback } } Server defaults: const options = { amqp: { idleTimeoutMilliseconds: 180000 , idleTimeoutTryKeepAlive: false, adjustSelfIdleTimeout: adjustSelfIdleTimeout // callback } } Endpoints \u00b6 Once a connection has been established its usage is quite symmetric for both peers. At least foreseen by the specification client and server both can begin and end sessions as well as attach and detach incoming or outgoing links. For example, a server may wait for clients to connect and may afterwards immediately begin a session, attach an outgoing link and may finally start sending messages (that the client has never asked for). However, in typical scenarios the client takes the active role and the server will wait for client requests. In particular, if the server is actually a message broker this is the expected behavior. Dynamic Endpoints \u00b6 The boolean endpoint property dynamic indicates whether or not an endpoint was created on peers request. Session , Sender and Receiver provide a common getter for it. The property is not covered by the specification, it is just used by this API as part of the endpoint lifecycle control. Client and Connection both support dynamic endpoints as follows: raise an event each time a dynamic endpoint was created and opened the very first time, destroy it immediately if the event is not handled to avoid uncontrolled resource consumption, destroy it automatically latest on connection close, allow the application to destroy it at any earlier point in time. In addition the Client allows to create non-dynamic endpoints, which stay registered by name or id until the application destroys it explicitly. Those endpoints can be used at any point in time, with or without an opened connection. Common Endpoint Behavior \u00b6 Overview on common methods for Session , Sender and Receiver (check JSDoc for details): dynamic() : returns true if the endpoint was created on peers request, active() : returns true if the endpoint gets opened automatically once Client is connected, opened() : returns true if local and remote endpoint are interactive, closed() : returns true if local and remote endpoint are neither opened nor on the way to open, destroyed() : returns true if the endpoint was destroyed; it is not registered anymore, destroy() : will immediately destroy the endpoint and cancel all of its messages in transit. Overview on common events for Session , Sender and Receiver (check JSDoc for details): opened : raised if the local and the remote endpoint are both opened, closed : raised if the local and the remote endpoint are both not opened, destroy : raised before the local endpoint is destroyed, application shall release any reference. Further methods and events depend on the specific endpoint type and applicable performatives. Session \u00b6 Each session groups multiple links and provides a higher-level flow control. For a single connection multiple sessions can be used, but one session is usually sufficient. A stable session identifier (comparable to a link name) is not defined by the specification. That's why, the library introduces an identifier (a simple string) just for local usage and applications convenience. It is never visible to the peer. There is one default session in use, identified with an empty string: const defSession = client.session ( '' ) ; ... const anySession = client.session ( 'anyLocalID' ) ; Overview on Session specific methods (check JSDoc for details): all common endpoint methods and begin(outgoing, incoming, options) : begin session, all parameters optional and defaulted by client options, flow(outgoing, incoming) : change current incoming and outgoing window size, end() : end the session, no messages will be sent or received, attached outgoing streams will wait based on flow control. Overview on Session specific events (check JSDoc for details): all common endpoint events and flow : flow settings were updated by the corresponding remote endpoint. A session will automatically begin if at least one active link endpoint is assigned to it. However, this can also be triggered explicitly. client.session ( '' ) .begin ( 200 , 200 ) ; The inherited method destroy() will first destroy all currently attached links before destroying itself. Sender \u00b6 Each Sender offers an OutgoingStream which extends the NodeJS stream class Writable . The stream runs in object mode and expects plain message objects (see also Message Streams ). Overview on Sender methods (check JSDoc for details): all common endpoint methods and session() : returns the currently assigned session endpoint, name() : returns the link name, options() : returns current settings as plain object, stream() : returns the currently associated stream, attach() : update settings, create the stream, attach the link and return the stream, detach() : destroy the stream and detach the link, A Sender provides only the common endpoint events (check JSDoc for details): Method attach() may also be called if the client is not connected. This will switch the endpoint in active mode and it will automatically attach whenever a connection is opened successfully. Immediately after calling attach() the application may also start using the stream. In any case flow control must be handled correctly, based on the standard NodeJS stream API. As long as the endpoint is active() it will try to send all queued messages. Even if the connection is interrupted the endpoint will resume its work as soon as the connection is opened again. The inherited method destroy() will first detach the endpoint before destroying its stream and finally itself. Destroying the stream means all queued messages including those that are already in transit will be cancelled. The message failed callback is used to notify the application. The application may also call stream.end() to indicate end of usage. New messages are not accepted anymore, but all queued messages will be processed before the link is detached. A Sender manages one instance of an OutgoingStream . Outgoing Stream \u00b6 Overview on OutgoingStream methods (check JSDoc for details): all methods of Writable and sender(): Sender : returns the associated sender endpoint, newDeliveryTag():string : returns a new delivery tag that can be registered by application before usage, flow(available) : send the amount of locally available messages, delivered():UInt : returns the amount of delivered messages, available():UInt : returns the amount of available messages, credit():UInt : returns the remaining message transfer credit, Overview on OutgoingStream events (check JSDoc for details): * all events of Writable and * ready : indicates the stream is attached and messages will now really be sent, not only queued. stream . on ( 'ready' , () => { send (); }) . on ( 'drain' , () => { send (); }) . on ( 'finish' , () => { client . disconnect (); }) ; See also the producer example. Delivery Tags \u00b6 If the application writes a message without a message.target.deliveryTag to an outgoing stream then this tag will be generated automatically. The result will be the same as if the application would have called stream.newDeliveryTag() first and would have assigned the new tag to a message, but the application was not able to register the tag for any kind of message correlation later on. Generated delivery tags will start with options.amqp.autoDeliveryTagPrefix , by default 'tag-' . Hence, the application may also use own delivery tags in parallel with generated tags, easily avoiding duplicate tags being used. Receiver \u00b6 Each Receiver offers an IncomingStream which extends the NodeJS stream class Readable . The stream runs in object mode and manages plain message objects (see also Message Streams ). Overview on Receiver methods (check JSDoc for details): all common endpoint methods and session() : returns the currently assigned session endpoint, name() : returns the link name, options() : returns current settings as plain object, stream() : returns the currently associated stream, attach() : update settings, create the stream, attach the link and return the stream, detach() : destroy the stream and detach the link, A Receiver provides only the common endpoint events (check JSDoc for details): Method attach() may also be called if the client is not connected and it will return the stream already. The endpoint is switched into active mode and will automatically attach whenever a connection is opened successfully. The inherited method destroy() will first detach before destroying its stream and finally itself. Destroying the stream means: all queued messages will be deleted immediately; it will not reach the application anymore, for messages in transit (already provided to the application, but not yet done) a following done() callback is ignored, A Receiver manages one instance of an IncomingStream . Incoming Stream \u00b6 The IncomingSteam handles also flow control for the application. It can renew the transfer credit after it was consumed and it can reduce the credit if application has to consume slower as the sender can send. Overview on IncomingStream methods (check JSDoc for details): all methods of Readable and receiver(): Receiver : returns the associated receiver endpoint, flow(maxCredit, minCredit) : updates message transfer credit settings, delivered():UInt : returns the amount of messages received by this stream, available():UInt : returns the amount of available messages from the remote endpoint, credit():UInt : returns the remaining message transfer credit, Overview on IncomingStream events (check JSDoc for details): * all events of Readable and * subscribed : indicates the stream is attached and messages could be received now. stream .on ( 'subscribed' , () = > { console.log ( 'attached' ) ; }) .on ( 'data' , ( message ) = > { ... message.done () ; ... }) ; As soon as the current credit reaches minCredit , the incoming stream will renew the credit with maxCredit automatically. However, if the application decides to set minCredit = -1 then the application will have to renew the credit explicitly using method stream.flow(maxCredit, minCredit) . The application must always call message.done() , independent from chosen settle mode. See also the consumer example. Message Delivery \u00b6 Messages are transferred as soon as a link between a Sender and a Receiver is attached. Message Streams \u00b6 As mentioned earlier Writable and Readable streams are provided to handle outgoing and incoming messages. These streams always run in object mode using options.amqp.linkHighWaterMsgCount . Here, a single message is represented as a plain object with the following attributes: * source : defined by the incoming stream, providing transfer attributes as well as the message header, annotations and properties, * target : defined optionally by the application, similar to the source, accepted by the outgoing stream, * payload : message data to transfer, see also this chapter , * done : a callback function to confirm final message processing, * failed : a callback function to indicate processing failure. A receiving application is expected to call either done or failed for each single message, exactly one time (maybe asynchronously) and independent from the used link settings. If a transfer was received unsettled then done will send a disposition with outcome DeliveryAccepted . In the case of a processing error, failed will either send outcome DeliveryRejected (if an error object is provided) or DeliveryReleased otherwise. stream.on ( 'data' , ( message ) = > { try { JSON.parse ( message.payload.toString ( 'utf8' )) ; ... message.done () ; } catch ( e ) { message.failed ( e ) ; } } ; A sending application can define the callbacks to get notified about the transfer result. const message = { payload : Buffer.from ( 'test' ) , done : () = > this._onSendDone ( message ) , failed : ( error ) = > this._onSendFailed ( error, message ) } ; const noPause = stream.write ( message ) ; Piped Message Streams \u00b6 An application may also pass trough (or transform) a received message from an incoming stream to an outgoing stream. In this case both streams would directly handle done and failed correctly. class Processor extends Transform { constructor () { super ({ writableObjectMode: true, writableHighWaterMark: 16 , readableObjectMode: true, readableHighWaterMark: 16 }) ; } _transform ( message, encoding, callback ) { try { JSON.parse ( message.payload.toString ( 'utf8' )) ; ... this.push ( message ) ; callback () ; } catch ( e ) { callback ( e ) ; } } } ... const istream = client.receiver ( 'inp' ) .attach ( 'queue:q001' ) ; const ostream = client.sender ( 'out' ) .attach ( 'topic:a/b/c' ) ; ... istream.pipe ( new Processor ()) .pipe ( ostream ) ; ... client.connect () ; Message Source and Target \u00b6 Both, message.source and message.target provide the same fields (check JSDoc for details): deliveryTag : an application tag to identify (and correlate) the message, batchable : true if a disposition can be delayed in order to optimize processing, settled : true if the sender has already settled, rcvSettleMode : senders requested receiver settle mode, header : plain object with header data ( see specification ), annotations : map with message annotations ( see specification ), properties : plain object with message properties ( see specification ). All target data are optional, defaults originate from the link definition that the message is sent over. Convert Source and Target \u00b6 Two fields of the Client and the Connection options allow the registration of conversion exits: * options.amqp.mapIncomingMsgSource * options.amqp.mapOutgoingMsgTarget The application or any other library could replace the default functions (check JSDoc for parameters). For example, @sap/xb-msg-env uses this mechanism to assure that a unified message source is provided and a unified target can be used by application. Variable Message Routing \u00b6 Using message.target the application can select dynamically the address that the message is sent to: let id = '42' ; ... message.target = { properties : { to: 'topic/order/' + id } } ; ... This allows to: * add message-related data as topic segment, e.g. an object identifier, * forward messages with variable target address over one single link. Please note, the specification defines only an address string . The address syntax depends on the connected service. For example, RabbitMQ, SolaceVMR or SAP Enterprise Messaging support different address expressions. And even more unexpected, RabbitMQ uses properties.subject instead of properties.to . However, package @sap/xb-msg-env would enable a unified processing here, if really needed. Quality of Service \u00b6 Chapter 2.6.12. of the protocol specification describes how to handle message transfers. With different combinations of sender and receiver settle mode the usual qualities can be realized. quality sndSettleMode rcvSettleMode at-most-once 1 (settled) 0 (first) at-least-once 0 (unsettled) 0 (first) exactly-once 0 (unsettled) 1 (second) Sender and receiver will agree on its settle modes when the link is attached: sender.attach ({ sndSettleMode: 0 , rcvSettleMode: 0 , target: { address: 'topic:a/b/c' } }) ; receiver.attach ({ sndSettleMode: 0 , rcvSettleMode: 0 , source: { address: 'queue:q001' } }) ; In any case the application has just to select the settle mode, usually at the client side. The library will assure correct handling of messages in transit, delivery states and message settlement. Mixed Quality of Service \u00b6 A sender may decide dynamically (per single message) on the settle mode. First, it would define sndSettleMode mixed while attaching the link. sender.attach ({ sndSettleMode: 2 , rcvSettleMode: 0 , target: { address: 'topic:a/b/c' } }) ; Later it would define the quality of service using the message target. ... message.target = { settled: false, // not yet settled by sender rcvSettleMode: 0 // receiver settles first } ; ... Flow Control \u00b6 There are actually 3 layers of flow control: * network socket and amount of bytes that is sent or received before the connection is throttled, * session layer with an incoming and outgoing message transfer window, * link layer with message transfer credits provided by the receiver to the sender. The library handles flow control on all layers automatically to protect the process in which it resides. The application just has to define the limits for each layer as part of the client or server options: section options.tune for the network layer and section options.amqp for the session and link layer. Message Payload \u00b6 The application may provide the message payload for an outgoing message as follows: a Buffer object, an Array of Buffer objects, a Payload object or a plain object with same properties as Payload . Properties of a Payload object: * chunks : an Array of Buffer objects, * type : an optional string providing the content type, * encoding : an optional string providing the content encoding, * data : any optional data to be sent either as AMQP sequence or as AMQP value , * properties : application properties . After the payload was given to a sender it must not be modified by the application anymore. And as soon as a single buffers size exceeds options.tune.ostreamPayloadCopyLimit (default 1024 bytes, minimum 128 bytes) it will not be copied anymore, but will be pushed to the network socket directly. Incoming messages will always provide a Payload object, just for application convenience. Message Payload and AMQP values \u00b6 Usually, the message payload will consist of binary data, an opaque array of bytes from the protocol libraries perspective. However, AMQP 1.0 allows also a single AMQP value or an AMQP sequence alternatively. If a received message payload consists of such values then the decoded values are provided as payload.data and in addition the corresponding parsed raw bytes as payload.chunks . The field payload.type will then have the special value 'amqp-1.0' , which is not a real mime type and in consequence not in danger to clash with such. Please note, 'amqp-1.0' is only a local API convention, not standardized. However, it has already been introduced by RabbitMQ AMQP 1.0 plugin . For an outgoing message payload with special type 'amqp-1.0' the encoder will either write payload.chunks (if provided) directly without any validation or it will encode the given payload.data as AMQP value or AMQP sequence. Limitations \u00b6 Similar to other libraries not the full scope of AMQP 1.0 could be implemented so far: * Only the following SASL mechanisms are supported: ANONYMOUS, PLAIN, EXTERNAL, * Deliveries cannot be resumed; once reconnected those messages are sent again with a new delivery, * Delivery state Received is not used, * Delivery state Modified is not supported, * Multiple Transfer Frames for one delivery are collected until the whole message can be provided to the application, * Message Footer is not supported, received but not exposed at the API, * Message Delivery Annotations are not supported, received, but not exposed at the API, * Decimal values are provided/accepted as binary data only, using a Buffer instance; use a specialized library for the conversion, * Transactions are not supported, * Incoming streams handle Quality of Service Exactly Once with one single callback to the application only, * Source filters are not supported, * Several fine-grained settings for endpoint lifecycle control may be ignored. Message Examples \u00b6 Just a few copy&paste templates: Payload as Buffer javascript const message = { payload : Buffer.from('hello world'), done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; Payload as Buffer Array javascript const message = { payload : [ Buffer.from('hello '), Buffer.from('world'), ], done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; Payload from JSON, application, properties, message properties and message header to be sent javascript const message = { payload: { chunks: [Buffer.from(JSON.stringify({ quantity: 100, uom: 'kg', }))], properties:{ // application properties, data to read without parsing full payload SalesOrder: '42', DeliveryID: '1764' }, type: 'application/json' }, target: { header: { durable: true, priority: 2, ttl: null, // or number in milliseconds }, properties: { messageID: '100037877', userID: '', to: 'topic:a/b/c', subject: '', replyTo: '', } }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; Cloud Event, structured format ```javascript const message = { payload: { chunks: [Buffer.from(JSON.stringify({ specversion: '0.3', source: 'sap/faas/demo', type: 'com.sap.coffee.produced', id: 'demo', cause: 'demo', subject: '', data: 'espresso', datacontenttype: 'text/plain' }))], type: 'application/cloudevents+json' }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; ``` Cloud Event, binary format ```javascript const message = { payload: { chunks: [ Buffer.from('espresso') ], properties: { 'cloudEvents:specversion': '0.3', 'cloudEvents:source': 'sap/faas/demo', 'cloudEvents:type': 'com.sap.coffee.produced', 'cloudEvents:id': 'demo', 'cloudEvents:cause': 'demo', 'cloudEvents:subject': '' }, type: 'text/plain' }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; ``` No binary payload, but single AMQP Value, e.g. a string ```javascript const AMQP = require('@sap/xb-msg-amqp-v100'); const message = { payload: { type: 'amqp-1.0', data: AMQP.Factory.String('Hello World') }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; ``` Simulate text message from Qpid JMS ```javascript const AMQP = require('@sap/xb-msg-amqp-v100'); const message = { target: { annotations: { 'x-opt-jms-msg-type': AMQP.Factory.Byte(5) } }, payload: { type: 'amqp-1.0', data: AMQP.Factory.String('Hello World') }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }, ``` Further Links \u00b6 Protocol Specification: AMQP 1.0, Part 1: Types AMQP 1.0, Part 2: Transport AMQP 1.0, Part 3: Messaging AMQP 1.0, Part 4: Transactions AMQP 1.0, Part 5: Security SASL and supported mechanisms: SASL Protocol SASL Mechanisms SASL Mechanism ANONYMOUS SASL Mechanism PLAIN SASL Mechanism EXTERNAL AMQP and WebSocket: AMQP WebSocketBinding WebSocket Protocol Http User Agent Header OAuth 2.0 OAuth 2.0, Client Credentials Grant OAuth 2.0, Resource Owner Password Credentials Grant Protocol Support by others: Rabbit MQ AMQP 1.0 plugin AMQP 1.0 in Azure Service Bus and Event Hubs protocol guide Solace: Using AMQP 1.0 Solace: AMQP 1.0 Protocol Conformance Qpid Proton Overview Qpid Proton C++ API Qpid Proton-J API Qpid JMS Qpid Proton github repository .Net Library: AMQP.Net Lite Node Library: Rhea Node Library: AMQP 1.0 Go Library (uses Qpid C library): Qpid Electron Go Library (pure GO, context.Context support): vcabbage/amqp Others: * Introduction to AMQP 1.0 * Node: Backpressuring in Streams","title":"@sap/xb-msg-amqp-v100"},{"location":"apis/xb-msg-amqp-v100/#sapxb-msg-amqp-v100","text":"Provides a protocol implementation for AMQP 1.0 .","title":"@sap/xb-msg-amqp-v100"},{"location":"apis/xb-msg-amqp-v100/#table-of-contents","text":"Prerequisites Install Overview Getting started API Client Options Server Options Idle Timeout Endpoints Dynamic Endpoints Common Behavior Session Sender Outgoing Stream Delivery Tags Receiver Incoming Stream Message Delivery Streams Piped Streams Message Source and Target Convert Source and Target Variable Message Routing Quality of Service Mixed Quality of Service Flow Control Payload Payload and AMQP values Message Examples Limitations Further Links","title":"Table of contents"},{"location":"apis/xb-msg-amqp-v100/#prerequisites","text":"Make sure to have a message broker available for testing, e.g. RabbitMQ with enabled AMQP 1.0 plugin.","title":"Prerequisites"},{"location":"apis/xb-msg-amqp-v100/#install","text":"Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency in applications package.json and run npm for it: npm install To generate complete API documentation run inside the library package folder npm run doc","title":"Install"},{"location":"apis/xb-msg-amqp-v100/#overview","text":"This library provides a messaging client as well as classes to realize a server for AMQP 1.0 . It has been tested successfully in combination with: * RabbitMQ, version 3.6.6 * Solace VMR, as of version 8.5.0.1008 * AMQPNetLite, version 2.1.1 * Apache Qpid Proton, version 0.23.0 (and electron go client) * Apache Qpid Proton-J, version 0.23.0 * Apache Qpid-JMS client, version 0.40.0 * Golang pack.ag/amqp, version 0.10.2 * Azure Service Bus, Queue Either TLS or NET socket is used, depending on the defined client options. Besides plain TCP/IP also WebSocket is supported, with and without OAuth 2.0 , grant flows ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . The API works completely asynchronous based on callbacks, typically providing done (resolve) and failed (reject) callbacks. Hence, it will be simple to use Promise objects in the application even if this library does not use it so far.","title":"Overview"},{"location":"apis/xb-msg-amqp-v100/#getting-started","text":"There are test programs in the package folder ./examples to demonstrate: * How to use a client as producer , consumer or counter * How to realize a server, here first basics for a protocol gateway All client examples shall run with provided defaults immediately if e.g. RabbitMQ is installed at localhost:5672 with user guest/guest, having the AMQP 1.0 plugin enabled. Alternatively, the producer may run in combination with the gateway example. All examples accept individual settings, e.g. to use a remote host or to try different stream settings. It can be provided with a js-file given as command line parameter. The file shall just export the options. Run it like this if the file is stored in folder config , same level as examples . node . \\e xamples \\p roducer.js .. \\c onfig \\m y-options.js Feel free to start testing with the following file content: 'use strict' ; module.exports = { net: { host : '127.0.0.1' , port : 5672 } , sasl: { mechanism : 'PLAIN' , user : 'guest' , password : 'guest' } , data: { source : 'q001' , // a queue name, source address for a receiver target : 'q002' , // a queue name, target address for a sender payload : Buffer.allocUnsafe ( 50 ) .fill ( 'X' ) , maxCount : 10000 , logCount : 1000 } } ; The data section is ignored by the client, it is just used by the example programs.","title":"Getting started"},{"location":"apis/xb-msg-amqp-v100/#api","text":"First, the library provides a Client class. It represents one AMQP container and is able to manage one connection. Session , Sender and Receiver are provided as endpoints. Readable/Writable streams are used to consume/produce messages. For the server implementation a basic Server class is provided. Like Client it supports connections running plain TCP (net/tls) as well as WebSocket (http/https). Incoming connections are represented as instances of the Connection class. Connection instances can also be created by an application-specific, more specialized server class. It could for example support different connection types or WebSocket sub-protocols in parallel or could apply more strict validation rules.","title":"API"},{"location":"apis/xb-msg-amqp-v100/#client-options","text":"Client instances are created directly, just providing options to the constructor: const AMQP = require ( '@sap/xb-msg-amqp-v100' ) ; ... const client = new AMQP.Client ( options ) ; ... Options for a plain TCP connection, authenticating with user/password only: const options = { net: { host: 'localhost' , port: 5672 , } , sasl: { mechanism: 'PLAIN' , user: 'guest' , password: 'guest' } } ; Options for a plain TCP connection, using TLS and special trusts: const options = { tls: { host: 'localhost' , port: 5671 , ca: [ fs.readFileSync ( '../truststore/cacert.pem' ) , fs.readFileSync ( '../truststore/cert.pem' ) ] } , sasl: { mechanism: 'PLAIN' , user: 'guest' , password: 'guest' } } ; Options to run AMQP over WebSocket (HTTP): const options = { ws: { host: 'localhost' , port: 80 , path: '/' auth: 'webUser:webPass' } sasl: { mechanism: 'PLAIN' , user: 'guest' , password: 'guest' } } ; Options to run AMQP over WebSocket, using TLS (HTTPS) with well-known CA: const options = { wss: { host: 'myhost' , port: 443 , path: '/' } , sasl: { user: 'guest' , password: 'guest' } } ; Either 'tls' attributes , 'net' attributes , wss attributes or ws attributes must be provided. If more than one is defined the preference is as follows: preferred 'tls' then 'net' then 'wss' then finally 'ws'. In case of WebSocket options the client will overwrite the HTTP method (with GET) and all web-socket relevant header fields. Everything else is given to http.request() or https.request() . Hence, you could for example use a specialized https agent: const HttpsProxyAgent = require ( 'https-proxy-agent' ) ; ... const options = { wss: { host : 'my.host.behind.proxy' , port : 443 , path: '/' , agent: new HttpsProxyAgent ( 'http://proxy:8080' ) } , sasl: { user: 'guest' , password: 'guest' } } ; It is also possible to provide connection data as URI. const options = { uri: 'amqp://user:pass@localhost:5672/?container=myAMQPContainerID' } ; To use 'tls' again with own trust: const options = { uri: 'amqps://user:pass@localhost:5671?cacertfile=cacert.pem&cacertfile=cert.pem' } ; Finally, also an array of URIs can be provided: const options = { uri: [ 'amqp://user11:pass11@host11:7777/?container=ABC123' , 'amqp://user22:pass22@host22:9999/?container=XYZ789' ] } ; The client will start using the first URI and will try further URIs automatically in the given sequence until the connection can be established. If the client fails with all URIs then it stops and waits for another explicit call to connect. At this point an event 'disconnected' is raised. An application that requires a continuously opened connection shall always handle the 'disconnected' event by calling client.connect() again, of course after a given delay time. Timers or other mechanisms may be used, depending on the application design. But keep in mind that NodeJS runtime does not guarantee precise timer execution. The scheduling depends on the event queue load. Finally, URIs can also be combined with all other settings. URI data (as far as provided) will just overwrite the corresponding fields. A typical example: const options = { uri: [ 'amqp://user11:pass11@host11:7777' , 'amqp://user22:pass22@host22:9999' ] amqp: { containerID: '' , // auto-generated by client maxMessageSize: 1000000 // bytes autoDeliveryTagPrefix: 'tag-' , outgoingSessionWindow: 1000 , incomingSessionWindow: 1000 , maxReceiverLinkCredit: 255 , minReceiverLinkCredit: 200 } } ; WebSocket connections may require the use of OAuth 2.0 as well, for example a local application connecting to SAP cloud. Relevant grant flows are: ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . const options = { wss: { host: 'myapp.cfapps.sap.hana.ondemand.com' , port: 443 , path: '/' } , oa2: { endpoint: 'https://myzone.authentication.sap.hana.ondemand.com/oauth/token' , client: 'myclientid' , secret: 'myclientsecret' , } , sasl: { mechanism: 'ANONYMOUS' , identity: 'test.user@sap.com' } } ; Further settings for the OAuth token request, for example a special agent: const options = { wss: { host: 'myapp.cfapps.sap.hana.ondemand.com' , port: 443 , path: '/' agent: new HttpsProxyAgent ( 'http://proxy:8080' ) } , oa2: { endpoint: 'https://myzone.authentication.sap.hana.ondemand.com/oauth/token' , client: 'myclientid' , secret: 'myclientsecret' , request: { agent: new HttpsProxyAgent ( 'http://proxy:8080' ) } } , sasl: { mechanism: 'ANONYMOUS' , identity: 'test.user@sap.com' } } ;","title":"Client Options"},{"location":"apis/xb-msg-amqp-v100/#server-options","text":"Similar to the client class new Server instances are created, using the constructor: const AMQP = require ( '@sap/xb-msg-amqp-v100' ) ; ... const server = new AMQP.Server ( options ) ; ... server.listen () ; Options for plain TCP connections, accepting two SASL mechanisms (validation triggered by event): const options = { net: { port: 9999 , } , sasl: { mechanism: 'ANONYMOUS PLAIN' , } } ; To use WebSocket with or without SASL processing, both possible in parallel: const options = { ws: { port: 8888 , } , sasl: { mechanism: 'ANONYMOUS PLAIN' , mandatory: false } } ; Secure plain TCP connections and more restrictive protocol settings: const options = { tls: { port: 5671 , } , sasl: { mechanism: 'PLAIN EXTERNAL' , } , amqp: { outgoingSessionWindow: 100 , incomingSessionWindow: 100 , maxReceiverLinkCredit: 10 , minReceiverLinkCredit: 5 maxMessageSize: 10000 // bytes } } The server will create one Connection instance for each incoming client connection. When running an own (more specialized) server similar instances can be created. The AMQP protocol is completely handled by the Connection class. It requires the same options as the Server class, but uses only the sections sasl , amqp and tune . const AMQP = require ( '@sap/xb-msg-amqp-v100' ) ; const options = { sasl: { mechanism: 'PLAIN' } , amqp: { outgoingSessionWindow: 100 , incomingSessionWindow: 100 , maxReceiverLinkCredit: 10 , minReceiverLinkCredit: 5 , maxMessageSize: 10000 // bytes } tune: { ostreamPayloadCopyLimit: 1024 // bytes } } function init ( socket ) { try { const connection = new Connection ( socket, 'net' , options ) ; ... connection .once ( 'authenticate' , ( mechanism, data, callback ) = > { ... } .once ( 'ready' , ( peerInfo ) = > { ... } .once ( 'abort' , ( hadError ) = > { ... } .once ( 'close' , ( hadError ) = > { ... } .on ( 'error' , ( error ) = > { ... } .on ( 'sender' , ( endpoint ) = > { ... } .on ( 'receiver' , ( endpoint ) = > { ... } ; ... } catch ( e ) { socket.destroy ( e ) ; // if e.g. options were not accepted } } The gateway example uses all of the defined events, you may compare it as check list. More details can also be found in JSDoc. Connection instances behave always the same, independent from the used server class. Each instance offers the expected endpoints: Session , Sender , Receiver .","title":"Server Options"},{"location":"apis/xb-msg-amqp-v100/#idle-timeout","text":"While opening a new connection both peers can declare an idle timeout . It means to expect receiving any frame within this time or to close the connection otherwise. The behavior is similar for client and server. And for both sides this library supports the following options: idleTimeoutMilliseconds : specifies the timeout value in milliseconds, 0 means no timeout. The value will be provided to net.setTimeout() idleTimeoutTryKeepAlive : defines the timeout behavior, indicates whether to send an empty frame to keep the connection alive or to end the connection, sending a close frame with an appropriate error message. adjustSelfIdleTimeout : optional callback to recalculate the own timeout after peer information are available, the default implementation calculates the minimum of the own timeout and the half of peers timeout, but only if running in keep alive mode. Client defaults: const options = { amqp: { idleTimeoutMilliseconds: 90000 , idleTimeoutTryKeepAlive: true, adjustSelfIdleTimeout: adjustSelfIdleTimeout // callback } } Server defaults: const options = { amqp: { idleTimeoutMilliseconds: 180000 , idleTimeoutTryKeepAlive: false, adjustSelfIdleTimeout: adjustSelfIdleTimeout // callback } }","title":"Idle Timeout"},{"location":"apis/xb-msg-amqp-v100/#endpoints","text":"Once a connection has been established its usage is quite symmetric for both peers. At least foreseen by the specification client and server both can begin and end sessions as well as attach and detach incoming or outgoing links. For example, a server may wait for clients to connect and may afterwards immediately begin a session, attach an outgoing link and may finally start sending messages (that the client has never asked for). However, in typical scenarios the client takes the active role and the server will wait for client requests. In particular, if the server is actually a message broker this is the expected behavior.","title":"Endpoints"},{"location":"apis/xb-msg-amqp-v100/#dynamic-endpoints","text":"The boolean endpoint property dynamic indicates whether or not an endpoint was created on peers request. Session , Sender and Receiver provide a common getter for it. The property is not covered by the specification, it is just used by this API as part of the endpoint lifecycle control. Client and Connection both support dynamic endpoints as follows: raise an event each time a dynamic endpoint was created and opened the very first time, destroy it immediately if the event is not handled to avoid uncontrolled resource consumption, destroy it automatically latest on connection close, allow the application to destroy it at any earlier point in time. In addition the Client allows to create non-dynamic endpoints, which stay registered by name or id until the application destroys it explicitly. Those endpoints can be used at any point in time, with or without an opened connection.","title":"Dynamic Endpoints"},{"location":"apis/xb-msg-amqp-v100/#common-endpoint-behavior","text":"Overview on common methods for Session , Sender and Receiver (check JSDoc for details): dynamic() : returns true if the endpoint was created on peers request, active() : returns true if the endpoint gets opened automatically once Client is connected, opened() : returns true if local and remote endpoint are interactive, closed() : returns true if local and remote endpoint are neither opened nor on the way to open, destroyed() : returns true if the endpoint was destroyed; it is not registered anymore, destroy() : will immediately destroy the endpoint and cancel all of its messages in transit. Overview on common events for Session , Sender and Receiver (check JSDoc for details): opened : raised if the local and the remote endpoint are both opened, closed : raised if the local and the remote endpoint are both not opened, destroy : raised before the local endpoint is destroyed, application shall release any reference. Further methods and events depend on the specific endpoint type and applicable performatives.","title":"Common Endpoint Behavior"},{"location":"apis/xb-msg-amqp-v100/#session","text":"Each session groups multiple links and provides a higher-level flow control. For a single connection multiple sessions can be used, but one session is usually sufficient. A stable session identifier (comparable to a link name) is not defined by the specification. That's why, the library introduces an identifier (a simple string) just for local usage and applications convenience. It is never visible to the peer. There is one default session in use, identified with an empty string: const defSession = client.session ( '' ) ; ... const anySession = client.session ( 'anyLocalID' ) ; Overview on Session specific methods (check JSDoc for details): all common endpoint methods and begin(outgoing, incoming, options) : begin session, all parameters optional and defaulted by client options, flow(outgoing, incoming) : change current incoming and outgoing window size, end() : end the session, no messages will be sent or received, attached outgoing streams will wait based on flow control. Overview on Session specific events (check JSDoc for details): all common endpoint events and flow : flow settings were updated by the corresponding remote endpoint. A session will automatically begin if at least one active link endpoint is assigned to it. However, this can also be triggered explicitly. client.session ( '' ) .begin ( 200 , 200 ) ; The inherited method destroy() will first destroy all currently attached links before destroying itself.","title":"Session"},{"location":"apis/xb-msg-amqp-v100/#sender","text":"Each Sender offers an OutgoingStream which extends the NodeJS stream class Writable . The stream runs in object mode and expects plain message objects (see also Message Streams ). Overview on Sender methods (check JSDoc for details): all common endpoint methods and session() : returns the currently assigned session endpoint, name() : returns the link name, options() : returns current settings as plain object, stream() : returns the currently associated stream, attach() : update settings, create the stream, attach the link and return the stream, detach() : destroy the stream and detach the link, A Sender provides only the common endpoint events (check JSDoc for details): Method attach() may also be called if the client is not connected. This will switch the endpoint in active mode and it will automatically attach whenever a connection is opened successfully. Immediately after calling attach() the application may also start using the stream. In any case flow control must be handled correctly, based on the standard NodeJS stream API. As long as the endpoint is active() it will try to send all queued messages. Even if the connection is interrupted the endpoint will resume its work as soon as the connection is opened again. The inherited method destroy() will first detach the endpoint before destroying its stream and finally itself. Destroying the stream means all queued messages including those that are already in transit will be cancelled. The message failed callback is used to notify the application. The application may also call stream.end() to indicate end of usage. New messages are not accepted anymore, but all queued messages will be processed before the link is detached. A Sender manages one instance of an OutgoingStream .","title":"Sender"},{"location":"apis/xb-msg-amqp-v100/#outgoing-stream","text":"Overview on OutgoingStream methods (check JSDoc for details): all methods of Writable and sender(): Sender : returns the associated sender endpoint, newDeliveryTag():string : returns a new delivery tag that can be registered by application before usage, flow(available) : send the amount of locally available messages, delivered():UInt : returns the amount of delivered messages, available():UInt : returns the amount of available messages, credit():UInt : returns the remaining message transfer credit, Overview on OutgoingStream events (check JSDoc for details): * all events of Writable and * ready : indicates the stream is attached and messages will now really be sent, not only queued. stream . on ( 'ready' , () => { send (); }) . on ( 'drain' , () => { send (); }) . on ( 'finish' , () => { client . disconnect (); }) ; See also the producer example.","title":"Outgoing Stream"},{"location":"apis/xb-msg-amqp-v100/#delivery-tags","text":"If the application writes a message without a message.target.deliveryTag to an outgoing stream then this tag will be generated automatically. The result will be the same as if the application would have called stream.newDeliveryTag() first and would have assigned the new tag to a message, but the application was not able to register the tag for any kind of message correlation later on. Generated delivery tags will start with options.amqp.autoDeliveryTagPrefix , by default 'tag-' . Hence, the application may also use own delivery tags in parallel with generated tags, easily avoiding duplicate tags being used.","title":"Delivery Tags"},{"location":"apis/xb-msg-amqp-v100/#receiver","text":"Each Receiver offers an IncomingStream which extends the NodeJS stream class Readable . The stream runs in object mode and manages plain message objects (see also Message Streams ). Overview on Receiver methods (check JSDoc for details): all common endpoint methods and session() : returns the currently assigned session endpoint, name() : returns the link name, options() : returns current settings as plain object, stream() : returns the currently associated stream, attach() : update settings, create the stream, attach the link and return the stream, detach() : destroy the stream and detach the link, A Receiver provides only the common endpoint events (check JSDoc for details): Method attach() may also be called if the client is not connected and it will return the stream already. The endpoint is switched into active mode and will automatically attach whenever a connection is opened successfully. The inherited method destroy() will first detach before destroying its stream and finally itself. Destroying the stream means: all queued messages will be deleted immediately; it will not reach the application anymore, for messages in transit (already provided to the application, but not yet done) a following done() callback is ignored, A Receiver manages one instance of an IncomingStream .","title":"Receiver"},{"location":"apis/xb-msg-amqp-v100/#incoming-stream","text":"The IncomingSteam handles also flow control for the application. It can renew the transfer credit after it was consumed and it can reduce the credit if application has to consume slower as the sender can send. Overview on IncomingStream methods (check JSDoc for details): all methods of Readable and receiver(): Receiver : returns the associated receiver endpoint, flow(maxCredit, minCredit) : updates message transfer credit settings, delivered():UInt : returns the amount of messages received by this stream, available():UInt : returns the amount of available messages from the remote endpoint, credit():UInt : returns the remaining message transfer credit, Overview on IncomingStream events (check JSDoc for details): * all events of Readable and * subscribed : indicates the stream is attached and messages could be received now. stream .on ( 'subscribed' , () = > { console.log ( 'attached' ) ; }) .on ( 'data' , ( message ) = > { ... message.done () ; ... }) ; As soon as the current credit reaches minCredit , the incoming stream will renew the credit with maxCredit automatically. However, if the application decides to set minCredit = -1 then the application will have to renew the credit explicitly using method stream.flow(maxCredit, minCredit) . The application must always call message.done() , independent from chosen settle mode. See also the consumer example.","title":"Incoming Stream"},{"location":"apis/xb-msg-amqp-v100/#message-delivery","text":"Messages are transferred as soon as a link between a Sender and a Receiver is attached.","title":"Message Delivery"},{"location":"apis/xb-msg-amqp-v100/#message-streams","text":"As mentioned earlier Writable and Readable streams are provided to handle outgoing and incoming messages. These streams always run in object mode using options.amqp.linkHighWaterMsgCount . Here, a single message is represented as a plain object with the following attributes: * source : defined by the incoming stream, providing transfer attributes as well as the message header, annotations and properties, * target : defined optionally by the application, similar to the source, accepted by the outgoing stream, * payload : message data to transfer, see also this chapter , * done : a callback function to confirm final message processing, * failed : a callback function to indicate processing failure. A receiving application is expected to call either done or failed for each single message, exactly one time (maybe asynchronously) and independent from the used link settings. If a transfer was received unsettled then done will send a disposition with outcome DeliveryAccepted . In the case of a processing error, failed will either send outcome DeliveryRejected (if an error object is provided) or DeliveryReleased otherwise. stream.on ( 'data' , ( message ) = > { try { JSON.parse ( message.payload.toString ( 'utf8' )) ; ... message.done () ; } catch ( e ) { message.failed ( e ) ; } } ; A sending application can define the callbacks to get notified about the transfer result. const message = { payload : Buffer.from ( 'test' ) , done : () = > this._onSendDone ( message ) , failed : ( error ) = > this._onSendFailed ( error, message ) } ; const noPause = stream.write ( message ) ;","title":"Message Streams"},{"location":"apis/xb-msg-amqp-v100/#piped-message-streams","text":"An application may also pass trough (or transform) a received message from an incoming stream to an outgoing stream. In this case both streams would directly handle done and failed correctly. class Processor extends Transform { constructor () { super ({ writableObjectMode: true, writableHighWaterMark: 16 , readableObjectMode: true, readableHighWaterMark: 16 }) ; } _transform ( message, encoding, callback ) { try { JSON.parse ( message.payload.toString ( 'utf8' )) ; ... this.push ( message ) ; callback () ; } catch ( e ) { callback ( e ) ; } } } ... const istream = client.receiver ( 'inp' ) .attach ( 'queue:q001' ) ; const ostream = client.sender ( 'out' ) .attach ( 'topic:a/b/c' ) ; ... istream.pipe ( new Processor ()) .pipe ( ostream ) ; ... client.connect () ;","title":"Piped Message Streams"},{"location":"apis/xb-msg-amqp-v100/#message-source-and-target","text":"Both, message.source and message.target provide the same fields (check JSDoc for details): deliveryTag : an application tag to identify (and correlate) the message, batchable : true if a disposition can be delayed in order to optimize processing, settled : true if the sender has already settled, rcvSettleMode : senders requested receiver settle mode, header : plain object with header data ( see specification ), annotations : map with message annotations ( see specification ), properties : plain object with message properties ( see specification ). All target data are optional, defaults originate from the link definition that the message is sent over.","title":"Message Source and Target"},{"location":"apis/xb-msg-amqp-v100/#convert-source-and-target","text":"Two fields of the Client and the Connection options allow the registration of conversion exits: * options.amqp.mapIncomingMsgSource * options.amqp.mapOutgoingMsgTarget The application or any other library could replace the default functions (check JSDoc for parameters). For example, @sap/xb-msg-env uses this mechanism to assure that a unified message source is provided and a unified target can be used by application.","title":"Convert Source and Target"},{"location":"apis/xb-msg-amqp-v100/#variable-message-routing","text":"Using message.target the application can select dynamically the address that the message is sent to: let id = '42' ; ... message.target = { properties : { to: 'topic/order/' + id } } ; ... This allows to: * add message-related data as topic segment, e.g. an object identifier, * forward messages with variable target address over one single link. Please note, the specification defines only an address string . The address syntax depends on the connected service. For example, RabbitMQ, SolaceVMR or SAP Enterprise Messaging support different address expressions. And even more unexpected, RabbitMQ uses properties.subject instead of properties.to . However, package @sap/xb-msg-env would enable a unified processing here, if really needed.","title":"Variable Message Routing"},{"location":"apis/xb-msg-amqp-v100/#quality-of-service","text":"Chapter 2.6.12. of the protocol specification describes how to handle message transfers. With different combinations of sender and receiver settle mode the usual qualities can be realized. quality sndSettleMode rcvSettleMode at-most-once 1 (settled) 0 (first) at-least-once 0 (unsettled) 0 (first) exactly-once 0 (unsettled) 1 (second) Sender and receiver will agree on its settle modes when the link is attached: sender.attach ({ sndSettleMode: 0 , rcvSettleMode: 0 , target: { address: 'topic:a/b/c' } }) ; receiver.attach ({ sndSettleMode: 0 , rcvSettleMode: 0 , source: { address: 'queue:q001' } }) ; In any case the application has just to select the settle mode, usually at the client side. The library will assure correct handling of messages in transit, delivery states and message settlement.","title":"Quality of Service"},{"location":"apis/xb-msg-amqp-v100/#mixed-quality-of-service","text":"A sender may decide dynamically (per single message) on the settle mode. First, it would define sndSettleMode mixed while attaching the link. sender.attach ({ sndSettleMode: 2 , rcvSettleMode: 0 , target: { address: 'topic:a/b/c' } }) ; Later it would define the quality of service using the message target. ... message.target = { settled: false, // not yet settled by sender rcvSettleMode: 0 // receiver settles first } ; ...","title":"Mixed Quality of Service"},{"location":"apis/xb-msg-amqp-v100/#flow-control","text":"There are actually 3 layers of flow control: * network socket and amount of bytes that is sent or received before the connection is throttled, * session layer with an incoming and outgoing message transfer window, * link layer with message transfer credits provided by the receiver to the sender. The library handles flow control on all layers automatically to protect the process in which it resides. The application just has to define the limits for each layer as part of the client or server options: section options.tune for the network layer and section options.amqp for the session and link layer.","title":"Flow Control"},{"location":"apis/xb-msg-amqp-v100/#message-payload","text":"The application may provide the message payload for an outgoing message as follows: a Buffer object, an Array of Buffer objects, a Payload object or a plain object with same properties as Payload . Properties of a Payload object: * chunks : an Array of Buffer objects, * type : an optional string providing the content type, * encoding : an optional string providing the content encoding, * data : any optional data to be sent either as AMQP sequence or as AMQP value , * properties : application properties . After the payload was given to a sender it must not be modified by the application anymore. And as soon as a single buffers size exceeds options.tune.ostreamPayloadCopyLimit (default 1024 bytes, minimum 128 bytes) it will not be copied anymore, but will be pushed to the network socket directly. Incoming messages will always provide a Payload object, just for application convenience.","title":"Message Payload"},{"location":"apis/xb-msg-amqp-v100/#message-payload-and-amqp-values","text":"Usually, the message payload will consist of binary data, an opaque array of bytes from the protocol libraries perspective. However, AMQP 1.0 allows also a single AMQP value or an AMQP sequence alternatively. If a received message payload consists of such values then the decoded values are provided as payload.data and in addition the corresponding parsed raw bytes as payload.chunks . The field payload.type will then have the special value 'amqp-1.0' , which is not a real mime type and in consequence not in danger to clash with such. Please note, 'amqp-1.0' is only a local API convention, not standardized. However, it has already been introduced by RabbitMQ AMQP 1.0 plugin . For an outgoing message payload with special type 'amqp-1.0' the encoder will either write payload.chunks (if provided) directly without any validation or it will encode the given payload.data as AMQP value or AMQP sequence.","title":"Message Payload and AMQP values"},{"location":"apis/xb-msg-amqp-v100/#limitations","text":"Similar to other libraries not the full scope of AMQP 1.0 could be implemented so far: * Only the following SASL mechanisms are supported: ANONYMOUS, PLAIN, EXTERNAL, * Deliveries cannot be resumed; once reconnected those messages are sent again with a new delivery, * Delivery state Received is not used, * Delivery state Modified is not supported, * Multiple Transfer Frames for one delivery are collected until the whole message can be provided to the application, * Message Footer is not supported, received but not exposed at the API, * Message Delivery Annotations are not supported, received, but not exposed at the API, * Decimal values are provided/accepted as binary data only, using a Buffer instance; use a specialized library for the conversion, * Transactions are not supported, * Incoming streams handle Quality of Service Exactly Once with one single callback to the application only, * Source filters are not supported, * Several fine-grained settings for endpoint lifecycle control may be ignored.","title":"Limitations"},{"location":"apis/xb-msg-amqp-v100/#message-examples","text":"Just a few copy&paste templates: Payload as Buffer javascript const message = { payload : Buffer.from('hello world'), done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; Payload as Buffer Array javascript const message = { payload : [ Buffer.from('hello '), Buffer.from('world'), ], done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; Payload from JSON, application, properties, message properties and message header to be sent javascript const message = { payload: { chunks: [Buffer.from(JSON.stringify({ quantity: 100, uom: 'kg', }))], properties:{ // application properties, data to read without parsing full payload SalesOrder: '42', DeliveryID: '1764' }, type: 'application/json' }, target: { header: { durable: true, priority: 2, ttl: null, // or number in milliseconds }, properties: { messageID: '100037877', userID: '', to: 'topic:a/b/c', subject: '', replyTo: '', } }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; Cloud Event, structured format ```javascript const message = { payload: { chunks: [Buffer.from(JSON.stringify({ specversion: '0.3', source: 'sap/faas/demo', type: 'com.sap.coffee.produced', id: 'demo', cause: 'demo', subject: '', data: 'espresso', datacontenttype: 'text/plain' }))], type: 'application/cloudevents+json' }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; ``` Cloud Event, binary format ```javascript const message = { payload: { chunks: [ Buffer.from('espresso') ], properties: { 'cloudEvents:specversion': '0.3', 'cloudEvents:source': 'sap/faas/demo', 'cloudEvents:type': 'com.sap.coffee.produced', 'cloudEvents:id': 'demo', 'cloudEvents:cause': 'demo', 'cloudEvents:subject': '' }, type: 'text/plain' }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; ``` No binary payload, but single AMQP Value, e.g. a string ```javascript const AMQP = require('@sap/xb-msg-amqp-v100'); const message = { payload: { type: 'amqp-1.0', data: AMQP.Factory.String('Hello World') }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }; ``` Simulate text message from Qpid JMS ```javascript const AMQP = require('@sap/xb-msg-amqp-v100'); const message = { target: { annotations: { 'x-opt-jms-msg-type': AMQP.Factory.Byte(5) } }, payload: { type: 'amqp-1.0', data: AMQP.Factory.String('Hello World') }, done: () => { console.log('message was sent'); }, failed: (err) => { console.log('message not sent,', err); } }, ```","title":"Message Examples"},{"location":"apis/xb-msg-amqp-v100/#further-links","text":"Protocol Specification: AMQP 1.0, Part 1: Types AMQP 1.0, Part 2: Transport AMQP 1.0, Part 3: Messaging AMQP 1.0, Part 4: Transactions AMQP 1.0, Part 5: Security SASL and supported mechanisms: SASL Protocol SASL Mechanisms SASL Mechanism ANONYMOUS SASL Mechanism PLAIN SASL Mechanism EXTERNAL AMQP and WebSocket: AMQP WebSocketBinding WebSocket Protocol Http User Agent Header OAuth 2.0 OAuth 2.0, Client Credentials Grant OAuth 2.0, Resource Owner Password Credentials Grant Protocol Support by others: Rabbit MQ AMQP 1.0 plugin AMQP 1.0 in Azure Service Bus and Event Hubs protocol guide Solace: Using AMQP 1.0 Solace: AMQP 1.0 Protocol Conformance Qpid Proton Overview Qpid Proton C++ API Qpid Proton-J API Qpid JMS Qpid Proton github repository .Net Library: AMQP.Net Lite Node Library: Rhea Node Library: AMQP 1.0 Go Library (uses Qpid C library): Qpid Electron Go Library (pure GO, context.Context support): vcabbage/amqp Others: * Introduction to AMQP 1.0 * Node: Backpressuring in Streams","title":"Further Links"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . [0.9.40] - 2020-05-29 \u00b6 fixed: always copy payload if websocket writer masks data (client to server) [0.9.39] - 2020-03-23 \u00b6 added: improved default options for better performance [0.9.38]- fixed: no disposition for early closed sessions (channels) - 2020-03-10 \u00b6 [0.9.36] - 2020-02-12 \u00b6 fixed: link state in combination with frequent state changes on same connection [0.9.35] - 2020-02-11 \u00b6 [0.9.34] - 2019-12-23 \u00b6 fixed: correct minimum value for idleTimeoutMilliseconds fixed: early destroy of dynamic endpoints (server-side) [0.9.32] - 2019-12-10 \u00b6 added: echo example, receives and send via same connection fixed: end handling of consumer example [0.9.31] - 2019-11-18 \u00b6 added: more fine-grained handling of idle timeout, for client and for server side [0.9.29] - 2019-11-15 \u00b6 fixed: payload encoding independent from payload (content) type [0.9.28] - 2019-10-17 \u00b6 [0.9.27] - 2019-10-16 \u00b6 fixed: encoding of explicit bool value as application property [0.9.26] - 2019-10-15 \u00b6 fixed: increment transfer.message.header.deliveryCount after serialization fixed: decode value type CHAR correctly fixed: application properties with long strings fixed: updated dependencies [0.9.20] - 2019-09-27 \u00b6 fixed: Value Factory, AMQP type Byte, Short, Int added: Value Factory, AMQP type String and Symbol fixed: payload type amqp-1.0 for AMQP values added: sample to send AMQP values as payload [0.9.19] - 2019-07-26 \u00b6 fixed: close plain TCP server [0.9.18] - 2019-07-23 \u00b6 fixed: wrong transfer resumption in outgoing stream, when sending before ready event [0.9.17] - 2019-06-06 \u00b6 [0.9.16] - 2019-06-06 \u00b6 [0.9.15] - 2019-06-06 \u00b6 fixed: flow.drain mode, missing flow response (to JMS client) [0.9.14] - 2019-05-22 \u00b6 added: message examples in README.md fixed: exeption handling, init connection fixed: jsdoc annotations, js hint errors [0.9.13] - 2019-03-18 \u00b6 fixed: incoming and outgoing endpoint errors fixed: support info fields on AMQP errors added: provide error object with endpoint closed events [0.9.10] - 2019-02-11 \u00b6 [0.9.9] - 2019-02-11 \u00b6 [0.9.8] - 2019-02-01 \u00b6 [0.9.7] - 2019-02-01 \u00b6 fixed: link handles managed per session fixed: endpoint state handling in case of early close fixed: links destroyed automatically if owning session is destroyed added: sender handles received flow.drain added: peerInfo provides complete property map in addition [0.9.2] - 2018-05-30 \u00b6 amqp v100 client-side implementation ready amqp v100 server-side implementation ready","title":"Change Log"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0940-2020-05-29","text":"fixed: always copy payload if websocket writer masks data (client to server)","title":"[0.9.40] - 2020-05-29"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0939-2020-03-23","text":"added: improved default options for better performance","title":"[0.9.39] - 2020-03-23"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0938-fixed-no-disposition-for-early-closed-sessions-channels-2020-03-10","text":"","title":"[0.9.38]- fixed: no disposition for early closed sessions (channels) - 2020-03-10"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0936-2020-02-12","text":"fixed: link state in combination with frequent state changes on same connection","title":"[0.9.36] - 2020-02-12"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0935-2020-02-11","text":"","title":"[0.9.35] - 2020-02-11"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0934-2019-12-23","text":"fixed: correct minimum value for idleTimeoutMilliseconds fixed: early destroy of dynamic endpoints (server-side)","title":"[0.9.34] - 2019-12-23"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0932-2019-12-10","text":"added: echo example, receives and send via same connection fixed: end handling of consumer example","title":"[0.9.32] - 2019-12-10"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0931-2019-11-18","text":"added: more fine-grained handling of idle timeout, for client and for server side","title":"[0.9.31] - 2019-11-18"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0929-2019-11-15","text":"fixed: payload encoding independent from payload (content) type","title":"[0.9.29] - 2019-11-15"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0928-2019-10-17","text":"","title":"[0.9.28] - 2019-10-17"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0927-2019-10-16","text":"fixed: encoding of explicit bool value as application property","title":"[0.9.27] - 2019-10-16"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0926-2019-10-15","text":"fixed: increment transfer.message.header.deliveryCount after serialization fixed: decode value type CHAR correctly fixed: application properties with long strings fixed: updated dependencies","title":"[0.9.26] - 2019-10-15"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0920-2019-09-27","text":"fixed: Value Factory, AMQP type Byte, Short, Int added: Value Factory, AMQP type String and Symbol fixed: payload type amqp-1.0 for AMQP values added: sample to send AMQP values as payload","title":"[0.9.20] - 2019-09-27"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0919-2019-07-26","text":"fixed: close plain TCP server","title":"[0.9.19] - 2019-07-26"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0918-2019-07-23","text":"fixed: wrong transfer resumption in outgoing stream, when sending before ready event","title":"[0.9.18] - 2019-07-23"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0917-2019-06-06","text":"","title":"[0.9.17] - 2019-06-06"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0916-2019-06-06","text":"","title":"[0.9.16] - 2019-06-06"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0915-2019-06-06","text":"fixed: flow.drain mode, missing flow response (to JMS client)","title":"[0.9.15] - 2019-06-06"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0914-2019-05-22","text":"added: message examples in README.md fixed: exeption handling, init connection fixed: jsdoc annotations, js hint errors","title":"[0.9.14] - 2019-05-22"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0913-2019-03-18","text":"fixed: incoming and outgoing endpoint errors fixed: support info fields on AMQP errors added: provide error object with endpoint closed events","title":"[0.9.13] - 2019-03-18"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#0910-2019-02-11","text":"","title":"[0.9.10] - 2019-02-11"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#099-2019-02-11","text":"","title":"[0.9.9] - 2019-02-11"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#098-2019-02-01","text":"","title":"[0.9.8] - 2019-02-01"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#097-2019-02-01","text":"fixed: link handles managed per session fixed: endpoint state handling in case of early close fixed: links destroyed automatically if owning session is destroyed added: sender handles received flow.drain added: peerInfo provides complete property map in addition","title":"[0.9.7] - 2019-02-01"},{"location":"apis/xb-msg-amqp-v100/CHANGELOG/#092-2018-05-30","text":"amqp v100 client-side implementation ready amqp v100 server-side implementation ready","title":"[0.9.2] - 2018-05-30"},{"location":"apis/xb-msg-env/","text":"xb-msg-env \u00b6 Provides functions to setup messaging client options from CF (or XSA) environment variables. The following clients are supported: * @sap/xb-msg , protocol-agnostic API, multiple destinations per single client * @sap/xb-msg-amqp-v100 , protocol-specific, single connection per client * @sap/xb-msg-amqp-v091 , protocol-specific, single connection per client * @sap/xb-msg-mqtt-v311 , protocol-specific, single connection per client. The following environment variables are used: * VCAP_SERVICES with bindings to RabbitMQ or Enterprise Messaging, * SAP_XBEM_SERVICE_LABEL to use an alternative service label for Enterprise Messaging, * SAP_XBEM_BINDINGS to define incoming and/or outgoing message streams. Table of contents \u00b6 Install API Examples Limitations Install \u00b6 Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency to your applications package.json and run npm for it: npm install API \u00b6 Environment Variables \u00b6 The following parameters exist in the SAP_XBEM_BINDINGS environment variable. SAP_XBEM_BINDINGS contains an input and an output map. \"SAP_XBEM_BINDINGS\": { \"outputs\": { }, \"inputs\": { } } A single input or output can have the following properties: Parameter Type Input Output Description service string yes yes Name of the messaging service to which this item is assigned address string yes yes Queue name (e.g. \u2018queue:q001\u2019) or topic in unified syntax (e.g. \u2018topic:BO/Sales/Order/Released\u2019) reliable boolean yes yes Indicates whether acknowledgements shall be used for reliable message transfers exclusive boolean yes no Indicates whether only one single consumer is allowed at a time persistent boolean no yes Indicates whether the message broker shall persist messages maxMsgInFlight number yes no The maximum number of unacknowledged messages the broker shall send to the consumer Create xb-msg Client Options \u00b6 Create a messaging client and start consuming messages. const msg = require ( '@sap/xb-msg' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . msgClientOptions ( 'msg-instance-01' , [ 'MyInpA' ] , [] ); /* start messaging */ const client = new msg . Client ( options ); client . istream ( 'MyInpA' ) . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect (); Create xb-msg-amqp-v100 Client Options without SAP_XBEM_BINDINGS \u00b6 Create an AMQP 1.0 messaging client and start consuming messages, receiving each at-least-once. const msg = require ( '@sap/xb-msg-amqp-v100' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . amqpV100ClientOptions ( 'my-service' ); /* start messaging */ const client = new msg . Client ( options ); const stream = client . receiver ( 'MyLinkA' ). attach ( 'MyQueue1' ); stream . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect (); Create xb-msg-amqp-v091 Client Options \u00b6 Create an AMQP v091 messaging client and start consuming messages. const msg = require ( '@sap/xb-msg-amqp-v091' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . amqpV091ClientOptions ( 'msg-instance-02' , [ 'MyInpB' ] , [] ); /* start messaging */ const client = new msg . Client ( options ); client . channel ( 1 ) . on ( 'opened' , () => { console . log ( 'opened' ); } ) . on ( 'flow' , ( active ) => { console . log ( active ? 'continue' : 'wait' ); } ) . on ( 'closed' , ( hadError ) => { console . log ( 'closed' ); client . disconnect (); } ); client . istream ( 'MyInpB' ) . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect (); Create xb-msg-mqtt-v311 Client Options \u00b6 Create an MQTT v311 messaging client and start consuming messages. const msg = require ( '@sap/xb-msg-mqtt-v311' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . mqttV311ClientOptions ( 'msg-instance-03' , [ 'MyInpC' ] , [] ); /* start messaging */ const client = new msg . Client ( options ); client . istream ( 'MyInpC' ) . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect (); Examples \u00b6 Below is an example of 'Environment Variables'. There is one Rabbit MQ instance named 'myService'. The messaging service inputs and outputs are maintained via another environment variable named SAP_XBEM_BINDINGS. Here, one output name 'myOutA' is defined. { \"VCAP_SERVICES\" : { \"rabbitmq\" : [ { \"credentials\" : { \"hostname\" : \"10.11.11.11\" , \"ports\" : { \"15672/tcp\" : \"8888\" , \"5672/tcp\" : \"9999\" }, \"port\" : \"9999\" , \"username\" : \"user\" , \"password\" : \"pwd\" , \"uri\" : \"amqp://user:pwd@10.11.11.11:9999\" }, \"syslog_drain_url\" : null , \"volume_mounts\" : [], \"label\" : \"rabbitmq\" , \"provider\" : null , \"plan\" : \"v3.6-container\" , \"name\" : \"myService\" , \"tags\" : [ \"rabbitmq\" , \"mbus\" , \"pubsub\" , \"amqp\" ] } ] }, \"SAP_XBEM_BINDINGS\" : { \"outputs\" : { \"myOutA\" : { \"service\" : \"myService\" , \"address\" : \"topic:Cars/Velocity/milesPerHour\" , \"reliable\" : false } } } } The following call: const env = require ( '@sap/xb-msg-env' ); const opt = env . msgClientOptions ( 'myService' , [], [ 'myOutA' ]); will provide the client options for @sap/xb-msg : { \"destinations\" : [ { \"name\" : \"myService\" , \"type\" : \"amqp-v091\" , \"net\" : { \"host\" : \"10.11.11.11\" , \"port\" : 9999 }, \"sasl\" : { \"user\" : \"user\" , \"password\" : \"pwd\" }, \"amqp\" : { \"vhost\" : \"/\" }, \"istreams\" : { }, \"ostreams\" : { \"out\" : { \"channel\" : 1 , \"exchange\" : \"amq.topic\" , \"routingKey\" : \"Cars.Velocity.milesPerHour\" , \"confirms\" : false } } } ] } Limitations \u00b6 Minimum version required for @sap/xb-msg is 0.2.3 Minimum version required for @sap/xb-msg-mqtt-v311 is 0.2.9 Minimum version required for @sap/xb-msg-amqp-v091 is 0.2.9 Minimum version required for @sap/xb-msg-amqp-v100 is 0.2.4","title":"xb-msg-env"},{"location":"apis/xb-msg-env/#xb-msg-env","text":"Provides functions to setup messaging client options from CF (or XSA) environment variables. The following clients are supported: * @sap/xb-msg , protocol-agnostic API, multiple destinations per single client * @sap/xb-msg-amqp-v100 , protocol-specific, single connection per client * @sap/xb-msg-amqp-v091 , protocol-specific, single connection per client * @sap/xb-msg-mqtt-v311 , protocol-specific, single connection per client. The following environment variables are used: * VCAP_SERVICES with bindings to RabbitMQ or Enterprise Messaging, * SAP_XBEM_SERVICE_LABEL to use an alternative service label for Enterprise Messaging, * SAP_XBEM_BINDINGS to define incoming and/or outgoing message streams.","title":"xb-msg-env"},{"location":"apis/xb-msg-env/#table-of-contents","text":"Install API Examples Limitations","title":"Table of contents"},{"location":"apis/xb-msg-env/#install","text":"Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency to your applications package.json and run npm for it: npm install","title":"Install"},{"location":"apis/xb-msg-env/#api","text":"","title":"API"},{"location":"apis/xb-msg-env/#environment-variables","text":"The following parameters exist in the SAP_XBEM_BINDINGS environment variable. SAP_XBEM_BINDINGS contains an input and an output map. \"SAP_XBEM_BINDINGS\": { \"outputs\": { }, \"inputs\": { } } A single input or output can have the following properties: Parameter Type Input Output Description service string yes yes Name of the messaging service to which this item is assigned address string yes yes Queue name (e.g. \u2018queue:q001\u2019) or topic in unified syntax (e.g. \u2018topic:BO/Sales/Order/Released\u2019) reliable boolean yes yes Indicates whether acknowledgements shall be used for reliable message transfers exclusive boolean yes no Indicates whether only one single consumer is allowed at a time persistent boolean no yes Indicates whether the message broker shall persist messages maxMsgInFlight number yes no The maximum number of unacknowledged messages the broker shall send to the consumer","title":"Environment Variables"},{"location":"apis/xb-msg-env/#create-xb-msg-client-options","text":"Create a messaging client and start consuming messages. const msg = require ( '@sap/xb-msg' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . msgClientOptions ( 'msg-instance-01' , [ 'MyInpA' ] , [] ); /* start messaging */ const client = new msg . Client ( options ); client . istream ( 'MyInpA' ) . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect ();","title":"Create xb-msg Client Options"},{"location":"apis/xb-msg-env/#create-xb-msg-amqp-v100-client-options-without-sap_xbem_bindings","text":"Create an AMQP 1.0 messaging client and start consuming messages, receiving each at-least-once. const msg = require ( '@sap/xb-msg-amqp-v100' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . amqpV100ClientOptions ( 'my-service' ); /* start messaging */ const client = new msg . Client ( options ); const stream = client . receiver ( 'MyLinkA' ). attach ( 'MyQueue1' ); stream . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect ();","title":"Create xb-msg-amqp-v100 Client Options without SAP_XBEM_BINDINGS"},{"location":"apis/xb-msg-env/#create-xb-msg-amqp-v091-client-options","text":"Create an AMQP v091 messaging client and start consuming messages. const msg = require ( '@sap/xb-msg-amqp-v091' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . amqpV091ClientOptions ( 'msg-instance-02' , [ 'MyInpB' ] , [] ); /* start messaging */ const client = new msg . Client ( options ); client . channel ( 1 ) . on ( 'opened' , () => { console . log ( 'opened' ); } ) . on ( 'flow' , ( active ) => { console . log ( active ? 'continue' : 'wait' ); } ) . on ( 'closed' , ( hadError ) => { console . log ( 'closed' ); client . disconnect (); } ); client . istream ( 'MyInpB' ) . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect ();","title":"Create xb-msg-amqp-v091 Client Options"},{"location":"apis/xb-msg-env/#create-xb-msg-mqtt-v311-client-options","text":"Create an MQTT v311 messaging client and start consuming messages. const msg = require ( '@sap/xb-msg-mqtt-v311' ); const env = require ( '@sap/xb-msg-env' ); /* get options from cf/xsa environment */ const options = env . mqttV311ClientOptions ( 'msg-instance-03' , [ 'MyInpC' ] , [] ); /* start messaging */ const client = new msg . Client ( options ); client . istream ( 'MyInpC' ) . on ( 'subscribed' , () => { console . log ( 'subscribed' ); } ) . on ( 'data' , ( message ) => { console . log ( 'message: ' + message . payload . toString ()); message . done (); } ); client . connect ();","title":"Create xb-msg-mqtt-v311 Client Options"},{"location":"apis/xb-msg-env/#examples","text":"Below is an example of 'Environment Variables'. There is one Rabbit MQ instance named 'myService'. The messaging service inputs and outputs are maintained via another environment variable named SAP_XBEM_BINDINGS. Here, one output name 'myOutA' is defined. { \"VCAP_SERVICES\" : { \"rabbitmq\" : [ { \"credentials\" : { \"hostname\" : \"10.11.11.11\" , \"ports\" : { \"15672/tcp\" : \"8888\" , \"5672/tcp\" : \"9999\" }, \"port\" : \"9999\" , \"username\" : \"user\" , \"password\" : \"pwd\" , \"uri\" : \"amqp://user:pwd@10.11.11.11:9999\" }, \"syslog_drain_url\" : null , \"volume_mounts\" : [], \"label\" : \"rabbitmq\" , \"provider\" : null , \"plan\" : \"v3.6-container\" , \"name\" : \"myService\" , \"tags\" : [ \"rabbitmq\" , \"mbus\" , \"pubsub\" , \"amqp\" ] } ] }, \"SAP_XBEM_BINDINGS\" : { \"outputs\" : { \"myOutA\" : { \"service\" : \"myService\" , \"address\" : \"topic:Cars/Velocity/milesPerHour\" , \"reliable\" : false } } } } The following call: const env = require ( '@sap/xb-msg-env' ); const opt = env . msgClientOptions ( 'myService' , [], [ 'myOutA' ]); will provide the client options for @sap/xb-msg : { \"destinations\" : [ { \"name\" : \"myService\" , \"type\" : \"amqp-v091\" , \"net\" : { \"host\" : \"10.11.11.11\" , \"port\" : 9999 }, \"sasl\" : { \"user\" : \"user\" , \"password\" : \"pwd\" }, \"amqp\" : { \"vhost\" : \"/\" }, \"istreams\" : { }, \"ostreams\" : { \"out\" : { \"channel\" : 1 , \"exchange\" : \"amq.topic\" , \"routingKey\" : \"Cars.Velocity.milesPerHour\" , \"confirms\" : false } } } ] }","title":"Examples"},{"location":"apis/xb-msg-env/#limitations","text":"Minimum version required for @sap/xb-msg is 0.2.3 Minimum version required for @sap/xb-msg-mqtt-v311 is 0.2.9 Minimum version required for @sap/xb-msg-amqp-v091 is 0.2.9 Minimum version required for @sap/xb-msg-amqp-v100 is 0.2.4","title":"Limitations"},{"location":"apis/xb-msg-env/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Unreleased \u00b6 [0.9.4] - 2019-02-11 \u00b6 [0.9.3] - 2019-02-11 \u00b6 [0.9.2] - 2019-02-11 \u00b6 [0.9.1] - 2019-02-06 \u00b6 Added \u00b6 amqp-v100 protocol support Changed \u00b6 adapt to new enterprise-messaging VCAP structure Removed \u00b6","title":"Change Log"},{"location":"apis/xb-msg-env/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xb-msg-env/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"apis/xb-msg-env/CHANGELOG/#094-2019-02-11","text":"","title":"[0.9.4] - 2019-02-11"},{"location":"apis/xb-msg-env/CHANGELOG/#093-2019-02-11","text":"","title":"[0.9.3] - 2019-02-11"},{"location":"apis/xb-msg-env/CHANGELOG/#092-2019-02-11","text":"","title":"[0.9.2] - 2019-02-11"},{"location":"apis/xb-msg-env/CHANGELOG/#091-2019-02-06","text":"","title":"[0.9.1] - 2019-02-06"},{"location":"apis/xb-msg-env/CHANGELOG/#added","text":"amqp-v100 protocol support","title":"Added"},{"location":"apis/xb-msg-env/CHANGELOG/#changed","text":"adapt to new enterprise-messaging VCAP structure","title":"Changed"},{"location":"apis/xb-msg-env/CHANGELOG/#removed","text":"","title":"Removed"},{"location":"apis/xb-msg-mqtt-v311/","text":"@sap/xb-msg-mqtt-v311 \u00b6 Provides a protocol implementation for MQTT 3.1.1 . Table of contents \u00b6 Prerequisites Install Overview Getting started API Limitations Prerequisites \u00b6 Make sure to have an message broker available, e.g. RabbitMQ with enabled MQTT plugin. Install \u00b6 Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency in applications package.json and run npm for it: npm install Overview \u00b6 This library provides a messaging client for MQTT 3.1.1 . A single client instance represents one connection to the broker. Either TLS or NET socket is used, depending on defined client options. Besides plain TCP/IP also WebSocket is supported, with and without OAuth 2.0 , grant flows ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . The API works completely asynchronous based on callbacks, often providing also done (resolve) and failed (reject) callbacks. This means it would be simple to use Promise objects in the application even if the client library so far does not use it. Getting started \u00b6 There are test programs in the package folder ./examples : * How to use plain API directly publisher.js and subscriber.js * How to use unified streams producer.js and consumer.js It shall run with defaults immediately if for example a RabbitMQ with active MQTT plugin is listening at localhost:1883 with default settings. All examples support individual settings, e.g. to use a remote host or to try different stream settings. It can be provided with a js-file given as command line parameter. The file shall export a client option object. Defaults will still be used for undefined fields. API \u00b6 The library provides a client class. const MQTT = require ( '@sap/xb-msg-mqtt-v311' ) ; ... const client = new MQTT.Client ( options ) ; ... Client Options \u00b6 Create a client instance using plain TCP: const options = { net: { host: 'localhost' , port: 1883 } , credentials: { user: '' , password: '' } , mqtt: { clientID : '' , cleanSession : true, keepAlive : 30 } } ; const client = new MQTT.Client ( options ) ; or plain TCP with TLS connection: const options = { tls: { host: 'localhost' , port: 8883 , ca: [ fs.readFileSync ( '../../../truststore/cacert.pem' ) , fs.readFileSync ( '../../../truststore/cert.pem' ) ] } , credentials: { user: '' , password: '' } } ; const client = new MQTT.Client ( options ) ; as well as MQTT over WebSocket (HTTP): const options = { ws: { host: 'localhost' , port: 80 , path: '/' auth: 'webUser:webPass' } credentials: { user: 'mqttUser' , // used in CONNECT packet password: 'mqttPass' // used in CONNECT packet } } ; const client = new MQTT.Client ( options ) ; or MQTT over WebSocket using TLS (HTTPS): const options = { wss: { host: 'localhost' , port: 443 , path: '/' , ca: [ fs.readFileSync ( '../../../truststore/cacert.pem' ) , fs.readFileSync ( '../../../truststore/cert.pem' ) ] } , credentials: { user: '' , password: '' } } ; const client = new MQTT.Client ( options ) ; Either 'tls' attributes , 'net' attributes , wss attributes or ws attributes must be provided. If more than one is provided the preference is as follows: preferred 'tls' then 'net' then 'wss' then finally 'ws'. In case of WebSocket options the client will overwrite HTTP method (GET) and all web-socket relevant header fields. Everything else is given to http.request() or https.request(). It is also possible to provide connection data as URI : const options = { uri: 'mqtt://user:pass@localhost:1883/?keepalive=300&clientid=abcd' } ; const client = new MQTT.Client ( options ) ; Or using 'tls' again: const options = { uri: 'mqtts://user:pass@localhost:8883?cacertfile=cacert.pem&cacertfile=cert.pem' } ; const client = new MQTT.Client ( options ) ; Finally, also an array of URIs can be provided: const options = { uri: [ 'mqtt://user11:pass11@host11:1883/?heartbeat=300' , 'mqtt://user22:pass22@host22:1884/' ] } ; const client = new MQTT.Client ( options ) ; The client will start using the first URI and will try further URIs automatically in the given sequence until the connection can be established. If the client fails with all URIs then it stops and waits for another explicit call to connect. At this point an event 'disconnected' is raised. An application that requires a permanent opened connection shall always handle the 'disconnect' event by calling client.connect() again, of course after a given delay time. Timers or other mechanisms may be used, depending on the application design. Keep in mind that NodeJS runtime does not guarantee precise timer execution, it depends on the event queue load. Finally, URIs can also be combined with all other settings. URI data (as far as provided) will just overwrite the corresponding fields. A typical example could be the following: const options = { uri: [ 'mqtt://user11:pass11@host11:1883/?keepalive=300' , 'mqtt://user22:pass22@host22:1884/?clientid=myCID' ] mqtt: { clientID: '' , keepAlive: 60 } , istreams: { in1: { topic: 'a/b/c/d' , qos: 1 } , in2: { topic: 'x/y/z/#' , qos: 1 } } ostreams: { out1: { topic: 'test/out1' , qos: 0 } , out2: { topic: 'test/out2' , qos: 2 } } } ; const client = new MQTT.Client ( options ) ; WebSocket connections may require the use of OAuth 2.0 as well. Relevant grant flows are: ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . One example is an external application, connecting to the cloud. const options = { oa2: { endpoint: 'https://myzone.authentication.sap.hana.ondemand.com/oauth/token' , client: 'myclientid' , secret: 'myclientsecret' , } , wss: { host: 'myapp.cfapps.sap.hana.ondemand.com' , port: 443 , path: '/' } } ; const client = new MQTT.Client ( options ) ; After an connection has been established the application may start to publish and/or subscribe. Details can be found in the sample applications, in project folder ./examples . Message Payload \u00b6 The application may provide message payload as follows: a simple Buffer object, an Array of simple Buffer objects or a Payload (see API) object, mainly for compatibility with other @sap/xb-msg* libraries. After the payload was handed over to the client the buffer content must not be modified by the application. And as soon as the buffer size exceeds options.tune.ostreamPayloadCopyLimit (default 1024 bytes, minimum 128 bytes) the client will not copy these data, but will directly push it to the network socket. Using a plain TCP connection the data will be sent unchanged. Running a WebSocket connection the encoder will have to mask (means to modify) all data before sending. Hence, if (and only if) an application * uses WebSocket connections and * uses payload buffer objects larger than the defined payload copy limit and * re-uses the same buffer object(s) for multiple messages then it must take copy of those buffer objects itself before calling the client to publish. Typically, the payload is created per message and released by application already after calling the client to publish. In this case do not copy anything. Limitations \u00b6 Currently, you may only set the MQTT flag cleanSession to true.","title":"@sap/xb-msg-mqtt-v311"},{"location":"apis/xb-msg-mqtt-v311/#sapxb-msg-mqtt-v311","text":"Provides a protocol implementation for MQTT 3.1.1 .","title":"@sap/xb-msg-mqtt-v311"},{"location":"apis/xb-msg-mqtt-v311/#table-of-contents","text":"Prerequisites Install Overview Getting started API Limitations","title":"Table of contents"},{"location":"apis/xb-msg-mqtt-v311/#prerequisites","text":"Make sure to have an message broker available, e.g. RabbitMQ with enabled MQTT plugin.","title":"Prerequisites"},{"location":"apis/xb-msg-mqtt-v311/#install","text":"Add the SAP NPM Registry to your npm configuration for all @sap scoped modules. npm config set \"@sap:registry=https://npm.sap.com\" Add the dependency in applications package.json and run npm for it: npm install","title":"Install"},{"location":"apis/xb-msg-mqtt-v311/#overview","text":"This library provides a messaging client for MQTT 3.1.1 . A single client instance represents one connection to the broker. Either TLS or NET socket is used, depending on defined client options. Besides plain TCP/IP also WebSocket is supported, with and without OAuth 2.0 , grant flows ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . The API works completely asynchronous based on callbacks, often providing also done (resolve) and failed (reject) callbacks. This means it would be simple to use Promise objects in the application even if the client library so far does not use it.","title":"Overview"},{"location":"apis/xb-msg-mqtt-v311/#getting-started","text":"There are test programs in the package folder ./examples : * How to use plain API directly publisher.js and subscriber.js * How to use unified streams producer.js and consumer.js It shall run with defaults immediately if for example a RabbitMQ with active MQTT plugin is listening at localhost:1883 with default settings. All examples support individual settings, e.g. to use a remote host or to try different stream settings. It can be provided with a js-file given as command line parameter. The file shall export a client option object. Defaults will still be used for undefined fields.","title":"Getting started"},{"location":"apis/xb-msg-mqtt-v311/#api","text":"The library provides a client class. const MQTT = require ( '@sap/xb-msg-mqtt-v311' ) ; ... const client = new MQTT.Client ( options ) ; ...","title":"API"},{"location":"apis/xb-msg-mqtt-v311/#client-options","text":"Create a client instance using plain TCP: const options = { net: { host: 'localhost' , port: 1883 } , credentials: { user: '' , password: '' } , mqtt: { clientID : '' , cleanSession : true, keepAlive : 30 } } ; const client = new MQTT.Client ( options ) ; or plain TCP with TLS connection: const options = { tls: { host: 'localhost' , port: 8883 , ca: [ fs.readFileSync ( '../../../truststore/cacert.pem' ) , fs.readFileSync ( '../../../truststore/cert.pem' ) ] } , credentials: { user: '' , password: '' } } ; const client = new MQTT.Client ( options ) ; as well as MQTT over WebSocket (HTTP): const options = { ws: { host: 'localhost' , port: 80 , path: '/' auth: 'webUser:webPass' } credentials: { user: 'mqttUser' , // used in CONNECT packet password: 'mqttPass' // used in CONNECT packet } } ; const client = new MQTT.Client ( options ) ; or MQTT over WebSocket using TLS (HTTPS): const options = { wss: { host: 'localhost' , port: 443 , path: '/' , ca: [ fs.readFileSync ( '../../../truststore/cacert.pem' ) , fs.readFileSync ( '../../../truststore/cert.pem' ) ] } , credentials: { user: '' , password: '' } } ; const client = new MQTT.Client ( options ) ; Either 'tls' attributes , 'net' attributes , wss attributes or ws attributes must be provided. If more than one is provided the preference is as follows: preferred 'tls' then 'net' then 'wss' then finally 'ws'. In case of WebSocket options the client will overwrite HTTP method (GET) and all web-socket relevant header fields. Everything else is given to http.request() or https.request(). It is also possible to provide connection data as URI : const options = { uri: 'mqtt://user:pass@localhost:1883/?keepalive=300&clientid=abcd' } ; const client = new MQTT.Client ( options ) ; Or using 'tls' again: const options = { uri: 'mqtts://user:pass@localhost:8883?cacertfile=cacert.pem&cacertfile=cert.pem' } ; const client = new MQTT.Client ( options ) ; Finally, also an array of URIs can be provided: const options = { uri: [ 'mqtt://user11:pass11@host11:1883/?heartbeat=300' , 'mqtt://user22:pass22@host22:1884/' ] } ; const client = new MQTT.Client ( options ) ; The client will start using the first URI and will try further URIs automatically in the given sequence until the connection can be established. If the client fails with all URIs then it stops and waits for another explicit call to connect. At this point an event 'disconnected' is raised. An application that requires a permanent opened connection shall always handle the 'disconnect' event by calling client.connect() again, of course after a given delay time. Timers or other mechanisms may be used, depending on the application design. Keep in mind that NodeJS runtime does not guarantee precise timer execution, it depends on the event queue load. Finally, URIs can also be combined with all other settings. URI data (as far as provided) will just overwrite the corresponding fields. A typical example could be the following: const options = { uri: [ 'mqtt://user11:pass11@host11:1883/?keepalive=300' , 'mqtt://user22:pass22@host22:1884/?clientid=myCID' ] mqtt: { clientID: '' , keepAlive: 60 } , istreams: { in1: { topic: 'a/b/c/d' , qos: 1 } , in2: { topic: 'x/y/z/#' , qos: 1 } } ostreams: { out1: { topic: 'test/out1' , qos: 0 } , out2: { topic: 'test/out2' , qos: 2 } } } ; const client = new MQTT.Client ( options ) ; WebSocket connections may require the use of OAuth 2.0 as well. Relevant grant flows are: ClientCredentialsFlow and ResourceOwnerPasswordCredentialsFlow . One example is an external application, connecting to the cloud. const options = { oa2: { endpoint: 'https://myzone.authentication.sap.hana.ondemand.com/oauth/token' , client: 'myclientid' , secret: 'myclientsecret' , } , wss: { host: 'myapp.cfapps.sap.hana.ondemand.com' , port: 443 , path: '/' } } ; const client = new MQTT.Client ( options ) ; After an connection has been established the application may start to publish and/or subscribe. Details can be found in the sample applications, in project folder ./examples .","title":"Client Options"},{"location":"apis/xb-msg-mqtt-v311/#message-payload","text":"The application may provide message payload as follows: a simple Buffer object, an Array of simple Buffer objects or a Payload (see API) object, mainly for compatibility with other @sap/xb-msg* libraries. After the payload was handed over to the client the buffer content must not be modified by the application. And as soon as the buffer size exceeds options.tune.ostreamPayloadCopyLimit (default 1024 bytes, minimum 128 bytes) the client will not copy these data, but will directly push it to the network socket. Using a plain TCP connection the data will be sent unchanged. Running a WebSocket connection the encoder will have to mask (means to modify) all data before sending. Hence, if (and only if) an application * uses WebSocket connections and * uses payload buffer objects larger than the defined payload copy limit and * re-uses the same buffer object(s) for multiple messages then it must take copy of those buffer objects itself before calling the client to publish. Typically, the payload is created per message and released by application already after calling the client to publish. In this case do not copy anything.","title":"Message Payload"},{"location":"apis/xb-msg-mqtt-v311/#limitations","text":"Currently, you may only set the MQTT flag cleanSession to true.","title":"Limitations"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . [0.9.12] - 2020-06-02 \u00b6 fixed: always copy payload if websocket writer masks data (client to server) [0.9.9] - 2019-11-15 \u00b6 [0.9.7] - 2019-02-11 \u00b6 [0.9.6] - 2019-02-11 \u00b6 [0.9.5] - 2019-02-11 \u00b6 [0.9.4] - 2019-02-11 \u00b6 [0.9.2] - 2018-05-30 \u00b6 Added \u00b6 Changed \u00b6 Removed \u00b6","title":"Change Log"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#0912-2020-06-02","text":"fixed: always copy payload if websocket writer masks data (client to server)","title":"[0.9.12] - 2020-06-02"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#099-2019-11-15","text":"","title":"[0.9.9] - 2019-11-15"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#097-2019-02-11","text":"","title":"[0.9.7] - 2019-02-11"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#096-2019-02-11","text":"","title":"[0.9.6] - 2019-02-11"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#095-2019-02-11","text":"","title":"[0.9.5] - 2019-02-11"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#094-2019-02-11","text":"","title":"[0.9.4] - 2019-02-11"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#092-2018-05-30","text":"","title":"[0.9.2] - 2018-05-30"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#added","text":"","title":"Added"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#changed","text":"","title":"Changed"},{"location":"apis/xb-msg-mqtt-v311/CHANGELOG/#removed","text":"","title":"Removed"},{"location":"apis/xsenv/","text":"@sap/xsenv \u00b6 Utility for easily reading application configurations for bound services and certificates in the SAP Cloud Platform Cloud Foundry environment, SAP XS advanced model and Kubernetes (K8S). Install \u00b6 npm install --save @sap/xsenv Usage \u00b6 var xsenv = require ( '@sap/xsenv' ); // Read the configuration for all bound service instances var services = xsenv . readServices (); console . log ( services . serviceInstance ); // prints { credentials: { user: ..., pass:... }, name: 'serviceInstance', tags: [...], label: ... // Read the credentials for all bound service instances matching a given service query var services = xsenv . filterServices ({ label : 'hana' }); console . log ( services ); // prints [ { credentials: { ... } }, { credentials: { ... } } ] // Read only the credentials portion of the configuration for a service instance matching a given service query var svc = xsenv . serviceCredentials ({ tag : 'hana' }); console . log ( svc ); // prints { host: '...', port: '...', user: '...', password: '...', ... } // Read configuration for a service instance matching a given service query var services = xsenv . getServices ({ hana : { name : 'hanaInstance' }}); // returns { hana: { host: '...', port: '...', user: '...', password: '...', ... } } var hanaInstanceCredentials = services . hana ; For specifics in the usage in different environments, read below. Usage in Cloud Foundry and SAP XS Advanced \u00b6 Cloud Foundry and SAP XS advanced both provide application configurations via environment variables. The properties of the bound services are in VCAP_SERVICES environment variable in both cases. Service Lookup \u00b6 Normally in Cloud Foundry you bind a service instance to your application with a command like this one: cf bind-service my-app aservice Here is how you can get this service configuration in your Node.js application if you don't know the instance name in advance: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . readServices (); var svc = services [ process . env . SERVICE_NAME ]; You can look up services based on their metadata: var svc = xsenv . serviceCredentials ({ tag : 'hdb' }); console . log ( svc ); // prints { host: '...', port: '...', user: '...', password: '...', ... } This example finds a service binding with hdb in the tags. See Service Query below for description of the supported query values. You can also look up multiple services in a single call: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . getServices ({ hana : { tag : 'hdb' }, scheduler : { label : 'jobs' } }); var hanaCredentials = services . hana ; var schedulerCredentials = services . scheduler ; This example finds two services - one with tag hdb and the other with label jobs . getServices function provides additional convenience that default service configuration can be provided in a JSON file. To test the above example locally, create a file called default-services.json in the working directory of your application. This file should contain something like this: { \"hana\" : { \"host\" : \"localhost\" , \"port\" : \"30015\" , \"user\" : \"SYSTEM\" , \"password\" : \"secret\" }, \"scheduler\" : { \"host\" : \"localhost\" , \"port\" : \"4242\" , \"user\" : \"my_user\" , \"password\" : \"secret\" } } Note: The result property names ( hana and scheduler ) are the same as those in the query object and also those in default-services.json . Local environment setup describes an alternative approach to provide service configurations for local testing. User-Provided Service Instances \u00b6 While this package can look up any kind of bound service instances, you should be aware that User-Provided Service Instances have less properties than managed service instances. Here is an example: \"VCAP_SERVICES\" : { \"user-provided\" : [ { \"name\" : \"pubsub\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"binary\" : \"pubsub.rb\" , \"host\" : \"pubsub01.example.com\" , \"password\" : \"p@29w0rd\" , \"port\" : \"1234\" , \"username\" : \"pubsubuser\" }, \"syslog_drain_url\" : \"\" } ] } As you can see the only usable property is the name . In particular, there are no tags for a user-provided services. Usage in Kubernetes \u00b6 Kubernetes offers several ways of handling application configurations for bound services and certificates. @sap/xsenv expects that such configurations are handled as Kubernetes Secrets and mounted as files to the pod at a specific path. This path can be provided by the application developer, but the default is /etc/secrets/sapcp . From there, @sap/xsenv assumes that the directory structure is the following /etc/secrets/sapcp/<service-name>/<instance-name> . Here <service-name> and <instance-name> are both directories and the latter contains the credentials/configurations for the service instance as files, where the file name is the name of the configuration/credential and the content is respectively the value. For example, the following folder structure: /etc/ /secrets/ /sapcp/ /hana/ | /hanaInst1/ | | /user1 | | /pass1 | /hanaInst2/ | /user2 | /pass2 /xsuaa/ /xsuaaInst/ /user /pass resembles two instances of service hana - hanaInst1 and hanaInst2 each with their own credentials/configurations and one instance of service xsuaa called xsuaaInst with its credentials. In Kubernetes you can create and bind to a service instance in the following way using the Service Catalog: svcat provision xsuaaInst --class xsuaa --plan application svcat bind xsuaaInst --name xsuaaBind Upon creation of the binding, the Service Catalog will create a Kubernetes secret (by default with the same name as the binding) containing credentials, configurations and certificates. This secret can then be mounted to the pod as a volume. The following deployment.yml file would generate the file structure above, assuming we have bindings hanaBind1 , hanaBind2 and xsuaaBind for service instances hanaInst1 , hanaInst2 and xsuaaInst created with Service Catalog: ... containers: - name: app image: app-image:1.0.0 ports: - appPort: 8080 volumeMounts: - name: hana-volume-1 mountPath: \"/etc/secrets/sapcp/hana/hanaInst1\" readOnly: true - name: hana-volume-2 mountPath: \"/etc/secrets/sapcp/hana/hanaInst2\" readOnly: true - name: xsuaa-volume mountPath: \"/etc/secrets/sapcp/xsuaa/xsuaaInst\" readOnly: true volumes: - name: hana-volume-1 secret: secretName: hanaBind1 - name: hana-volume-2 secret: secretName: hanaBind2 - name: xsuaa-volume secret: secretName: xsuaaBind Of course, you can also create Kubernetes secrets directly with kubectl and mount them to the pod. As long as the mount path follows the <root-path>/<service-name>/<instance-name> pattern, @sap/xsenv will be able to read and filter the bound services configurations. Note : The library attempts to parse property values which represent valid JSON objects. Property values representing arrays are not being parsed. The following service credentials: /etc/ /secrets/ /sapcp/ /some-service/ /some-instance/ /url - containing https://some-service /uaa - containing { \"url\": \"https://uaa\", \"clientid\": \"client\", \"clientsecret\": \"secret\" } /other - containing [1, \"two\"] Will be available to the application as: { url : 'https://some-service' , uaa : { url : 'https://uaa' , clientid : 'client' , clientsecret : 'secret' }, other : '[1, \"two\"]' } Service Lookup \u00b6 Service look up in the Kubernetes environment looks the same way as it does in the Cloud Foundry one. Looking at the above example of bound services here is how you can get the service configuration of hanaInst1 in your node application: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . readServices (); console . log ( services . hanaInst1 . credentials ); // prints { user1: '...', pass1: '...', ... } Here is how to lookup the service based on its metadata in Kubernetes: var svc = xsenv . serviceCredentials ({ label : 'hana' }); console . log ( svc ); // prints { host: '...', port: '...', user: '...', passwrod: '...', ... } This example finds a service binding with hana as a label. Note that for Kubernetes lookup based on metadata is limited. See Service Query below for description of the supported query values in Cloud Foundry and Kubernetes. If you have mounted your secrets to a different path, you can pass it to @sap/xsenv like so: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . getServices ( '/some/user/path' , { hana : { name : 'hanaInst1' }, xsuaa : { label : 'xsuaa' } }); var hanaCredentials = services . hana ; var schedulerCredentials = services . xsuaa ; Local Usage \u00b6 For local testing you can provide configurations by yourself. This package allows you to provide default configurations in a separate configuration file. * This reduces clutter by removing configuration data from the app code. * You don't have to set env vars manually each time you start your app. * Different developers can use their own configurations for their local tests without changing files under source control. Just add this configuration file to .gitignore and .cfignore . You can provide default configurations on two levels: * For bound services via getServices() and default-services.json * For any environment variable via loadEnv() and default-env.json Service Query \u00b6 Both getServices and filterServices use the same service query values. Due to specifics of the environment the queries in Cloud Foundry can be richer - see property table below. Query value Description Matches the service with the same service instance name ( name property). Same as { name: '<string>' } . All properties of the given object should match corresponding service instance properties as they appear in VCAP_SERVICES or the Kubernetes secret. See below what is supported on each platform. A function that takes a service object as argument and returns true , only if it is considered a match. If an object is given as a query value, it may have the following properties: Property CF K8S Description name yes yes Service instance name - the name you use to bind the service label yes yes Service name - the name shown by cf marketplace tag yes no Should match any of the service tags plan yes no Service instance plan - the plan you use in cf create-service If multiple properties are given, all of them must match. Note: Do not confuse the instance name ( name property) with the service name ( label property). Since you can have multiple instances of the same service bound to your app, instance name is unique while service name is not. Here are some examples. Find a service instance by name: xsenv . serviceCredentials ( 'hana' ); Look up a service by tag: xsenv . serviceCredentials ({ tag : 'relational' }); Match several properties: xsenv . serviceCredentials ({ label : 'hana' , plan : 'shared' }); Pass a custom filter function: xsenv . serviceCredentials ( function ( service ) { return /shared/ . test ( service . plan ) && /hdi/ . test ( service . label ); }); Notice that the filter function is called with the full service object as it appears in VCAP_SERVICES, but serviceCredentials returns only the credentials property of the matching service. The behaviour is the same in Kubernetes - the function will return only the contents of the credentials portion of the mounted secret. API \u00b6 getServices([path], query, [servicesFile]) \u00b6 Looks up bound service instances matching the given query. If a service is not found - returns default service configuration loaded from a JSON file. The order of lookup is VCAP_SERVICES -> mounted secrets path in K8S -> default service configuration. path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". For example, by default the credentials for an instance \"inst-name\" of service \"service-name\" would be located under \"/etc/secrets/sapcp/service-name/inst-name\". query - An object describing requested services. Each property value is a filter as described in Service Query servicesFile - (optional) path to JSON file to load default service configuration (default is default-services.json). If null , do not load default service configuration. returns - An object with the same properties as in query argument where the value of each property is the respective service credentials object throws - An error, if for some of the requested services no or multiple instances are found serviceCredentials([path], filter) \u00b6 Looks up a bound service instance matching the given filter works for both the Kubernetes and Cloud Foundry environments. Note: This function does not load default service configuration from default-services.json. path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". filter - Service lookup criteria as described in Service Query returns - Credentials object of found service throws - An error in case no or multiple matching services are found filterServices([path], filter) \u00b6 Returns all bound services that match the given criteria. Works in Cloud Foundry and Kubernetes. path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". filter - Service lookup criteria as described in Service Query returns - An array of credentials objects of matching services. Empty array, if no matches found. readServices([path]) \u00b6 path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". returns Returns an object where each service instance is mapped to its name. Works in Kubernetes and Cloud Foundry. For example, given this VCAP_SERVICES: { \"hana\" : [ { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana1\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\" ] }, { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana2\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\", \"SP09\" ] } ] } readServices would return: { hana1: { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana1\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\" ] }, hana2: { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana2\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\", \"SP09\" ] } } cfServiceCredentials(filter) \u00b6 Same as serviceCredentials(filter) but works only in Cloud Foundry. It is recommended to use the generic function. filterCFServices(filter) \u00b6 Same as filterServices(filter) but works only in Cloud Foundry. It is recommended to use the generic function. readCFServices() \u00b6 Same as readServices() but works only in Cloud Foundry. It is recommended to use the generic function. Local environment setup \u00b6 To test your application locally you often need to setup its environment so that resembles the environment in Cloud Foundry or Kubernetes. You can do this easily by defining the necessary environment variables in a JSON file. For example you can create file default-env.json with the following content in the working directory of the application : { \"PORT\" : 3000 , \"VCAP_SERVICES\" : { \"hana\" : [ { \"credentials\" : { \"host\" : \"myhana\" , \"port\" : \"30015\" , \"user\" : \"SYSTEM\" , \"password\" : \"secret\" }, \"label\" : \"hana\" , \"name\" : \"hana-R90\" , \"tags\" : [ \"hana\" , \"database\" , \"relational\" ] } ], \"scheduler\" : [ { \"credentials\" : { \"host\" : \"localhost\" , \"port\" : \"4242\" , \"user\" : \"jobuser\" , \"password\" : \"jobpassword\" }, \"label\" : \"scheduler\" , \"name\" : \"jobscheduler\" , \"tags\" : [ \"scheduler\" ] } ] } } Then load it in your application: xsenv . loadEnv (); console . log ( process . env . PORT ); // prints 3000 console . log ( xsenv . cfServiceCredentials ( 'hana-R90' )); // prints { host: 'myhana, port: '30015', user: 'SYSTEM', password: 'secret' } This way you don't need in your code conditional logic if it is running in Cloud Foundry or locally. You can also use a different file name: xsenv . loadEnv ( 'myenv.json' ); loadEnv([file]) \u00b6 Loads the environment from a JSON file. This function converts each top-level property to a string and sets it in the respective environment variable, unless it is already set. This function does not change existing environment variables. So the file content acts like default values for environment variables. This function does not complain if the file does not exist. file - optional name of JSON file to load, 'default-env.json' by default. Does nothing if the file does not exist. Loading SSL Certificates \u00b6 If SSL is configured in XS advanced On-Premise Runtime, it will provide one or more trusted CA certificates that applications can use to make SSL connections. If present, the file paths of these certificates are listed in XS_CACERT_PATH environment variable separated by path.delimiter ( : on LINUX and ; on Windows). loadCertificates([certPath]) \u00b6 Loads the certificates listed in the given path. If this argument is not provided, it uses XS_CACERT_PATH environment variable instead. If that is not set either, the function returns undefined . The function returns an array even if a single certificate is provided. This function is synchronous. certPath - optional string with certificate files to load. The file names are separated by path.delimiter . Default is process.env.XS_CACERT_PATH . returns - an array of loaded certificates or undefined if certPath argument is not provided throws - an error, if some of the files could not be loaded For example, this code loads the trusted CA certificates so they are used for all subsequent outgoing HTTPS connections: var https = require ( 'https' ); var xsenv = require ( '@sap/xsenv' ); https . globalAgent . options . ca = xsenv . loadCertificates (); This function can be used also to load SSL certificates for HANA like this: var hdb = require ( 'hdb' ); var xsenv = require ( '@sap/xsenv' ); var client = hdb . createClient ({ host : 'hostname' , port : 30015 , ca : xsenv . loadCertificates (), ... }); Debugging \u00b6 Set DEBUG=xsenv in the environment to enable debug traces. See debug package for details.","title":"@sap/xsenv"},{"location":"apis/xsenv/#sapxsenv","text":"Utility for easily reading application configurations for bound services and certificates in the SAP Cloud Platform Cloud Foundry environment, SAP XS advanced model and Kubernetes (K8S).","title":"@sap/xsenv"},{"location":"apis/xsenv/#install","text":"npm install --save @sap/xsenv","title":"Install"},{"location":"apis/xsenv/#usage","text":"var xsenv = require ( '@sap/xsenv' ); // Read the configuration for all bound service instances var services = xsenv . readServices (); console . log ( services . serviceInstance ); // prints { credentials: { user: ..., pass:... }, name: 'serviceInstance', tags: [...], label: ... // Read the credentials for all bound service instances matching a given service query var services = xsenv . filterServices ({ label : 'hana' }); console . log ( services ); // prints [ { credentials: { ... } }, { credentials: { ... } } ] // Read only the credentials portion of the configuration for a service instance matching a given service query var svc = xsenv . serviceCredentials ({ tag : 'hana' }); console . log ( svc ); // prints { host: '...', port: '...', user: '...', password: '...', ... } // Read configuration for a service instance matching a given service query var services = xsenv . getServices ({ hana : { name : 'hanaInstance' }}); // returns { hana: { host: '...', port: '...', user: '...', password: '...', ... } } var hanaInstanceCredentials = services . hana ; For specifics in the usage in different environments, read below.","title":"Usage"},{"location":"apis/xsenv/#usage-in-cloud-foundry-and-sap-xs-advanced","text":"Cloud Foundry and SAP XS advanced both provide application configurations via environment variables. The properties of the bound services are in VCAP_SERVICES environment variable in both cases.","title":"Usage in Cloud Foundry and SAP XS Advanced"},{"location":"apis/xsenv/#service-lookup","text":"Normally in Cloud Foundry you bind a service instance to your application with a command like this one: cf bind-service my-app aservice Here is how you can get this service configuration in your Node.js application if you don't know the instance name in advance: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . readServices (); var svc = services [ process . env . SERVICE_NAME ]; You can look up services based on their metadata: var svc = xsenv . serviceCredentials ({ tag : 'hdb' }); console . log ( svc ); // prints { host: '...', port: '...', user: '...', password: '...', ... } This example finds a service binding with hdb in the tags. See Service Query below for description of the supported query values. You can also look up multiple services in a single call: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . getServices ({ hana : { tag : 'hdb' }, scheduler : { label : 'jobs' } }); var hanaCredentials = services . hana ; var schedulerCredentials = services . scheduler ; This example finds two services - one with tag hdb and the other with label jobs . getServices function provides additional convenience that default service configuration can be provided in a JSON file. To test the above example locally, create a file called default-services.json in the working directory of your application. This file should contain something like this: { \"hana\" : { \"host\" : \"localhost\" , \"port\" : \"30015\" , \"user\" : \"SYSTEM\" , \"password\" : \"secret\" }, \"scheduler\" : { \"host\" : \"localhost\" , \"port\" : \"4242\" , \"user\" : \"my_user\" , \"password\" : \"secret\" } } Note: The result property names ( hana and scheduler ) are the same as those in the query object and also those in default-services.json . Local environment setup describes an alternative approach to provide service configurations for local testing.","title":"Service Lookup"},{"location":"apis/xsenv/#user-provided-service-instances","text":"While this package can look up any kind of bound service instances, you should be aware that User-Provided Service Instances have less properties than managed service instances. Here is an example: \"VCAP_SERVICES\" : { \"user-provided\" : [ { \"name\" : \"pubsub\" , \"label\" : \"user-provided\" , \"tags\" : [], \"credentials\" : { \"binary\" : \"pubsub.rb\" , \"host\" : \"pubsub01.example.com\" , \"password\" : \"p@29w0rd\" , \"port\" : \"1234\" , \"username\" : \"pubsubuser\" }, \"syslog_drain_url\" : \"\" } ] } As you can see the only usable property is the name . In particular, there are no tags for a user-provided services.","title":"User-Provided Service Instances"},{"location":"apis/xsenv/#usage-in-kubernetes","text":"Kubernetes offers several ways of handling application configurations for bound services and certificates. @sap/xsenv expects that such configurations are handled as Kubernetes Secrets and mounted as files to the pod at a specific path. This path can be provided by the application developer, but the default is /etc/secrets/sapcp . From there, @sap/xsenv assumes that the directory structure is the following /etc/secrets/sapcp/<service-name>/<instance-name> . Here <service-name> and <instance-name> are both directories and the latter contains the credentials/configurations for the service instance as files, where the file name is the name of the configuration/credential and the content is respectively the value. For example, the following folder structure: /etc/ /secrets/ /sapcp/ /hana/ | /hanaInst1/ | | /user1 | | /pass1 | /hanaInst2/ | /user2 | /pass2 /xsuaa/ /xsuaaInst/ /user /pass resembles two instances of service hana - hanaInst1 and hanaInst2 each with their own credentials/configurations and one instance of service xsuaa called xsuaaInst with its credentials. In Kubernetes you can create and bind to a service instance in the following way using the Service Catalog: svcat provision xsuaaInst --class xsuaa --plan application svcat bind xsuaaInst --name xsuaaBind Upon creation of the binding, the Service Catalog will create a Kubernetes secret (by default with the same name as the binding) containing credentials, configurations and certificates. This secret can then be mounted to the pod as a volume. The following deployment.yml file would generate the file structure above, assuming we have bindings hanaBind1 , hanaBind2 and xsuaaBind for service instances hanaInst1 , hanaInst2 and xsuaaInst created with Service Catalog: ... containers: - name: app image: app-image:1.0.0 ports: - appPort: 8080 volumeMounts: - name: hana-volume-1 mountPath: \"/etc/secrets/sapcp/hana/hanaInst1\" readOnly: true - name: hana-volume-2 mountPath: \"/etc/secrets/sapcp/hana/hanaInst2\" readOnly: true - name: xsuaa-volume mountPath: \"/etc/secrets/sapcp/xsuaa/xsuaaInst\" readOnly: true volumes: - name: hana-volume-1 secret: secretName: hanaBind1 - name: hana-volume-2 secret: secretName: hanaBind2 - name: xsuaa-volume secret: secretName: xsuaaBind Of course, you can also create Kubernetes secrets directly with kubectl and mount them to the pod. As long as the mount path follows the <root-path>/<service-name>/<instance-name> pattern, @sap/xsenv will be able to read and filter the bound services configurations. Note : The library attempts to parse property values which represent valid JSON objects. Property values representing arrays are not being parsed. The following service credentials: /etc/ /secrets/ /sapcp/ /some-service/ /some-instance/ /url - containing https://some-service /uaa - containing { \"url\": \"https://uaa\", \"clientid\": \"client\", \"clientsecret\": \"secret\" } /other - containing [1, \"two\"] Will be available to the application as: { url : 'https://some-service' , uaa : { url : 'https://uaa' , clientid : 'client' , clientsecret : 'secret' }, other : '[1, \"two\"]' }","title":"Usage in Kubernetes"},{"location":"apis/xsenv/#service-lookup_1","text":"Service look up in the Kubernetes environment looks the same way as it does in the Cloud Foundry one. Looking at the above example of bound services here is how you can get the service configuration of hanaInst1 in your node application: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . readServices (); console . log ( services . hanaInst1 . credentials ); // prints { user1: '...', pass1: '...', ... } Here is how to lookup the service based on its metadata in Kubernetes: var svc = xsenv . serviceCredentials ({ label : 'hana' }); console . log ( svc ); // prints { host: '...', port: '...', user: '...', passwrod: '...', ... } This example finds a service binding with hana as a label. Note that for Kubernetes lookup based on metadata is limited. See Service Query below for description of the supported query values in Cloud Foundry and Kubernetes. If you have mounted your secrets to a different path, you can pass it to @sap/xsenv like so: var xsenv = require ( '@sap/xsenv' ); var services = xsenv . getServices ( '/some/user/path' , { hana : { name : 'hanaInst1' }, xsuaa : { label : 'xsuaa' } }); var hanaCredentials = services . hana ; var schedulerCredentials = services . xsuaa ;","title":"Service Lookup"},{"location":"apis/xsenv/#local-usage","text":"For local testing you can provide configurations by yourself. This package allows you to provide default configurations in a separate configuration file. * This reduces clutter by removing configuration data from the app code. * You don't have to set env vars manually each time you start your app. * Different developers can use their own configurations for their local tests without changing files under source control. Just add this configuration file to .gitignore and .cfignore . You can provide default configurations on two levels: * For bound services via getServices() and default-services.json * For any environment variable via loadEnv() and default-env.json","title":"Local Usage"},{"location":"apis/xsenv/#service-query","text":"Both getServices and filterServices use the same service query values. Due to specifics of the environment the queries in Cloud Foundry can be richer - see property table below. Query value Description Matches the service with the same service instance name ( name property). Same as { name: '<string>' } . All properties of the given object should match corresponding service instance properties as they appear in VCAP_SERVICES or the Kubernetes secret. See below what is supported on each platform. A function that takes a service object as argument and returns true , only if it is considered a match. If an object is given as a query value, it may have the following properties: Property CF K8S Description name yes yes Service instance name - the name you use to bind the service label yes yes Service name - the name shown by cf marketplace tag yes no Should match any of the service tags plan yes no Service instance plan - the plan you use in cf create-service If multiple properties are given, all of them must match. Note: Do not confuse the instance name ( name property) with the service name ( label property). Since you can have multiple instances of the same service bound to your app, instance name is unique while service name is not. Here are some examples. Find a service instance by name: xsenv . serviceCredentials ( 'hana' ); Look up a service by tag: xsenv . serviceCredentials ({ tag : 'relational' }); Match several properties: xsenv . serviceCredentials ({ label : 'hana' , plan : 'shared' }); Pass a custom filter function: xsenv . serviceCredentials ( function ( service ) { return /shared/ . test ( service . plan ) && /hdi/ . test ( service . label ); }); Notice that the filter function is called with the full service object as it appears in VCAP_SERVICES, but serviceCredentials returns only the credentials property of the matching service. The behaviour is the same in Kubernetes - the function will return only the contents of the credentials portion of the mounted secret.","title":"Service Query"},{"location":"apis/xsenv/#api","text":"","title":"API"},{"location":"apis/xsenv/#getservicespath-query-servicesfile","text":"Looks up bound service instances matching the given query. If a service is not found - returns default service configuration loaded from a JSON file. The order of lookup is VCAP_SERVICES -> mounted secrets path in K8S -> default service configuration. path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". For example, by default the credentials for an instance \"inst-name\" of service \"service-name\" would be located under \"/etc/secrets/sapcp/service-name/inst-name\". query - An object describing requested services. Each property value is a filter as described in Service Query servicesFile - (optional) path to JSON file to load default service configuration (default is default-services.json). If null , do not load default service configuration. returns - An object with the same properties as in query argument where the value of each property is the respective service credentials object throws - An error, if for some of the requested services no or multiple instances are found","title":"getServices([path], query, [servicesFile])"},{"location":"apis/xsenv/#servicecredentialspath-filter","text":"Looks up a bound service instance matching the given filter works for both the Kubernetes and Cloud Foundry environments. Note: This function does not load default service configuration from default-services.json. path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". filter - Service lookup criteria as described in Service Query returns - Credentials object of found service throws - An error in case no or multiple matching services are found","title":"serviceCredentials([path], filter)"},{"location":"apis/xsenv/#filterservicespath-filter","text":"Returns all bound services that match the given criteria. Works in Cloud Foundry and Kubernetes. path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". filter - Service lookup criteria as described in Service Query returns - An array of credentials objects of matching services. Empty array, if no matches found.","title":"filterServices([path], filter)"},{"location":"apis/xsenv/#readservicespath","text":"path - (optional) A string containing the mount path where the secrets are located in Kubernetes. By default is \"/etc/secrets/sapcp\". returns Returns an object where each service instance is mapped to its name. Works in Kubernetes and Cloud Foundry. For example, given this VCAP_SERVICES: { \"hana\" : [ { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana1\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\" ] }, { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana2\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\", \"SP09\" ] } ] } readServices would return: { hana1: { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana1\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\" ] }, hana2: { \"credentials\" : { ... }, \"label\" : \"hana\", \"name\" : \"hana2\", \"plan\" : \"shared\", \"tags\" : [ \"hana\", \"relational\", \"SP09\" ] } }","title":"readServices([path])"},{"location":"apis/xsenv/#cfservicecredentialsfilter","text":"Same as serviceCredentials(filter) but works only in Cloud Foundry. It is recommended to use the generic function.","title":"cfServiceCredentials(filter)"},{"location":"apis/xsenv/#filtercfservicesfilter","text":"Same as filterServices(filter) but works only in Cloud Foundry. It is recommended to use the generic function.","title":"filterCFServices(filter)"},{"location":"apis/xsenv/#readcfservices","text":"Same as readServices() but works only in Cloud Foundry. It is recommended to use the generic function.","title":"readCFServices()"},{"location":"apis/xsenv/#local-environment-setup","text":"To test your application locally you often need to setup its environment so that resembles the environment in Cloud Foundry or Kubernetes. You can do this easily by defining the necessary environment variables in a JSON file. For example you can create file default-env.json with the following content in the working directory of the application : { \"PORT\" : 3000 , \"VCAP_SERVICES\" : { \"hana\" : [ { \"credentials\" : { \"host\" : \"myhana\" , \"port\" : \"30015\" , \"user\" : \"SYSTEM\" , \"password\" : \"secret\" }, \"label\" : \"hana\" , \"name\" : \"hana-R90\" , \"tags\" : [ \"hana\" , \"database\" , \"relational\" ] } ], \"scheduler\" : [ { \"credentials\" : { \"host\" : \"localhost\" , \"port\" : \"4242\" , \"user\" : \"jobuser\" , \"password\" : \"jobpassword\" }, \"label\" : \"scheduler\" , \"name\" : \"jobscheduler\" , \"tags\" : [ \"scheduler\" ] } ] } } Then load it in your application: xsenv . loadEnv (); console . log ( process . env . PORT ); // prints 3000 console . log ( xsenv . cfServiceCredentials ( 'hana-R90' )); // prints { host: 'myhana, port: '30015', user: 'SYSTEM', password: 'secret' } This way you don't need in your code conditional logic if it is running in Cloud Foundry or locally. You can also use a different file name: xsenv . loadEnv ( 'myenv.json' );","title":"Local environment setup"},{"location":"apis/xsenv/#loadenvfile","text":"Loads the environment from a JSON file. This function converts each top-level property to a string and sets it in the respective environment variable, unless it is already set. This function does not change existing environment variables. So the file content acts like default values for environment variables. This function does not complain if the file does not exist. file - optional name of JSON file to load, 'default-env.json' by default. Does nothing if the file does not exist.","title":"loadEnv([file])"},{"location":"apis/xsenv/#loading-ssl-certificates","text":"If SSL is configured in XS advanced On-Premise Runtime, it will provide one or more trusted CA certificates that applications can use to make SSL connections. If present, the file paths of these certificates are listed in XS_CACERT_PATH environment variable separated by path.delimiter ( : on LINUX and ; on Windows).","title":"Loading SSL Certificates"},{"location":"apis/xsenv/#loadcertificatescertpath","text":"Loads the certificates listed in the given path. If this argument is not provided, it uses XS_CACERT_PATH environment variable instead. If that is not set either, the function returns undefined . The function returns an array even if a single certificate is provided. This function is synchronous. certPath - optional string with certificate files to load. The file names are separated by path.delimiter . Default is process.env.XS_CACERT_PATH . returns - an array of loaded certificates or undefined if certPath argument is not provided throws - an error, if some of the files could not be loaded For example, this code loads the trusted CA certificates so they are used for all subsequent outgoing HTTPS connections: var https = require ( 'https' ); var xsenv = require ( '@sap/xsenv' ); https . globalAgent . options . ca = xsenv . loadCertificates (); This function can be used also to load SSL certificates for HANA like this: var hdb = require ( 'hdb' ); var xsenv = require ( '@sap/xsenv' ); var client = hdb . createClient ({ host : 'hostname' , port : 30015 , ca : xsenv . loadCertificates (), ... });","title":"loadCertificates([certPath])"},{"location":"apis/xsenv/#debugging","text":"Set DEBUG=xsenv in the environment to enable debug traces. See debug package for details.","title":"Debugging"},{"location":"apis/xsenv/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 3.0.0 - 2020-06-05 \u00b6 Removed \u00b6 Node.js 6 support Changed \u00b6 K8S case: nested objects in credentials are now automatically parsed (does not apply to arrays) 2.2.0 - 2019-11-28 \u00b6 Added \u00b6 Support Node.js 12.x 2.1.0 - 2019-10-15 \u00b6 Added \u00b6 Support for K8S secrets mounted as volumes. 2.0.0 - 2019-04-22 \u00b6 Removed \u00b6 Node.js 4 support Remove deprecated loadCaCert function 1.3.0 - 2018-12-18 \u00b6 Added \u00b6 Node.js 10 support Fixed \u00b6 Update lodash to 4.17.11 1.2.9 - 2018-01-18 \u00b6 Added \u00b6 Release with npm-shrinkwrap.json 1.2.8 - 2017-10-09 \u00b6 Security \u00b6 Updated debug package to fix a security issue https://snyk.io/vuln/npm:debug:20170905","title":"Change Log"},{"location":"apis/xsenv/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xsenv/CHANGELOG/#300-2020-06-05","text":"","title":"3.0.0 - 2020-06-05"},{"location":"apis/xsenv/CHANGELOG/#removed","text":"Node.js 6 support","title":"Removed"},{"location":"apis/xsenv/CHANGELOG/#changed","text":"K8S case: nested objects in credentials are now automatically parsed (does not apply to arrays)","title":"Changed"},{"location":"apis/xsenv/CHANGELOG/#220-2019-11-28","text":"","title":"2.2.0 - 2019-11-28"},{"location":"apis/xsenv/CHANGELOG/#added","text":"Support Node.js 12.x","title":"Added"},{"location":"apis/xsenv/CHANGELOG/#210-2019-10-15","text":"","title":"2.1.0 - 2019-10-15"},{"location":"apis/xsenv/CHANGELOG/#added_1","text":"Support for K8S secrets mounted as volumes.","title":"Added"},{"location":"apis/xsenv/CHANGELOG/#200-2019-04-22","text":"","title":"2.0.0 - 2019-04-22"},{"location":"apis/xsenv/CHANGELOG/#removed_1","text":"Node.js 4 support Remove deprecated loadCaCert function","title":"Removed"},{"location":"apis/xsenv/CHANGELOG/#130-2018-12-18","text":"","title":"1.3.0 - 2018-12-18"},{"location":"apis/xsenv/CHANGELOG/#added_2","text":"Node.js 10 support","title":"Added"},{"location":"apis/xsenv/CHANGELOG/#fixed","text":"Update lodash to 4.17.11","title":"Fixed"},{"location":"apis/xsenv/CHANGELOG/#129-2018-01-18","text":"","title":"1.2.9 - 2018-01-18"},{"location":"apis/xsenv/CHANGELOG/#added_3","text":"Release with npm-shrinkwrap.json","title":"Added"},{"location":"apis/xsenv/CHANGELOG/#128-2017-10-09","text":"","title":"1.2.8 - 2017-10-09"},{"location":"apis/xsenv/CHANGELOG/#security","text":"Updated debug package to fix a security issue https://snyk.io/vuln/npm:debug:20170905","title":"Security"},{"location":"apis/xsenv/migration/","text":"Migration Guide \u00b6 Version 2 ==> Version 3 \u00b6 Changes to application code \u00b6 Nested objects in credentials (K8S case only) \u00b6 The following service credentials: /etc/ /secrets/ /sapcp/ /some-service/ /some-instance/ /url - containing https://some-service /uaa - containing { \"url\": \"https://uaa\", \"clientid\": \"client\", \"clientsecret\": \"secret\" } /other - containing [1, \"two\"] had been provided to applications in v2 of @sap/xsenv as: { url : 'https://some-service' , uaa : '{ \"url\": \"https://uaa\", \"clientid\": \"client\", \"clientsecret\": \"secret\" }' , other : '[1, \"two\"]' } The uaa property requires parsing (with JSON.parse ) in order to use its properties individually. With v3 of @sap/xsenv nested JSON objects are parsed automatically and are provided to applications as: { url : 'https://some-service' , uaa : { url : 'https://uaa' , clientid : 'client' , clientsecret : 'secret' }, other : '[1, \"two\"]' Invocation to JSON.parse should be removed from application code. Note : property values representing arrays are currently not automatically parsed.","title":"Migration Guide"},{"location":"apis/xsenv/migration/#migration-guide","text":"","title":"Migration Guide"},{"location":"apis/xsenv/migration/#version-2-version-3","text":"","title":"Version 2 ==&gt; Version 3"},{"location":"apis/xsenv/migration/#changes-to-application-code","text":"","title":"Changes to application code"},{"location":"apis/xsenv/migration/#nested-objects-in-credentials-k8s-case-only","text":"The following service credentials: /etc/ /secrets/ /sapcp/ /some-service/ /some-instance/ /url - containing https://some-service /uaa - containing { \"url\": \"https://uaa\", \"clientid\": \"client\", \"clientsecret\": \"secret\" } /other - containing [1, \"two\"] had been provided to applications in v2 of @sap/xsenv as: { url : 'https://some-service' , uaa : '{ \"url\": \"https://uaa\", \"clientid\": \"client\", \"clientsecret\": \"secret\" }' , other : '[1, \"two\"]' } The uaa property requires parsing (with JSON.parse ) in order to use its properties individually. With v3 of @sap/xsenv nested JSON objects are parsed automatically and are provided to applications as: { url : 'https://some-service' , uaa : { url : 'https://uaa' , clientid : 'client' , clientsecret : 'secret' }, other : '[1, \"two\"]' Invocation to JSON.parse should be removed from application code. Note : property values representing arrays are currently not automatically parsed.","title":"Nested objects in credentials (K8S case only)"},{"location":"apis/xsjs/","text":"@sap/xsjs \u00b6 Compatibility layer for SAP HANA extended application services, classic model (SAP HANA XS Classic) applications to run on Node.js in SAP HANA extended application services, advanced model. Usage Options hana secureStore formData mail destinationProvider auditLog context libraryCache Multitenant usage OData support Clear OData model cache NPM packages support Destinations support Via user provided services Via custom provider function Accessing column values by index in $.hdb.ResultSet rows Tracing via $.trace API Troubleshooting Differences with HANA XS Classic For the API of XS Engine * SAP HANA XS JavaScript Reference Usage \u00b6 It is as simple as it could be. 'use strict' ; var xsenv = require ( '@sap/xsenv' ); var xsjs = require ( '@sap/xsjs' ); var port = process . env . PORT || 3000 ; var options = xsenv . getServices ({ uaa : 'xsuaa' , hana : 'hana-hdi' , jobs : 'scheduler' , mail : 'mail' , secureStore : 'secureStore' , auditLog : 'audit-log' }); xsjs ( options ). listen ( port ); console . log ( 'Node XS server listening on port %d' , port ); The starting function takes an object that contains service credentials and application options. You will need to setup the Application Router for authentication. For a step by step tutorial see Use the XSJS Compatibility Layer in XS Advanced in SAP HANA Developer Guide for SAP HANA XS Advanced Model . For local testing you can set options.anonymous = true to disable authentication. Options \u00b6 Here is a list with options you can provide: property default usage rootDir 'lib' xsjs files location rootDirs same as above, but array of directories can be provided, overrides rootDir if provided uaa UAA configuration necessary to enable JWT token authentication and business user propagation to HANA hana object containing HANA DB connection parameters, used for DB connectivity secureStore object containing HANA DB connection parameters, used for secure store connectivity jobs Job scheduler connection parameters used to register jobs during application startup and later for updating job execution status when job finished mail Mail options, used by $.net.Mail API maxBodySize '1mb' Maximum body size accepted by xsjs. The value is passed to the bytes library for parsing. anonymous false Enable anonymous access, i.e. without credentials formData Special restrictions over form-data submitted to server destinationProvider Custom function, synchronous or asynchronous, to be used when $.net.http.readDestination is called in XSJS code. For more information on destinations support, check the detailed description for this configuration option. ca certificates listed in XS_CACERT_PATH env var Trusted SSL certificates for any outgoing HTTPS connections. Should be an array of loaded certificates. compression true By default text resources over 1K are compressed. auditLog Object containing Audit log service credentials. If not provied audit logging will be disabled. If set to { logToConsole: true } audit log messages will be written on the console (only suitable for non-productive setup, e.g. local development). context Extend the default context in xsjs scripts. libraryCache Contains the xsjslibs that should be cached. redirectUrl If specified, a redirect to this url is triggered when the root path is requested. Note : When xsjs is behind a reverse proxy (Application Router for instance), the value of this property should be aligned with the path rewriting rules that may apply. xsApplicationUser true If set to false, the session variable XS_APPLICATIONUSER will not be set. Note: When there are several rootDirs (for example: repo1 and repo2) and their file strucutre is equivalent (/repo1/hello.xsjs and /repo2/hello.xsjs) the file from the first directory (as listed in the 'rootDirs' property) will be used (/repo1/hello.xsjs) and the file from the second directory (/repo2/hello.xsjs) will be ignored with a warning message in the logs. SAP HANA XS Advanced applications connect to HANA with a fixed technical user provided via CloudFoundry service (environment variables). The actual (business) user of the application is retrieved from the JWT token and propagated to HANA. The connection to Job scheduler service is done with a fixed technical user provided by the CloudFoundry service binding. hana \u00b6 property mandatory usage host x DB host port x DB port user x Technical user used for DB connection password x Technical user password schema If provided will be set as current schema to DB connection connectWithLoggedUser Possible values are true / false , default is false . If provided the DB connection will be done with the SAML assertion contained in the JWT token of the logged user. Note: This option is provided only for HANA cockpit transition to SAP HANA XS Advanced. In general this option should be avoided. sqlcc Object containing all SQLCC configurations as properties with name after SQLCC name used in XSJS code ca Trusted SSL certificates explicitly for HANA connection. Should be an array of loaded certificates. If not provided, certificate from service binding will be used. If none are available HANA connection will not be encrypted. sqlcc - referring to the example above, SQLCC property can be initialized from the bound services like this: ... options . hana . sqlcc = xsenv . getServices ({ 'com.sap.my.sqlcc_config' : 'SQLCC__NAME' , 'com.sap.my.other_sqlcc_config' : 'OTHER_SQLCC_UPS_NAME' }); ... and used later in xsjs code like: var connection = $ . db . getConnection ( 'com.sap.my.sqlcc_config' ); secureStore \u00b6 property mandatory usage host x DB host port x DB port user x Technical user used for DB connection password x Technical user password schema If provided will be set as current schema to DB connection formData \u00b6 object with following properties: property default usage maxFilesSizeInBytes 10485760 It restricts the total size of all the uploaded files. mail \u00b6 object with following properties: property mandatory usage host x SMTP server host. port x SMTP server port. ignoreTLS Could be true or false . This represents whether a STARTTLS command should be invoked if available by the mail server. Defaults to false . secure Could be true or false . This represents whether the connection should be over TLS/SSL. Defaults to false . connectionTimeout Connection timeout in ms. Defaults to 60000. authMethod Authentication method to use. Could be 'PLAIN' / 'LOGIN' / 'CRAM-MD5'. auth Authentication credentials. Example: destinationProvider \u00b6 If your application requires different mechanism for destination configuration for example dynamic configuration changes or dynamically adding new destinations to your application, you can provide own function that retrieves these configurations from your storage. For convenience we support synchronous and asynchronous destination provider function. Depending on the number of parameters your function has we call it synchronously or asynchronously. Here are the signatures for both: function getDestinationSync ( packagename , objectname , dtDescriptor ) { } function getDestinationAsync ( packagename , objectname , dtDescriptor , callback ) { } parameter description packagename the package of the destination supplied to $.net.http.readDestination objectname the object name of the destination supplied to $.net.http.readDestination dtDescriptor object containing all properties contained in the corresponding .xshttpdest file, if such file is available, otherwise undefined callback provided only in the asynchronous case - should be called by your provider function to return the destination or report error auditLog \u00b6 This package audit logs entries in the following cases: - when the validation of the incoming JWT token fails - when the token in the request used to trigger a job does not contain the required scope Applications can also write audit log messages: var xsjs = require ( '@sap/xsjs' ); var xsenv = require ( '@sap/xsenv' ); var auditLogging = require ( '@sap/audit-logging' ); var port = process . env . PORT || 3000 ; var options = xsenv . getServices ({ auditLog : 'audit-log' , uaa : 'xsuaa' , hana : 'hana-hdi' }); // Using Audit log REST API v2 auditLogging . v2 ( options . auditLog , function ( err , auditLog ) { if ( err ) { return console . log ( 'Could not create audit log client:' , err ); } options . context = { auditLog : auditLog }; xsjs ( options ). listen ( port ); }); Note : Check in advance whether the Audit log service to be used supports REST API v2 (note the invocation of the v2 method of auditLogging ). Otherwise instantiate a client object that works with Audit log REST API v1: // Using Audit log REST API v1 var auditLog = auditLogging ( options . auditLog ); It is recommended to use Audit log REST API v2 if available. Refer to the documentation of the @sap/audit-logging package for more information. The audit log client object can then be used as following: auditLog . securityMessage ( 'Content of the message' ) . by ( $ . session . getUsername ()) . sync . log (); Note : The usage of sync before log - this ensures that the call to the Audit log service is synchronous. Note : $.session.getUsername() returns undefined in case anonymous mode is used. It is up to applications whether to use another string as user or not audit log at all. context \u00b6 This option can be used if you want to extend the xsjs scripts with additional global variables. Example: var xsjs = require ( '@sap/xsjs' ); var options = { anonymous : true , context : { answer : 42 } }; xsjs ( options ). listen ( 3000 ); This configuration extends the context of xsjs scripts with one additional variable called answer . Every time an xsjs script is executed it will not only have the $ variable in it's context, but it will also include variable answer with value 42 . Lets have a file answer.xsjs with the following content: $ . response . setBody ( answer ); A request to http://<your_domain>:3000/answer.xsjs will respond with 42 . With the context property set, you can expose Node.js packages and variables: var options = { anonymous : true , context : { environment : process . env , _ : require ( 'lodash' ) } }; Currently we are aware of a limitation, which causes <variable> instanceof <constructor_function> used in a xsjs script to have odd behaviour. Also stubbing or mocking constructor functions such as Date , String , etc in a xsjs script won't affect other xsjs files. The context property also finds usage in a workaround for this limitations. Setting: var options = { anonymous : true , context : { Array : Array , String : String } }; will fix these problems, but has side effects: Creating an array in xsjs script and checking it's instance will now return false: var myArray = [ 1 , 2 , 3 ]; $ . response . setBody ( myArray instanceof Array ); // Responds with false Monkey-patching built-in types won't work as expected, if they are exposed through the context property: String . prototype . contains = function ( str ) { return this . indexOf ( str ) >= 0 ; }; var stringLiteral = 'Abc' ; var stringObject = new String ( 'Abc' ); console . log ( stringLiteral . contains ); // undefined console . log ( stringObject . contains ); // [Function] Since there might be other side effects, use this feature at your own risk. libraryCache \u00b6 An object that contains the xsjslibs that will be cached. Example: { 'my.libs.utility' : 'global' } In XSJS code the import looks like: var utility = $ . import ( 'my.libs' , 'utility' ); Note: it is recommended to use this feature only when necessary because keeps the cached content until the application is running. It might have side effects in case the xsjslib keeps state. It also leads to extensive memory consumption and this should be considered while calculating application memory limits. Multitenant usage \u00b6 In multitenant scenarios, the hana and secureStore properties can contain an object with the credentials of a managed-hana (Instance Manager) service (created with the appropriate service plan) instead of the credentials of a hana service. In this case the application will connect to a HANA system depending on the tenant (identity zone) of the incoming request. A managed service instance for the particular tenant should be created in advance and the corresponding database artefacts should be deployed prior to requesting the application with this tenant. Otherwise the processing of the request will be terminated with an error. Note : Currently jobs are not multitenant-aware. Jobs are shared between tenants and a connection to a HANA database cannot be established. A job executing xsjs code can still connect to a specific HANA service instance using SQLCC configuration. OData support \u00b6 OData support is provided by OData package @sap/xsodata. Details on what features are provided can be found in the project itself. The compatibility layer scans for .xsodata files in the specified source directory and registers OData endpoints for each valid descriptor. Both JavaScript and SQL script exits are supported. Clear OData model cache \u00b6 For each OData service the model is loaded and cached in memory upon first request. In case the schema of the underlying db objects is changed at runtime, it is necessary to reload the model. Here is an example: var app = xsjs ( options ); function onSchemaChange ( tenant ) { app . clearODataCache ( tenant ); } clearODataCache(tenant) clears the OData model cache for the given tenant. tenant argument is optional. If not provided, the cache for all tenants will be cleared. Note: Each application instance contains a cache of OData models. Clearing the cache in one of those instances does not automatically trigger cache invalidation in the others. The application itself is responsible for calling clearODataCache in each instance. Since an HTTP request is received only by a single instance, it cannot be used to trigger clearing the cache in a consistent manner for the whole application. Other solutions, like messaging, are more suitable for that purpose. NPM packages support \u00b6 As an extension in the dollar API we included support for all the available NPM packages. For example, in your xsjs file you can add the following code: var _ = $ . require ( 'underscore' ); // Count to ten var count = '' ; _ . range ( 11 ). forEach ( function ( number ) { count += number + ' ' ; }); $ . response . setBody ( count ); NOTE : If you require an npm package that is asynchronous, you have to use the sync property to make it synchronous. See fibrous package for details. Let's take for example the request module from npm. The standard Node.js approach for using the module will be: var request = $ . require ( 'request' ); request ( 'http://google.com' , function ( error , response ) { if ( error ) { $ . trace . error ( error ); return ; } $ . response . setBody ( response . body ); }); This snippet won't work in a xsjs file. The right xsjs approach would be: var request = $ . require ( 'request' ); try { var response = request . sync ( 'http://google.com' ); $ . response . setBody ( response . body ); } catch ( error ) { $ . trace . error ( error . message ); } You can also require a file relatively. The required file will execute in Node.js context. This means you will have access to global Node.js variables, such as __dirname , process , etc. in it. For example, if we have a file called myAPI.js with content: // myAPI.js module . exports = { getDirname : function () { return __dirname ; } }; Let's say myAPI.js is located in a parent directory for the following xsjs file: var myAPI = $ . require ( '../myAPI.js' ); $ . response . setBody ( myAPI . getDirname ()); Destinations support \u00b6 Via user provided services \u00b6 By default the compatibility layer supports destinations configuration via user provided services. The destination name (the repo resource id, e.g. package + '.' + xshttpdest name) is matched to service name. Example content of VCAP_SERVICES: \"VCAP_SERVICES\" : { \"user-provided\" : [ { \"label\" : \"user-provided\" , \"name\" : \"foobar.httpdest.mydest\" , \"credentials\" : { \"host\" : \"some.host\" , \"port\" : 8088 , \"username\" : \"user\" , \"password\" : \"secret\" } } ] } Example usage in XSJS code: var destination = $ . net . http . readDestination ( 'foobar.httpdest' , 'mydest' ); If there is no service in VCAP_SERVICES with same name as the destination requested, an exception is thrown. When destination is read the content of the design time descriptor is merged with the properties provided in the user provided service. Property values of the UP service override DT descriptor values. Via custom provider function \u00b6 If the default support is not enough for your use case, you can provide custom destination provider function. For details how to do that, see the destinationProvider configuration option explained above. Accessing column values by index in $.hdb.ResultSet rows \u00b6 Column values from within a row of a $.hdb.ResultSet in XS Classic can be accessed either by column name or by column index. If an application does not make use of accessing columns by index, then this capability can be turned off which will result in improved performance: var connection = $ . hdb . getConnection ({ enableColumnIndices : false }); Tracing via $.trace API \u00b6 Each trace entry is associated with a location. The entry point being accessed is used as a location: - All application trace entries produced during OData handling (entries produced by exits and the imported .xsjslib scripts, @sap/xsodata entries) use the location of the .xsodata service itself, e.g. '/odata/service.xsodata'. - All application trace entries produced during job execution (entries from .xsjs scripts and the imported .xsjslib s) use the location of the .xsjob descriptor, e.g '/jobs/my-job.xsjob'. - All application trace entries produced by .xsjs code (including the imported .xsjslib scripts) use the location of the .xsjs file itself, e.g. '/xsjs/service.xsjs'. The same applies to scripts referenced from $.response.followUp . This allows easier changing of the tracing level (only of the entry point - a .xsodata , a .xsjob or a .xsjs ) without doing so for every single script involved in the execution or by using wildcards. The trace message can be used to find the source line that has produced it. Note: Regarding request-ids for jobs - the run-id received from the jobscheduler is used as the request-id instead of an auto-generated one. Troubleshooting \u00b6 This package uses @sap/logging package so all of its features are available to control logging. For example to set all logging and tracing to finest level set XS_APP_LOG_LEVEL environment variable to debug . If the application is deployed on XS Advanced On-premise Runtime, you can change the log level without restarting the application. For example this command will set all logging and tracing to finest level. xs set-logging-level <application-name> \"*\" debug See @sap/logging documentation for details. Some of the libraries used by this package employ other tracing mechanisms. For example many use the popular debug package. This means that by setting DEBUG environment variable, you can enable additional traces. Set it to * to enable all of them, but be careful as the output may be overwhelming. In addition internal Node.js traces can be enabled via NODE_DEBUG environment variable. This post describes it in more detail. Warning: Enabling some of these options may trace security sensitive data, so use with caution. Differences with HANA XS Classic \u00b6 See the differences here .","title":"Index"},{"location":"apis/xsjs/#sapxsjs","text":"Compatibility layer for SAP HANA extended application services, classic model (SAP HANA XS Classic) applications to run on Node.js in SAP HANA extended application services, advanced model. Usage Options hana secureStore formData mail destinationProvider auditLog context libraryCache Multitenant usage OData support Clear OData model cache NPM packages support Destinations support Via user provided services Via custom provider function Accessing column values by index in $.hdb.ResultSet rows Tracing via $.trace API Troubleshooting Differences with HANA XS Classic For the API of XS Engine * SAP HANA XS JavaScript Reference","title":"@sap/xsjs"},{"location":"apis/xsjs/#usage","text":"It is as simple as it could be. 'use strict' ; var xsenv = require ( '@sap/xsenv' ); var xsjs = require ( '@sap/xsjs' ); var port = process . env . PORT || 3000 ; var options = xsenv . getServices ({ uaa : 'xsuaa' , hana : 'hana-hdi' , jobs : 'scheduler' , mail : 'mail' , secureStore : 'secureStore' , auditLog : 'audit-log' }); xsjs ( options ). listen ( port ); console . log ( 'Node XS server listening on port %d' , port ); The starting function takes an object that contains service credentials and application options. You will need to setup the Application Router for authentication. For a step by step tutorial see Use the XSJS Compatibility Layer in XS Advanced in SAP HANA Developer Guide for SAP HANA XS Advanced Model . For local testing you can set options.anonymous = true to disable authentication.","title":"Usage"},{"location":"apis/xsjs/#options","text":"Here is a list with options you can provide: property default usage rootDir 'lib' xsjs files location rootDirs same as above, but array of directories can be provided, overrides rootDir if provided uaa UAA configuration necessary to enable JWT token authentication and business user propagation to HANA hana object containing HANA DB connection parameters, used for DB connectivity secureStore object containing HANA DB connection parameters, used for secure store connectivity jobs Job scheduler connection parameters used to register jobs during application startup and later for updating job execution status when job finished mail Mail options, used by $.net.Mail API maxBodySize '1mb' Maximum body size accepted by xsjs. The value is passed to the bytes library for parsing. anonymous false Enable anonymous access, i.e. without credentials formData Special restrictions over form-data submitted to server destinationProvider Custom function, synchronous or asynchronous, to be used when $.net.http.readDestination is called in XSJS code. For more information on destinations support, check the detailed description for this configuration option. ca certificates listed in XS_CACERT_PATH env var Trusted SSL certificates for any outgoing HTTPS connections. Should be an array of loaded certificates. compression true By default text resources over 1K are compressed. auditLog Object containing Audit log service credentials. If not provied audit logging will be disabled. If set to { logToConsole: true } audit log messages will be written on the console (only suitable for non-productive setup, e.g. local development). context Extend the default context in xsjs scripts. libraryCache Contains the xsjslibs that should be cached. redirectUrl If specified, a redirect to this url is triggered when the root path is requested. Note : When xsjs is behind a reverse proxy (Application Router for instance), the value of this property should be aligned with the path rewriting rules that may apply. xsApplicationUser true If set to false, the session variable XS_APPLICATIONUSER will not be set. Note: When there are several rootDirs (for example: repo1 and repo2) and their file strucutre is equivalent (/repo1/hello.xsjs and /repo2/hello.xsjs) the file from the first directory (as listed in the 'rootDirs' property) will be used (/repo1/hello.xsjs) and the file from the second directory (/repo2/hello.xsjs) will be ignored with a warning message in the logs. SAP HANA XS Advanced applications connect to HANA with a fixed technical user provided via CloudFoundry service (environment variables). The actual (business) user of the application is retrieved from the JWT token and propagated to HANA. The connection to Job scheduler service is done with a fixed technical user provided by the CloudFoundry service binding.","title":"Options"},{"location":"apis/xsjs/#hana","text":"property mandatory usage host x DB host port x DB port user x Technical user used for DB connection password x Technical user password schema If provided will be set as current schema to DB connection connectWithLoggedUser Possible values are true / false , default is false . If provided the DB connection will be done with the SAML assertion contained in the JWT token of the logged user. Note: This option is provided only for HANA cockpit transition to SAP HANA XS Advanced. In general this option should be avoided. sqlcc Object containing all SQLCC configurations as properties with name after SQLCC name used in XSJS code ca Trusted SSL certificates explicitly for HANA connection. Should be an array of loaded certificates. If not provided, certificate from service binding will be used. If none are available HANA connection will not be encrypted. sqlcc - referring to the example above, SQLCC property can be initialized from the bound services like this: ... options . hana . sqlcc = xsenv . getServices ({ 'com.sap.my.sqlcc_config' : 'SQLCC__NAME' , 'com.sap.my.other_sqlcc_config' : 'OTHER_SQLCC_UPS_NAME' }); ... and used later in xsjs code like: var connection = $ . db . getConnection ( 'com.sap.my.sqlcc_config' );","title":"hana"},{"location":"apis/xsjs/#securestore","text":"property mandatory usage host x DB host port x DB port user x Technical user used for DB connection password x Technical user password schema If provided will be set as current schema to DB connection","title":"secureStore"},{"location":"apis/xsjs/#formdata","text":"object with following properties: property default usage maxFilesSizeInBytes 10485760 It restricts the total size of all the uploaded files.","title":"formData"},{"location":"apis/xsjs/#mail","text":"object with following properties: property mandatory usage host x SMTP server host. port x SMTP server port. ignoreTLS Could be true or false . This represents whether a STARTTLS command should be invoked if available by the mail server. Defaults to false . secure Could be true or false . This represents whether the connection should be over TLS/SSL. Defaults to false . connectionTimeout Connection timeout in ms. Defaults to 60000. authMethod Authentication method to use. Could be 'PLAIN' / 'LOGIN' / 'CRAM-MD5'. auth Authentication credentials. Example:","title":"mail"},{"location":"apis/xsjs/#destinationprovider","text":"If your application requires different mechanism for destination configuration for example dynamic configuration changes or dynamically adding new destinations to your application, you can provide own function that retrieves these configurations from your storage. For convenience we support synchronous and asynchronous destination provider function. Depending on the number of parameters your function has we call it synchronously or asynchronously. Here are the signatures for both: function getDestinationSync ( packagename , objectname , dtDescriptor ) { } function getDestinationAsync ( packagename , objectname , dtDescriptor , callback ) { } parameter description packagename the package of the destination supplied to $.net.http.readDestination objectname the object name of the destination supplied to $.net.http.readDestination dtDescriptor object containing all properties contained in the corresponding .xshttpdest file, if such file is available, otherwise undefined callback provided only in the asynchronous case - should be called by your provider function to return the destination or report error","title":"destinationProvider"},{"location":"apis/xsjs/#auditlog","text":"This package audit logs entries in the following cases: - when the validation of the incoming JWT token fails - when the token in the request used to trigger a job does not contain the required scope Applications can also write audit log messages: var xsjs = require ( '@sap/xsjs' ); var xsenv = require ( '@sap/xsenv' ); var auditLogging = require ( '@sap/audit-logging' ); var port = process . env . PORT || 3000 ; var options = xsenv . getServices ({ auditLog : 'audit-log' , uaa : 'xsuaa' , hana : 'hana-hdi' }); // Using Audit log REST API v2 auditLogging . v2 ( options . auditLog , function ( err , auditLog ) { if ( err ) { return console . log ( 'Could not create audit log client:' , err ); } options . context = { auditLog : auditLog }; xsjs ( options ). listen ( port ); }); Note : Check in advance whether the Audit log service to be used supports REST API v2 (note the invocation of the v2 method of auditLogging ). Otherwise instantiate a client object that works with Audit log REST API v1: // Using Audit log REST API v1 var auditLog = auditLogging ( options . auditLog ); It is recommended to use Audit log REST API v2 if available. Refer to the documentation of the @sap/audit-logging package for more information. The audit log client object can then be used as following: auditLog . securityMessage ( 'Content of the message' ) . by ( $ . session . getUsername ()) . sync . log (); Note : The usage of sync before log - this ensures that the call to the Audit log service is synchronous. Note : $.session.getUsername() returns undefined in case anonymous mode is used. It is up to applications whether to use another string as user or not audit log at all.","title":"auditLog"},{"location":"apis/xsjs/#context","text":"This option can be used if you want to extend the xsjs scripts with additional global variables. Example: var xsjs = require ( '@sap/xsjs' ); var options = { anonymous : true , context : { answer : 42 } }; xsjs ( options ). listen ( 3000 ); This configuration extends the context of xsjs scripts with one additional variable called answer . Every time an xsjs script is executed it will not only have the $ variable in it's context, but it will also include variable answer with value 42 . Lets have a file answer.xsjs with the following content: $ . response . setBody ( answer ); A request to http://<your_domain>:3000/answer.xsjs will respond with 42 . With the context property set, you can expose Node.js packages and variables: var options = { anonymous : true , context : { environment : process . env , _ : require ( 'lodash' ) } }; Currently we are aware of a limitation, which causes <variable> instanceof <constructor_function> used in a xsjs script to have odd behaviour. Also stubbing or mocking constructor functions such as Date , String , etc in a xsjs script won't affect other xsjs files. The context property also finds usage in a workaround for this limitations. Setting: var options = { anonymous : true , context : { Array : Array , String : String } }; will fix these problems, but has side effects: Creating an array in xsjs script and checking it's instance will now return false: var myArray = [ 1 , 2 , 3 ]; $ . response . setBody ( myArray instanceof Array ); // Responds with false Monkey-patching built-in types won't work as expected, if they are exposed through the context property: String . prototype . contains = function ( str ) { return this . indexOf ( str ) >= 0 ; }; var stringLiteral = 'Abc' ; var stringObject = new String ( 'Abc' ); console . log ( stringLiteral . contains ); // undefined console . log ( stringObject . contains ); // [Function] Since there might be other side effects, use this feature at your own risk.","title":"context"},{"location":"apis/xsjs/#librarycache","text":"An object that contains the xsjslibs that will be cached. Example: { 'my.libs.utility' : 'global' } In XSJS code the import looks like: var utility = $ . import ( 'my.libs' , 'utility' ); Note: it is recommended to use this feature only when necessary because keeps the cached content until the application is running. It might have side effects in case the xsjslib keeps state. It also leads to extensive memory consumption and this should be considered while calculating application memory limits.","title":"libraryCache"},{"location":"apis/xsjs/#multitenant-usage","text":"In multitenant scenarios, the hana and secureStore properties can contain an object with the credentials of a managed-hana (Instance Manager) service (created with the appropriate service plan) instead of the credentials of a hana service. In this case the application will connect to a HANA system depending on the tenant (identity zone) of the incoming request. A managed service instance for the particular tenant should be created in advance and the corresponding database artefacts should be deployed prior to requesting the application with this tenant. Otherwise the processing of the request will be terminated with an error. Note : Currently jobs are not multitenant-aware. Jobs are shared between tenants and a connection to a HANA database cannot be established. A job executing xsjs code can still connect to a specific HANA service instance using SQLCC configuration.","title":"Multitenant usage"},{"location":"apis/xsjs/#odata-support","text":"OData support is provided by OData package @sap/xsodata. Details on what features are provided can be found in the project itself. The compatibility layer scans for .xsodata files in the specified source directory and registers OData endpoints for each valid descriptor. Both JavaScript and SQL script exits are supported.","title":"OData support"},{"location":"apis/xsjs/#clear-odata-model-cache","text":"For each OData service the model is loaded and cached in memory upon first request. In case the schema of the underlying db objects is changed at runtime, it is necessary to reload the model. Here is an example: var app = xsjs ( options ); function onSchemaChange ( tenant ) { app . clearODataCache ( tenant ); } clearODataCache(tenant) clears the OData model cache for the given tenant. tenant argument is optional. If not provided, the cache for all tenants will be cleared. Note: Each application instance contains a cache of OData models. Clearing the cache in one of those instances does not automatically trigger cache invalidation in the others. The application itself is responsible for calling clearODataCache in each instance. Since an HTTP request is received only by a single instance, it cannot be used to trigger clearing the cache in a consistent manner for the whole application. Other solutions, like messaging, are more suitable for that purpose.","title":"Clear OData model cache"},{"location":"apis/xsjs/#npm-packages-support","text":"As an extension in the dollar API we included support for all the available NPM packages. For example, in your xsjs file you can add the following code: var _ = $ . require ( 'underscore' ); // Count to ten var count = '' ; _ . range ( 11 ). forEach ( function ( number ) { count += number + ' ' ; }); $ . response . setBody ( count ); NOTE : If you require an npm package that is asynchronous, you have to use the sync property to make it synchronous. See fibrous package for details. Let's take for example the request module from npm. The standard Node.js approach for using the module will be: var request = $ . require ( 'request' ); request ( 'http://google.com' , function ( error , response ) { if ( error ) { $ . trace . error ( error ); return ; } $ . response . setBody ( response . body ); }); This snippet won't work in a xsjs file. The right xsjs approach would be: var request = $ . require ( 'request' ); try { var response = request . sync ( 'http://google.com' ); $ . response . setBody ( response . body ); } catch ( error ) { $ . trace . error ( error . message ); } You can also require a file relatively. The required file will execute in Node.js context. This means you will have access to global Node.js variables, such as __dirname , process , etc. in it. For example, if we have a file called myAPI.js with content: // myAPI.js module . exports = { getDirname : function () { return __dirname ; } }; Let's say myAPI.js is located in a parent directory for the following xsjs file: var myAPI = $ . require ( '../myAPI.js' ); $ . response . setBody ( myAPI . getDirname ());","title":"NPM packages support"},{"location":"apis/xsjs/#destinations-support","text":"","title":"Destinations support"},{"location":"apis/xsjs/#via-user-provided-services","text":"By default the compatibility layer supports destinations configuration via user provided services. The destination name (the repo resource id, e.g. package + '.' + xshttpdest name) is matched to service name. Example content of VCAP_SERVICES: \"VCAP_SERVICES\" : { \"user-provided\" : [ { \"label\" : \"user-provided\" , \"name\" : \"foobar.httpdest.mydest\" , \"credentials\" : { \"host\" : \"some.host\" , \"port\" : 8088 , \"username\" : \"user\" , \"password\" : \"secret\" } } ] } Example usage in XSJS code: var destination = $ . net . http . readDestination ( 'foobar.httpdest' , 'mydest' ); If there is no service in VCAP_SERVICES with same name as the destination requested, an exception is thrown. When destination is read the content of the design time descriptor is merged with the properties provided in the user provided service. Property values of the UP service override DT descriptor values.","title":"Via user provided services"},{"location":"apis/xsjs/#via-custom-provider-function","text":"If the default support is not enough for your use case, you can provide custom destination provider function. For details how to do that, see the destinationProvider configuration option explained above.","title":"Via custom provider function"},{"location":"apis/xsjs/#accessing-column-values-by-index-in-hdbresultset-rows","text":"Column values from within a row of a $.hdb.ResultSet in XS Classic can be accessed either by column name or by column index. If an application does not make use of accessing columns by index, then this capability can be turned off which will result in improved performance: var connection = $ . hdb . getConnection ({ enableColumnIndices : false });","title":"Accessing column values by index in $.hdb.ResultSet rows"},{"location":"apis/xsjs/#tracing-via-trace-api","text":"Each trace entry is associated with a location. The entry point being accessed is used as a location: - All application trace entries produced during OData handling (entries produced by exits and the imported .xsjslib scripts, @sap/xsodata entries) use the location of the .xsodata service itself, e.g. '/odata/service.xsodata'. - All application trace entries produced during job execution (entries from .xsjs scripts and the imported .xsjslib s) use the location of the .xsjob descriptor, e.g '/jobs/my-job.xsjob'. - All application trace entries produced by .xsjs code (including the imported .xsjslib scripts) use the location of the .xsjs file itself, e.g. '/xsjs/service.xsjs'. The same applies to scripts referenced from $.response.followUp . This allows easier changing of the tracing level (only of the entry point - a .xsodata , a .xsjob or a .xsjs ) without doing so for every single script involved in the execution or by using wildcards. The trace message can be used to find the source line that has produced it. Note: Regarding request-ids for jobs - the run-id received from the jobscheduler is used as the request-id instead of an auto-generated one.","title":"Tracing via $.trace API"},{"location":"apis/xsjs/#troubleshooting","text":"This package uses @sap/logging package so all of its features are available to control logging. For example to set all logging and tracing to finest level set XS_APP_LOG_LEVEL environment variable to debug . If the application is deployed on XS Advanced On-premise Runtime, you can change the log level without restarting the application. For example this command will set all logging and tracing to finest level. xs set-logging-level <application-name> \"*\" debug See @sap/logging documentation for details. Some of the libraries used by this package employ other tracing mechanisms. For example many use the popular debug package. This means that by setting DEBUG environment variable, you can enable additional traces. Set it to * to enable all of them, but be careful as the output may be overwhelming. In addition internal Node.js traces can be enabled via NODE_DEBUG environment variable. This post describes it in more detail. Warning: Enabling some of these options may trace security sensitive data, so use with caution.","title":"Troubleshooting"},{"location":"apis/xsjs/#differences-with-hana-xs-classic","text":"See the differences here .","title":"Differences with HANA XS Classic"},{"location":"apis/xsjs/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 6.0.4 - 2020-06-01 \u00b6 Fixed \u00b6 Crash when executing a CALL procedure statement with $.hdb.Connection.executeQuery or $.hdb.Connection.executeUpdate when there are no output tables Document some known incompatibilities in regard to jobs Add missing entry in CHANGELOG.md in regard to dropping support for PowerPC big endian in v6.0.0 Update @sap/node-jwt to v1.6.9 (contains binaries for PowerPC little endian) Update @sap/node-vsi to v1.4.18 (contains binaries for PowerPC little endian) 6.0.3 - 2020-05-18 \u00b6 Fixed \u00b6 Update @sap/xsodata to v7.0.2 6.0.2 - 2020-04-29 \u00b6 Fixed \u00b6 Update @sap/xsodata to v7.0.0 Update @sap/node-jwt to v1.6.8 Update @sap/node-vsi to v1.4.17 Update @sap/hdbext to v6.2.2 Update @sap/hana-client to v2.4.196 6.0.1 - 2020-04-16 \u00b6 Fixed \u00b6 Adjustments to avoid IsGlobalEmpty crash with $.db and $.hdb have been added Performance when executing queries with $.db and $.hdb has been improved 6.0.0 - 2020-03-13 \u00b6 Added \u00b6 Node.js 12.x support. Removed \u00b6 Support for Node.js versions 6.x and 8.x Support (pre-built binaries) for PowerPC big endian. Fixed \u00b6 Update @sap/xssec to v2.2.5 Update @sap/xsodata to v6.0.0 Update @sap/hana-client to v2.4.182 Update @sap/hdbext to v6.2.0 Update @sap/fibers to v4.0.3-0 Update @sap/fibrous to v0.5.0-5 Update @sap/node-jwt to v1.6.7 Update @sap/node-vsi to v1.4.16 5.3.1 - 2019-12-17 \u00b6 Fixed \u00b6 Update @sap/xsenv to v2.2.0 Update @sap/xsodata to v5.0.0 5.3.0 - 2019-11-20 \u00b6 Added \u00b6 Audit logging could be disabled now (providing audit log configuration is optional). Fixed \u00b6 Update @sap/hana-client to v2.4.167 5.2.3 - 2019-10-31 \u00b6 Fixed \u00b6 Update @sap/xsodata to v4.7.0 5.2.2 - 2019-10-25 \u00b6 Fixed \u00b6 Update @sap/xsodata to v4.6.0 Update @sap/hdbext to v6.1.0 (adds support for synonyms as table parameters in procedures) 5.2.1 - 2019-09-19 \u00b6 Fixed \u00b6 Integrate nodemailer v6.2.1 Update dependencies Locale of database connections when no locale information is present in the incoming request (the driver's default is now used) var s and function s from xsjslib s are now enumerable 5.2.0 - 2019-06-06 \u00b6 Added \u00b6 Node 10 support Fixed \u00b6 Updated dependencies 5.1.0 - 2019-05-20 \u00b6 Fixed \u00b6 Remove x-powered-by response header Update nodemailer to v4.3.1 Update express to v4.16.4 Added \u00b6 Adopt @sap/hana-client v2.4.139 5.0.0 - 2019-02-05 \u00b6 Fixed \u00b6 Update @sap/xsodata to v4.4.0 Update @sap/fibers to 3.1.1-1 Update @sap/fibrous to 0.5.0-4 Removed \u00b6 The support for Node.js v4.x 4.0.2 - 2019-01-21 \u00b6 Added \u00b6 Flag to disable setting XS_APPLICATIONUSER Fixed \u00b6 Update @sap/hdbext to v5.1.0. 4.0.1 - 2018-10-22 \u00b6 Fixed \u00b6 Update @sap/xsodata to v4.3.0. 4.0.0 - 2018-10-04 \u00b6 Changed \u00b6 Providing auditLog options is now mandatory. Underlying database driver is now @sap/hana-client . Due to the changed driver, precision and scale in metadata may differ for some data types (e.g. REAL, FLOAT, DOUBLE, BLOB). $.db.ResultSetMetaData.getCatalogName now throws an exception instead of returning a value. $.db.ResultSetMetaData.getColumnDisplaySize now throws an exception instead of returning a value. String representations of SECONDDATE and TIMESTAMP are in a different format (without 'T'). The format now is: YYYY-MM-DD HH24:MI:SS.FF , the format in previous versions was: YYYY-MM-DDTHH24:MI:SS.FF . $.hdb , calling stored procedures with input table parameters: since default data type conversions are not performed over input table parameters, and since @sap/hana-client is more restrictive on values provided for DATE and TIME types compared to the hdb driver, scenarios with input table parameters and table content provided as an array of objects will now throw if the input table parameter has DATE or TIME columns and the values are provided as Date objects. $.db.ResultSet.close does not close the result set. All results will be closed when the corresponding statement is closed. Added \u00b6 typeName property in result set metadata of $.hdb . Fixed \u00b6 $.db , string representations of TIMESTAMPs have all the digits from the fractional seconds that are stored in the database. Return values of $.db.ParameterMetaData.getParameterMode is now aligned with XS Classic. $.db , parameter and result set metadata - prior to this version getPrecision returned the scale and getScale returned the precision. These methods are now fixed. $.db.PreparedStatement.executeBatch now returns a value - an array with integers representing the number of updated rows per batch. Type of ALPHANUM columns is now ALPHANUM instead of NVARCHAR. Type of SECONDDATE columns is now SECONDDATE instead of TIMESTAMP. Type of SHORTTEXT columns in result set metadata is now SHORTTEXT instead of NVARCHAR. Note that parameter metadata returns NSTRING for SHORTTEXT as in versions prior to this one. Type of TEXT columns is now TEXT instead of NCLOB. Type of BINTEXT columns is now BINTEXT instead of NCLOB. 3.7.0 - 2018-10-04 \u00b6 Added \u00b6 Integration with Audit log service. 3.6.0 - 2018-09-20 \u00b6 Added \u00b6 Support for CF Log format (via adopting @sap/logging v4). Fixed \u00b6 Updated dependencies. 3.5.0 - 2018-09-04 \u00b6 Added \u00b6 enableColumnIndices option in $.hdb.getConnection with which column indices for result sets can be turned off (improves performance). Defaults to true . Warning log for aborted requests. Fixed \u00b6 Conversion of input strings for binary data types. Documentation improvements. Updated dependencies. 3.4.2 - 2018-07-10 \u00b6 Fixed \u00b6 Updated @sap/hdbext to 4.7.3 Fix regression caused by performance optimization in $.import for Node.js 6 and up ( this optimization has been removed ) Clean up acquired database connections for aborted requests 3.4.1 - 2018-06-26 \u00b6 Fixed \u00b6 Imported (via $.import ) but unused xsjslib s are no longer loaded (applicable to Node.js 6 and up) Performance during attaching column indices for $.hdb result sets (applicable to Node.js 6 and up) 3.4.0 - 2018-05-28 \u00b6 Added \u00b6 Enable setting maxBodySize Fixed \u00b6 Use @sap/xsodata feature for lazy db connection creation Updated dependencies 3.3.7 - 2018-04-23 \u00b6 Fixed \u00b6 Updated @sap/xsodata to 3.6.0 3.3.6 - 2018-04-20 \u00b6 Fixed \u00b6 Update @sap/xssec to 2.1.10 3.3.5 - 2018-04-19 \u00b6 Fixed \u00b6 Update @sap/fibers to 2.0.2-0 Update @sap/fibrous to 0.5.0-3 3.3.4 - 2018-04-06 \u00b6 Added \u00b6 A note in the documentation regarding the redirectUrl option. Fixed \u00b6 Update dependencies 3.3.3 - 2018-03-12 \u00b6 Fixed \u00b6 Improved performance of $.hdb. 3.3.2 - 2018-03-02 \u00b6 Fixed \u00b6 Fix callable statement output params. 3.3.1 - 2018-02-26 \u00b6 Fixed \u00b6 Incorrect milliseconds in TIMESTAMPS. 3.3.0 - 2018-02-21 \u00b6 Changed \u00b6 @sap/xsodata version. Added \u00b6 DSR metrics. Fixed \u00b6 Trailing zeros of decimals will not be removed. Performance issue for string to date conversions in $.hdb. 3.2.1 - 2018-02-13 \u00b6 Changed \u00b6 @sap/xsodata version. Fixed \u00b6 sqlcc user overrides default one. Returned error code in batch affected rows. 3.2.0 - 2018-01-23 \u00b6 Added \u00b6 npm-shrinkwrap.json 3.1.0 - 2018-01-16 \u00b6 Added \u00b6 Result set indices in $.hdb after output type conversions. Support for gzipped and deflated requests. Expose security context to XSJS code. Documentation for redirectUrl and libraryCache . Fixed \u00b6 Missing $.request.body in some requests. Always return array result for batch update. 3.0.0 - 2017-12-06 \u00b6 Changed \u00b6 An array of affected rows is returned for failed batch inserts via $.hdb instead of throwing an error. Added \u00b6 Node 8 support. Support for tilde ( ~ ) headers (except for ~server headers). Fixed \u00b6 Update dependencies. 2.1.2 - 2017-11-27 \u00b6 Fixed \u00b6 Updated dependencies. Apply compatible formatting for decimal strings. Warning messages for files that will be ignored. 2.1.1 - 2017-10-17 \u00b6 Changed \u00b6 Dependencies' versions. 2.1.0 - 2017-10-13 \u00b6 Added \u00b6 The authorization header is now exposed to application code. Improvements to documentation. Fixed \u00b6 Locale handling in OData. Changed \u00b6 Dependencies' versions. 2.0.0 - 2017-08-28 \u00b6 Changed \u00b6 Missing UAA configuration when anonymous access is not enabled results in an error during application startup. Not valid files (e.g. .xsjs files with syntax errors) cause an error during application startup. $.hdb.ResultSetMetadata has been incompatibly changed (compared to @sap/xsjs v1) in order to become more compatible with XS Classic. Removed \u00b6 The deprecated xsjs.extend function. The support for the 'jwt' option (use the 'uaa' option instead). The support for Node.js v0.12.x. Fixed \u00b6 $.session.language now fallbacks to the value of $.request.language if xsSessionLanguage cookie is not present. 1.16.4 - 2017-07-28 \u00b6 Added \u00b6 Provide a request-specific logger to @sap/xsodata. Fixed \u00b6 Upload of binary files. 1.16.3 - 2017-07-17 \u00b6 Fixed \u00b6 $.session missing in OData exits. Errors from .xsjs files not handled properly. 1.16.2 - 2017-07-04 \u00b6 Fixed \u00b6 .xsaccess rewrite rules scope. Default conversions on input parameters. Retrieval of job logs $.hdb.rollback is executed synchronously. 1.16.1 - 2017-06-02 \u00b6 Added \u00b6 Support for HTTP method PATCH in $.request.method. Fixed \u00b6 Fix database connection pooling. Trace uncaught exceptions stack trace. Log package version and Node version. Improvements in README.md. 1.16.0 - 2017-05-09 \u00b6 Added \u00b6 Support for Date objects as input parameters in $.hdb. Support for the treatDateAsUTC flag for $.hdb connections. Performance improvements via adopting @sap/logging version 3. Fixed \u00b6 Typo in the name of the category used for logging. Getting null values from $.db.ResultSet. Automatic closing of database connections. Changed \u00b6 The entry point of the application being accessed is used as a location of $.trace API entries. 1.15.1 - 2017-04-13 \u00b6 Fixed \u00b6 Allow query parameters for OData $batch requests 1.15.0 - 2017-04-06 \u00b6 Added \u00b6 API for clearing OData model cache. 1.14.2 - 2017-04-04 \u00b6 Fixed \u00b6 http compression was not enabled when configured. Added \u00b6 README.md table of content. 1.14.1 - 2017-03-20 \u00b6 Fixed \u00b6 ResultSet::getTimestamp regression when getting null values. xsjob can refer .xsjs files placed in the application root directory. 1.14.0 - 2017-03-13 \u00b6 Added \u00b6 Multitenancy support via integration with Instance Manager 1.13.1 - 2017-02-21 \u00b6 Fixed \u00b6 Fix jobs execution with authentication. Improve ResultSet getters parameter validation and functionallity. Fix $.session.hasAppPrivilege when using anonymous access. 1.13.0 - 2017-01-30 \u00b6 Added \u00b6 Adding, altering and deleting entries from Zip objects. Log error for jobs without HANA config. Changed \u00b6 Rename package to use @sap scope Fixed \u00b6 npm restriction. 1.12.0 - 2017-01-06 \u00b6 Added \u00b6 Column indexing functionality for $.hdb.ResultSet SAP passport support when connecting to db Fixed \u00b6 Jobs callback url Direct execution of queries in $.hdb 1.11.4 - 2016-11-25 \u00b6 Fixed \u00b6 Fix in xsodata: use same quoting semantic for input parameters of calcviews as in XS Classic 1.11.3 - 2016-11-16 \u00b6 Fixed \u00b6 Adapt Zip objects in xsjs APIs Align TupelList behavior Fix ReDoS issue in negotiator Use getter/setter for library execution result property assignment Do not trace an error stack for 4xx status codes Document decimal column incompatibility Use default previous component name in SAP passport 1.11.2 - 2016-10-14 \u00b6 Fixed \u00b6 Fixes database connectivity 1.11.1 - 2016-10-13 \u00b6 Fixed \u00b6 Fixes in xsodata 1.11.0 - 2016-10-11 \u00b6 Fixed \u00b6 Minor fixes and improvements 1.10.1 - 2016-09-28 \u00b6 Fixed \u00b6 Fixes in xsodata 1.10.0 - 2016-09-28 \u00b6 Added \u00b6 $.util.Zip $.util.SAXParser Fixed \u00b6 Align content-type header values with XS Classic Minor bug fixes 1.9.0 - 2016-08-29 \u00b6 Added \u00b6 HANA connection pooling Support for Node.js v6 1.8.0 - 2016-08-05 \u00b6 Added \u00b6 'context' property in xsjs bootstrap options which can be used if you want to extend the xsjs scripts with additional global variables Fixed \u00b6 Fixes in database connectivity 1.7.0 - 2016-07-13 \u00b6 Added \u00b6 $.util.compression $.text.mining support Support for compression","title":"Change Log"},{"location":"apis/xsjs/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xsjs/CHANGELOG/#604-2020-06-01","text":"","title":"6.0.4 - 2020-06-01"},{"location":"apis/xsjs/CHANGELOG/#fixed","text":"Crash when executing a CALL procedure statement with $.hdb.Connection.executeQuery or $.hdb.Connection.executeUpdate when there are no output tables Document some known incompatibilities in regard to jobs Add missing entry in CHANGELOG.md in regard to dropping support for PowerPC big endian in v6.0.0 Update @sap/node-jwt to v1.6.9 (contains binaries for PowerPC little endian) Update @sap/node-vsi to v1.4.18 (contains binaries for PowerPC little endian)","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#603-2020-05-18","text":"","title":"6.0.3 - 2020-05-18"},{"location":"apis/xsjs/CHANGELOG/#fixed_1","text":"Update @sap/xsodata to v7.0.2","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#602-2020-04-29","text":"","title":"6.0.2 - 2020-04-29"},{"location":"apis/xsjs/CHANGELOG/#fixed_2","text":"Update @sap/xsodata to v7.0.0 Update @sap/node-jwt to v1.6.8 Update @sap/node-vsi to v1.4.17 Update @sap/hdbext to v6.2.2 Update @sap/hana-client to v2.4.196","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#601-2020-04-16","text":"","title":"6.0.1 - 2020-04-16"},{"location":"apis/xsjs/CHANGELOG/#fixed_3","text":"Adjustments to avoid IsGlobalEmpty crash with $.db and $.hdb have been added Performance when executing queries with $.db and $.hdb has been improved","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#600-2020-03-13","text":"","title":"6.0.0 - 2020-03-13"},{"location":"apis/xsjs/CHANGELOG/#added","text":"Node.js 12.x support.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#removed","text":"Support for Node.js versions 6.x and 8.x Support (pre-built binaries) for PowerPC big endian.","title":"Removed"},{"location":"apis/xsjs/CHANGELOG/#fixed_4","text":"Update @sap/xssec to v2.2.5 Update @sap/xsodata to v6.0.0 Update @sap/hana-client to v2.4.182 Update @sap/hdbext to v6.2.0 Update @sap/fibers to v4.0.3-0 Update @sap/fibrous to v0.5.0-5 Update @sap/node-jwt to v1.6.7 Update @sap/node-vsi to v1.4.16","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#531-2019-12-17","text":"","title":"5.3.1 - 2019-12-17"},{"location":"apis/xsjs/CHANGELOG/#fixed_5","text":"Update @sap/xsenv to v2.2.0 Update @sap/xsodata to v5.0.0","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#530-2019-11-20","text":"","title":"5.3.0 - 2019-11-20"},{"location":"apis/xsjs/CHANGELOG/#added_1","text":"Audit logging could be disabled now (providing audit log configuration is optional).","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_6","text":"Update @sap/hana-client to v2.4.167","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#523-2019-10-31","text":"","title":"5.2.3 - 2019-10-31"},{"location":"apis/xsjs/CHANGELOG/#fixed_7","text":"Update @sap/xsodata to v4.7.0","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#522-2019-10-25","text":"","title":"5.2.2 - 2019-10-25"},{"location":"apis/xsjs/CHANGELOG/#fixed_8","text":"Update @sap/xsodata to v4.6.0 Update @sap/hdbext to v6.1.0 (adds support for synonyms as table parameters in procedures)","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#521-2019-09-19","text":"","title":"5.2.1 - 2019-09-19"},{"location":"apis/xsjs/CHANGELOG/#fixed_9","text":"Integrate nodemailer v6.2.1 Update dependencies Locale of database connections when no locale information is present in the incoming request (the driver's default is now used) var s and function s from xsjslib s are now enumerable","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#520-2019-06-06","text":"","title":"5.2.0 - 2019-06-06"},{"location":"apis/xsjs/CHANGELOG/#added_2","text":"Node 10 support","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_10","text":"Updated dependencies","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#510-2019-05-20","text":"","title":"5.1.0 - 2019-05-20"},{"location":"apis/xsjs/CHANGELOG/#fixed_11","text":"Remove x-powered-by response header Update nodemailer to v4.3.1 Update express to v4.16.4","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#added_3","text":"Adopt @sap/hana-client v2.4.139","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#500-2019-02-05","text":"","title":"5.0.0 - 2019-02-05"},{"location":"apis/xsjs/CHANGELOG/#fixed_12","text":"Update @sap/xsodata to v4.4.0 Update @sap/fibers to 3.1.1-1 Update @sap/fibrous to 0.5.0-4","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#removed_1","text":"The support for Node.js v4.x","title":"Removed"},{"location":"apis/xsjs/CHANGELOG/#402-2019-01-21","text":"","title":"4.0.2 - 2019-01-21"},{"location":"apis/xsjs/CHANGELOG/#added_4","text":"Flag to disable setting XS_APPLICATIONUSER","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_13","text":"Update @sap/hdbext to v5.1.0.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#401-2018-10-22","text":"","title":"4.0.1 - 2018-10-22"},{"location":"apis/xsjs/CHANGELOG/#fixed_14","text":"Update @sap/xsodata to v4.3.0.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#400-2018-10-04","text":"","title":"4.0.0 - 2018-10-04"},{"location":"apis/xsjs/CHANGELOG/#changed","text":"Providing auditLog options is now mandatory. Underlying database driver is now @sap/hana-client . Due to the changed driver, precision and scale in metadata may differ for some data types (e.g. REAL, FLOAT, DOUBLE, BLOB). $.db.ResultSetMetaData.getCatalogName now throws an exception instead of returning a value. $.db.ResultSetMetaData.getColumnDisplaySize now throws an exception instead of returning a value. String representations of SECONDDATE and TIMESTAMP are in a different format (without 'T'). The format now is: YYYY-MM-DD HH24:MI:SS.FF , the format in previous versions was: YYYY-MM-DDTHH24:MI:SS.FF . $.hdb , calling stored procedures with input table parameters: since default data type conversions are not performed over input table parameters, and since @sap/hana-client is more restrictive on values provided for DATE and TIME types compared to the hdb driver, scenarios with input table parameters and table content provided as an array of objects will now throw if the input table parameter has DATE or TIME columns and the values are provided as Date objects. $.db.ResultSet.close does not close the result set. All results will be closed when the corresponding statement is closed.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#added_5","text":"typeName property in result set metadata of $.hdb .","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_15","text":"$.db , string representations of TIMESTAMPs have all the digits from the fractional seconds that are stored in the database. Return values of $.db.ParameterMetaData.getParameterMode is now aligned with XS Classic. $.db , parameter and result set metadata - prior to this version getPrecision returned the scale and getScale returned the precision. These methods are now fixed. $.db.PreparedStatement.executeBatch now returns a value - an array with integers representing the number of updated rows per batch. Type of ALPHANUM columns is now ALPHANUM instead of NVARCHAR. Type of SECONDDATE columns is now SECONDDATE instead of TIMESTAMP. Type of SHORTTEXT columns in result set metadata is now SHORTTEXT instead of NVARCHAR. Note that parameter metadata returns NSTRING for SHORTTEXT as in versions prior to this one. Type of TEXT columns is now TEXT instead of NCLOB. Type of BINTEXT columns is now BINTEXT instead of NCLOB.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#370-2018-10-04","text":"","title":"3.7.0 - 2018-10-04"},{"location":"apis/xsjs/CHANGELOG/#added_6","text":"Integration with Audit log service.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#360-2018-09-20","text":"","title":"3.6.0 - 2018-09-20"},{"location":"apis/xsjs/CHANGELOG/#added_7","text":"Support for CF Log format (via adopting @sap/logging v4).","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_16","text":"Updated dependencies.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#350-2018-09-04","text":"","title":"3.5.0 - 2018-09-04"},{"location":"apis/xsjs/CHANGELOG/#added_8","text":"enableColumnIndices option in $.hdb.getConnection with which column indices for result sets can be turned off (improves performance). Defaults to true . Warning log for aborted requests.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_17","text":"Conversion of input strings for binary data types. Documentation improvements. Updated dependencies.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#342-2018-07-10","text":"","title":"3.4.2 - 2018-07-10"},{"location":"apis/xsjs/CHANGELOG/#fixed_18","text":"Updated @sap/hdbext to 4.7.3 Fix regression caused by performance optimization in $.import for Node.js 6 and up ( this optimization has been removed ) Clean up acquired database connections for aborted requests","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#341-2018-06-26","text":"","title":"3.4.1 - 2018-06-26"},{"location":"apis/xsjs/CHANGELOG/#fixed_19","text":"Imported (via $.import ) but unused xsjslib s are no longer loaded (applicable to Node.js 6 and up) Performance during attaching column indices for $.hdb result sets (applicable to Node.js 6 and up)","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#340-2018-05-28","text":"","title":"3.4.0 - 2018-05-28"},{"location":"apis/xsjs/CHANGELOG/#added_9","text":"Enable setting maxBodySize","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_20","text":"Use @sap/xsodata feature for lazy db connection creation Updated dependencies","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#337-2018-04-23","text":"","title":"3.3.7 - 2018-04-23"},{"location":"apis/xsjs/CHANGELOG/#fixed_21","text":"Updated @sap/xsodata to 3.6.0","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#336-2018-04-20","text":"","title":"3.3.6 - 2018-04-20"},{"location":"apis/xsjs/CHANGELOG/#fixed_22","text":"Update @sap/xssec to 2.1.10","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#335-2018-04-19","text":"","title":"3.3.5 - 2018-04-19"},{"location":"apis/xsjs/CHANGELOG/#fixed_23","text":"Update @sap/fibers to 2.0.2-0 Update @sap/fibrous to 0.5.0-3","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#334-2018-04-06","text":"","title":"3.3.4 - 2018-04-06"},{"location":"apis/xsjs/CHANGELOG/#added_10","text":"A note in the documentation regarding the redirectUrl option.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_24","text":"Update dependencies","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#333-2018-03-12","text":"","title":"3.3.3 - 2018-03-12"},{"location":"apis/xsjs/CHANGELOG/#fixed_25","text":"Improved performance of $.hdb.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#332-2018-03-02","text":"","title":"3.3.2 - 2018-03-02"},{"location":"apis/xsjs/CHANGELOG/#fixed_26","text":"Fix callable statement output params.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#331-2018-02-26","text":"","title":"3.3.1 - 2018-02-26"},{"location":"apis/xsjs/CHANGELOG/#fixed_27","text":"Incorrect milliseconds in TIMESTAMPS.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#330-2018-02-21","text":"","title":"3.3.0 - 2018-02-21"},{"location":"apis/xsjs/CHANGELOG/#changed_1","text":"@sap/xsodata version.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#added_11","text":"DSR metrics.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_28","text":"Trailing zeros of decimals will not be removed. Performance issue for string to date conversions in $.hdb.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#321-2018-02-13","text":"","title":"3.2.1 - 2018-02-13"},{"location":"apis/xsjs/CHANGELOG/#changed_2","text":"@sap/xsodata version.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#fixed_29","text":"sqlcc user overrides default one. Returned error code in batch affected rows.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#320-2018-01-23","text":"","title":"3.2.0 - 2018-01-23"},{"location":"apis/xsjs/CHANGELOG/#added_12","text":"npm-shrinkwrap.json","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#310-2018-01-16","text":"","title":"3.1.0 - 2018-01-16"},{"location":"apis/xsjs/CHANGELOG/#added_13","text":"Result set indices in $.hdb after output type conversions. Support for gzipped and deflated requests. Expose security context to XSJS code. Documentation for redirectUrl and libraryCache .","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_30","text":"Missing $.request.body in some requests. Always return array result for batch update.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#300-2017-12-06","text":"","title":"3.0.0 - 2017-12-06"},{"location":"apis/xsjs/CHANGELOG/#changed_3","text":"An array of affected rows is returned for failed batch inserts via $.hdb instead of throwing an error.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#added_14","text":"Node 8 support. Support for tilde ( ~ ) headers (except for ~server headers).","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_31","text":"Update dependencies.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#212-2017-11-27","text":"","title":"2.1.2 - 2017-11-27"},{"location":"apis/xsjs/CHANGELOG/#fixed_32","text":"Updated dependencies. Apply compatible formatting for decimal strings. Warning messages for files that will be ignored.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#211-2017-10-17","text":"","title":"2.1.1 - 2017-10-17"},{"location":"apis/xsjs/CHANGELOG/#changed_4","text":"Dependencies' versions.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#210-2017-10-13","text":"","title":"2.1.0 - 2017-10-13"},{"location":"apis/xsjs/CHANGELOG/#added_15","text":"The authorization header is now exposed to application code. Improvements to documentation.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_33","text":"Locale handling in OData.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#changed_5","text":"Dependencies' versions.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#200-2017-08-28","text":"","title":"2.0.0 - 2017-08-28"},{"location":"apis/xsjs/CHANGELOG/#changed_6","text":"Missing UAA configuration when anonymous access is not enabled results in an error during application startup. Not valid files (e.g. .xsjs files with syntax errors) cause an error during application startup. $.hdb.ResultSetMetadata has been incompatibly changed (compared to @sap/xsjs v1) in order to become more compatible with XS Classic.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#removed_2","text":"The deprecated xsjs.extend function. The support for the 'jwt' option (use the 'uaa' option instead). The support for Node.js v0.12.x.","title":"Removed"},{"location":"apis/xsjs/CHANGELOG/#fixed_34","text":"$.session.language now fallbacks to the value of $.request.language if xsSessionLanguage cookie is not present.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1164-2017-07-28","text":"","title":"1.16.4 - 2017-07-28"},{"location":"apis/xsjs/CHANGELOG/#added_16","text":"Provide a request-specific logger to @sap/xsodata.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_35","text":"Upload of binary files.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1163-2017-07-17","text":"","title":"1.16.3 - 2017-07-17"},{"location":"apis/xsjs/CHANGELOG/#fixed_36","text":"$.session missing in OData exits. Errors from .xsjs files not handled properly.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1162-2017-07-04","text":"","title":"1.16.2 - 2017-07-04"},{"location":"apis/xsjs/CHANGELOG/#fixed_37","text":".xsaccess rewrite rules scope. Default conversions on input parameters. Retrieval of job logs $.hdb.rollback is executed synchronously.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1161-2017-06-02","text":"","title":"1.16.1 - 2017-06-02"},{"location":"apis/xsjs/CHANGELOG/#added_17","text":"Support for HTTP method PATCH in $.request.method.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_38","text":"Fix database connection pooling. Trace uncaught exceptions stack trace. Log package version and Node version. Improvements in README.md.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1160-2017-05-09","text":"","title":"1.16.0 - 2017-05-09"},{"location":"apis/xsjs/CHANGELOG/#added_18","text":"Support for Date objects as input parameters in $.hdb. Support for the treatDateAsUTC flag for $.hdb connections. Performance improvements via adopting @sap/logging version 3.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_39","text":"Typo in the name of the category used for logging. Getting null values from $.db.ResultSet. Automatic closing of database connections.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#changed_7","text":"The entry point of the application being accessed is used as a location of $.trace API entries.","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#1151-2017-04-13","text":"","title":"1.15.1 - 2017-04-13"},{"location":"apis/xsjs/CHANGELOG/#fixed_40","text":"Allow query parameters for OData $batch requests","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1150-2017-04-06","text":"","title":"1.15.0 - 2017-04-06"},{"location":"apis/xsjs/CHANGELOG/#added_19","text":"API for clearing OData model cache.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#1142-2017-04-04","text":"","title":"1.14.2 - 2017-04-04"},{"location":"apis/xsjs/CHANGELOG/#fixed_41","text":"http compression was not enabled when configured.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#added_20","text":"README.md table of content.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#1141-2017-03-20","text":"","title":"1.14.1 - 2017-03-20"},{"location":"apis/xsjs/CHANGELOG/#fixed_42","text":"ResultSet::getTimestamp regression when getting null values. xsjob can refer .xsjs files placed in the application root directory.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1140-2017-03-13","text":"","title":"1.14.0 - 2017-03-13"},{"location":"apis/xsjs/CHANGELOG/#added_21","text":"Multitenancy support via integration with Instance Manager","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#1131-2017-02-21","text":"","title":"1.13.1 - 2017-02-21"},{"location":"apis/xsjs/CHANGELOG/#fixed_43","text":"Fix jobs execution with authentication. Improve ResultSet getters parameter validation and functionallity. Fix $.session.hasAppPrivilege when using anonymous access.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1130-2017-01-30","text":"","title":"1.13.0 - 2017-01-30"},{"location":"apis/xsjs/CHANGELOG/#added_22","text":"Adding, altering and deleting entries from Zip objects. Log error for jobs without HANA config.","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#changed_8","text":"Rename package to use @sap scope","title":"Changed"},{"location":"apis/xsjs/CHANGELOG/#fixed_44","text":"npm restriction.","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1120-2017-01-06","text":"","title":"1.12.0 - 2017-01-06"},{"location":"apis/xsjs/CHANGELOG/#added_23","text":"Column indexing functionality for $.hdb.ResultSet SAP passport support when connecting to db","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_45","text":"Jobs callback url Direct execution of queries in $.hdb","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1114-2016-11-25","text":"","title":"1.11.4 - 2016-11-25"},{"location":"apis/xsjs/CHANGELOG/#fixed_46","text":"Fix in xsodata: use same quoting semantic for input parameters of calcviews as in XS Classic","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1113-2016-11-16","text":"","title":"1.11.3 - 2016-11-16"},{"location":"apis/xsjs/CHANGELOG/#fixed_47","text":"Adapt Zip objects in xsjs APIs Align TupelList behavior Fix ReDoS issue in negotiator Use getter/setter for library execution result property assignment Do not trace an error stack for 4xx status codes Document decimal column incompatibility Use default previous component name in SAP passport","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1112-2016-10-14","text":"","title":"1.11.2 - 2016-10-14"},{"location":"apis/xsjs/CHANGELOG/#fixed_48","text":"Fixes database connectivity","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1111-2016-10-13","text":"","title":"1.11.1 - 2016-10-13"},{"location":"apis/xsjs/CHANGELOG/#fixed_49","text":"Fixes in xsodata","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1110-2016-10-11","text":"","title":"1.11.0 - 2016-10-11"},{"location":"apis/xsjs/CHANGELOG/#fixed_50","text":"Minor fixes and improvements","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1101-2016-09-28","text":"","title":"1.10.1 - 2016-09-28"},{"location":"apis/xsjs/CHANGELOG/#fixed_51","text":"Fixes in xsodata","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#1100-2016-09-28","text":"","title":"1.10.0 - 2016-09-28"},{"location":"apis/xsjs/CHANGELOG/#added_24","text":"$.util.Zip $.util.SAXParser","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_52","text":"Align content-type header values with XS Classic Minor bug fixes","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#190-2016-08-29","text":"","title":"1.9.0 - 2016-08-29"},{"location":"apis/xsjs/CHANGELOG/#added_25","text":"HANA connection pooling Support for Node.js v6","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#180-2016-08-05","text":"","title":"1.8.0 - 2016-08-05"},{"location":"apis/xsjs/CHANGELOG/#added_26","text":"'context' property in xsjs bootstrap options which can be used if you want to extend the xsjs scripts with additional global variables","title":"Added"},{"location":"apis/xsjs/CHANGELOG/#fixed_53","text":"Fixes in database connectivity","title":"Fixed"},{"location":"apis/xsjs/CHANGELOG/#170-2016-07-13","text":"","title":"1.7.0 - 2016-07-13"},{"location":"apis/xsjs/CHANGELOG/#added_27","text":"$.util.compression $.text.mining support Support for compression","title":"Added"},{"location":"apis/xsjs/differences/","text":"Differences between XSJS on Node.js and HANA XS Classic \u00b6 Legacy Database API ($.db) Database API ($.hdb) Jobs API ($.jobs) Network API ($.net) Security API ($.security) Session API ($.session) Text Analysis and Text Mining ($.text) Trace API ($.trace) Util API ($.util) Request Processing API ($.web) ODATA Repository access ($.repo) JavaScript VM Other Legacy Database API ($.db) \u00b6 getX functions where X is some type do not perform as many type conversions as in HANA XS Classic $.db.ResultSet.getString() works for unicode characters (e.g. if the column from the ResultSet is NSTRING) $.db.ResultSet.getClob() works for unicode characters (e.g. if the column from the ResultSet is NCLOB) $.db.ResultSet.close does not close the result set. ParameterMetaData getParameterType and getParameterTypeName may return different values from HANA XS Classic, e.g. NSTRING returned instead of SHORTTEXT DECIMAL returned instead of SMALLDECIMAL table output parameters from stored procedures are not described in ParameterMetaData isNullable - Not supported isSigned - Not supported hasDefault - Not supported ResultSetMetaData getColumnType and getColumnTypeName may return different values from HANA XS Classic, similarly to ParameterMetaData getCatalogName - Not supported getColumnDisplaySize - Not supported PreparedStatement, CallableStatement - setDate, setTime, setTimestamp not all date/time formats are supported Database API ($.hdb) \u00b6 The ResultSet metadata object does not contain the following properties: catalogName displaySize The ResultSet metadata uses true and false instead of 1 and 0 for the isNullable property Date objects received for the TIME data type may have arbitrary values for year, month and day. Values returned for the TEXT and BINTEXT data types are strings instead of ArrayBuffers. Objects representing a date-time value via a string and optionally a format for parsing (for example, { '$date': '...' } or { '$timestamp': '...', '$format': '...' } ) are not supported as input parameters. Default conversions are not applied for input table parameters. $.hdb.ResultSet if there is a column with a numeric name (e.g. \"99\") and this number is equal or greater than the number of columns, accessing this column by name (e.g. row[\"99\"] ) in XS Classic returns undefined while in XS Advanced it returns the column value. columns with numeric names which are within the range of possible column indices are non-enumerable in XS Advanced. Values of INOUT/OUT procedure parameters are retrieved using upper case parameter names. It is possible to execute a CALL procedure statement with $.hdb.Connection.executeQuery or $.hdb.Connection.executeUpdate . Output parameters cannot be retrieved from the result of such a call, only the first output table is returned (if there are any output tables). Note that this is not supported in XS Classic and is not recommended to be used in @sap/xsjs . $.hdb.Connection.loadProcedure or $.db.Connection.prepareCall should be used instead. Jobs API ($.jobs) \u00b6 All jobs (defined in .xsjob files) are active by default $.jobs.Job sqlcc property in the constructor parameter is not supported getConfiguration method is not supported In XS Classic the ID of a job schedule is a number, while in XSJS it is a uuid (a string with 36 characters) In XSJS only a Date object is accepted for a date/time property, while XS Classic accepts also an object with value and format properties allowing custom date formats The JobLogObject does not support the following properties: host port action user thread_id Network API ($.net) \u00b6 Destinations only the following properties are supported - host, port, pathPrefix, useProxy, proxyHost, proxyPort, authType, username, password Mail, SMTPConnection proxy support and Digest-MD5 authentication method are not supported Security API ($.security) \u00b6 Supported. Note: $.security.Store - store files are created automatically Session API ($.session) \u00b6 Only the following properties are supported: * user * language * getUsername() * hasAppPrivilege() * assertAppPrivilege() Note: $.session.language - holds the same value as $.request.language unless xsSessionLanguage cookie is set. In comparison to XS Classic, XSJS does not set this cookie. In case the xsSessionLanguage cookie is provided, it will be honored in the same manner as in XS Classic. New properties supported: * securityContext - holds the security context provided by @sap/xssec security library. This property will be undefined in case there is no authenticated user, e.g. the application does not require authentication. The security context provides synchronous and asynchronous functions. Calling sync functions is straight forward, while calling async functions should be done by adding .sync property. See NPM packages support . Text Analysis and Text Mining ($.text) \u00b6 $.text.mining supported. $.text.analysis supported when @sap/xsjs is connected to HANA 2.0. Trace API ($.trace) \u00b6 Supported. Util API ($.util) \u00b6 $.util.Zip is partially supported: Originally in XS Classic the Zip constructor accepts setting object with two properties: password and maxUncompressedSizeInBytes . Currently password-protected zips are not supported so the password property is forbidden. If an entry is added to a Zip object its value no longer gets converted to ArrayBuffer, but remains the same. $.util.compression.gunzip does not support the maxUncompressedSizeInBytes parameter. $.util.SAXParser - partial support. stop and resume methods are not supported. currentByteIndex , currentColumnNumber and currentLineNumber properties are not supported. attlistDeclHandler , endDoctypeDeclHandler , endNameSpaceDeclHandler , entityDeclHandler , externalEntityRefHandler , notationDeclHandler , processingInstructionHandler , startDoctypeDeclHandler , startNameSpaceDeclHandler , xmlDeclHandler handlers are not supported. namespaces and entities are not supported. Request Processing API ($.web) \u00b6 Supported with the following differences: - Headers starting with ~server are not available. - Duplicated custom incoming request headers are represented as joined headers. For example, if a client sends a header abc once with value of 1 and second time with a value of 2 , $.request.headers.get('abc') will result into '1, 2' instead of ['1', '2'] . - webResponse.setBody(body) - In XS Classic if body is null, undefined or object, an exception is thrown. In XS Advanced the response is 'null', 'undefined' and JSON.stringify(object), respectively. ODATA \u00b6 Supported, including SQL and JavaScript exists. Repository access ($.repo) \u00b6 Not supported. JavaScript VM \u00b6 Node.js uses V8 from Google, while HANA XS uses SpiderMonkey from Mozilla. * In XS Classic xsjs: * always runs implicitly in strict mode. * supports conditional catches (non-standard): js try { willfail() // throws FooException } catch (e if e instanceof FooException) { //do something } Node.js / V8 does not support this if construct in the catch statement - you can only provide a single parameter name, e.g. 'e'. instanceof - .xsjs files run in isolated contexts which have different references for the built-in Node.js types. This will cause instanceof not to work as expected. You can take a look on this issue in Node.js. This issue applies for built-in types like: Array , String , RegExp , Number , etc. For Array , you should use Array.isArray instead of instanceof Array . For String it is suitable to use typeof . With newer versions of Node.js (and V8 respectively), there might be fixes in the time zone offsets which can result in different string representations of Date objects (which take the timezone offset into consideration) compared to XS Classic. Other \u00b6 DXC (Direct Extractor Connection) and xsxmla are not supported. Constants inside .xsjslib (defined with const ) are not visible outside the library.","title":"Differences between XSJS on Node.js and HANA XS Classic"},{"location":"apis/xsjs/differences/#differences-between-xsjs-on-nodejs-and-hana-xs-classic","text":"Legacy Database API ($.db) Database API ($.hdb) Jobs API ($.jobs) Network API ($.net) Security API ($.security) Session API ($.session) Text Analysis and Text Mining ($.text) Trace API ($.trace) Util API ($.util) Request Processing API ($.web) ODATA Repository access ($.repo) JavaScript VM Other","title":"Differences between XSJS on Node.js and HANA XS Classic"},{"location":"apis/xsjs/differences/#legacy-database-api-db","text":"getX functions where X is some type do not perform as many type conversions as in HANA XS Classic $.db.ResultSet.getString() works for unicode characters (e.g. if the column from the ResultSet is NSTRING) $.db.ResultSet.getClob() works for unicode characters (e.g. if the column from the ResultSet is NCLOB) $.db.ResultSet.close does not close the result set. ParameterMetaData getParameterType and getParameterTypeName may return different values from HANA XS Classic, e.g. NSTRING returned instead of SHORTTEXT DECIMAL returned instead of SMALLDECIMAL table output parameters from stored procedures are not described in ParameterMetaData isNullable - Not supported isSigned - Not supported hasDefault - Not supported ResultSetMetaData getColumnType and getColumnTypeName may return different values from HANA XS Classic, similarly to ParameterMetaData getCatalogName - Not supported getColumnDisplaySize - Not supported PreparedStatement, CallableStatement - setDate, setTime, setTimestamp not all date/time formats are supported","title":"Legacy Database API ($.db)"},{"location":"apis/xsjs/differences/#database-api-hdb","text":"The ResultSet metadata object does not contain the following properties: catalogName displaySize The ResultSet metadata uses true and false instead of 1 and 0 for the isNullable property Date objects received for the TIME data type may have arbitrary values for year, month and day. Values returned for the TEXT and BINTEXT data types are strings instead of ArrayBuffers. Objects representing a date-time value via a string and optionally a format for parsing (for example, { '$date': '...' } or { '$timestamp': '...', '$format': '...' } ) are not supported as input parameters. Default conversions are not applied for input table parameters. $.hdb.ResultSet if there is a column with a numeric name (e.g. \"99\") and this number is equal or greater than the number of columns, accessing this column by name (e.g. row[\"99\"] ) in XS Classic returns undefined while in XS Advanced it returns the column value. columns with numeric names which are within the range of possible column indices are non-enumerable in XS Advanced. Values of INOUT/OUT procedure parameters are retrieved using upper case parameter names. It is possible to execute a CALL procedure statement with $.hdb.Connection.executeQuery or $.hdb.Connection.executeUpdate . Output parameters cannot be retrieved from the result of such a call, only the first output table is returned (if there are any output tables). Note that this is not supported in XS Classic and is not recommended to be used in @sap/xsjs . $.hdb.Connection.loadProcedure or $.db.Connection.prepareCall should be used instead.","title":"Database API ($.hdb)"},{"location":"apis/xsjs/differences/#jobs-api-jobs","text":"All jobs (defined in .xsjob files) are active by default $.jobs.Job sqlcc property in the constructor parameter is not supported getConfiguration method is not supported In XS Classic the ID of a job schedule is a number, while in XSJS it is a uuid (a string with 36 characters) In XSJS only a Date object is accepted for a date/time property, while XS Classic accepts also an object with value and format properties allowing custom date formats The JobLogObject does not support the following properties: host port action user thread_id","title":"Jobs API ($.jobs)"},{"location":"apis/xsjs/differences/#network-api-net","text":"Destinations only the following properties are supported - host, port, pathPrefix, useProxy, proxyHost, proxyPort, authType, username, password Mail, SMTPConnection proxy support and Digest-MD5 authentication method are not supported","title":"Network API ($.net)"},{"location":"apis/xsjs/differences/#security-api-security","text":"Supported. Note: $.security.Store - store files are created automatically","title":"Security API ($.security)"},{"location":"apis/xsjs/differences/#session-api-session","text":"Only the following properties are supported: * user * language * getUsername() * hasAppPrivilege() * assertAppPrivilege() Note: $.session.language - holds the same value as $.request.language unless xsSessionLanguage cookie is set. In comparison to XS Classic, XSJS does not set this cookie. In case the xsSessionLanguage cookie is provided, it will be honored in the same manner as in XS Classic. New properties supported: * securityContext - holds the security context provided by @sap/xssec security library. This property will be undefined in case there is no authenticated user, e.g. the application does not require authentication. The security context provides synchronous and asynchronous functions. Calling sync functions is straight forward, while calling async functions should be done by adding .sync property. See NPM packages support .","title":"Session API ($.session)"},{"location":"apis/xsjs/differences/#text-analysis-and-text-mining-text","text":"$.text.mining supported. $.text.analysis supported when @sap/xsjs is connected to HANA 2.0.","title":"Text Analysis and Text Mining ($.text)"},{"location":"apis/xsjs/differences/#trace-api-trace","text":"Supported.","title":"Trace API ($.trace)"},{"location":"apis/xsjs/differences/#util-api-util","text":"$.util.Zip is partially supported: Originally in XS Classic the Zip constructor accepts setting object with two properties: password and maxUncompressedSizeInBytes . Currently password-protected zips are not supported so the password property is forbidden. If an entry is added to a Zip object its value no longer gets converted to ArrayBuffer, but remains the same. $.util.compression.gunzip does not support the maxUncompressedSizeInBytes parameter. $.util.SAXParser - partial support. stop and resume methods are not supported. currentByteIndex , currentColumnNumber and currentLineNumber properties are not supported. attlistDeclHandler , endDoctypeDeclHandler , endNameSpaceDeclHandler , entityDeclHandler , externalEntityRefHandler , notationDeclHandler , processingInstructionHandler , startDoctypeDeclHandler , startNameSpaceDeclHandler , xmlDeclHandler handlers are not supported. namespaces and entities are not supported.","title":"Util API ($.util)"},{"location":"apis/xsjs/differences/#request-processing-api-web","text":"Supported with the following differences: - Headers starting with ~server are not available. - Duplicated custom incoming request headers are represented as joined headers. For example, if a client sends a header abc once with value of 1 and second time with a value of 2 , $.request.headers.get('abc') will result into '1, 2' instead of ['1', '2'] . - webResponse.setBody(body) - In XS Classic if body is null, undefined or object, an exception is thrown. In XS Advanced the response is 'null', 'undefined' and JSON.stringify(object), respectively.","title":"Request Processing API ($.web)"},{"location":"apis/xsjs/differences/#odata","text":"Supported, including SQL and JavaScript exists.","title":"ODATA"},{"location":"apis/xsjs/differences/#repository-access-repo","text":"Not supported.","title":"Repository access ($.repo)"},{"location":"apis/xsjs/differences/#javascript-vm","text":"Node.js uses V8 from Google, while HANA XS uses SpiderMonkey from Mozilla. * In XS Classic xsjs: * always runs implicitly in strict mode. * supports conditional catches (non-standard): js try { willfail() // throws FooException } catch (e if e instanceof FooException) { //do something } Node.js / V8 does not support this if construct in the catch statement - you can only provide a single parameter name, e.g. 'e'. instanceof - .xsjs files run in isolated contexts which have different references for the built-in Node.js types. This will cause instanceof not to work as expected. You can take a look on this issue in Node.js. This issue applies for built-in types like: Array , String , RegExp , Number , etc. For Array , you should use Array.isArray instead of instanceof Array . For String it is suitable to use typeof . With newer versions of Node.js (and V8 respectively), there might be fixes in the time zone offsets which can result in different string representations of Date objects (which take the timezone offset into consideration) compared to XS Classic.","title":"JavaScript VM"},{"location":"apis/xsjs/differences/#other","text":"DXC (Direct Extractor Connection) and xsxmla are not supported. Constants inside .xsjslib (defined with const ) are not visible outside the library.","title":"Other"},{"location":"apis/xsjs-test/","text":"@sap/xsjs-test \u00b6 Unit test framework for the compatibility layer (XS runtime) Simple steps to use xsjs-test in your project: * Declare a dev dependency to @sap/xsjs-test in your XSJS application project (package.json) * Your tests are in folder test/ parallel to package.json and lib/ * Configure a xstest script in your application package.json which runs xstest script * Run with npm run xstest Details \u00b6 1) Dev dependency to @sap/xsjs-test Please verify which version of @sap/xsjs-test is released and refer to it accordingly. Dev dependency means that @sap/xsjs-test will be installed only in local dev installation, not in productive installation. Another option would be to install @sap/xsjs-test globally on your PC: npm install -g @sap/xsjs-test Then you do not need to include it in dev dependency, it is visible everywhere on your workstation. 2) Test folder Normally xsjs runtime files are under xsjs/ folder. So following paths are expected: < >/xsjs/package.json < >/xsjs/lib/ < >/xsjs/test/ The last path is where the tests are expected. Of course you are free to put the tests in another folder, but then a special configuration is required. 3) Test script There is a normal binary script defined in bin folder. The normal way would be to define a script in the application package.json \"scripts\" : { \"xstest\" : \"xstest\" } 4) Test execution npm run xstest 5) Example configuration in file ./test/xstest.json { test : { format : \"xml\" , // optional, default: \"html\" pattern : \".*[Tt]Test\" , // optional, default: \"\".*[Tt]Test\" reportdir : \"test results folder\" , // optional, default: \".\" filename : \"test results file name without extension\" // optional, default: \"report\" }, coverage : { reporting : { reports : [ \"json\" ] // default: \"html\" }, dir : \"coverage results folder\" , // optional, default: \"{test.reportdir}/coverage\" filename : \"coverage results file name without extension\" // optional, default \"coverage\" } } Known Restrictions \u00b6 jasmine.callHTTPService() (see http://help.sap.com/hana/SAP_HANA_XS_Unit_JavaScript_API_Reference_en/jasmine.html ) is not supported because of the different underlying architecture of XSA. Instead of writing integration tests going through http, you should rely on pure unit tests to check the expected responses. jasmine.tags is not supported. jasmine.addProfile() is not supported. describe( ... ).x() is not supported. spys on globals like Date, Array, etc. won't work because each xsjslib is executed in a separate context. Try to stub/spy/mock via local members of your test instead. jasmine.hdbConnection not supported (use jasmine.dbConnection) jasmine.log is not supported (use console.log) describeDB() and xdescribeDB() are not supported because they were already deprecated before (see http://help.sap.com/hana/SAP_HANA_XS_Unit_JavaScript_API_Reference_en/global.html#describeDb ) jasmine expect().toThrowError() is not supported (use toThrow(new Error()) instead) tableUtils::copy*UserSchema() (http://help.sap.com/hana/SAP_HANA_XS_Unit_JavaScript_API_Reference_en/module-tableUtils-TableUtils.html) are not supported on HDI because there is a) no schema to copy from and b) by default no writable user schema tableUtils.fillFromCsvFile() is not supported. Use HDI *.tableimport files instead to fill your HDI container with test data. mockstar is discouraged/deprecated. Use HDI containers instead. If you need to reference larger test data, use HDI synonyms.","title":"Index"},{"location":"apis/xsjs-test/#sapxsjs-test","text":"Unit test framework for the compatibility layer (XS runtime) Simple steps to use xsjs-test in your project: * Declare a dev dependency to @sap/xsjs-test in your XSJS application project (package.json) * Your tests are in folder test/ parallel to package.json and lib/ * Configure a xstest script in your application package.json which runs xstest script * Run with npm run xstest","title":"@sap/xsjs-test"},{"location":"apis/xsjs-test/#details","text":"1) Dev dependency to @sap/xsjs-test Please verify which version of @sap/xsjs-test is released and refer to it accordingly. Dev dependency means that @sap/xsjs-test will be installed only in local dev installation, not in productive installation. Another option would be to install @sap/xsjs-test globally on your PC: npm install -g @sap/xsjs-test Then you do not need to include it in dev dependency, it is visible everywhere on your workstation. 2) Test folder Normally xsjs runtime files are under xsjs/ folder. So following paths are expected: < >/xsjs/package.json < >/xsjs/lib/ < >/xsjs/test/ The last path is where the tests are expected. Of course you are free to put the tests in another folder, but then a special configuration is required. 3) Test script There is a normal binary script defined in bin folder. The normal way would be to define a script in the application package.json \"scripts\" : { \"xstest\" : \"xstest\" } 4) Test execution npm run xstest 5) Example configuration in file ./test/xstest.json { test : { format : \"xml\" , // optional, default: \"html\" pattern : \".*[Tt]Test\" , // optional, default: \"\".*[Tt]Test\" reportdir : \"test results folder\" , // optional, default: \".\" filename : \"test results file name without extension\" // optional, default: \"report\" }, coverage : { reporting : { reports : [ \"json\" ] // default: \"html\" }, dir : \"coverage results folder\" , // optional, default: \"{test.reportdir}/coverage\" filename : \"coverage results file name without extension\" // optional, default \"coverage\" } }","title":"Details"},{"location":"apis/xsjs-test/#known-restrictions","text":"jasmine.callHTTPService() (see http://help.sap.com/hana/SAP_HANA_XS_Unit_JavaScript_API_Reference_en/jasmine.html ) is not supported because of the different underlying architecture of XSA. Instead of writing integration tests going through http, you should rely on pure unit tests to check the expected responses. jasmine.tags is not supported. jasmine.addProfile() is not supported. describe( ... ).x() is not supported. spys on globals like Date, Array, etc. won't work because each xsjslib is executed in a separate context. Try to stub/spy/mock via local members of your test instead. jasmine.hdbConnection not supported (use jasmine.dbConnection) jasmine.log is not supported (use console.log) describeDB() and xdescribeDB() are not supported because they were already deprecated before (see http://help.sap.com/hana/SAP_HANA_XS_Unit_JavaScript_API_Reference_en/global.html#describeDb ) jasmine expect().toThrowError() is not supported (use toThrow(new Error()) instead) tableUtils::copy*UserSchema() (http://help.sap.com/hana/SAP_HANA_XS_Unit_JavaScript_API_Reference_en/module-tableUtils-TableUtils.html) are not supported on HDI because there is a) no schema to copy from and b) by default no writable user schema tableUtils.fillFromCsvFile() is not supported. Use HDI *.tableimport files instead to fill your HDI container with test data. mockstar is discouraged/deprecated. Use HDI containers instead. If you need to reference larger test data, use HDI synonyms.","title":"Known Restrictions"},{"location":"apis/xsjs-test/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 2.0.15 - 2018-04-19 \u00b6 Fixed \u00b6 use newer fibers to enable running on newer node.js runtimes 2.0.14 - 2018-01-18 \u00b6 Changed \u00b6 cleaned integrity field from npm-shrinkwrap.json to avoid checksum errors on customer side 2.0.13 - 2018-01-15 \u00b6 Changed \u00b6 use released version of hdbext added missing double quote for table names in createTestTable 2.0.12 - 2018-01-12 \u00b6 Added \u00b6 CHANGELOG.md 2.0.11 - 2018-01-12 \u00b6 Added \u00b6 Node 8 support. Fixed \u00b6 Update dependencies. 2.0.10 - 2018-01-09 \u00b6 Added \u00b6 console output for test results Fixed \u00b6 jasmine.toEqualObject matches semantic equality correct decimal value of a column in a row in resultSet expect().toEqual(jasmine.any()) fixed Can't wait without a fiber bug set package parameter sqlExecutor.execQuery (when hdbConnection) returns correct ColumnType and ColumnTypeName execSingle works for update statement","title":"Change Log"},{"location":"apis/xsjs-test/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xsjs-test/CHANGELOG/#2015-2018-04-19","text":"","title":"2.0.15 - 2018-04-19"},{"location":"apis/xsjs-test/CHANGELOG/#fixed","text":"use newer fibers to enable running on newer node.js runtimes","title":"Fixed"},{"location":"apis/xsjs-test/CHANGELOG/#2014-2018-01-18","text":"","title":"2.0.14 - 2018-01-18"},{"location":"apis/xsjs-test/CHANGELOG/#changed","text":"cleaned integrity field from npm-shrinkwrap.json to avoid checksum errors on customer side","title":"Changed"},{"location":"apis/xsjs-test/CHANGELOG/#2013-2018-01-15","text":"","title":"2.0.13 - 2018-01-15"},{"location":"apis/xsjs-test/CHANGELOG/#changed_1","text":"use released version of hdbext added missing double quote for table names in createTestTable","title":"Changed"},{"location":"apis/xsjs-test/CHANGELOG/#2012-2018-01-12","text":"","title":"2.0.12 - 2018-01-12"},{"location":"apis/xsjs-test/CHANGELOG/#added","text":"CHANGELOG.md","title":"Added"},{"location":"apis/xsjs-test/CHANGELOG/#2011-2018-01-12","text":"","title":"2.0.11 - 2018-01-12"},{"location":"apis/xsjs-test/CHANGELOG/#added_1","text":"Node 8 support.","title":"Added"},{"location":"apis/xsjs-test/CHANGELOG/#fixed_1","text":"Update dependencies.","title":"Fixed"},{"location":"apis/xsjs-test/CHANGELOG/#2010-2018-01-09","text":"","title":"2.0.10 - 2018-01-09"},{"location":"apis/xsjs-test/CHANGELOG/#added_2","text":"console output for test results","title":"Added"},{"location":"apis/xsjs-test/CHANGELOG/#fixed_2","text":"jasmine.toEqualObject matches semantic equality correct decimal value of a column in a row in resultSet expect().toEqual(jasmine.any()) fixed Can't wait without a fiber bug set package parameter sqlExecutor.execQuery (when hdbConnection) returns correct ColumnType and ColumnTypeName execSingle works for update statement","title":"Fixed"},{"location":"apis/xsodata/","text":"XSODATA \u00b6 Expose data from HANA database artifacts like tables or views as OData V2 service with the help of .xsodata service definition files. Note: XSOData was developed to provide XS Classic users using XSOData the possibility to migrate to XS Advanced on node.js. This library contains nearly the same feature set as XSOData provided on SAP HANA XS Classic. This module is already in maintenance mode and it is not planned to extend or enhance it. If you want to create new OData services we strongly reoommend to use OData V4 along with a generic CDS - OData provider . Here you can model your consumption persistency model with CDS ( Core Data Services ) and expose parts or the complete model as OData service . Such a solution is already productively available on the JAVA runtime stack . For node . js we also provide an OData V4 solution . The development of the OData V4 node . js Library already started in 2016 . It is also planned that a generic CDS - Odata provider will be deliverd . Usage \u00b6 This module is used in the XSJS shim for SAP HANA XSC Engine applications to allow the reuse of .xsodata files from XSC applications on SAP HANA XSA. It can also be used directly in your own nodejs server application. Be aware that you use the same version of the hdb and winston node module version in your application. Documentation \u00b6 For documentation see here Warning \u00b6 In order to restrict the amount of records loaded from the database (to reduce the memory usage) please use the limit setting which can be set in the xsodata file see here The xsodata library CHANGES the TRANSACTION ISOLATION LEVEL on the used database connection The xsodata library CHANGES the SCHEMA on the used database connection The xsodata library uses temporary tables for performance reasons If you manually modify the db-connection/client inside xsodata-application-exits the modifications you have done will not be restored by the xsodata library So the user of the xsodata library should clean the database connection Features - Overview \u00b6 Automatic metadata handling based on XSOData definition and HANA db metadata artifacts OData request handling with URI parsing including system query options OData request/response serialization and deserialization Load table records from HANA database via generated SQL queries Calculation view support Batch handling Logging: When the xsjs application log is enabled then xsodata also writes log information. If, in addition, the environment variable XSODATA_LOG_MEMORY_CONSUMPTION is set to 'true' xsodata writes also memory consumption information to the logs Supported OData V2 Features: \u00b6 GET Requests: URI0 = scheme serviceRoot URI1 = scheme serviceRoot \"/\" entitySet URI2 = scheme serviceRoot \"/\" entitySet \"(\" keyPredicate \")\" URI6 = scheme serviceRoot \"/\" entitySet \"(\" keyPredicate \")/\" entityNavProperty URI7 = scheme serviceRoot \"/\" entitySet \"(\" keyPredicate \")/$links/\" entityNavProperty URI8 = scheme serviceRoot \"/$metadata\" URI9 = scheme serviceRoot \"/$batch\" URI15 = scheme serviceRoot \"/\" entitySet count CreateUpdateDelete Requests: CUD - Entity CUD - Link System Query options : $top $skip $filter, except for: comparison of navigation properties $orderby, except for: comparison of navigation properties $expand $select $format only json supported $inlinecount Supported HTTP methods per requests type Supported XS1 OData features (defined in the XSOData file): \u00b6 Definition of OData schema namespace OData Service exposure Metadata caching Create/update/delete restrictions of OData requests Exposure of table and views (including calculation views) as EntitySet Property Projection: Expose a subset of the table columns as properties of an OData EntityType [Automatic OData key generation] (/documentation/generatedKeys.md), e.g. required for aggregated views Simple and complex associations [Data aggregation] (/documentation/aggregations.md) Parameter EntitySets for calculation views ETAG handling Nullable properties Cache Control via cache header [Custom exits] (/documentation/customExits.md) (JavaScript and SQL Script) for modification and validation requests Custom exits in batch requests Uses only UTF-8 Uses \"content-type: application/json\" for CREATE, UPDATE, DELETE Expose data only via JSON format (ATOM format is not supported) Supported types and type mapping see here [Supported XSOData features by OSDL] (/documentation/xsodataEbnf.md) Note: XS1 applications using analytical views, attribute views or calculation views <= SAP HANA SPS 10 have to migrate first their views to the new calculation views of SPS 11. Authentication/Authorisation is not handled by XSOData node module and has to be done by the application using the node module. [The module can be used in development mode and productive mode] (/documentation/modes.md) [Debug View is available when using the module in development mode] (/documentation/debugView.md) Features per HANA DB Artifact \u00b6 Table \u00b6 Supports the following Features: - Explicit Aggregations - Generated Local Key Supported Http Verbs: - GET, PUT, POST, DELETE SQL View \u00b6 Supports the following Features: - Explicit Aggregations - Generated Local Key Supported Http Verbs: - GET XS Advanced Calculation View \u00b6 Supports the following Features: - Implicit Aggregations - Generated Local Key Supported Http Verbs: - GET Samples \u00b6 xsodata code samples without xsjs Calcview","title":"Index"},{"location":"apis/xsodata/#xsodata","text":"Expose data from HANA database artifacts like tables or views as OData V2 service with the help of .xsodata service definition files. Note: XSOData was developed to provide XS Classic users using XSOData the possibility to migrate to XS Advanced on node.js. This library contains nearly the same feature set as XSOData provided on SAP HANA XS Classic. This module is already in maintenance mode and it is not planned to extend or enhance it. If you want to create new OData services we strongly reoommend to use OData V4 along with a generic CDS - OData provider . Here you can model your consumption persistency model with CDS ( Core Data Services ) and expose parts or the complete model as OData service . Such a solution is already productively available on the JAVA runtime stack . For node . js we also provide an OData V4 solution . The development of the OData V4 node . js Library already started in 2016 . It is also planned that a generic CDS - Odata provider will be deliverd .","title":"XSODATA"},{"location":"apis/xsodata/#usage","text":"This module is used in the XSJS shim for SAP HANA XSC Engine applications to allow the reuse of .xsodata files from XSC applications on SAP HANA XSA. It can also be used directly in your own nodejs server application. Be aware that you use the same version of the hdb and winston node module version in your application.","title":"Usage"},{"location":"apis/xsodata/#documentation","text":"For documentation see here","title":"Documentation"},{"location":"apis/xsodata/#warning","text":"In order to restrict the amount of records loaded from the database (to reduce the memory usage) please use the limit setting which can be set in the xsodata file see here The xsodata library CHANGES the TRANSACTION ISOLATION LEVEL on the used database connection The xsodata library CHANGES the SCHEMA on the used database connection The xsodata library uses temporary tables for performance reasons If you manually modify the db-connection/client inside xsodata-application-exits the modifications you have done will not be restored by the xsodata library So the user of the xsodata library should clean the database connection","title":"Warning"},{"location":"apis/xsodata/#features-overview","text":"Automatic metadata handling based on XSOData definition and HANA db metadata artifacts OData request handling with URI parsing including system query options OData request/response serialization and deserialization Load table records from HANA database via generated SQL queries Calculation view support Batch handling Logging: When the xsjs application log is enabled then xsodata also writes log information. If, in addition, the environment variable XSODATA_LOG_MEMORY_CONSUMPTION is set to 'true' xsodata writes also memory consumption information to the logs","title":"Features - Overview"},{"location":"apis/xsodata/#supported-odata-v2-features","text":"GET Requests: URI0 = scheme serviceRoot URI1 = scheme serviceRoot \"/\" entitySet URI2 = scheme serviceRoot \"/\" entitySet \"(\" keyPredicate \")\" URI6 = scheme serviceRoot \"/\" entitySet \"(\" keyPredicate \")/\" entityNavProperty URI7 = scheme serviceRoot \"/\" entitySet \"(\" keyPredicate \")/$links/\" entityNavProperty URI8 = scheme serviceRoot \"/$metadata\" URI9 = scheme serviceRoot \"/$batch\" URI15 = scheme serviceRoot \"/\" entitySet count CreateUpdateDelete Requests: CUD - Entity CUD - Link System Query options : $top $skip $filter, except for: comparison of navigation properties $orderby, except for: comparison of navigation properties $expand $select $format only json supported $inlinecount Supported HTTP methods per requests type","title":"Supported OData V2 Features:"},{"location":"apis/xsodata/#supported-xs1-odata-features-defined-in-the-xsodata-file","text":"Definition of OData schema namespace OData Service exposure Metadata caching Create/update/delete restrictions of OData requests Exposure of table and views (including calculation views) as EntitySet Property Projection: Expose a subset of the table columns as properties of an OData EntityType [Automatic OData key generation] (/documentation/generatedKeys.md), e.g. required for aggregated views Simple and complex associations [Data aggregation] (/documentation/aggregations.md) Parameter EntitySets for calculation views ETAG handling Nullable properties Cache Control via cache header [Custom exits] (/documentation/customExits.md) (JavaScript and SQL Script) for modification and validation requests Custom exits in batch requests Uses only UTF-8 Uses \"content-type: application/json\" for CREATE, UPDATE, DELETE Expose data only via JSON format (ATOM format is not supported) Supported types and type mapping see here [Supported XSOData features by OSDL] (/documentation/xsodataEbnf.md) Note: XS1 applications using analytical views, attribute views or calculation views <= SAP HANA SPS 10 have to migrate first their views to the new calculation views of SPS 11. Authentication/Authorisation is not handled by XSOData node module and has to be done by the application using the node module. [The module can be used in development mode and productive mode] (/documentation/modes.md) [Debug View is available when using the module in development mode] (/documentation/debugView.md)","title":"Supported XS1 OData features (defined in the XSOData file):"},{"location":"apis/xsodata/#features-per-hana-db-artifact","text":"","title":"Features per HANA DB Artifact"},{"location":"apis/xsodata/#table","text":"Supports the following Features: - Explicit Aggregations - Generated Local Key Supported Http Verbs: - GET, PUT, POST, DELETE","title":"Table"},{"location":"apis/xsodata/#sql-view","text":"Supports the following Features: - Explicit Aggregations - Generated Local Key Supported Http Verbs: - GET","title":"SQL View"},{"location":"apis/xsodata/#xs-advanced-calculation-view","text":"Supports the following Features: - Implicit Aggregations - Generated Local Key Supported Http Verbs: - GET","title":"XS Advanced Calculation View"},{"location":"apis/xsodata/#samples","text":"xsodata code samples without xsjs Calcview","title":"Samples"},{"location":"apis/xsodata/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . Unreleased \u00b6 [7.0.2] - 2020-05-18 \u00b6 Add support for create, update, delete operations via user-exits on calculation views without input parameters. Work for both, calculation views without input parameters exposed as normal view and exposed as calcview. [7.0.1] - 2020-05-12 \u00b6 Add support for calculation views without input parameters. Before release 7.0.0 calcviews without input parameters have not been supported, but worked accidentally if a calcview was wrongly exposed as normal view. After the major release 7.0.0 this wrong exposure of a calcview resulted in an error. Because calcviews without input parameters are used more often, the support for this calcviews is now supported. You can either expose a calcview as normal view or as proper calcview, for the latter an input parameter entityset with parenthesis must be used. [7.0.0] - 2020-04-23 \u00b6 Add support for NodeJS version 12 Removed support for NodeJS version 6 Fix bug when using a view with explicit key in combination with concurrency token using default properties for ETag. Now key properties are not considered for etag generation as written in the \"SAP HANA Developer Guide\": If you specify concurrency token only, then all properties, except the key properties, are used to calculate the ETag value. If you provide specific properties, then only those properties are used for the calculation. [6.2.1] - 2020-03-05 \u00b6 fixes in release process [6.1.0] - 2020-03-05 \u00b6 fixes in release process [6.0.0] - 2020-03-05 \u00b6 Add support for LTS Node.js version 12 and 10 Support for create/update/delete requests on calculation views if \"parameter via keys\" definition is used. Requirements: input parameters in the calculation view of type ALPHANUM, BLOB, DECIMAL, NVARCHAR, VARBINARY, VARCHAR must have length restriction input parameters in the calculation view of type DECIMAL must have scale restriction all key semantics also apply to keys coming from input parameters IMPORTANT By default, now a maximum body size of \"10mb\" per request is allowed. More payload leads to an \"413 Payload Too Large\" error. This value of 10mb can be changed with the odata settings in the *.xsodata file see XSOdata Settings [5.0.0] - 2019-12-17 \u00b6 Info \u00b6 Removed lock when opening a db connection The new native hana-client driver used by xsjs is thread save, so the lock for retrieving a new db connection is not required anymore. IMPORTANT If a custom open function is used, then this function must be reentrant or implement an own lock inside. Fixed \u00b6 When using $count to determine the number of records of an entity set in junction with the limit feature, the returned number was also capped by the limit, this was wrong. Now the correct full number of records is returned. Fixed typeError if a stored procedure used as custom exit does not return a proper error structure. [4.7.0] - 2019-10-28 \u00b6 Fixed \u00b6 Fixed error causing duplicate properties and property references in the metadata document. Prerequisites: * The error occurs if an calculation view has been used as source for an entityset * This calculation view contains an input parameter which is used in more than one measures * Example: Input parameter \"Input_Currency\" (a calcview variable) is used in the currency conversion for the measures \"VALUE\" and \"TAX\" [4.6.0] - 2019-10-11 \u00b6 Fixed \u00b6 Fixed error \"Error while executing a DB query\" when using an navigation property to navigate from a calculation view to an related entity. [4.5.4] - 2019-08-26 \u00b6 Info \u00b6 Update module dependencies [4.5.3] - 2019-08-26 \u00b6 Info \u00b6 Update module dependencies [4.5.1] - 2019-08-23 \u00b6 Info \u00b6 Updated documentation [4.5.0] - 2019-08-23 \u00b6 Info \u00b6 Update module dependencies Adopt to new async behaviour Adopt to new calcview metadata Fixed \u00b6 Fix bug in error case (duplicate call of callback) [4.4.0] - 2019-01-25 \u00b6 Update module dependencies The code field inside an OData error response (error.code) is now correctly send as string (not as number) For calcviews the columns type length is determined from the COLUMN_SQL_TYPE if LENGTH is not set. Fixed error while parsing multipart/mixed batch requests [4.3.0] - 2018-10-19 \u00b6 Info \u00b6 Minimal required @sap/hana-client version is 2.3.123 Improved test exits IMPORTANT Conversion: When converting TIMESTAMP db type to OData V2 json payload, only the first 3 digits of the fractional part are used (OData V2 type DateTime does only supports millisecond precision). With the old hdb db driver the xsodata library got already only millisecond precision, with the new hana-client db-driver the xsodata library itself has to remove any digits and use only the millisecond part. The check if the digits for micro- or nanoseconds are zero and throwing an error if not (added with release 4.0.0) has been removed due to backward compatibility reasons. [4.2.0] - 2018-09-18 \u00b6 Changed \u00b6 Upgraded lodash module dependency to 4.17.11 [4.1.0] - 2018-08-31 \u00b6 Added \u00b6 Write memory consumption to log if requested Fixed \u00b6 Improve cleanup of temporary tables [4.0.0] - 2018-08-15 \u00b6 Added \u00b6 IMPORTANT | INCOMPATIBLE Added limit feature to restrict the amount of records loaded from the database. There are defaults for the limit values see XSOdata Settings which need to be validated before using this version. Support for hana-client database connector IMPORTANT | INCOMPATIBLE Switched default database connector from hdb to hana-client see Database connector Fixed \u00b6 Use always the original DB property ordering when copying data into temporary tables for use in exits in the insert and update steps. [3.7.0] - 2018-05-22 \u00b6 Fixed \u00b6 Update dependencies [3.6.7] - 2018-05-18 \u00b6 Fixed \u00b6 Extended DB-Version check to avoid unnecessary cleanup of temporary tables (added new db versions) Allow throwing an Error object in custom exits New features with xsodata 3.6.0: \u00b6 Fixed \u00b6 Extended DB-Version check to avoid unnecessary cleanup of temporary tables Commands for cleanup of temporary tables don't stop the request processing if tables are truncated/dropped already Fixed error which leads to an unclosed db connection. This error occurred only if the xsdata library is used without the xsjs layer (which is not recommended) and the db connection information was provided via host, port, user,... to the OdataHandler as request options for the processRequest method a string containing the uriPrefix is used (not an RequestOptions object). $batch processing is used Fixed wrong decoding of OData strings of type Edm.String in $filter and $orderby expressions if the string contained exactly one single quote (e.g. '''' have been decoded wrongly to Json \"\" not to the correct \"'\") Parsing milliseconds for Edm.DateTime works now as expected for hana column type TIMESTAMP. Sample: HANA value \"9999-12-31T23:59:59.99\" is parsed now to have 990 ms instead of just 99ms Changed \u00b6 Upgraded @sap/xssec module dependencies New features with xsodata 3.5.0: \u00b6 Fixed \u00b6 Proper pattern escaping for substringof, startswith and endswith operations on $filter or $orderby. Fixed SQL error when retrieving the row count of calculation views with transparent filters. Added: \u00b6 Added new SQL error class to pass all errors related to DB query execution New features with xsodata 3.4.0: \u00b6 Added: \u00b6 Support for points \".\" in HANA table column names and consistently in OData property names. This feature has been added for backward compatibility reasons only. The OData V2 specification does not allow the usage of points for property names as points are used to separate namespace parts and names. So please consider not using it. Changed \u00b6 Upgraded @sap/xssec and @sap/xsenv module dependencies New features with xsodata 3.3.0: \u00b6 Fixed: \u00b6 Removed failing sql calls to cleanup temporary tables, which become unnecessary with db patch 2.00.030.00.1515544046. Numbers of type Edm.Int64 must be represented as string (e.g. \"123\") in json format even if they are within in the range of JS Number. New features with xsodata 3.0.0: \u00b6 Added \u00b6 Support Node.js 4.x.x, 6.x.x and newly 8.x.x Changed \u00b6 Updated dependencies Improved content id handling in batch requests Fixed \u00b6 Fixed conversion of binary data if generated key are used Removed \u00b6 Removed support for Node.js 0.12.9 New features with xsodata 2.4.0: \u00b6 Added \u00b6 Add \"hints\" setting to xsodata file definition to provide custom hints for SQL-select New features with xsodata 2.3.0: \u00b6 Added \u00b6 Before/After commit exits also called for non batch modifications Improved cleanup of temporary tables Improved error message when using key property with point '.' Rollback performed also for non batch modifications Changed \u00b6 Updated dependencies Fixed \u00b6 Fixed __metadata Uri in payload: name/value key pairs are now correct Modifications with SAP HANA XSA 2.0 SPS 2: \u00b6 Added \u00b6 Request specific logging I18N support for language specific metadata, e.g. labels in annotations Update of Open Source libraries Fixed \u00b6 Several smaller bug fixes Modifications with SAP HANA XSA 2.0 SPS 1: \u00b6 Added \u00b6 Switch to scoped package name @sap/xsodata Support for node.js version 4.X.X & 6.9.X New Features with SAP HANA XSA 2.0 SPS 0: \u00b6 Added \u00b6 Annotations in metadata Scope based authorization checks Support for node.js version 4.4.X & 6.2.X New Features with SAP HANA XSA SPS 12: \u00b6 Added \u00b6 Support for $links requests Custom exits for $links requests (modification requests only) Support for node.js version 0.12.X & 4.4.X","title":"Change Log"},{"location":"apis/xsodata/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xsodata/CHANGELOG/#unreleased","text":"","title":"Unreleased"},{"location":"apis/xsodata/CHANGELOG/#702-2020-05-18","text":"Add support for create, update, delete operations via user-exits on calculation views without input parameters. Work for both, calculation views without input parameters exposed as normal view and exposed as calcview.","title":"[7.0.2] - 2020-05-18"},{"location":"apis/xsodata/CHANGELOG/#701-2020-05-12","text":"Add support for calculation views without input parameters. Before release 7.0.0 calcviews without input parameters have not been supported, but worked accidentally if a calcview was wrongly exposed as normal view. After the major release 7.0.0 this wrong exposure of a calcview resulted in an error. Because calcviews without input parameters are used more often, the support for this calcviews is now supported. You can either expose a calcview as normal view or as proper calcview, for the latter an input parameter entityset with parenthesis must be used.","title":"[7.0.1] - 2020-05-12"},{"location":"apis/xsodata/CHANGELOG/#700-2020-04-23","text":"Add support for NodeJS version 12 Removed support for NodeJS version 6 Fix bug when using a view with explicit key in combination with concurrency token using default properties for ETag. Now key properties are not considered for etag generation as written in the \"SAP HANA Developer Guide\": If you specify concurrency token only, then all properties, except the key properties, are used to calculate the ETag value. If you provide specific properties, then only those properties are used for the calculation.","title":"[7.0.0] - 2020-04-23"},{"location":"apis/xsodata/CHANGELOG/#621-2020-03-05","text":"fixes in release process","title":"[6.2.1] - 2020-03-05"},{"location":"apis/xsodata/CHANGELOG/#610-2020-03-05","text":"fixes in release process","title":"[6.1.0] - 2020-03-05"},{"location":"apis/xsodata/CHANGELOG/#600-2020-03-05","text":"Add support for LTS Node.js version 12 and 10 Support for create/update/delete requests on calculation views if \"parameter via keys\" definition is used. Requirements: input parameters in the calculation view of type ALPHANUM, BLOB, DECIMAL, NVARCHAR, VARBINARY, VARCHAR must have length restriction input parameters in the calculation view of type DECIMAL must have scale restriction all key semantics also apply to keys coming from input parameters IMPORTANT By default, now a maximum body size of \"10mb\" per request is allowed. More payload leads to an \"413 Payload Too Large\" error. This value of 10mb can be changed with the odata settings in the *.xsodata file see XSOdata Settings","title":"[6.0.0] - 2020-03-05"},{"location":"apis/xsodata/CHANGELOG/#500-2019-12-17","text":"","title":"[5.0.0] - 2019-12-17"},{"location":"apis/xsodata/CHANGELOG/#info","text":"Removed lock when opening a db connection The new native hana-client driver used by xsjs is thread save, so the lock for retrieving a new db connection is not required anymore. IMPORTANT If a custom open function is used, then this function must be reentrant or implement an own lock inside.","title":"Info"},{"location":"apis/xsodata/CHANGELOG/#fixed","text":"When using $count to determine the number of records of an entity set in junction with the limit feature, the returned number was also capped by the limit, this was wrong. Now the correct full number of records is returned. Fixed typeError if a stored procedure used as custom exit does not return a proper error structure.","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#470-2019-10-28","text":"","title":"[4.7.0] - 2019-10-28"},{"location":"apis/xsodata/CHANGELOG/#fixed_1","text":"Fixed error causing duplicate properties and property references in the metadata document. Prerequisites: * The error occurs if an calculation view has been used as source for an entityset * This calculation view contains an input parameter which is used in more than one measures * Example: Input parameter \"Input_Currency\" (a calcview variable) is used in the currency conversion for the measures \"VALUE\" and \"TAX\"","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#460-2019-10-11","text":"","title":"[4.6.0] - 2019-10-11"},{"location":"apis/xsodata/CHANGELOG/#fixed_2","text":"Fixed error \"Error while executing a DB query\" when using an navigation property to navigate from a calculation view to an related entity.","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#454-2019-08-26","text":"","title":"[4.5.4] - 2019-08-26"},{"location":"apis/xsodata/CHANGELOG/#info_1","text":"Update module dependencies","title":"Info"},{"location":"apis/xsodata/CHANGELOG/#453-2019-08-26","text":"","title":"[4.5.3] - 2019-08-26"},{"location":"apis/xsodata/CHANGELOG/#info_2","text":"Update module dependencies","title":"Info"},{"location":"apis/xsodata/CHANGELOG/#451-2019-08-23","text":"","title":"[4.5.1] - 2019-08-23"},{"location":"apis/xsodata/CHANGELOG/#info_3","text":"Updated documentation","title":"Info"},{"location":"apis/xsodata/CHANGELOG/#450-2019-08-23","text":"","title":"[4.5.0] - 2019-08-23"},{"location":"apis/xsodata/CHANGELOG/#info_4","text":"Update module dependencies Adopt to new async behaviour Adopt to new calcview metadata","title":"Info"},{"location":"apis/xsodata/CHANGELOG/#fixed_3","text":"Fix bug in error case (duplicate call of callback)","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#440-2019-01-25","text":"Update module dependencies The code field inside an OData error response (error.code) is now correctly send as string (not as number) For calcviews the columns type length is determined from the COLUMN_SQL_TYPE if LENGTH is not set. Fixed error while parsing multipart/mixed batch requests","title":"[4.4.0] - 2019-01-25"},{"location":"apis/xsodata/CHANGELOG/#430-2018-10-19","text":"","title":"[4.3.0] - 2018-10-19"},{"location":"apis/xsodata/CHANGELOG/#info_5","text":"Minimal required @sap/hana-client version is 2.3.123 Improved test exits IMPORTANT Conversion: When converting TIMESTAMP db type to OData V2 json payload, only the first 3 digits of the fractional part are used (OData V2 type DateTime does only supports millisecond precision). With the old hdb db driver the xsodata library got already only millisecond precision, with the new hana-client db-driver the xsodata library itself has to remove any digits and use only the millisecond part. The check if the digits for micro- or nanoseconds are zero and throwing an error if not (added with release 4.0.0) has been removed due to backward compatibility reasons.","title":"Info"},{"location":"apis/xsodata/CHANGELOG/#420-2018-09-18","text":"","title":"[4.2.0] - 2018-09-18"},{"location":"apis/xsodata/CHANGELOG/#changed","text":"Upgraded lodash module dependency to 4.17.11","title":"Changed"},{"location":"apis/xsodata/CHANGELOG/#410-2018-08-31","text":"","title":"[4.1.0] - 2018-08-31"},{"location":"apis/xsodata/CHANGELOG/#added","text":"Write memory consumption to log if requested","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#fixed_4","text":"Improve cleanup of temporary tables","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#400-2018-08-15","text":"","title":"[4.0.0] - 2018-08-15"},{"location":"apis/xsodata/CHANGELOG/#added_1","text":"IMPORTANT | INCOMPATIBLE Added limit feature to restrict the amount of records loaded from the database. There are defaults for the limit values see XSOdata Settings which need to be validated before using this version. Support for hana-client database connector IMPORTANT | INCOMPATIBLE Switched default database connector from hdb to hana-client see Database connector","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#fixed_5","text":"Use always the original DB property ordering when copying data into temporary tables for use in exits in the insert and update steps.","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#370-2018-05-22","text":"","title":"[3.7.0] - 2018-05-22"},{"location":"apis/xsodata/CHANGELOG/#fixed_6","text":"Update dependencies","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#367-2018-05-18","text":"","title":"[3.6.7] - 2018-05-18"},{"location":"apis/xsodata/CHANGELOG/#fixed_7","text":"Extended DB-Version check to avoid unnecessary cleanup of temporary tables (added new db versions) Allow throwing an Error object in custom exits","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-xsodata-360","text":"","title":"New features with xsodata 3.6.0:"},{"location":"apis/xsodata/CHANGELOG/#fixed_8","text":"Extended DB-Version check to avoid unnecessary cleanup of temporary tables Commands for cleanup of temporary tables don't stop the request processing if tables are truncated/dropped already Fixed error which leads to an unclosed db connection. This error occurred only if the xsdata library is used without the xsjs layer (which is not recommended) and the db connection information was provided via host, port, user,... to the OdataHandler as request options for the processRequest method a string containing the uriPrefix is used (not an RequestOptions object). $batch processing is used Fixed wrong decoding of OData strings of type Edm.String in $filter and $orderby expressions if the string contained exactly one single quote (e.g. '''' have been decoded wrongly to Json \"\" not to the correct \"'\") Parsing milliseconds for Edm.DateTime works now as expected for hana column type TIMESTAMP. Sample: HANA value \"9999-12-31T23:59:59.99\" is parsed now to have 990 ms instead of just 99ms","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#changed_1","text":"Upgraded @sap/xssec module dependencies","title":"Changed"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-xsodata-350","text":"","title":"New features with xsodata 3.5.0:"},{"location":"apis/xsodata/CHANGELOG/#fixed_9","text":"Proper pattern escaping for substringof, startswith and endswith operations on $filter or $orderby. Fixed SQL error when retrieving the row count of calculation views with transparent filters.","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#added_2","text":"Added new SQL error class to pass all errors related to DB query execution","title":"Added:"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-xsodata-340","text":"","title":"New features with xsodata 3.4.0:"},{"location":"apis/xsodata/CHANGELOG/#added_3","text":"Support for points \".\" in HANA table column names and consistently in OData property names. This feature has been added for backward compatibility reasons only. The OData V2 specification does not allow the usage of points for property names as points are used to separate namespace parts and names. So please consider not using it.","title":"Added:"},{"location":"apis/xsodata/CHANGELOG/#changed_2","text":"Upgraded @sap/xssec and @sap/xsenv module dependencies","title":"Changed"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-xsodata-330","text":"","title":"New features with xsodata 3.3.0:"},{"location":"apis/xsodata/CHANGELOG/#fixed_10","text":"Removed failing sql calls to cleanup temporary tables, which become unnecessary with db patch 2.00.030.00.1515544046. Numbers of type Edm.Int64 must be represented as string (e.g. \"123\") in json format even if they are within in the range of JS Number.","title":"Fixed:"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-xsodata-300","text":"","title":"New features with xsodata 3.0.0:"},{"location":"apis/xsodata/CHANGELOG/#added_4","text":"Support Node.js 4.x.x, 6.x.x and newly 8.x.x","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#changed_3","text":"Updated dependencies Improved content id handling in batch requests","title":"Changed"},{"location":"apis/xsodata/CHANGELOG/#fixed_11","text":"Fixed conversion of binary data if generated key are used","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#removed","text":"Removed support for Node.js 0.12.9","title":"Removed"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-xsodata-240","text":"","title":"New features with xsodata 2.4.0:"},{"location":"apis/xsodata/CHANGELOG/#added_5","text":"Add \"hints\" setting to xsodata file definition to provide custom hints for SQL-select","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-xsodata-230","text":"","title":"New features with xsodata 2.3.0:"},{"location":"apis/xsodata/CHANGELOG/#added_6","text":"Before/After commit exits also called for non batch modifications Improved cleanup of temporary tables Improved error message when using key property with point '.' Rollback performed also for non batch modifications","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#changed_4","text":"Updated dependencies","title":"Changed"},{"location":"apis/xsodata/CHANGELOG/#fixed_12","text":"Fixed __metadata Uri in payload: name/value key pairs are now correct","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#modifications-with-sap-hana-xsa-20-sps-2","text":"","title":"Modifications with SAP HANA XSA 2.0 SPS 2:"},{"location":"apis/xsodata/CHANGELOG/#added_7","text":"Request specific logging I18N support for language specific metadata, e.g. labels in annotations Update of Open Source libraries","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#fixed_13","text":"Several smaller bug fixes","title":"Fixed"},{"location":"apis/xsodata/CHANGELOG/#modifications-with-sap-hana-xsa-20-sps-1","text":"","title":"Modifications with SAP HANA XSA 2.0 SPS 1:"},{"location":"apis/xsodata/CHANGELOG/#added_8","text":"Switch to scoped package name @sap/xsodata Support for node.js version 4.X.X & 6.9.X","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-sap-hana-xsa-20-sps-0","text":"","title":"New Features with SAP HANA XSA 2.0 SPS 0:"},{"location":"apis/xsodata/CHANGELOG/#added_9","text":"Annotations in metadata Scope based authorization checks Support for node.js version 4.4.X & 6.2.X","title":"Added"},{"location":"apis/xsodata/CHANGELOG/#new-features-with-sap-hana-xsa-sps-12","text":"","title":"New Features with SAP HANA XSA SPS 12:"},{"location":"apis/xsodata/CHANGELOG/#added_10","text":"Support for $links requests Custom exits for $links requests (modification requests only) Support for node.js version 0.12.X & 4.4.X","title":"Added"},{"location":"apis/xss-secure/","text":"@sap/xss-secure \u00b6 XSSSecurity Implementation taken from SAP UI5 Usage \u00b6 var xssSecure = require('@sap/xss-secure'); API Reference \u00b6 encodeCSS(string) \u00b6 Encode the string for inclusion into CSS string literals or identifiers. * string - The string to be escaped Returns the escaped string . xssSecure . encodeCSS ( '1<4' ); // returns '1\\\\3c 4' xssSecure . encodeCSS ( 'a-b' ); // returns 'a\\2d b' encodeHTML(string) \u00b6 Encode the string for inclusion into HTML content/attribute. * string - The string to be escaped Returns the escaped string . xssSecure . encodeHTML ( '1<4' ); // returns '1&lt;4' xssSecure . encodeHTML ( '\\x00' ); // returns '&#xfffd;' encodeJS(string) \u00b6 Encode the string for inclusion into a JS string literal. * string - The string to be escaped Returns the escaped string . xssSecure . encodeJS ( '1<4' ); // returns '1\\\\x3c4' xssSecure . encodeJS ( '\\x00' ); // returns '\\\\x00' encodeURL(string) \u00b6 Encode the string for inclusion into an URL parameter. * string - The string to be escaped Returns the escaped string . xssSecure . encodeURL ( 'http://testing.com/?a=1&b=\"ok\"' ); // returns 'http%3a%2f%2ftesting.com%2f%3fa%3d1%26b%3d%22ok%22' encodeXML(string) \u00b6 Encode the string for inclusion into XML content/attribute. * string - The string to be escaped Returns the escaped string . This function is alias to encodeHTML .","title":"Index"},{"location":"apis/xss-secure/#sapxss-secure","text":"XSSSecurity Implementation taken from SAP UI5","title":"@sap/xss-secure"},{"location":"apis/xss-secure/#usage","text":"var xssSecure = require('@sap/xss-secure');","title":"Usage"},{"location":"apis/xss-secure/#api-reference","text":"","title":"API Reference"},{"location":"apis/xss-secure/#encodecssstring","text":"Encode the string for inclusion into CSS string literals or identifiers. * string - The string to be escaped Returns the escaped string . xssSecure . encodeCSS ( '1<4' ); // returns '1\\\\3c 4' xssSecure . encodeCSS ( 'a-b' ); // returns 'a\\2d b'","title":"encodeCSS(string)"},{"location":"apis/xss-secure/#encodehtmlstring","text":"Encode the string for inclusion into HTML content/attribute. * string - The string to be escaped Returns the escaped string . xssSecure . encodeHTML ( '1<4' ); // returns '1&lt;4' xssSecure . encodeHTML ( '\\x00' ); // returns '&#xfffd;'","title":"encodeHTML(string)"},{"location":"apis/xss-secure/#encodejsstring","text":"Encode the string for inclusion into a JS string literal. * string - The string to be escaped Returns the escaped string . xssSecure . encodeJS ( '1<4' ); // returns '1\\\\x3c4' xssSecure . encodeJS ( '\\x00' ); // returns '\\\\x00'","title":"encodeJS(string)"},{"location":"apis/xss-secure/#encodeurlstring","text":"Encode the string for inclusion into an URL parameter. * string - The string to be escaped Returns the escaped string . xssSecure . encodeURL ( 'http://testing.com/?a=1&b=\"ok\"' ); // returns 'http%3a%2f%2ftesting.com%2f%3fa%3d1%26b%3d%22ok%22'","title":"encodeURL(string)"},{"location":"apis/xss-secure/#encodexmlstring","text":"Encode the string for inclusion into XML content/attribute. * string - The string to be escaped Returns the escaped string . This function is alias to encodeHTML .","title":"encodeXML(string)"},{"location":"apis/xss-secure/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog . 2.1.0 - 2018-01-08 \u00b6 Added \u00b6 Node.js version 8 support. CHANGELOG.md 2.0.11 - 2017-01-24 \u00b6 Changed \u00b6 Rename package to use sap scope. 2.0.10 - 2017-01-23 \u00b6 Changed \u00b6 Improvements in documentation.","title":"Change Log"},{"location":"apis/xss-secure/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning . The format is based on Keep a Changelog .","title":"Change Log"},{"location":"apis/xss-secure/CHANGELOG/#210-2018-01-08","text":"","title":"2.1.0 - 2018-01-08"},{"location":"apis/xss-secure/CHANGELOG/#added","text":"Node.js version 8 support. CHANGELOG.md","title":"Added"},{"location":"apis/xss-secure/CHANGELOG/#2011-2017-01-24","text":"","title":"2.0.11 - 2017-01-24"},{"location":"apis/xss-secure/CHANGELOG/#changed","text":"Rename package to use sap scope.","title":"Changed"},{"location":"apis/xss-secure/CHANGELOG/#2010-2017-01-23","text":"","title":"2.0.10 - 2017-01-23"},{"location":"apis/xss-secure/CHANGELOG/#changed_1","text":"Improvements in documentation.","title":"Changed"},{"location":"apis/xssec/","text":"@sap/xssec: XS Advanced Container Security API for node.js \u00b6 XS Advanced Authentication Primer \u00b6 Authentication for node applications in XS Advanced relies on a special usage of the OAuth 2.0 protocol, which is based on central authentication at the UAA server that then vouches for the authenticated user's identity via a so-called OAuth Access Token. The current implementation uses as access token a JSON web token (JWT), which is a signed text-based token following the JSON syntax. Normally, your node application will consist of several parts, that appear as separate applications in your manifest file, e.g. one application part that is responsible for the HANA database content, one application part for your application logic written e.g. in node.js (this is the one that can make use of this XS Advanced Container Security API for node.js), and finally one application part that is responsible for the UI layer (this is the one that may make use of the application router functionality). The latter two applications (the application logic in node.js and the application router) should be bound to one and the same UAA service instance. This has the effect, that these two parts can use the same OAuth client credentials. When your business users access your application UI with their broser, the application router redirects the browser to the UAA where your business users need to authenticate. After successful authentication, the UAA sends - again via the business user's browser - an OAuth authorization code back to the application router. Now the application router sends this authorization code directly (not via the browser) to the UAA to exchange it into an OAuth access token. If the access token is obtained successfully, the business user has logged on to the UI part of your application already. In order to enable your UI to pass this authentication on to the node.js application part, you need to ensure that the destination to your node.js application part is configured such that the access token is actually sent to the node.js part (\"forwardAuthToken\": true). In order to authenticate this request, which arrives at the node.js backend, sap-xssec offers two mechanisms: Firstly, you can use the XS Advanced Container Security API directly to validate the access token. Secondly, you can make use of the passport strategy that is contained in module sap-xssec as another convenient way how to handle the access token. In the following, both options are described followed by the sap-xssec API description. sap-xssec offers an offline validation of the access token, which requires no additional call to the UAA. The trust for this offline validation is created by binding the XS UAA service instance to your application. Inside the credentials section in the environment variable VCAP_SERVICES, the key for validation of tokens is included. By default, the offline validation check will only accept tokens intended for the same OAuth2 client in the same UAA identity zone. This makes sense and will cover the vast majority of use cases. If you want to enable another (foreign) application to use some of your application's scopes, you can add a granted-apps marker to your scope in the xs-security.json file (as in the following example). The value of the marker is a list of applications that is allowed to request a token with the denoted scope. { \"xsappname\" : \"sample-leave-request-app\" , \"description\" : \"This sample application demos leave requests\" , \"scopes\" : [ { \"name\" : \"$XSAPPNAME.createLR\" , \"description\" : \"create leave requests\" }, { \"name\" : \"$XSAPPNAME.approveLR\" , \"description\" : \"approve leave requests\" , \"granted-apps\" : [ \"MobileApprovals\" ] } ], \"attributes\" : [ { \"name\" : \"costcenter\" , \"description\" : \"costcenter\" , \"valueType\" : \"string\" } ], \"role-templates\" : [ { \"name\" : \"employee\" , \"description\" : \"Role for creating leave requests\" , \"scope-references\" : [ \"$XSAPPNAME.createLR\" , \"JobScheduler.scheduleJobs\" ], \"attribute-references\" : [ \"costcenter\" ] }, { \"name\" : \"manager\" , \"description\" : \"Role for creating and approving leave requests\" , \"scope-references\" : [ \"$XSAPPNAME.createLR\" , \"$XSAPPNAME.approveLR\" , \"JobScheduler.scheduleJobs\" ], \"attribute-references\" : [ \"costcenter\" ] } ] } Usage of the XS Advanced Container Security API in your node.js Application \u00b6 In order to use the capabilities of the XS Advanced container security API, add the module \"sap-xssec\" to the dependencies section of your application's package.json. To enable tracing, you can set the environment variable DEBUG as follows: DEBUG=xssec:* . Direct Usage with existing Access Token \u00b6 For the usage of the XS Advanced Container Security API it is necessary to pass a JWT token. If you have such a token, you may use the API as follows. The examples below rely on users and credentials that you should substitute with the ones in your context. The code below is based on version v0.0.9 (if you use another version, the coding might differ). The typical use case for calling this API lies from within a container when an HTTP request is received. In an authorization header (with keyword bearer ) an access token is contained already. You can remove the prefix bearer and pass the remaining string (just as in the following example as access_token ) to the API. xssec . createSecurityContext ( access_token , xsenv . getServices ({ xsuaa : { tag : 'xsuaa' }}). xsuaa , function ( error , securityContext ) { if ( error ) { console . log ( 'Security Context creation failed' ); return ; } console . log ( 'Security Context created successfully' ); }); Note that the example above uses module xsenv to retrieve the configuration of the default services (which are read from environment variable VCAP_SERVICES or if not set, from the default configuration file). However, it passes only the required uaa configuration to the method createSecurityContext . As default the UAA configuration is searched with tag xsuaa by xsenv . For details we refer to module @sap/xsenv. The xsenv documentation also helps if you want to provide the credentials from e.g. a user provided service. The creation function xssec.createSecurityContext is to be used for an end-user token (e.g. for grant_type password or grant_type authorization_code ) where user information is expected to be available within the token and thus within the security context. createSecurityContext also accepts a token of grant_type client_credentials . This leads to the creation of a limited SecurityContext where certain functions are not available. For more details please consult the API description below or your documentation. Usage with Passport Strategy \u00b6 If you use express and passport , you can easily plug a ready-made authentication strategy. var express = require ( 'express' ); var passport = require ( 'passport' ); var JWTStrategy = require ( '@sap/xssec' ). JWTStrategy ; var xsenv = require ( '@sap/xsenv' ); ... var app = express (); ... passport . use ( new JWTStrategy ( xsenv . getServices ({ xsuaa : { tag : 'xsuaa' }}). xsuaa )); app . use ( passport . initialize ()); app . use ( passport . authenticate ( 'JWT' , { session : false })); If JWT token is present in the request and it is successfully verified, following objects are created: * request.user - according to User Profile convention * id * name * givenName * familyName * emails [ { value: <email> } ] * request.authInfo - the Security Context If the client_credentials JWT token is present in the request and it is successfully verified, following objects are created: * request.user - empty object * request.authInfo - the Security Context Session \u00b6 It is recommended to disable the session as in the example above. In XSA each request comes with a JWT token so it is authenticated explicitly and identifies the user. If you still need the session, you can enable it but then you should also implement user serialization/deserialization and some sort of session persistency . Test Usage without having an Access Token \u00b6 For test purposes, you may retrieve the token for a certain user (whose credentials you know) from the UAA as in the following code-snippet. var http = require ( \"http\" ); var xssec = require ( \"@sap/xssec\" ); var xsenv = require ( '@sap/xsenv' ); var request = require ( 'request' ); var uaaService = xsenv . getServices ( { uaa : 'uaa' } ). uaa ; var testService = xsenv . getServices ( { test : { label : 'test' } } ). test ; process . env . XSAPPNAME = testService . test . xsappname ; var options = { url : uaaService . url + '/oauth/token?client_id=' + uaaService . clientid + '&grant_type=password&username=' + testService . userid + '&password=' + testService . usersecret }; request . get ( options , function ( error , response , body ) { if ( error || response . statusCode !== 200 ) { console . log ( 'Token request failed' ); return ; } var json = null ; try { json = JSON . parse ( body ); } catch ( e ) { return callback ( e ); } xssec . createSecurityContext ( json . access_token , uaaService , function ( error , securityContext ) { if ( error ) { console . log ( 'Security Context creation failed' ); return ; } console . log ( 'Security Context created successfully' ); }); } ). auth ( uaaService . clientid , uaaService . clientsecret , false ); Note that this example assumes additional test configuration in the file default-services.json . { \"uaa\" : { \"url\" : \"<UAA URL>\" , \"clientid\" : \"<your application's OAuth client id>\" , \"clientsecret\" : \"<your application's OAuth client secret>\" , \"xsappname\" : \"<your application's name>\" , \"identityzone\" : \"<desired UAA identity zone>\" , \"tags\" : [ \"xsuaa\" ], \"verificationkey\" : \"<verification key for offline validation>\" }, \"test\" : { \"userid\" : \"marissa\" , \"usersecret\" : \"koala\" } } Usage in Docker \u00b6 If you intend to use XS Advanced Container Security inside a Docker image make sure to use a base image other than alpine . The alpine base system is lacking needed symbols for system calls. API Description \u00b6 createSecurityContext \u00b6 This function creates the Security Context by validating the received access token against credentials put into the application's environment via the UAA service binding. Usually, the received token must be intended for the current application. More clearly, the OAuth client id in the access token needs to be equal to the OAuth client id of the application (from the application's environment). However, there are some use cases, when a \"foreign\" token could be accepted although it was not intended for the current application. If you want to enable other applications calling your application backend directly, you can specify in your xs-security.json file an access control list (ACL) entry and declare which OAuth client from which Identity Zone may call your backend. Parameters: access token ... the access token as received from UAA in the \"authorization Bearer\" HTTP header config ... a structure with mandatory elements url, clientid and clientsecret callback(error, securityContext) getLogonName \u00b6 not available for tokens of grant_type client_credentials , returns the logon name getGivenName \u00b6 not available for tokens of grant_type client_credentials , returns the given name getFamilyName \u00b6 not available for tokens of grant_type client_credentials , returns the family name getEmail \u00b6 not available for tokens of grant_type client_credentials , returns the email getUserName \u00b6 returns unique principal name of a user user/<origin>/<logon name> or client id that the access token has been issued for client/<client id> getUniquePrincipalName \u00b6 not available for tokens of grant_type client_credentials , returns unique principal name of a user. user/<origin>/<logon name> getOrigin \u00b6 returns the user origin. The origin is an alias that refers to a user store in which the user is persisted. For example, users that are authenticated by the UAA itself with a username/password combination have their origin set to the value uaa. checkLocalScope \u00b6 checks a scope that is published by the current application in the xs-security.json file. Parameters: scope ... the scope whose existence is checked against the available scopes of the current user. Here, no prefix is required. returns true if the scope is contained in the user's scopes, false otherwise checkScope \u00b6 checks a scope that is published by an application. Parameters: scope ... the scope whose existence is checked against the available scopes of the current user. Here, the prefix is required, thus the scope string is \"globally unique\". returns true if the scope is contained in the user's scopes, false otherwise getAppToken \u00b6 returns the token of the application that can be used e.g. for token forwarding to another app. getHdbToken \u00b6 returns a token that can be used for contacting the HANA database. If the token, that the security context has been instantiated with, is a foreign token (meaning that the OAuth client contained in the token and the OAuth client of the current application do not match), null is returned instead of a token. requestToken \u00b6 Requests a token based on the given type. The type can be constants.TYPE_USER_TOKEN or constants.TYPE_CLIENT_CREDENTIALS_TOKEN . Prerequisite for the former is that the requesting client has grant_type=user_token and that the current user token includes the scope uaa.user . serviceCredentials ... the credentials of the service as JSON object. The attributes clientid , clientsecret and url (UAA) are mandatory. Note that the subdomain of the url will be adapted to the subdomain of the application token if necessary. type ... allowed values are constants.TYPE_USER_TOKEN and constants.TYPE_CLIENT_CREDENTIALS_TOKEN additionalAttributes ... the attributes that should be included into the JWT token as JSON object (key-value list), e.g. {\"attr1\" : \"value1\", \"attr2\" : \"value2\"} cb(error, token) ... callback function hasAttributes \u00b6 not available for tokens of grant_type client_credentials . returns true if the token contains any xs user attributes, false otherwise. getAttribute \u00b6 not available for tokens of grant_type client_credentials . Parameters: name ... The name of the attribute that is requested. returns the attribute exactly as it is contained in the access token. If no attribute with the given name is contained in the access token, null is returned. If the token, that the security context has been instantiated with, is a foreign token (meaning that the OAuth client contained in the token and the OAuth client of the current application do not match), null is returned regardless of whether the requested attribute is contained in the token or not. getAdditionalAuthAttribute \u00b6 Parameters: name ... The name of the additional authentication attribute that is requested. returns the additional authentication attribute exactly as it is contained in the access token. If no attribute with the given name is contained in the access token, null is returned. Note that additional authentication attributes are also returned in foreign mode (in contrast to getAttribute). isInForeignMode \u00b6 returns true if the token, that the security context has been instantiated with, is a foreign token that was not originally issued for the current application, false otherwise. getSubdomain \u00b6 returns the subdomain that the access token has been issued for. getClientId \u00b6 returns the client id that the access token has been issued for. getSubaccountId \u00b6 returns the subaccount id that the access token has been issued for. getExpirationDate \u00b6 returns the expiration date of the access token as javascript Date object. getCloneServiceInstanceId \u00b6 returns the service instance id of the clone if the XSUAA broker plan is used. getGrantType \u00b6 returns the grant type of the JWT token, e.g. authorization_code , password , client_credentials or urn:ietf:params:oauth:grant-type:saml2-bearer . Latest published Version \u00b6 Use this command to check for the latest version that is published to the NPM repository: npm view --registry https://npm.sap.com @sap/xssec versions","title":"Index"},{"location":"apis/xssec/#sapxssec-xs-advanced-container-security-api-for-nodejs","text":"","title":"@sap/xssec: XS Advanced Container Security API for node.js"},{"location":"apis/xssec/#xs-advanced-authentication-primer","text":"Authentication for node applications in XS Advanced relies on a special usage of the OAuth 2.0 protocol, which is based on central authentication at the UAA server that then vouches for the authenticated user's identity via a so-called OAuth Access Token. The current implementation uses as access token a JSON web token (JWT), which is a signed text-based token following the JSON syntax. Normally, your node application will consist of several parts, that appear as separate applications in your manifest file, e.g. one application part that is responsible for the HANA database content, one application part for your application logic written e.g. in node.js (this is the one that can make use of this XS Advanced Container Security API for node.js), and finally one application part that is responsible for the UI layer (this is the one that may make use of the application router functionality). The latter two applications (the application logic in node.js and the application router) should be bound to one and the same UAA service instance. This has the effect, that these two parts can use the same OAuth client credentials. When your business users access your application UI with their broser, the application router redirects the browser to the UAA where your business users need to authenticate. After successful authentication, the UAA sends - again via the business user's browser - an OAuth authorization code back to the application router. Now the application router sends this authorization code directly (not via the browser) to the UAA to exchange it into an OAuth access token. If the access token is obtained successfully, the business user has logged on to the UI part of your application already. In order to enable your UI to pass this authentication on to the node.js application part, you need to ensure that the destination to your node.js application part is configured such that the access token is actually sent to the node.js part (\"forwardAuthToken\": true). In order to authenticate this request, which arrives at the node.js backend, sap-xssec offers two mechanisms: Firstly, you can use the XS Advanced Container Security API directly to validate the access token. Secondly, you can make use of the passport strategy that is contained in module sap-xssec as another convenient way how to handle the access token. In the following, both options are described followed by the sap-xssec API description. sap-xssec offers an offline validation of the access token, which requires no additional call to the UAA. The trust for this offline validation is created by binding the XS UAA service instance to your application. Inside the credentials section in the environment variable VCAP_SERVICES, the key for validation of tokens is included. By default, the offline validation check will only accept tokens intended for the same OAuth2 client in the same UAA identity zone. This makes sense and will cover the vast majority of use cases. If you want to enable another (foreign) application to use some of your application's scopes, you can add a granted-apps marker to your scope in the xs-security.json file (as in the following example). The value of the marker is a list of applications that is allowed to request a token with the denoted scope. { \"xsappname\" : \"sample-leave-request-app\" , \"description\" : \"This sample application demos leave requests\" , \"scopes\" : [ { \"name\" : \"$XSAPPNAME.createLR\" , \"description\" : \"create leave requests\" }, { \"name\" : \"$XSAPPNAME.approveLR\" , \"description\" : \"approve leave requests\" , \"granted-apps\" : [ \"MobileApprovals\" ] } ], \"attributes\" : [ { \"name\" : \"costcenter\" , \"description\" : \"costcenter\" , \"valueType\" : \"string\" } ], \"role-templates\" : [ { \"name\" : \"employee\" , \"description\" : \"Role for creating leave requests\" , \"scope-references\" : [ \"$XSAPPNAME.createLR\" , \"JobScheduler.scheduleJobs\" ], \"attribute-references\" : [ \"costcenter\" ] }, { \"name\" : \"manager\" , \"description\" : \"Role for creating and approving leave requests\" , \"scope-references\" : [ \"$XSAPPNAME.createLR\" , \"$XSAPPNAME.approveLR\" , \"JobScheduler.scheduleJobs\" ], \"attribute-references\" : [ \"costcenter\" ] } ] }","title":"XS Advanced Authentication Primer"},{"location":"apis/xssec/#usage-of-the-xs-advanced-container-security-api-in-your-nodejs-application","text":"In order to use the capabilities of the XS Advanced container security API, add the module \"sap-xssec\" to the dependencies section of your application's package.json. To enable tracing, you can set the environment variable DEBUG as follows: DEBUG=xssec:* .","title":"Usage of the XS Advanced Container Security API in your node.js Application"},{"location":"apis/xssec/#direct-usage-with-existing-access-token","text":"For the usage of the XS Advanced Container Security API it is necessary to pass a JWT token. If you have such a token, you may use the API as follows. The examples below rely on users and credentials that you should substitute with the ones in your context. The code below is based on version v0.0.9 (if you use another version, the coding might differ). The typical use case for calling this API lies from within a container when an HTTP request is received. In an authorization header (with keyword bearer ) an access token is contained already. You can remove the prefix bearer and pass the remaining string (just as in the following example as access_token ) to the API. xssec . createSecurityContext ( access_token , xsenv . getServices ({ xsuaa : { tag : 'xsuaa' }}). xsuaa , function ( error , securityContext ) { if ( error ) { console . log ( 'Security Context creation failed' ); return ; } console . log ( 'Security Context created successfully' ); }); Note that the example above uses module xsenv to retrieve the configuration of the default services (which are read from environment variable VCAP_SERVICES or if not set, from the default configuration file). However, it passes only the required uaa configuration to the method createSecurityContext . As default the UAA configuration is searched with tag xsuaa by xsenv . For details we refer to module @sap/xsenv. The xsenv documentation also helps if you want to provide the credentials from e.g. a user provided service. The creation function xssec.createSecurityContext is to be used for an end-user token (e.g. for grant_type password or grant_type authorization_code ) where user information is expected to be available within the token and thus within the security context. createSecurityContext also accepts a token of grant_type client_credentials . This leads to the creation of a limited SecurityContext where certain functions are not available. For more details please consult the API description below or your documentation.","title":"Direct Usage with existing Access Token"},{"location":"apis/xssec/#usage-with-passport-strategy","text":"If you use express and passport , you can easily plug a ready-made authentication strategy. var express = require ( 'express' ); var passport = require ( 'passport' ); var JWTStrategy = require ( '@sap/xssec' ). JWTStrategy ; var xsenv = require ( '@sap/xsenv' ); ... var app = express (); ... passport . use ( new JWTStrategy ( xsenv . getServices ({ xsuaa : { tag : 'xsuaa' }}). xsuaa )); app . use ( passport . initialize ()); app . use ( passport . authenticate ( 'JWT' , { session : false })); If JWT token is present in the request and it is successfully verified, following objects are created: * request.user - according to User Profile convention * id * name * givenName * familyName * emails [ { value: <email> } ] * request.authInfo - the Security Context If the client_credentials JWT token is present in the request and it is successfully verified, following objects are created: * request.user - empty object * request.authInfo - the Security Context","title":"Usage with Passport Strategy"},{"location":"apis/xssec/#session","text":"It is recommended to disable the session as in the example above. In XSA each request comes with a JWT token so it is authenticated explicitly and identifies the user. If you still need the session, you can enable it but then you should also implement user serialization/deserialization and some sort of session persistency .","title":"Session"},{"location":"apis/xssec/#test-usage-without-having-an-access-token","text":"For test purposes, you may retrieve the token for a certain user (whose credentials you know) from the UAA as in the following code-snippet. var http = require ( \"http\" ); var xssec = require ( \"@sap/xssec\" ); var xsenv = require ( '@sap/xsenv' ); var request = require ( 'request' ); var uaaService = xsenv . getServices ( { uaa : 'uaa' } ). uaa ; var testService = xsenv . getServices ( { test : { label : 'test' } } ). test ; process . env . XSAPPNAME = testService . test . xsappname ; var options = { url : uaaService . url + '/oauth/token?client_id=' + uaaService . clientid + '&grant_type=password&username=' + testService . userid + '&password=' + testService . usersecret }; request . get ( options , function ( error , response , body ) { if ( error || response . statusCode !== 200 ) { console . log ( 'Token request failed' ); return ; } var json = null ; try { json = JSON . parse ( body ); } catch ( e ) { return callback ( e ); } xssec . createSecurityContext ( json . access_token , uaaService , function ( error , securityContext ) { if ( error ) { console . log ( 'Security Context creation failed' ); return ; } console . log ( 'Security Context created successfully' ); }); } ). auth ( uaaService . clientid , uaaService . clientsecret , false ); Note that this example assumes additional test configuration in the file default-services.json . { \"uaa\" : { \"url\" : \"<UAA URL>\" , \"clientid\" : \"<your application's OAuth client id>\" , \"clientsecret\" : \"<your application's OAuth client secret>\" , \"xsappname\" : \"<your application's name>\" , \"identityzone\" : \"<desired UAA identity zone>\" , \"tags\" : [ \"xsuaa\" ], \"verificationkey\" : \"<verification key for offline validation>\" }, \"test\" : { \"userid\" : \"marissa\" , \"usersecret\" : \"koala\" } }","title":"Test Usage without having an Access Token"},{"location":"apis/xssec/#usage-in-docker","text":"If you intend to use XS Advanced Container Security inside a Docker image make sure to use a base image other than alpine . The alpine base system is lacking needed symbols for system calls.","title":"Usage in Docker"},{"location":"apis/xssec/#api-description","text":"","title":"API Description"},{"location":"apis/xssec/#createsecuritycontext","text":"This function creates the Security Context by validating the received access token against credentials put into the application's environment via the UAA service binding. Usually, the received token must be intended for the current application. More clearly, the OAuth client id in the access token needs to be equal to the OAuth client id of the application (from the application's environment). However, there are some use cases, when a \"foreign\" token could be accepted although it was not intended for the current application. If you want to enable other applications calling your application backend directly, you can specify in your xs-security.json file an access control list (ACL) entry and declare which OAuth client from which Identity Zone may call your backend. Parameters: access token ... the access token as received from UAA in the \"authorization Bearer\" HTTP header config ... a structure with mandatory elements url, clientid and clientsecret callback(error, securityContext)","title":"createSecurityContext"},{"location":"apis/xssec/#getlogonname","text":"not available for tokens of grant_type client_credentials , returns the logon name","title":"getLogonName"},{"location":"apis/xssec/#getgivenname","text":"not available for tokens of grant_type client_credentials , returns the given name","title":"getGivenName"},{"location":"apis/xssec/#getfamilyname","text":"not available for tokens of grant_type client_credentials , returns the family name","title":"getFamilyName"},{"location":"apis/xssec/#getemail","text":"not available for tokens of grant_type client_credentials , returns the email","title":"getEmail"},{"location":"apis/xssec/#getusername","text":"returns unique principal name of a user user/<origin>/<logon name> or client id that the access token has been issued for client/<client id>","title":"getUserName"},{"location":"apis/xssec/#getuniqueprincipalname","text":"not available for tokens of grant_type client_credentials , returns unique principal name of a user. user/<origin>/<logon name>","title":"getUniquePrincipalName"},{"location":"apis/xssec/#getorigin","text":"returns the user origin. The origin is an alias that refers to a user store in which the user is persisted. For example, users that are authenticated by the UAA itself with a username/password combination have their origin set to the value uaa.","title":"getOrigin"},{"location":"apis/xssec/#checklocalscope","text":"checks a scope that is published by the current application in the xs-security.json file. Parameters: scope ... the scope whose existence is checked against the available scopes of the current user. Here, no prefix is required. returns true if the scope is contained in the user's scopes, false otherwise","title":"checkLocalScope"},{"location":"apis/xssec/#checkscope","text":"checks a scope that is published by an application. Parameters: scope ... the scope whose existence is checked against the available scopes of the current user. Here, the prefix is required, thus the scope string is \"globally unique\". returns true if the scope is contained in the user's scopes, false otherwise","title":"checkScope"},{"location":"apis/xssec/#getapptoken","text":"returns the token of the application that can be used e.g. for token forwarding to another app.","title":"getAppToken"},{"location":"apis/xssec/#gethdbtoken","text":"returns a token that can be used for contacting the HANA database. If the token, that the security context has been instantiated with, is a foreign token (meaning that the OAuth client contained in the token and the OAuth client of the current application do not match), null is returned instead of a token.","title":"getHdbToken"},{"location":"apis/xssec/#requesttoken","text":"Requests a token based on the given type. The type can be constants.TYPE_USER_TOKEN or constants.TYPE_CLIENT_CREDENTIALS_TOKEN . Prerequisite for the former is that the requesting client has grant_type=user_token and that the current user token includes the scope uaa.user . serviceCredentials ... the credentials of the service as JSON object. The attributes clientid , clientsecret and url (UAA) are mandatory. Note that the subdomain of the url will be adapted to the subdomain of the application token if necessary. type ... allowed values are constants.TYPE_USER_TOKEN and constants.TYPE_CLIENT_CREDENTIALS_TOKEN additionalAttributes ... the attributes that should be included into the JWT token as JSON object (key-value list), e.g. {\"attr1\" : \"value1\", \"attr2\" : \"value2\"} cb(error, token) ... callback function","title":"requestToken"},{"location":"apis/xssec/#hasattributes","text":"not available for tokens of grant_type client_credentials . returns true if the token contains any xs user attributes, false otherwise.","title":"hasAttributes"},{"location":"apis/xssec/#getattribute","text":"not available for tokens of grant_type client_credentials . Parameters: name ... The name of the attribute that is requested. returns the attribute exactly as it is contained in the access token. If no attribute with the given name is contained in the access token, null is returned. If the token, that the security context has been instantiated with, is a foreign token (meaning that the OAuth client contained in the token and the OAuth client of the current application do not match), null is returned regardless of whether the requested attribute is contained in the token or not.","title":"getAttribute"},{"location":"apis/xssec/#getadditionalauthattribute","text":"Parameters: name ... The name of the additional authentication attribute that is requested. returns the additional authentication attribute exactly as it is contained in the access token. If no attribute with the given name is contained in the access token, null is returned. Note that additional authentication attributes are also returned in foreign mode (in contrast to getAttribute).","title":"getAdditionalAuthAttribute"},{"location":"apis/xssec/#isinforeignmode","text":"returns true if the token, that the security context has been instantiated with, is a foreign token that was not originally issued for the current application, false otherwise.","title":"isInForeignMode"},{"location":"apis/xssec/#getsubdomain","text":"returns the subdomain that the access token has been issued for.","title":"getSubdomain"},{"location":"apis/xssec/#getclientid","text":"returns the client id that the access token has been issued for.","title":"getClientId"},{"location":"apis/xssec/#getsubaccountid","text":"returns the subaccount id that the access token has been issued for.","title":"getSubaccountId"},{"location":"apis/xssec/#getexpirationdate","text":"returns the expiration date of the access token as javascript Date object.","title":"getExpirationDate"},{"location":"apis/xssec/#getcloneserviceinstanceid","text":"returns the service instance id of the clone if the XSUAA broker plan is used.","title":"getCloneServiceInstanceId"},{"location":"apis/xssec/#getgranttype","text":"returns the grant type of the JWT token, e.g. authorization_code , password , client_credentials or urn:ietf:params:oauth:grant-type:saml2-bearer .","title":"getGrantType"},{"location":"apis/xssec/#latest-published-version","text":"Use this command to check for the latest version that is published to the NPM repository: npm view --registry https://npm.sap.com @sap/xssec versions","title":"Latest published Version"},{"location":"apis/xssec/CHANGELOG/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. 3.0.3 - 2020-05-25 \u00b6 Fix jwt-bearer flow to take the right token as uri parameter. 3.0.2 - 2020-05-20 \u00b6 Fix get verification key from keycache. 3.0.1 - 2020-05-19 \u00b6 HotFix missing debugTrace in verification key Fix RetryStrategy 3.0.0 - 2020-05-15 \u00b6 Replace grant type user_token in method requestToken (TYPE_USER_TOKEN) in favor of urn:ietf:params:oauth:grant-type:jwt-bearer Remove obsolete method getToken (use getHdbToken or getAppToken)) Remove obsolete method requestTokenForClient (use requestToken) Remove obsolete method getIdentityZone (getSubaccountId) Support for audience validation in token remove of SAP_JWT_TRUST_ACL environment variable support (functionality now comes with audience validation) remove depencency to node-jwt (ALPINE support) restructure internal code for better maintainability 2.2.5 - 2020-02-28 \u00b6 Update to node-jwt version 1.6.6 2.2.4 - 2019-08-14 \u00b6 Support for API methods getUserName and getUniquePrincipalName 2.2.3 - 2019-08-07 \u00b6 Add retry for recieving keys 2.2.2 - 2019-06-24 \u00b6 Use verification key from binding as backup if online key retrieval fails 2.2.1 - 2019-06-17 \u00b6 Fix uaaDomain comparison in key cache 2.2.0 - 2019-06-17 \u00b6 Align key cache implementation with other container security libraries 2.1.17 - 2019-05-17 \u00b6 Introduce http timeout of two seconds Update version of module debug, lru-cache and @sap/xsenv Fix token verification for broker master instance subscriptions 2.1.16 - 2019-01-28 \u00b6 Fix token parser: switch ASCII to Utf8 decode 2.1.15 - 2018-08-13 \u00b6 Update version of module request 2.1.14 - 2018-07-24 \u00b6 Evaluate SAP_JWT_TRUST_ACL if trustedclientidsuffix is present but not matching 2.1.13 - 2018-07-18 \u00b6 Update version of module request 2.1.12 - 2018-06-01 \u00b6 Support for API methods getSubaccountId and getOrigin Mark API method getIdentityZone as deprecated 2.1.11 - 2018-05-18 \u00b6 Update version of module request 2.1.10 - 2018-04-20 \u00b6 Fixes for keycache 2.1.9 - 2018-04-18 \u00b6 Update version of module @sap/node-jwt (1.4.8) Fixes for keycache Update version of module request 2.1.8 - 2018-03-14 \u00b6 Support for API method getAppToken 2.1.7 - 2018-03-05 \u00b6 Support for API method requestToken 2.1.6 - 2018-02-19 \u00b6 Update version of module @sap/node-jwt 2.1.5 - 2018-02-07 \u00b6 Update version of module request 2.1.4 - 2017-12-04 \u00b6 Support new JWT structure (attribute location ext_cxt) First implementation for keycache 2.1.3 - 2017-11-29 \u00b6 Support for API method getClientId 2.1.2 - 2017-10-23 \u00b6 Support for API method getSubdomain 2.1.1 - 2017-10-09 \u00b6 Update version of modules @sap/node-jwt, @sap/xsenv and debug 2.1.0 - 2017-07-06 \u00b6 Support of API method requestTokenForClient Update version of module @sap/node-jwt 2.0.0 - 2017-06-26 \u00b6 Removal of deprecated constructor method createSecurityContextCc Removal of API method method getUserInfo 1.3.0 - 2017-06-23 \u00b6 Revert removal of API method method getUserInfo 1.2.0 - 2017-06-22 \u00b6 Support for API methods getLogonName, getGivenName, getFamilyName, getEmail Removal of API method method getUserInfo Fix identity zone validation (only relevant for tenants created with SAP Cloud Cockpit) 1.1.1 - 2017-05-30 \u00b6 Update version of dependent modules 1.1.0 - 2017-05-22 \u00b6 Mark API method createSecurityContextCC as deprecated 1.0.4 - 2017-05-17 \u00b6 Support for validation of XSUAA broker plan tokens Support for API methods getCloneServiceInstanceId and getAdditionalAuthAttribute Support for validation of XSUAA application plan tokens in arbitrary identity zones 1.0.3 - 2017-03-29 \u00b6 Update version of dependent modules 1.0.2 - 2017-02-22 \u00b6 Support for validation of SAML Bearer tokens 1.0.1 - 2017-02-02 \u00b6 Support for client credentials tokens in JWT strategy 1.0.0 - 2017-01-25 \u00b6 Introduction of scopeing, module name changed to @sap/xssec","title":"Change Log"},{"location":"apis/xssec/CHANGELOG/#change-log","text":"All notable changes to this project will be documented in this file.","title":"Change Log"},{"location":"apis/xssec/CHANGELOG/#303-2020-05-25","text":"Fix jwt-bearer flow to take the right token as uri parameter.","title":"3.0.3 - 2020-05-25"},{"location":"apis/xssec/CHANGELOG/#302-2020-05-20","text":"Fix get verification key from keycache.","title":"3.0.2 - 2020-05-20"},{"location":"apis/xssec/CHANGELOG/#301-2020-05-19","text":"HotFix missing debugTrace in verification key Fix RetryStrategy","title":"3.0.1 - 2020-05-19"},{"location":"apis/xssec/CHANGELOG/#300-2020-05-15","text":"Replace grant type user_token in method requestToken (TYPE_USER_TOKEN) in favor of urn:ietf:params:oauth:grant-type:jwt-bearer Remove obsolete method getToken (use getHdbToken or getAppToken)) Remove obsolete method requestTokenForClient (use requestToken) Remove obsolete method getIdentityZone (getSubaccountId) Support for audience validation in token remove of SAP_JWT_TRUST_ACL environment variable support (functionality now comes with audience validation) remove depencency to node-jwt (ALPINE support) restructure internal code for better maintainability","title":"3.0.0 - 2020-05-15"},{"location":"apis/xssec/CHANGELOG/#225-2020-02-28","text":"Update to node-jwt version 1.6.6","title":"2.2.5 - 2020-02-28"},{"location":"apis/xssec/CHANGELOG/#224-2019-08-14","text":"Support for API methods getUserName and getUniquePrincipalName","title":"2.2.4 - 2019-08-14"},{"location":"apis/xssec/CHANGELOG/#223-2019-08-07","text":"Add retry for recieving keys","title":"2.2.3 - 2019-08-07"},{"location":"apis/xssec/CHANGELOG/#222-2019-06-24","text":"Use verification key from binding as backup if online key retrieval fails","title":"2.2.2 - 2019-06-24"},{"location":"apis/xssec/CHANGELOG/#221-2019-06-17","text":"Fix uaaDomain comparison in key cache","title":"2.2.1 - 2019-06-17"},{"location":"apis/xssec/CHANGELOG/#220-2019-06-17","text":"Align key cache implementation with other container security libraries","title":"2.2.0 - 2019-06-17"},{"location":"apis/xssec/CHANGELOG/#2117-2019-05-17","text":"Introduce http timeout of two seconds Update version of module debug, lru-cache and @sap/xsenv Fix token verification for broker master instance subscriptions","title":"2.1.17 - 2019-05-17"},{"location":"apis/xssec/CHANGELOG/#2116-2019-01-28","text":"Fix token parser: switch ASCII to Utf8 decode","title":"2.1.16 - 2019-01-28"},{"location":"apis/xssec/CHANGELOG/#2115-2018-08-13","text":"Update version of module request","title":"2.1.15 - 2018-08-13"},{"location":"apis/xssec/CHANGELOG/#2114-2018-07-24","text":"Evaluate SAP_JWT_TRUST_ACL if trustedclientidsuffix is present but not matching","title":"2.1.14 - 2018-07-24"},{"location":"apis/xssec/CHANGELOG/#2113-2018-07-18","text":"Update version of module request","title":"2.1.13 - 2018-07-18"},{"location":"apis/xssec/CHANGELOG/#2112-2018-06-01","text":"Support for API methods getSubaccountId and getOrigin Mark API method getIdentityZone as deprecated","title":"2.1.12 - 2018-06-01"},{"location":"apis/xssec/CHANGELOG/#2111-2018-05-18","text":"Update version of module request","title":"2.1.11 - 2018-05-18"},{"location":"apis/xssec/CHANGELOG/#2110-2018-04-20","text":"Fixes for keycache","title":"2.1.10 - 2018-04-20"},{"location":"apis/xssec/CHANGELOG/#219-2018-04-18","text":"Update version of module @sap/node-jwt (1.4.8) Fixes for keycache Update version of module request","title":"2.1.9 - 2018-04-18"},{"location":"apis/xssec/CHANGELOG/#218-2018-03-14","text":"Support for API method getAppToken","title":"2.1.8 - 2018-03-14"},{"location":"apis/xssec/CHANGELOG/#217-2018-03-05","text":"Support for API method requestToken","title":"2.1.7 - 2018-03-05"},{"location":"apis/xssec/CHANGELOG/#216-2018-02-19","text":"Update version of module @sap/node-jwt","title":"2.1.6 - 2018-02-19"},{"location":"apis/xssec/CHANGELOG/#215-2018-02-07","text":"Update version of module request","title":"2.1.5 - 2018-02-07"},{"location":"apis/xssec/CHANGELOG/#214-2017-12-04","text":"Support new JWT structure (attribute location ext_cxt) First implementation for keycache","title":"2.1.4 - 2017-12-04"},{"location":"apis/xssec/CHANGELOG/#213-2017-11-29","text":"Support for API method getClientId","title":"2.1.3 - 2017-11-29"},{"location":"apis/xssec/CHANGELOG/#212-2017-10-23","text":"Support for API method getSubdomain","title":"2.1.2 - 2017-10-23"},{"location":"apis/xssec/CHANGELOG/#211-2017-10-09","text":"Update version of modules @sap/node-jwt, @sap/xsenv and debug","title":"2.1.1 - 2017-10-09"},{"location":"apis/xssec/CHANGELOG/#210-2017-07-06","text":"Support of API method requestTokenForClient Update version of module @sap/node-jwt","title":"2.1.0 - 2017-07-06"},{"location":"apis/xssec/CHANGELOG/#200-2017-06-26","text":"Removal of deprecated constructor method createSecurityContextCc Removal of API method method getUserInfo","title":"2.0.0 - 2017-06-26"},{"location":"apis/xssec/CHANGELOG/#130-2017-06-23","text":"Revert removal of API method method getUserInfo","title":"1.3.0 - 2017-06-23"},{"location":"apis/xssec/CHANGELOG/#120-2017-06-22","text":"Support for API methods getLogonName, getGivenName, getFamilyName, getEmail Removal of API method method getUserInfo Fix identity zone validation (only relevant for tenants created with SAP Cloud Cockpit)","title":"1.2.0 - 2017-06-22"},{"location":"apis/xssec/CHANGELOG/#111-2017-05-30","text":"Update version of dependent modules","title":"1.1.1 - 2017-05-30"},{"location":"apis/xssec/CHANGELOG/#110-2017-05-22","text":"Mark API method createSecurityContextCC as deprecated","title":"1.1.0 - 2017-05-22"},{"location":"apis/xssec/CHANGELOG/#104-2017-05-17","text":"Support for validation of XSUAA broker plan tokens Support for API methods getCloneServiceInstanceId and getAdditionalAuthAttribute Support for validation of XSUAA application plan tokens in arbitrary identity zones","title":"1.0.4 - 2017-05-17"},{"location":"apis/xssec/CHANGELOG/#103-2017-03-29","text":"Update version of dependent modules","title":"1.0.3 - 2017-03-29"},{"location":"apis/xssec/CHANGELOG/#102-2017-02-22","text":"Support for validation of SAML Bearer tokens","title":"1.0.2 - 2017-02-22"},{"location":"apis/xssec/CHANGELOG/#101-2017-02-02","text":"Support for client credentials tokens in JWT strategy","title":"1.0.1 - 2017-02-02"},{"location":"apis/xssec/CHANGELOG/#100-2017-01-25","text":"Introduction of scopeing, module name changed to @sap/xssec","title":"1.0.0 - 2017-01-25"}]}